Title: Impact of the “when the fun stops, stop” gambling message on online gambling behaviour: a randomised, online experimental study


Abstract: Summary


Abstract_Section: Background

Safer gambling messages are a common freedom-preserving method of protecting individuals from gambling-related harm. Yet, there is little independent and rigorous evidence assessing the effectiveness of safer gambling messages. In our study, we aimed to test the effect of the historically most commonly-used UK safer gambling message on concurrent gambling behaviour of people who gamble in the UK.

Abstract_Section: Methods

In this study, three preregistered, incentivised, and randomised online experiments, testing the UK's “when the fun stops, stop” message, were carried out via the crowdsourcing platform Prolific. Adults based in the UK who had previously participated in the gambling activities relevant to each experiment were eligible to participate. Experiments 1 and 3 involved bets on real soccer events, and experiment 2 used a commercially available online roulette game. Safer gambling message presence was varied between participants in each experiment. In experiment 2, exposed participants could be shown either a yellow or a black-and-white version of the safer gambling message. Participants were provided with a monetary endowment with which they were allowed to bet. Any of this money not bet was afterwards paid to participants as a bonus, in addition to the payouts from any winning bets. In experiment 2 participants had the opportunity to re-wager any winnings from the roulette game. The primary outcome in experiment 1 was participants’ decisions to accept (or reject) a series of football bets, which varied in their specificity (and payoffs), and the primary outcomes of experiments 2 and 3 were the proportion of available funds bet, which were defined as the total amount of money bet by a participant out of the total that could have been bet.

Abstract_Section: Findings

Participants for all three experiments were recruited between May 17, 2019, and Oct 17, 2020. Of the 506 participants in experiment 1, 41·3% of available bets were made by the 254 participants in the gambling message condition, which was not significantly different (p=0·15, odds ratio 1·22 [95% CI 0·93 to 1·61]) to the 37·8% of available bets made by the 252 participants in the control condition. In experiment 2, the only credible difference between conditions was that the 501 participants in the condition with the yellow version of the gambling message bet 3·64% (95% Bayesian credibility interval 0·00% to 7·27%) more of available funds left over than the 499 participants in the control condition. There were no credible differences between the bets made by the 500 participants in the black-and-white gambling message condition and the other conditions. In experiment 3, there were no credible differences between the 502 participants in the gambling message condition and the 501 participants in the control condition, with the largest effect being a 5·87% (95% Bayesian credibility interval –1·44% to 13·20%) increase in the probability of betting everything in the gambling message condition.

Abstract_Section: Interpretation

In our study, no evidence was found for a protective effect of the most common UK safer gambling message. Alternative interventions should be considered as part of an evidence-based public health approach to reducing gambling-related harm.

Abstract_Section: Funding

University of Warwick, British Academy and Leverhume, Swiss National Science Foundation.

Section: Introduction

The UK has the world's largest regulated online gambling market. Gambling can lead to negative outcomes with financial losses potentially contributing to a range of negative outcomes across financial, social, and health domains. Consequently, a key issue for gambling regulators is the trade-off between making gambling products freely available and protecting consumers’ welfare, especially those who are most vulnerable. In 2019, the UK's Gambling Commission announced a new National Strategy to Reduce Gambling Harms. With its focus on prevention and education, the strategy set out a requirement that operators use gambling messages to promote safer gambling behaviours, both at point of sale and as part of broader, population-based campaigns. In addition, the strategy stressed the importance of rigorous empirical evaluation of safer gambling intervention, with a preference towards independent appraisal (ie, not funded by gambling operators). In a similar vein, the UK government issued a call for evidence to review the effectiveness of mandatory safer gambling messages in adverts to prevent harm. Yet there is little evidence to help address these questions.

From 2014 until at least October, 2021, “when the fun stops, stop” was the most common UK gambling message , which depicted the phrase "when the fun stops, stop" in captilised letters against a yellow background. In the main versions of the message, the word fun is shown in a larger font, and the second mention of the word stop is shown inside a stop traffic road sign. This type of message can be encountered on television, in print, online, and in bookmakers’ shop windows. Similar messages are also used in other jurisdictions: the Nevada Council on Problem Gambling has trademarked the slogan “when the fun stops”, NSW Lotteries in Australia uses the message “have fun & play responsibly”, and the provincial monopoly gambling provider in Ontario, Canada, has a “PlaySmart” campaign that tells people who gamble to “keep the fun in the game”. Despite their prominence across different jurisdictions, to the best of our knowledge, there is no independent evidence that these gambling messages influence gambling behaviours in their intended ways.
Despite the growing pressure to consider gambling a public health issue, little justification for the use of the “when the fun stops, stop” message exists. Moreover, this particular slogan has been criticised by some political leaders and regulatory leaders. One common observation is the emphasis that most versions of the message place on the word “fun”. The only previous empirical evaluation of the message was funded by the group that devised the message. In a self-report survey (n=2001), 19% of participants responded yes to the item that the message “Led me to warn other people about their gambling, if only jokingly”. This result, however, is based on a self-report measure and not a behavioural outcome.
To better assess the effect of this gambling message, we aimed to conduct three preregistered, incentivised online experiments on large samples of people who gamble in the UK to compare the effects of multiple versions of the “when the fun stops, stop” message. The null hypothesis was that the presence of a gambling message would have no effect on gambling behaviour. To test this hypothesis, safer gambling message presence was randomly assigned to participants who were provided with an opportunity to bet money on games of chance.

Section: Methods

The study included three online experiments, in which participants could gamble real money on the results of either football matches (experiments 1 and 3) or a virtual roulette wheel (experiment 2), and in conditions designed to emulate real-life online gambling scenarios. Each of the three randomised, online experiments were preregistered. Anonymised data, analysis code and output, materials, and the preregistration documents can be accessed from the Open science Framework (OSF) repository. Participants were paid a fee of £0·50 to partake in experiment 1, £2·50 to partake in experiment 2, and £1·50 to partake in experiment 3. These payments were made to participants for completing the task, independent of any bets that they made. In addition, participants were endowed with a bonus that could be used in the gambling task in each experiment. In experiment 1, all participants were endowed with £0·90, whereas in experiments 2 and 3, only participants who correctly completed the transcription of seven or more captcha codes at the start of the experiment earned the endowment of £3 and could proceed to the experimental task ( appendix pp 6–8 ). Those who failed the captcha test were paid the participation fee and had the task terminated without being randomised to the experimental condition. The goal of this step in experiments 2 and 3 was to make sure that participants earned and felt ownership over their endowments. The captcha task also served a purpose of screening-out inattentive participants. These endowment values and the subsequent potential payouts in the experiments were designed to be in line with typical online bet sizes and payouts seen in the real world.
Participants were informed about the gambling content of each study and could choose to keep their original endowments and not to gamble. Each study received ethical approval from the University of Warwick's Humanities and Social Sciences Research Ethics Committee.
CONSORT flowcharts are shown for experiments 1 ( figure 1 ), 2 ( figure 2 ), and 3 ( figure 3 ). Participants were recruited and paid via the crowdsourcing platform Prolific. Participants were living in the UK and had, in the case of experiments 1 and 3, indicated previous experience in online sports betting. Participants in experiment 1 also previously reported an interest in UK Premier League football on Prolific. To achieve the target sample size for experiment 3, we expanded the eligibility criteria in the last day of data capture, collecting data from 48 participants (5% of total) who had indicated previous experience in any sort of online gambling. In experiment 2, eligible participants indicated previous experience in playing online roulette. 500 participants were not eligible as they were recruited for an earlier version that did not mention that any bonuses earned could be wagered on a roulette game. Participants were prevented from taking part in both experiment 2 and experiment 3, but participants from experiment 1 could have taken part in one of the two remaining experiments
Experiment 1's sample size was justified via a simulation-based power analysis, which used a generalised linear mixed model (GLMM) with a binomial family, indicating that the experiment had a minimum power of 80% to detect a difference in probability of accepting the bet of roughly 6% (the further away the average probability of accepting the bet was from 50%, the larger the power to detect an effect of 6% difference). Because these were the first experiments to use the gambling tasks used in experiments 2 and 3, we did not have the necessary information (eg, an estimate of the precision of the beta distribution) to run sensible a priori power analyses. Instead, the sample size was set to exceed the 322 participants per group required to detect a small effect size with a power of 0·8 using a traditional ANOVA model. As our funds allowed us to collect around 500 participants per condition, we opted to do so. Digital consent was obtained from each participant by clicking a relevant button in their browser.
Participants were randomly assigned online to the different conditions via JavaScript running locally on each individual's computer. Participants in the gambling message conditions clearly saw “when the fun stops, stop” gambling messages throughout the study, whereas participants in the no-message condition did not see any gambling messages throughout. Thus, participants could not be masked to which message condition they were in. However, participants were unaware that the other message conditions existed. The studies were conducted online with no contact between the research team and the participants. Thus, the research team can be considered as masked in relation to outcome assessments. Allocation to conditions were not masked to the researcher (HS) doing the statistical analyses.
In each experiment, participants were randomly allocated (1:1) to parallel groups that completed the gambling task with or without a safer gambling message. The treatment group in experiment 1 included the yellow gambling message. Experiments 2 and 3 used a more recent version of the gambling message. Finally, experiment 2 also included a third treatment group in which participants were presented with the black-and-white gambling message with the de-emphasised word “fun”. In experiment 1, we also varied the specificity of the described football bets (ie, low, medium, and high; appendix p 8).
Experiment 2 was based on a commercially available online roulette game that we purchased ( appendix p 11 ). In experiment 3, participants could browse and bet on the odds of 921 unique bets distributed across the upcoming round of ten English Premier League football matches that were collected from a large online UK betting operator's website ( appendix p 28 ). Participants could browse these bets and their odds across ten unique pages, calculate potential payouts of bets from different sizes, and confirm their selection before checking out, similarly to when betting on football on gambling operators’ websites. All payments were made on the basis of participants’ choices and any bets placed were paid according to random outcomes of the roulette wheel or actual football match results.
In experiment 1, participants were presented with a random order of nine mock gambling adverts (three each at low, medium, and high levels of specificity), which in the UK can be seen on TV displaying the odds for specific bets, such as “Manchester City to win 4–1. Win £1·70”. All bets were based on the upcoming 2019 Football Association cup final between Manchester City and Watford, the highest-profile match of the domestic football calendar. Payoff sizes were modelled on the total payoff based on a bet of £0·10 from available betting odds from a major gambling operator's website, and participants received all bonuses the day after the match. The text of each bet and the corresponding potential payoff were taken from a major gambling operator's website ( appendix pp 6–8 ). Safer gambling message presence was manipulated between participants. After making an accept versus reject decision for the nine bets presented to them, participants self-reported demographics and completed the Problem Gambling Severity Index (PGSI).
In experiment 2, participants who successfully completed at least seven captcha tasks and earned exactly £3 proceeded to the roulette game. For participants in the treatment condition, gambling messages were present on the screen while participants learned about the game and while they placed any bets on the roulette. Participants could play as many spins of roulette as they wanted, with no time limit on game play, by betting between £0·10 and £1 per spin using one or more betting chips of different values. The game was a realistic version of online roulette, programmed in JavaScript ( appendix pp 10–12 ). The winning number was randomly generated by the server at each spin. Participants could chose to check out of the roulette game at any point that they wanted, with the exception that any participant who managed to reach a balance of zero (meaning that they had lost everything) or more than £90 were moved on from the roulette game. After the roulette game, participants completed the PGSI and the enhancement motives subscale of the Gambling Motives Questionnaire (GMQ).
The procedure of experiment 3 closely resembled that of experiment 2, with the exception that participants could place bets on a selection of football matches on a bespoke football gambling platform programmed in Python using oTree (version 2.1.28; appendix pp 26–28). After successfully transcribing captchas, participants were informed that they could use their £3 bonus to place bets on the upcoming fixture for each of the English Premier League's 20 clubs. The message in the treatment group was displayed on top of each screen of the betting platform.
The betting platform started with pop-up instructions on how to place bets. After reading the instructions, participants could place up to £3 in bets, or they could proceed without placing any bets. Participants could bet on ten different matches, and within each match they could choose between an average of 40 unique bets across three subcategories: winning team, exact score, and first goal-scorer. The payments for all bets were calculated on the basis of the outcomes of the matches. All bonuses were paid after all the matches had been played, including any amounts that were not bet, to ensure there was no time-discounting benefit to not placing a bet (ie, all unbet bonuses and winning bets were paid at the same time to eliminate any advantages from not placing a bet).
To ensure that all odds were ecologically valid, the odds for each individual bet were extracted from a leading high-street bookmaker's website on Oct 13, 2020, with data collection proceeding until noon on Oct 17, 2020. A full description of the bets and their odds can be found on the OSF repository. Bet amounts started at £0·01 and could change in that increment. Potential payouts were calculated automatically and shown to participants according to the odds and the amount that they wanted to bet. Participants could review and edit their bet slip until they pressed on the “Continue” button, which saved and submitted their bets. Upon submitting their bet slip, participants completed the PGSI measure and the enhancement motives subscale of the GMQ.
The primary outcome in experiment 1 was participants’ decisions to accept (or reject) a series of football bets, which varied in their specificity (and payoffs). Experiment 2 and 3's main outcome measure was the proportion of available funds bet, which was defined as the total amount of money bet by a participant out of the total that could have been bet. This proportion bet ranged from 0 (ie, no money bet) to 1 (ie, all money bet).
As per the preregistration, the analysis of data from experiment 1 involved running a series of GLMMs with binomial family and logistic link function. These models included fixed effects of condition and specificity, as well as by-participant random-intercepts ( appendix p 9 ). Results of different preregistered variants of the models can be accessed on the OSF, but these all yielded similar results. A Bayesian analysis similar to the ones preregistered for experiments 2 and 3 (reported on OSF) also showed the same pattern of results.
In experiments 2 and 3, the statistical analysis was done using a preregistered zero-one-inflated beta regression (ZOIBR) model, which was implemented in a Bayesian statistical framework using the brms R package (version 2.13.0; appendix pp 13–14). The ZOIBR model was preregistered due to the anticipated tri-modal distribution of proportion bet. The data exhibited such a clearly non-normal distribution—one mode for participants who bet nothing, one mode for participants who bet everything, and one unimodal distribution for the remaining participants—which the ZOIBR model was able to adequately account for ( appendix p 15 ). Consequently, we did not diverge from the plan stated in the preregistration and did not use other analysis approaches. The ZOIBR model allowed us to test three patterns for each gambling message: (RQ1) whether the gambling message affected the likelihood of whether a participant gambled; (RQ2) whether, if the participant gambled, the gambling message affected the conditional probability of gambling everything; and (RQ3) whether the gambling message affected the conditional mean proportion bet, if participants gambled, but did not bet everything.
The funders of the study had no role in study design, data collection, data analysis, data interpretation, or writing of the report.

Section: Results

In experiment 1, 506 unique participants took part (252 [49·8%] in the control condition and 254 [50·2%] in the gambling message condition). The median age of participants was 34 years (mean age 36 years), 168 (33·2%) of whom were women. The average completion time was 4·4 min, and the average bet payout was £0·68 (range 0·1–0·9). This sum was added to the fixed payment of £0·50, resulting in an equivalent pay rate of £9 per hour. 56 (11%) participants declined to place any bets, thereby keeping their entire £0·90 endowment as a bonus.
Participants chose to place a bet more often in the condition in which the message was present (944 [41·3%] of 2286 total bets) than in the control condition (857 [37·8%] of 2268 total bets). Following our preregistered analysis plan, we reported results from the GLMM with binomial family and logistic link function with by-participant random intercepts and no further random-effects terms. This model was chosen because it was the first to converge without producing a singular fit. We began with the model with the maximal random-effect structure justified by the design (which produced a singular fit) and then iteratively reduced the random-effect structure until a model without singular fit was found. Predicted bet probabilities from this model were 38·8% (95% CI 34·4–43·4) for the gambling message condition and 34·1% (29·9–38·6) for the control condition, indicating that the model adequately described the observed data. Results of preregistered models with different fixed-effects and random-effects structures showed the same pattern of significant results, with only small numerical differences to the results reported here ( appendix p 9 )
The mild increase in willingness to place a bet following the gambling message label was not significant; χ 2 (1)=2·10, p=0·15 (the χ 2 -value represents the difference in the log-likelihood between the full model and the model without a condition fixed effect). This value corresponds to an effect size (odds ratio; OR) of 1·22 (95% CI 0·93–1·61). The 95% CI indicated that the true OR could be as low as 0·93, corresponding to a slight protective effect from the gambling message, or as high as 1·61, corresponding to much higher odds for the experimental group compared with the control group, consistent with a larger potential backfire effect from the gambling message. Following our a priori power analysis, these results suggest that any effect of the message was likely to be smaller than 6%, independent of the direction (which in the present case was opposite to the intention of the message).
The results of our secondary analyses, which adjusted for the potential effects of participants’ problem gambling severity, gambling frequency in the previous year, and gender, produced the same results pattern as the main results ( appendix p 9 ). Thus, overall, we found no evidence that the presence of a gambling message influenced participants’ propensity to gamble on sporting events.
In experiment 2, 1819 participants participated in the real-effort captcha task, of whom 317 (17·4%) participants transcribed six or fewer captcha tasks correctly and did not proceed to the roulette stage. Data from two participants were excluded because of missing data, resulting in a final sample size of 1500 (499 [33·3%] in the control condition, 500 [33·3%] in the black-and-white gambling message condition, and 501 [33·4%] in the yellow gambling message condition). The median age was 31 years (mean age 32 years) , 578 [38·5%] of whom were women. The average completion time was 7·2 min, and the average final roulette payout was £2·80 (range 0–30). This sum was added to the fixed payment of £2·50, which resulted in an equivalent pay rate of £44 per hour. On average, participants who gambled played for nine spins (1–204). 207 (14%) participants did not place any bets, thereby keeping their entire £3 bonus. No participants reached the upper limit (£90) of the roulette game, and the maximum balance reached at any point was £33.
Exploratory analyses found a small but statistically significant negative correlation between time spent completing the captcha tasks and number of captcha tasks correctly transcribed (r[1816]=–0·076, p=0·001). This analysis was done after excluding one participant who spent over 15 min (the median for the total group was 1·93 min) completing the captcha tasks. This result suggests that the initial captcha task did not selectively screen out impulsive participants from taking part in the experiment.
In experiment 2, the primary outcome was the proportion of money bet by each participant on the roulette game. We analysed the proportion bet using a Bayesian ZOIBR model across the three message conditions which provided a good account of the observed data ( appendix p 5 ). This model allows separate tests on whether the gambling message affected participants’ propensity to gamble at all, the propensity to bet everything, and the mean proportion of money bet.
Figure 4A shows the posterior distributions of the parameter estimates from the preregistered ZOIBR model across the three message gambling conditions, which represent the uncertainties for the message-condition-specific parameter estimates given the observed data. Because of the large sample size (N=1500), the precision of the parameter estimates was high (ie, uncertainties were low). Nevertheless, the differences between the three messages were small. To facilitate comparisons across the conditions, figure 4B shows the difference distributions between the two gambling message conditions from the no-message control condition.
Figure 4 (left column) shows how the presence of the messages affected the probability of gambling. The visual impression suggests that the messages could have had a slight protective effect. Participants who saw the gambling messages were on average around 2% less likely to gamble. As shown in Figure 4B , however, the uncertainty of the difference was substantially larger than 2% and thus a statistically meaningful difference is not supported by the model. There might have been a slight protective effect but, if true, the effect was so small that it would require an even larger sample size to be detected reliably.
Figure 4 (middle column) shows how the messages clearly had no effect on the conditional probability of gambling everything. The difference between the gambling message condition and the no-message condition was on average only around 1%. In addition, the difference distributions peaked close to zero, indicating that these data provide evidence for there being no difference between the conditions for any reasonable prior distribution.
Figure 4 (right column) also depicts how the messages affected the mean proportion bet. Both visual impression and statistical results provided evidence for a backfire effect with the yellow gambling message. The mean of the difference distribution between the no-message condition and the yellow message condition was around 4%, and the 95% credibility interval of the difference distribution just excluded zero (the lower bound was 0·003%). By contrast, the mean of the difference distribution between the no-message condition and the white message condition was lower at 2%, and the 95% credibility interval of the difference distribution included zero. Thus, these data provided evidence that, when presented with the yellow message, participants’ proportion of money bet was larger compared with the no-message condition.
We explored the evidence provided by the ZOIBR model with different possible prior probability distributions for the difference between the message conditions. The results show either evidence for a null effect or provide evidence for the backfire effect of the yellow message condition ( appendix pp 16–17 ).
Secondary analyses were also done, including participants’ individual difference scores on the PGSI and the enhancement motives subscale of the GMQ ( appendix pp 18–23 ). Overall, these secondary analyses supported the conclusions presented above, that the messages did not have any beneficial effects in reducing gambling behaviour. Finally, additional secondary analysis provided no evidence of differences in the riskiness of bets chosen across the three experimental conditions ( appendix pp 24–25 ).
In experiment 3, 1318 participants took part in the real-effort captcha task, but 310 transcribed six or fewer captcha tasks correctly and did not proceed to the football-betting stage. The data from four participants had to be excluded because they subsequently abandoned the task before checking out their bets and completing the final gambling questionnaire, and one participant had to be excluded because of missing captcha task data, resulting in a final sample size of 1003 (501 [50%] in the control condition and 502 [50%] in the yellow gambling message condition). The median age was 33 years, and 351 (35%) participants were women. The average completion time was 5·2 min, and the average final bonus payout was £2·20 (range 0–33), which added to the fixed payment of £1·50, resulting in an equivalent pay rate of £43 per hour. 395 (39%) participants did not place any bets, thereby keeping their entire £3 bonus. Participants who decided to bet placed an average of 2·2 bets.
As in experiment 2, we calculated the correlation coefficient between time spent completing the captcha tasks and number of captcha tasks correctly transcribed (after removing three participants who spent over 15 min on this part of the task). The correlation was weak (r[1308]=–0·072, p=0·009), once again suggesting that the captcha task did not exclude impulsive participants.
As in experiment 2, we applied the ZOIBR model, which provided an adequate account of the observed data ( appendix p 15 ), to determine whether the presence of a message influenced participants’ propensity to gamble, the propensity to bet everything, and the mean proportion of money bet.
Figure 5 shows the results of the ZOIBR model in experiment 3. Despite shifting from the roulette task to an online football-betting platform, the results are similar between the two studies. Figure 5 (left column) shows how the protective effect of the gambling message on the probability to gamble was even smaller than that found in experiment 2. In Figure 5B , the uncertainty around the 1% difference clearly crosses over zero, indicating that there was no reliable difference between the conditions. Figure 5 (middle column) shows how the largest difference appears in whether the message affects the conditional probability to gamble everything, but in the opposite direction to the intended effect of the safer gambling message. Participants who saw the “when the fun stops, stop” message were 6% more likely to gamble all of their money, if they gambled at all, compared with participants who were not shown this message. Despite the effect size, the 95% credibility interval did include zero. Finally, the gambling message did not affect the mean proportion bet, as shown in Figure 5 (right column), in which the difference between the conditions was very close to 0 (–0·4% difference).
As in experiment 2, we explored the evidence provided by the ZOIBR model with different possible priors for the difference between the two message conditions. The results show that, even for narrow priors, we either found evidence for the null effect or slight evidence for a backfire effect ( appendix p 29 ). Secondary analyses, including the two gambling scales, led to the same conclusions ( appendix pp 30–33 ). Finally, the treatment did not affect the riskiness of bets selected by participants ( appendix pp 34–35 ).

Section: Discussion

In this randomised, online experimental study we show that there is no evidence that gambling messages based on the phrase “when the fun stops, stop” were associated with safer concurrent gambling behaviour. Any potential reductions in the choice to gamble by participants exposed to the safer gambling message, compared to control participants , were too small to be reliably detected and can be contrasted with the largest effect in each experiment being a backfire effect. Any potential backfire effects, which we speculate could be potentially due to the prominence of the word “fun”, fits with the definition of so-called dark nudges: behaviour change interventions that make it harder for consumers to make good decisions, a concept highlighted previously in alcohol and gambling research. Our results might be considered relevant to other jurisdictions, in which similar messages can be observed, such as the message “when the fun stops” used in Nevada (USA), “have fun & play responsibly” used in New South Wales (Australia), or “keep the fun in the game” used in Ontario (Canada).
Our results are limited to a group of people who gamble in the UK and to concurrent gambling expenditure. Gambling expenditure was chosen as the dependent variable in this study as it is known to correlate with gambling-related harm. However, the short duration of the experiments might have contributed to the lack of observed beneficial effects via a floor effect. Other behavioural dependent variables should also be considered, such as visits to safer gambling awareness websites, the use of deposit limit setting tools, and calls to gambling helplines. It might be argued that people who gamble in the UK have seen “when the fun stops, stop” messages so often that improvements in safer gambling had already taken effect before the experimental manipulation. Although participants in all experiments were experienced gamblers, no direct measurements of gambling frequency were taken in either experiment 2 or 3. PGSI is, however, a proxy for gambling frequency, given that people who engage in problematic gambling behaviours tend to gamble much more than people who gamble recreationally. Although our results showed no differential effect of gambling messages across PGSI score, a replication study using people who gamble from a different jurisdiction could perhaps best test this potential explanation. Contrastingly, repeated exposure to an identical message might create psychological reactance that could lead to backfire effects; a potential explanation that appears more consistent with the observed results. Furthermore, the gambling messages used in our study might have had weak effects in the short term, but stronger effects with repeated exposure over longer timescales. A longitudinal study could test this explanation. Additionally, mode of delivery was not tested. There is evidence that so-called dynamic messages, which scroll across the screen, and pop-up messages, which appear in the centre of the screen, could be more effective than the static presentation format used in the gambling messages in our study.
An additional limitation of our study concerns the financial rewards for participation. Although the amounts wagered in our experiment were small, most online gambling is also done for small stakes. Data from online operators show that in sports betting the median bet size is £4·13 for women and £5·25 for men, and that 78% of online casino game sessions result in a win or loss smaller than £20. Only few people who gamble online stake sums substantially larger than these amounts, and this is the group that might require interventions stronger than messaging. Safer gambling messages might work best for most people who are at low risk of experiencing gambling-related harm.
Safer gambling messages, such as “when the fun stops, stop”, focus on individual behaviour and put the responsibility to change behaviour on the person who experienced the harm. An alternative approach would be to use warning messages that accurately convey the harm and risks for anyone who gambles. For example, gambling products could be accompanied by specific warning messages such as “Gambling is associated with significant harms including increased risks of physical and mental health problems, separation, divorce, financial difficulties and bankruptcy, intimate partner violence and fraud”. Other messaging approaches include personalised messages and positive emotional messages. Furthermore, any messaging approach might be unable to substantially modify the behaviour of people who gamble the largest amounts, for whom stronger interventions, such as binding precommitment and spending limits, should also be considered.
Independent evaluation of messages can provide an important input to evidence-based gambling policy. Our study found no credible evidence for the effectiveness of “when the fun stops, stop” gambling messages. Future interventions should be independently evaluated before being introduced.

Section: Data sharing

Anonymised data, analysis code and output, materials, and the preregistration document can be accessed from the Open Science Framework repository, available at https://osf.io/fwunh/ .

Section: Declaration of interests

PWSN is a member of the Advisory Board for Safer Gambling—an advisory group of the Gambling Commission in the UK. In 2020, PWSN was a special advisor to the House of Lords Select Committee Enquiry on the Social and Economic Impact of the Gambling Industry. In the past 3 years, PWSN has received research funding from Clean Up Gambling, and has contributed to research projects funded by GambleAware, Gambling Research Australia, NSW Responsible Gambling Fund, and the Victorian Responsible Gambling Foundation. In 2019, PWSN received travel and accommodation funding from the Spanish Federation of Rehabilitated Gamblers and, in 2020, received an open access fee grant from Gambling Research Exchange Ontario. EAL was a co-investigator on a grant funded by the Alberta Gambling Research Institute, which ended in February, 2019. All other authors declare no competing interests.

Section: Acknowledgments

This research was funded by a British Academy and Leverhume Small Research (grant number SRG19\191299), which was awarded to LW-C. This research was also funded by a Research Development Fund awarded to LW from the University of Warwick, and by a Swiss National Science Foundation grant (number 100014_179121) awarded to HS. We would like to thank Ty Hayes for his support in programming the online gambling platforms.

Section: Supplementary Material (1)

PDF (1.14 MB) Supplementary appendix
