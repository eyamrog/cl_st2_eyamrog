Title: Gesture


Section: 


Section: ABSTRACT

Gesture is intimately entwined with human language and thought. It is a tool for communication as well as cognition: conveying information to interlocutors, orchestrating interaction, and supporting problem-solving and learning. Over the past 25 years, the community of scholars interested in gesture has grown from a specialized group to a multidisciplinary community incorporating gesture into a wide range of topics. This article aims to capture and continue that growth by introducing readers to some of the most intriguing findings and questions in gesture research. It adopts a four-field approach, integrating multiple literatures and introducing work from outside anthropology. It defines key terminology and reviews five areas that have undergone significant recent growth: the integration of gesture with speech, gesture as communication and cognition, gesture's role in learning and language development, cultural variation in gesture, and the role of gesture in language origins. Taken together, these areas demonstrate that gesture is entangled with language, thought, and identity, starting in early childhood. This tangle has deep evolutionary roots; indeed, gesture may have been part of the human story from its start.

Section: INTRODUCTION

Everywhere humans are found, we find gesture. We gesture spontaneously when we talk, and these movements are integrated temporally and semantically with the speech acts they accompany. Gesture also occurs in the absence of speech: prelinguistically and in situations where speech is not possible or is ill-advised. Gesture is a robust, multifaceted phenomenon that crosses into almost every sphere of human life. Gesture research is almost as diverse as gesture itself, with scholars across the social and biological sciences as well as the humanities turning their eyes toward the hands of their subjects.
This article introduces readers to the highly interdisciplinary field of gesture research. It focuses on significant developments over the last 25 years. In 1997, Kendon wrote an article for the Annual Review of Anthropology , which focused on conversational cospeech gestures and the relationship of gesture to speech ( Kendon 1997 ). Gesture research has grown significantly in both size and scope since Kendon's seminal work. I aim to capture this growth by significantly expanding the focus of my review to include the roles of gesture in cognition, child language and learning, and language origins. This expansion mirrors the growth of gesture research, which has grown from a select community of scholars focused on gesture to scholars across many fields who previously paid little attention to gesture but who now include gesture in their work on communication, cognition, development, culture, and evolution. After reviewing core terminology used in gesture research, I highlight areas that have grown substantially over the past two decades. I introduce readers to the forms, uses, and importance of gesture across five key topics, roughly ordered by timescale: ( a ) the integration of gesture with speech, ( b ) gesture as communication and cognition, ( c ) gesture's role in learning and language development, ( d ) cultural variation in gesture, and ( e ) the role of gesture in language origins. My primary goal is to equip readers with some of the basic terminology and fundamental research questions in this vast literature. I adopt a four-field approach, weaving together work from biological, linguistic, cultural, and archaeological scholarship. I emphasize research in cognitive science, psychology, and linguistics, since these studies are likely to be less familiar to readers of this journal. I also highlight the linguistic and psychological features of gesture, reflecting my own stance and interdisciplinary training. It is important to note that many of the studies I cite focus on English speakers in the United States, which reflects a broader skew in the psychological literature. By introducing readers to the potential of gesture as a subject of inquiry, I hope to encourage more anthropologists to incorporate gesture in their work, providing an embodied perspective on human interaction, language, and culture and enriching the literature on gesture.
Gesture is typically defined as movements of the hand that occur in the context of communication, though it may also include movements of the head and body. Not all bodily movements are gesture. Gesture lies somewhere between manual action and manual language (sign language). Gesture differs from manual action in its communicative nature. Manual actions targeting one's own body to adjust or provide comfort can occur during communication but are not themselves part of the communicative act (see self-adaptors; Ekman & Friesen 1969 ). Gesture differs from signed languages because signed languages have all the linguistic features of spoken languages ( Klima & Bellugi 1979 , Sandler & Lillo-Martin 2006 ). Gesture, by contrast, lacks these rules and structures ( Cartmill & Goldin-Meadow 2016 ).
This is not to say that gesture has no structure or that it is merely hand-waving. Gesture can be conventionalized, possessing a normative form and requiring knowledge of the meaning of the form (e.g., the peace sign). It can index and leverage the surrounding environment in surprisingly complex ways (e.g., by pointing to things that are not present). It can highlight features of speech (e.g., by underscoring a stressed word). It can illustrate things in the physical environment or map physical features onto abstract concepts (e.g., opening the fingers like a blossom to represent a flower or an idea). These examples illustrate the gesture types introduced by McNeill (1992 , 2005 ) and Kendon (2004) and used by many gesture researchers today (emblem, deictic, beat, representational). Of course, these types are not mutually exclusive; a person giving directions might extend their arm toward a distant intersection (deictic) and dip their hand down in an arc to describe passing under an overpass (iconic). Table 1 provides further examples of these gesture types. I elaborate the features of representational gestures and pointing below, since most research has focused on these types.
Definitions and examples of gesture types (following McNeill 1992 )

Representational gestures are what many people think of when they think of gestures. These are the fluid, often complex movements used to illustrate objects, actions, or ideas. When they represent objects or actions in the real world, they do so iconically by recreating a feature of the referent in their shape or movement. When these movements are used to refer to an abstract concept, the gesture is described as metaphoric. Gesture can be used to illustrate a spoken metaphor or to add a metaphor not present in speech (for a collection of work on gesture and metaphor, see Cienki & Müller 2008 ). During iconic gestures, the hand typically represents one of three things: a hand acting on an invisible world (e.g., a curved hand mimes turning a doorknob and opening a door), an object in the world (e.g., a flat hand represents the door swinging open), or an abstract pointing shape used to trace the shape or trajectory of an object (e.g., an index finger point traces the arc through which the door opens).
Representational gestures are of particular interest to psychologically oriented researchers because these gestures can provide insight into how people represent an event, for example by depicting it from a first-person versus a third-person perspective ( Parrill 2010 ). Representational gestures can occur as single isolated movements (e.g., instructing someone to push rather than pull a door), or they can build on one another, drawing complex scenes with internal relationships (e.g., describing the route one takes from home to work). In their most complex forms, representational gestures can resemble diagrams or illustrations drawn in the air, capable of depicting abstract relationships like kinship ( Enfield 2005 ). Even in its simpler forms, such as flapping one's hands to represent a bird, representational gesture is still complex. It is relatively rare in children's communication and develops later in life than do other gesture types ( Iverson et al. 1994 , Özçalışkan & Goldin-Meadow 2005 ). Notably, representational gestures are also not seen in the gestures of nonhuman apes, though their gestures are complex in many other ways ( Cartmill et al. 2012 ). It may be that understanding the iconic mapping between hand and world relies on relatively sophisticated analogical abilities.
Pointing is the most ubiquitous form of gesture and the most studied. It appears deceptively straightforward, but successfully using or understanding a pointing gesture requires far more than following an outstretched appendage with one's eyes to a distal referent. A point can be a request, an acknowledgment, an accusation, an inquiry, or a commentary. It can reference a specific object, or it can refer to a class of objects, a habitual action, a past event, a future event, an absent entity, or a location in an imagined map. Pointing gestures are also among the earliest forms of reference produced by infants ( Bates 1976 ), and while these gestures remain simple in form, they are used in increasingly complex ways throughout ontogeny.
Heated debates exist over whether humans are the only species capable of pointing (we aren't; see Leavens 2004 ) and whether pointing is a human universal (it seems so; Liszkowski et al. 2012 ). People in all societies exhibit some form of bodily deixis; however, while most use manual pointing (either with the index finger or whole hand; Kita 2003 ), some use their heads, lips, or even noses ( Enfield 2001 , Cooperrider et al. 2018 ). Manual deixis can be achieved by means other than pointing, most notably by holding an object up or out to show or offer it to another person. Infants produce these hold-up gestures frequently ( Cameron-Faulkner et al. 2015 ), and some scholars argue that it is this simpler and more concrete form of deixis, rather than pointing, that serves as a sort of ur-gesture ( Rodríguez et al. 2015 ).
Even if they share the familiar extended index finger shape, not all point gestures are the same. For example, Lao speakers differentiate between “big points” and “small points,” using big points to convey essential information and small points to add detail or eliminate ambiguity ( Enfield et al. 2007 ). Speakers of the Australian aboriginal language Arrernte distinguish points even further, using six distinct forms to refer to different things ( Wilkins 2003 ).
Pointing typically references objects that are external to the speaker, which highlights the need to consider the speaker's environment. Goodwin (2003 , 2007 ) described gesture as an environmentally coupled, situated practice, one that could not be disassociated from its context without losing its meaning. This coupling is especially true for pointing. The context for pointing gestures includes the speaker's body, the physical environment, and the interactional space between interlocutors. The speaker's use of these spaces may change based on speech genre or common ground. For example, points referring to locations might accurately index their relative direction from the speaker; however, when points occur in the context of a narrative, they might instead index direction relative to the location in which the event originally took place ( Haviland 2000 ).
Gesture is typically defined as movements of the hand that occur in the context of communication, though it may also include movements of the head and body. Not all bodily movements are gesture. Gesture lies somewhere between manual action and manual language (sign language). Gesture differs from manual action in its communicative nature. Manual actions targeting one's own body to adjust or provide comfort can occur during communication but are not themselves part of the communicative act (see self-adaptors; Ekman & Friesen 1969 ). Gesture differs from signed languages because signed languages have all the linguistic features of spoken languages ( Klima & Bellugi 1979 , Sandler & Lillo-Martin 2006 ). Gesture, by contrast, lacks these rules and structures ( Cartmill & Goldin-Meadow 2016 ).
This is not to say that gesture has no structure or that it is merely hand-waving. Gesture can be conventionalized, possessing a normative form and requiring knowledge of the meaning of the form (e.g., the peace sign). It can index and leverage the surrounding environment in surprisingly complex ways (e.g., by pointing to things that are not present). It can highlight features of speech (e.g., by underscoring a stressed word). It can illustrate things in the physical environment or map physical features onto abstract concepts (e.g., opening the fingers like a blossom to represent a flower or an idea). These examples illustrate the gesture types introduced by McNeill (1992 , 2005 ) and Kendon (2004) and used by many gesture researchers today (emblem, deictic, beat, representational). Of course, these types are not mutually exclusive; a person giving directions might extend their arm toward a distant intersection (deictic) and dip their hand down in an arc to describe passing under an overpass (iconic). Table 1 provides further examples of these gesture types. I elaborate the features of representational gestures and pointing below, since most research has focused on these types.
Definitions and examples of gesture types (following McNeill 1992 )

Representational gestures are what many people think of when they think of gestures. These are the fluid, often complex movements used to illustrate objects, actions, or ideas. When they represent objects or actions in the real world, they do so iconically by recreating a feature of the referent in their shape or movement. When these movements are used to refer to an abstract concept, the gesture is described as metaphoric. Gesture can be used to illustrate a spoken metaphor or to add a metaphor not present in speech (for a collection of work on gesture and metaphor, see Cienki & Müller 2008 ). During iconic gestures, the hand typically represents one of three things: a hand acting on an invisible world (e.g., a curved hand mimes turning a doorknob and opening a door), an object in the world (e.g., a flat hand represents the door swinging open), or an abstract pointing shape used to trace the shape or trajectory of an object (e.g., an index finger point traces the arc through which the door opens).
Representational gestures are of particular interest to psychologically oriented researchers because these gestures can provide insight into how people represent an event, for example by depicting it from a first-person versus a third-person perspective ( Parrill 2010 ). Representational gestures can occur as single isolated movements (e.g., instructing someone to push rather than pull a door), or they can build on one another, drawing complex scenes with internal relationships (e.g., describing the route one takes from home to work). In their most complex forms, representational gestures can resemble diagrams or illustrations drawn in the air, capable of depicting abstract relationships like kinship ( Enfield 2005 ). Even in its simpler forms, such as flapping one's hands to represent a bird, representational gesture is still complex. It is relatively rare in children's communication and develops later in life than do other gesture types ( Iverson et al. 1994 , Özçalışkan & Goldin-Meadow 2005 ). Notably, representational gestures are also not seen in the gestures of nonhuman apes, though their gestures are complex in many other ways ( Cartmill et al. 2012 ). It may be that understanding the iconic mapping between hand and world relies on relatively sophisticated analogical abilities.
Pointing is the most ubiquitous form of gesture and the most studied. It appears deceptively straightforward, but successfully using or understanding a pointing gesture requires far more than following an outstretched appendage with one's eyes to a distal referent. A point can be a request, an acknowledgment, an accusation, an inquiry, or a commentary. It can reference a specific object, or it can refer to a class of objects, a habitual action, a past event, a future event, an absent entity, or a location in an imagined map. Pointing gestures are also among the earliest forms of reference produced by infants ( Bates 1976 ), and while these gestures remain simple in form, they are used in increasingly complex ways throughout ontogeny.
Heated debates exist over whether humans are the only species capable of pointing (we aren't; see Leavens 2004 ) and whether pointing is a human universal (it seems so; Liszkowski et al. 2012 ). People in all societies exhibit some form of bodily deixis; however, while most use manual pointing (either with the index finger or whole hand; Kita 2003 ), some use their heads, lips, or even noses ( Enfield 2001 , Cooperrider et al. 2018 ). Manual deixis can be achieved by means other than pointing, most notably by holding an object up or out to show or offer it to another person. Infants produce these hold-up gestures frequently ( Cameron-Faulkner et al. 2015 ), and some scholars argue that it is this simpler and more concrete form of deixis, rather than pointing, that serves as a sort of ur-gesture ( Rodríguez et al. 2015 ).
Even if they share the familiar extended index finger shape, not all point gestures are the same. For example, Lao speakers differentiate between “big points” and “small points,” using big points to convey essential information and small points to add detail or eliminate ambiguity ( Enfield et al. 2007 ). Speakers of the Australian aboriginal language Arrernte distinguish points even further, using six distinct forms to refer to different things ( Wilkins 2003 ).
Pointing typically references objects that are external to the speaker, which highlights the need to consider the speaker's environment. Goodwin (2003 , 2007 ) described gesture as an environmentally coupled, situated practice, one that could not be disassociated from its context without losing its meaning. This coupling is especially true for pointing. The context for pointing gestures includes the speaker's body, the physical environment, and the interactional space between interlocutors. The speaker's use of these spaces may change based on speech genre or common ground. For example, points referring to locations might accurately index their relative direction from the speaker; however, when points occur in the context of a narrative, they might instead index direction relative to the location in which the event originally took place ( Haviland 2000 ).

Section: INTEGRATION OF GESTURE WITH SPEECH

While gesture is sometimes produced on its own, it almost always accompanies speech ( McNeill 1992 ). Gesture is often described in terms of its relationship to such speech. Reinforcing gestures convey information also present in speech (e.g., pointing to a cow and saying “cow”). Disambiguating gestures help listeners understand ambiguous speech (e.g., pointing to a cow in a field of cows and saying “that one”). Supplementary gestures convey new information not present in speech (e.g., pointing to a cow and saying “Molly's”). While all gestures likely convey some information not found in speech, supplementary gestures bring in entirely new concepts, sometimes creating sentence-like structures ( Goldin-Meadow 2003a ).
Gesture is not only produced during speech; it is intimately entwined with speech on temporal and semantic levels. Temporally, gesture and speech are tightly synchronized. The most forceful movement in cospeech gesture (called the stroke phase) is produced concurrently with prosodic emphasis in speech ( McClave 1998 , Jannedy & Mendoza-Denton 2005 , Loehr 2007 ). This alignment of emphasis across modalities is not a simple artifact of producing vocal and manual acts simultaneously; gesture is more strongly synchronized with speech than are other manual actions produced during speech ( Church et al. 2014 ).
Evidence indicates that this alignment of speech and gesture occurs because the two are part of an integrated communicative system. Some scholars (e.g., Butterworth & Beattie 1978 ) argued that gesture and speech originate from separate systems and are produced concurrently but not meaningfully integrated. According to these authors, gesture serves as a backup system that can take over when speech fails. Other scholars argue that gesture and speech form an integrated system, aligned both temporally and linguistically ( Kendon 1980 , McNeill 1992 , McNeill & Duncan 2000 ). Studies over the last 30 years have overwhelmingly supported this integrated view; gesture and speech are now widely considered to be part of the same communicative system.
One of the strongest sources of evidence for gesture–speech integration comes from observing what happens when one modality is disrupted. When gesture or speech is interrupted, either through experimental manipulation or impairment, the other is affected as well. Speakers pause their gesturing during verbal stuttering ( Mayberry & Jaques 2000 ) and during temporary disfluencies in speech ( Graziano & Gullberg 2018 ). Conversely, speech is disrupted when gesture is experimentally interrupted ( Levelt et al. 1985 ). Experimental studies that interrupt gesture or speech mid-sentence provide evidence that the modalities interact dynamically during communication, not just during the planning phase of a communicative act ( Chu & Hagoort 2014 ).

Section: GESTURE AS COMMUNICATION AND COGNITION

Gesture occupies a liminal space between physical action and abstract representation ( McNeill 1992 , 2005 ), but it is enacted in physical (and typically interactional) environments ( Goodwin 2018 ). Gesture can be both a tool for carrying out social action and a tool for understanding gesturers’ minds. These two perspectives correspond to relatively divergent research cultures. Some authors focus on gestures that carry critical parts of the message in communicative exchanges; others focus on gestures that seem to be produced less consciously, thus providing a view into the gesturer's thought processes ( Cooperrider 2017 ).
This difference reflects the long-standing debate over whether gesture is produced more for the listener (i.e., primarily communicative) or for the speaker (i.e., primarily cognitive). Interactional scholars such as Clark (1996) , Kendon (2004) , Enfield (2009) , Streeck (2009) , Sweetser & Sizemore (2008) , and Goodwin (2018) emphasize gesture's role as a means for social action, focusing on the ways in which it is grounded in the physical and social environment. Cognitive scholars such as McNeill (1992 , 2005 ), Goldin-Meadow (2015) , Kita (2003) , Hostetter & Alibali (2008) , and Church et al. (2017) focus instead on gesture's potential as a “window on the mind” of the speaker-gesturer ( Goldin-Meadow 2003a ). While interactional scholars have long recognized gesture as a critical element of human interaction and meaning-making, gesture's potential as a nonverbal marker of the gesturer's knowledge, learning, stance, and perspective has made gesture a variable of interest in many new types of scholarship.
People gesture when they speak, even if they cannot be seen, raising the question of whether gestures are communicative at all ( Krauss et al. 1995 ). While out-of-view speakers may not stop gesturing, they do reduce the frequency of their gestures ( Alibali et al. 2001 ). Speakers adjust their gestures to accommodate conversational partners in other ways, shifting the orientation of their gestures relative to the dimensions of the space between them and their interlocutors ( Özyürek 2002 ). Gesture is a powerful tool for initiating and maintaining participation frameworks in interactional space ( Goodwin & Goodwin 2004 , Floyd et al. 2016 ). This is true even when the interactional spaces are multimodal and multilocational, as when gamers use gesture to refer simultaneously to the space they share with fellow players in the physical world and the space their avatars share in the virtual world ( Keating & Sunakawa 2010 ). Evidence also indicates that speakers modify their gestures in response to the epistemic states of their interlocutors, gesturing more frequently when presenting new knowledge to others ( Holler & Stevens 2007 ). Nonhuman apes also adjust their gestures in response to their recipient's visual attention, moving to another location or choosing auditory or tactile signals when they cannot be seen ( Liebal et al. 2004 ).
Gesture can also influence the way listeners interpret speech. When speech is accompanied by gestures that reinforce the spoken meaning, listeners more accurately perceive and recall information than when hearing speech without gesture ( Beattie & Shovelton 1999 , McNeil et al. 2000 ). But if the information in gesture conflicts with the information in speech, speech processing can be impaired ( Kelly et al. 2010 ). It seems clear that gesture can provide information to listeners, but there are many cases in which this information appears not to be taken up. A meta-analysis of 63 experimental studies found that gesture provides only moderate benefit to communication ( Hostetter 2011 ). Semantic content, relation to accompanying speech, and age of listeners all impacted the communicative effect of gesture. Gestures had the strongest effect when they conveyed information about motor actions rather than abstract concepts, when listeners were children, and when gestures were not redundant with accompanying speech. However, a later meta-analysis of 83 studies found that even gestures that appeared redundant with spoken information improved comprehension ( Dargue et al. 2019 ).
Scholars of interaction (e.g., Scheflen 1972 , Schegloff 1984 , Streeck et al. 2011 ) have long considered the body as a locus of communication and social action. In recent years, focus on embodied forms of interaction (and gesture in particular) has increased in other areas, bolstered by the use of video in data collection and by behavioral coding software such as ELAN and BORIS. This shift has been labeled the embodied turn ( Nevile 2015 ). Approaching interaction as an embodied practice opens up new analytic possibilities but can also have the effect of decentering spoken language, recontextualizing language as one of many semiotic practices ( Mondada 2016 ). Embodied studies of interaction explore how activity is organized through the weaving together of different resources, including orientation, gaze, gesture, object use, and spatial configuration ( Brassac et al. 2008 , Floyd et al. 2016 ). The use of video has also introduced challenges for data collection and analysis. Scholars must carefully consider how video is recorded, reflecting on what is left out as well as what is captured within the frame; these factors have implications for transcription and how the transcription process shapes analytic possibilities ( Ochs 1979 ).
Work on gesture as a communicative resource has revealed much about the ways in which people use their hands to inform, influence, interrogate, and interject. Listeners often but not always take gesture into account when interpreting communicative acts. Future studies should more thoroughly explore the conditions under which gesture does and does not convey meaning in order to more fully understand gesture's communicative potential.
People gesture in many situations where there is no clear communicative benefit (e.g., on the phone), which raises the possibility that people gesture not only for others, but also for themselves. The proposal that gesturing benefits the speaker is supported by a variety of phenomena, most notably gesture in congenitally blind individuals, gesture during lexical retrieval, and gesture during difficult cognitive tasks.
Congenitally blind people have never seen others gesturing; nevertheless, they gesture when they speak, even when they know they are addressing another blind person ( Iverson & Goldin-Meadow 1998 ). The frequency of gesture in blind speakers is lower than in sighted speakers ( Iverson et al. 2000 ), but they produce the same types of gestures, including deictic gestures (albeit without the typical index finger point) to indicate things in the environment ( Iverson & Goldin-Meadow 1997 ). That people who have no visual model for what gestures should look like produce gestures that are largely the same as those of sighted people supports the idea that the forms and uses of gesture are at least partially shaped by cognitive demands of the speaker.
Another source of evidence for gesture's role in cognition comes from the gestures that speakers make when searching for a word ( Goodwin & Goodwin 1986 ). Evidence indicates that these gestures can aid the speaker with lexical retrieval (finding the right word). Studies have found that when speakers are experimentally prevented from gesturing, it is more difficult for them to retrieve words (particularly during spatial language), and people show more disfluencies in speech, measured as pauses, filler words, or reduced speech rate ( Rauscher et al. 1996 , Frick-Horbury & Guttentag 1998 , Pine et al. 2007 ). However, a recent study of spatial language found no evidence that gesture aids lexical retrieval; it argues that past findings are more consistent with broad communicative impairment resulting from the unnaturalness of being asked not to gesture than from selectively impaired lexical retrieval ( Kisa et al. 2022 ).
Gesture may serve as an aid under many different cognitive demands. Speakers gesture more on difficult tasks than on simpler ones ( Kita & Davies 2009 ). Multilingual speakers gesture more when speaking in their nondominant language ( Gullberg 2010 ). Children's gestures become larger and more complex when working through difficult math problems ( Brooks et al. 2018 ).
Importantly, gesture can be a shared cognitive resource as well as an individual one. Gestures can be co-constructed or sequentially built in joint interactional frames ( Goodwin 2018 ). Gesture has the potential to render thought visible, allowing speakers to cooperatively reflect on and manipulate ideas during “collaborative imagining” ( Murphy 2005 ).
Findings that gesture increases during problem-solving are typically correlational, and it is difficult to determine whether gesture serves as a cognitive aid or merely reflects increased effort during these tasks. Experiments that manipulated participants’ gesturing during recall tasks concluded that gesture alleviated working memory stress ( Goldin-Meadow et al. 2001 , Ping & Goldin-Meadow 2010 ; but see Overoye & Wilson 2020 ). This finding was true whether people were instructed not to gesture or chose not to gesture, so the reduced performance in nongesturers was not due to the cognitive demands of being told not to gesture ( Goldin-Meadow et al. 2001 ).
Most experimental studies of gesture and cognition look for group effects (e.g., gesturers versus nongesturers). However, gesture may affect individuals in different ways, particularly given differences in task expertise or working memory. Many studies report measures of individual differences (e.g., by testing for age or gender effects), and scholars are starting to look more systematically at how gesture might play different roles for different people ( Guarino & Wakefield 2020 , Özer & Göksun 2020 ). As scholars continue to study when and how gesture relates to thought, they should look beyond experimental conditions to the cultures, contexts, and individual identities of their subjects, broadening the “when” and “how” to ask “for whom?”
People gesture when they speak, even if they cannot be seen, raising the question of whether gestures are communicative at all ( Krauss et al. 1995 ). While out-of-view speakers may not stop gesturing, they do reduce the frequency of their gestures ( Alibali et al. 2001 ). Speakers adjust their gestures to accommodate conversational partners in other ways, shifting the orientation of their gestures relative to the dimensions of the space between them and their interlocutors ( Özyürek 2002 ). Gesture is a powerful tool for initiating and maintaining participation frameworks in interactional space ( Goodwin & Goodwin 2004 , Floyd et al. 2016 ). This is true even when the interactional spaces are multimodal and multilocational, as when gamers use gesture to refer simultaneously to the space they share with fellow players in the physical world and the space their avatars share in the virtual world ( Keating & Sunakawa 2010 ). Evidence also indicates that speakers modify their gestures in response to the epistemic states of their interlocutors, gesturing more frequently when presenting new knowledge to others ( Holler & Stevens 2007 ). Nonhuman apes also adjust their gestures in response to their recipient's visual attention, moving to another location or choosing auditory or tactile signals when they cannot be seen ( Liebal et al. 2004 ).
Gesture can also influence the way listeners interpret speech. When speech is accompanied by gestures that reinforce the spoken meaning, listeners more accurately perceive and recall information than when hearing speech without gesture ( Beattie & Shovelton 1999 , McNeil et al. 2000 ). But if the information in gesture conflicts with the information in speech, speech processing can be impaired ( Kelly et al. 2010 ). It seems clear that gesture can provide information to listeners, but there are many cases in which this information appears not to be taken up. A meta-analysis of 63 experimental studies found that gesture provides only moderate benefit to communication ( Hostetter 2011 ). Semantic content, relation to accompanying speech, and age of listeners all impacted the communicative effect of gesture. Gestures had the strongest effect when they conveyed information about motor actions rather than abstract concepts, when listeners were children, and when gestures were not redundant with accompanying speech. However, a later meta-analysis of 83 studies found that even gestures that appeared redundant with spoken information improved comprehension ( Dargue et al. 2019 ).
Scholars of interaction (e.g., Scheflen 1972 , Schegloff 1984 , Streeck et al. 2011 ) have long considered the body as a locus of communication and social action. In recent years, focus on embodied forms of interaction (and gesture in particular) has increased in other areas, bolstered by the use of video in data collection and by behavioral coding software such as ELAN and BORIS. This shift has been labeled the embodied turn ( Nevile 2015 ). Approaching interaction as an embodied practice opens up new analytic possibilities but can also have the effect of decentering spoken language, recontextualizing language as one of many semiotic practices ( Mondada 2016 ). Embodied studies of interaction explore how activity is organized through the weaving together of different resources, including orientation, gaze, gesture, object use, and spatial configuration ( Brassac et al. 2008 , Floyd et al. 2016 ). The use of video has also introduced challenges for data collection and analysis. Scholars must carefully consider how video is recorded, reflecting on what is left out as well as what is captured within the frame; these factors have implications for transcription and how the transcription process shapes analytic possibilities ( Ochs 1979 ).
Work on gesture as a communicative resource has revealed much about the ways in which people use their hands to inform, influence, interrogate, and interject. Listeners often but not always take gesture into account when interpreting communicative acts. Future studies should more thoroughly explore the conditions under which gesture does and does not convey meaning in order to more fully understand gesture's communicative potential.
People gesture in many situations where there is no clear communicative benefit (e.g., on the phone), which raises the possibility that people gesture not only for others, but also for themselves. The proposal that gesturing benefits the speaker is supported by a variety of phenomena, most notably gesture in congenitally blind individuals, gesture during lexical retrieval, and gesture during difficult cognitive tasks.
Congenitally blind people have never seen others gesturing; nevertheless, they gesture when they speak, even when they know they are addressing another blind person ( Iverson & Goldin-Meadow 1998 ). The frequency of gesture in blind speakers is lower than in sighted speakers ( Iverson et al. 2000 ), but they produce the same types of gestures, including deictic gestures (albeit without the typical index finger point) to indicate things in the environment ( Iverson & Goldin-Meadow 1997 ). That people who have no visual model for what gestures should look like produce gestures that are largely the same as those of sighted people supports the idea that the forms and uses of gesture are at least partially shaped by cognitive demands of the speaker.
Another source of evidence for gesture's role in cognition comes from the gestures that speakers make when searching for a word ( Goodwin & Goodwin 1986 ). Evidence indicates that these gestures can aid the speaker with lexical retrieval (finding the right word). Studies have found that when speakers are experimentally prevented from gesturing, it is more difficult for them to retrieve words (particularly during spatial language), and people show more disfluencies in speech, measured as pauses, filler words, or reduced speech rate ( Rauscher et al. 1996 , Frick-Horbury & Guttentag 1998 , Pine et al. 2007 ). However, a recent study of spatial language found no evidence that gesture aids lexical retrieval; it argues that past findings are more consistent with broad communicative impairment resulting from the unnaturalness of being asked not to gesture than from selectively impaired lexical retrieval ( Kisa et al. 2022 ).
Gesture may serve as an aid under many different cognitive demands. Speakers gesture more on difficult tasks than on simpler ones ( Kita & Davies 2009 ). Multilingual speakers gesture more when speaking in their nondominant language ( Gullberg 2010 ). Children's gestures become larger and more complex when working through difficult math problems ( Brooks et al. 2018 ).
Importantly, gesture can be a shared cognitive resource as well as an individual one. Gestures can be co-constructed or sequentially built in joint interactional frames ( Goodwin 2018 ). Gesture has the potential to render thought visible, allowing speakers to cooperatively reflect on and manipulate ideas during “collaborative imagining” ( Murphy 2005 ).
Findings that gesture increases during problem-solving are typically correlational, and it is difficult to determine whether gesture serves as a cognitive aid or merely reflects increased effort during these tasks. Experiments that manipulated participants’ gesturing during recall tasks concluded that gesture alleviated working memory stress ( Goldin-Meadow et al. 2001 , Ping & Goldin-Meadow 2010 ; but see Overoye & Wilson 2020 ). This finding was true whether people were instructed not to gesture or chose not to gesture, so the reduced performance in nongesturers was not due to the cognitive demands of being told not to gesture ( Goldin-Meadow et al. 2001 ).
Most experimental studies of gesture and cognition look for group effects (e.g., gesturers versus nongesturers). However, gesture may affect individuals in different ways, particularly given differences in task expertise or working memory. Many studies report measures of individual differences (e.g., by testing for age or gender effects), and scholars are starting to look more systematically at how gesture might play different roles for different people ( Guarino & Wakefield 2020 , Özer & Göksun 2020 ). As scholars continue to study when and how gesture relates to thought, they should look beyond experimental conditions to the cultures, contexts, and individual identities of their subjects, broadening the “when” and “how” to ask “for whom?”

Section: GESTURE IN LEARNING AND LANGUAGE DEVELOPMENT

Gesture can do more than reveal the thoughts of the gesturer; it can play a critical role in learning, particularly for young children learning language. Children gesture before they can speak ( Bates 1976 ), and the gestures they make both precede and predict future developments in speech. Children begin pointing before they produce their first words, and their pointing predicts speed of vocabulary growth and which words they will acquire next ( Acredolo & Goodwyn 1985 , Iverson & Goldin-Meadow 2005 ). This pattern might be because gesture serves as an early indicator of language growth, because children change the types of spoken input they receive by gesturing, or because gesturing focuses children's attention on objects or object-word mappings ( LeBarton et al. 2015 ).
Once children begin to speak, they produce their earliest linguistic constructions by combining a word with a gesture. These gesture–speech combinations predict when children will begin to produce two-word spoken constructions ( Iverson & Goldin-Meadow 2005 ) and which types of spoken constructions will appear ( Özçalışkan & Goldin-Meadow 2009 , Rowe & Goldin-Meadow 2009 ). Supplementary gesture–speech combinations (where gesture adds information to speech) are particularly important in predicting early language development; young children may not yet be able to combine multiple words, but they nevertheless possess the communicative urge to convey sentence-like concepts. Even reinforcing gestures, conveying information that appears redundant with speech, can presage language development. Children start to point to objects while naming them in speech a few months before they learn to produce spoken determiners (a/the/this/that), and pointing-plus-naming fades as determiners take off. Pointing may serve as an early specifier, indicating which object the spoken label applies to ( Cartmill et al. 2014 ). Gesture also foreshadows developments in the sociopragmatic elements of language; beat gestures, along with other nonverbal prosodic markers, precede and predict developments in children's use of lexical pragmatic markers ( Hübscher & Prieto 2019 ).
As children age, gesture no longer stands in for missing words in children's constructions, but it can still predict upcoming linguistic developments. For example, children who incorporated character–viewpoint gestures (gesturing from a first-person perspective; Parrill 2010 ) into their retellings of a story at age 5 produced better-structured narratives at ages 6–8 than did children who did not produce these gestures ( Demir et al. 2015 ). The same did not hold for children who referenced perspective in speech; only embodying the character's perspective in gesture predicted narrative development. Because it emerges early and often predicts language development, gesture can also serve as an early predictor of language delay for multiple types of developmental disorders ( Iverson et al. 2003 , LeBarton & Iverson 2016 ).
While gesture can be used to predict language development, it is not an isolated or fleeting stop on the way to spoken language. Gesture occurs within a rich ecology of potential semiotic resources for the child. These include actions (and reactions) as well as gestures, vocalizations, and eventually words. Children weave together these different semiotic forms, shifting from more embodied forms of reference to more symbolic forms over time (e.g., in negation; Beaupoil-Hourdel et al. 2016 ). Note, the vast majority of developmental gesture studies focus on English-speaking children. Though a greater range of languages need to be studied, the tendency of gesture to precede and predict developments in speech seems to hold across languages (see reviews in Colonnesi et al. 2010 and Cameron-Faulkner et al. 2021 ).
Developmental researchers are also interested in the gestures that children see others use. Adults’ gestures form an important part of the learning environment for children (and other learners). Gesture is often exaggerated in child-directed gesturing ( Smith & Strader 2014 ), and it can play an important role in both formal and informal pedagogy (e.g., to highlight features of a problem or demonstrate a task; Streeck 2009 ). Teachers’ gestures can facilitate learning in classroom settings ( Valenzeno et al. 2003 ), while the gestures of content experts can do the same in informal learning environments ( Maynard & Greenfield 2005 ).
The mechanisms through which watching gesture impacts learning are not fully understood. Watching gesture might support learning by disambiguating speech and grounding it in the environment ( Ping & Goldin-Meadow 2008 ). Simultaneous presentation of information in gesture and speech might be important for learning, at least in some types of instruction (e.g., math; Congdon et al. 2017 ). An eye-tracking study of math instruction found that gesture helped children follow spoken instruction more effectively by making connections between the teacher's speech and different components of the problem ( Wakefield et al. 2018 ). However, gesturing does not always benefit instruction. The effect of gesture varies with content and structure, and there may be a trade-off in attentional resources directed toward gesture and other pedagogical material ( Yeo et al. 2017 ). Gesture might also play a different role for learners with varying prior access to content knowledge ( Guarino & Wakefield 2020 ).
Children's own gesturing can also play a role in guiding learning and shaping the learning environment, in both formal ( Goldin-Meadow et al. 2009 ) and informal ( de León 2015 ) settings. Experimental manipulations of children's own gesturing in educational settings have found that performing gestures (even when scripted and not spontaneous) can help children develop and integrate new knowledge ( Goldin-Meadow et al. 2009 ).
Most of the research on gesture's role in formal learning has focused on math instruction. Scholars do study other learning contexts (e.g., second language learning, see Gullberg 2006 , Kelly et al. 2009 , Morett & Chang 2015 ; moral reasoning, see Beaudoin-Ryan & Goldin-Meadow 2014 ), but math instruction makes up the lion's share of knowledge on gesture's role in learning. Other content areas and different types of pedagogy should be better represented in future research.

Section: CULTURAL VARIATION IN GESTURE

Some kinds of gestures (emblems) are expected to vary significantly across societies because they derive their meanings primarily from shared knowledge of particular form-meaning mappings (e.g., an OK sign or thumbs-up gesture). It is easy to notice such variation across societies and language communities—just consider the vast diversity and frequent opacity of rude gestures! However, some emblematic gestures have strikingly similar forms across societies. In certain cases, this similarity may be due to historical contact ( Kita 2009 ); in others, it may be because the gestures iconically depict actions performed in similar ways around the world ( Matsumoto & Hwang 2013 , Bressem et al. 2017 ). Communities also differ in the number of emblems they use, which may be due to differences in their communicative “ecology” ( Kendon 2004 ). For example, the emblem-heavy gesturing of Neapolitans may have arisen from the constraints of residential life in Naples, which necessitates communicating over long distances and standing out from closely related speakers ( Kendon 2004 ).
Cultural variation goes beyond emblems, however. The forms and uses of pointing and representational gestures vary across societies ( Kita 2003 , Cooperrider 2019 ). Some evidence indicates that beat gestures also differ cross-linguistically ( Brentari et al. 2013 ), though beat gestures are dramatically understudied. Differences in pointing and representational gestures might be driven by gestural conventions, social norms (e.g., politeness), or how people conceptualize things such as space, time, kinship, and animacy.
Gesture is often used to explore cross-cultural differences in the way people conceptualize space ( Haviland 2000 , Levinson 2003 ) and time ( Núñez & Sweetser 2006 , Gu et al. 2019 ). For example, speakers of English describe the future as in front of them and the past as behind them, and their gestures reflect this metaphor. Aymara speakers, on the other hand, describe the future as behind and the past in front. Their gestures also reflect this difference ( Núñez & Sweetser 2006 ). The same past-in-front, future-in-back gestural mapping has recently been shown in Chinese Mandarin speakers ( Gu et al. 2019 ). Gestural depictions of time sometimes follow the layout of written text instead ( Núñez & Cooperrider 2013 ). English speakers tend to place events on a gestural timeline with the oldest event on the left and the most recent on the right. Speakers of Hebrew, on the other hand, reverse this timeline. The gestures of each group reflect their writing system.
Of course, the forms and practices of gesture are not homogenous within societies or communities of practice. Gesture variation within communities may mark identity, expertise, status, or (dis)alignment with particular beliefs or groups, much as speech register, dialect, and style can. “Gesture ideologies” may reflect a group's positionality or stance relative to another ( Hoenes del Pinal 2011 ). Changes in gestures over time can also reveal shifts in ideologies, practices, or power. For example, a historical analysis of gestural performance of respect among BisiKongo people in the pre-colonial Kongo Kingdom in West Central Africa revealed how these practices shifted in response to the expansion of Christianity ( Covington-Ward 2019 ).
Gesture has long been recognized as an important embodied practice in ceremony, performance, and ritual ( Noland 2010 ). In fact, the earliest descriptions of gesture (Quintilian's writings on Ancient Roman oratory) focused on gesture during performance ( Graf 1992 ). However, the uses of gesture in everyday life are not accorded as much attention within anthropology as are spoken or written semiotic practices. Consideration of the ways in which gesture can reflect, reconstitute, and reconfigure ideologies, beliefs, and systems of power in everyday encounters expands the tools available to ethnographers and provides a different lens onto key anthropological questions of identity, culture, and interaction.
Variation in cospeech gesture across communities (or over time) may reflect differences in bodily habitus, practices, or ideologies or may reflect differences in linguistic structure. Some studies aim to discover whether people conceptualize or remember events in similar ways despite linguistic differences by asking whether gestural differences disappear when people are asked to gesture without using speech. While cospeech gesture often shows significant differences in how it depicts events during speech, silent gesture experiments typically reveal more similarities than differences across languages. For example, despite differences in the word order of their spoken languages, speakers of English, Turkish, Spanish, and Chinese tend to use a gesture order comparable to subject-object-verb when asked to describe an event without speech ( Goldin-Meadow et al. 2008 ). Similarly, differences in how manner and path are depicted gesturally by Turkish and English speakers disappear when speakers describe events silently ( Özçalışkan et al. 2016 ).

Section: GESTURE IN LANGUAGE ORIGINS

Over the past 25 years, the idea that gesture played a significant role in the evolution of human language has gained traction, bolstered by research on the communicative importance of gesture in early childhood, the complexity and flexibility of gestures in nonhuman primates, and a growing view of language as a multimodal phenomenon. Some scholars support a gesture-first theory, in which language evolved first in the manual modality and later transitioned to speech (e.g., Armstrong et al. 1995 , Corballis 2002 , Arbib 2012 ). Others propose that language was multimodal from the start, with both vocalization and gesture playing a role (e.g., McNeill 2012 , Kendon 2017 , Fröhlich et al. 2019 ). Interest in gesture's role in language origins has catalyzed research on gesture's potential to convey information in the absence of speech. Three topics have been particularly influential: comparative gesture, conventionalization of manual communication, and sign language emergence.
Comparative studies of gesture compare human language and gesture to the gestural communication of nonhuman animals (typically great apes) to shed light on our evolutionary past ( Call & Tomasello 2020 , Cartmill et al. 2012 , Liebal et al. 2014 ). Great apes are prolific gesturers, using gestures flexibly to accomplish specific social goals. There is considerable debate about how apes acquire their gestures ( Cartmill & Hobaiter 2019 ): Some argue for a relatively fixed repertoire deployed flexibly ( Byrne et al. 2017 ), whereas others argue for a process of ontogenetic ritualization that reduces actions into gestures ( Tomasello & Call 2019 ). The cognitive similarities between ape and human gesturing are also debated. Some argue that apes (and other animals) lack the human capacities of inference and ostension necessary to use gesture with Gricean communicative intent ( Scott-Phillips 2014 ). Others argue that species differences are greatly exaggerated ( Moore 2016 ). Perceptions of ape communication as lacking in ostension may arise from a bias in how ape gesture is studied, particularly the reliance on a “code model” of communication ( Cartmill 2016 ). While many scholars have compared the gestures of apes and humans, study designs—and, critically, transcription practices—differ significantly. Recent work analyzing the gestures of human children with methods from ape studies found many more similarities than previous studies had ( Kersken et al. 2019 ). These similarities suggest that human gesture may, in fact, be built on a manual communication system with deep evolutionary roots.
It is, of course, impossible to know what the earliest forms of human language were like. No one was there to document our hominin ancestors as they started to use symbols to label their world. Conventionalization experiments ask participants to complete communicative tasks without using words and show how new communicative conventions can emerge over short timescales through repeated interaction (e.g., Fay et al. 2014 , Namboodiripad et al. 2016 , Motamedi et al. 2019 ). Observations of language emergence in real-world interactions have come largely from documentation of spoken pidgins and creoles ( McWhorter 1998 ). But manual systems sometimes emerge out of necessity, when speech is impossible or dispreferred (including noisy environments), when stealth is needed, or when following norms of politeness or respect ( Kendon 1997 ). For example, Aboriginal Australians use Desert Sign Languages to enhance or replace speech when speakers are out of earshot, in mourning, or participating in certain ceremonies ( Kendon 1997 , Ellis et al. 2019 ). Likewise, tactile communication systems can emerge when deaf signers lose their sight ( Edwards & Brentari 2021 ).
While these studies demonstrate how quickly conventionalization and language change can occur, the creators of these systems have prior knowledge of language; the systems are not created de novo. There is, however, one context in which it is possible to observe the birth of a new language from individuals who lack a language model. This process occurs when profoundly deaf people, who did not previously have access to a sign language, communicate with one another and develop new sign languages.
Individuals whose deafness prevents them from acquiring a spoken language and who have not been exposed to sign language (homesigners) idiosyncratically invent the rudiments of language in gesture ( Goldin-Meadow 2003b , 2012 ). Homesigns can develop into full-fledged sign languages once the system is shared, where users are both producers and recipients ( Senghas et al. 2004 , Meir et al. 2010 , Coppola 2020 ). New sign languages emerge when local populations have unusually high numbers of deaf children (village/rural sign languages) or when previously isolated homesigners are brought together to form new communities (community/urban sign languages) ( Meir et al. 2010 , Hou 2016 ). Community sign languages have been documented most extensively in Nicaragua ( Senghas et al. 2004 , 2014 ; Abner et al. 2019 ) and Israel ( Sandler et al. 2005 ); each language shows increasingly complex linguistic structure over time. Village sign languages have been recorded around the world, but small numbers of users and isolation make these languages difficult to document ( Meir et al. 2010 ). Despite these hurdles, sign language emergence is a rapidly growing area of research ( Le Guen et al. 2020 , Zeshan & de Vos 2012 ). There is considerable time pressure to document the process of emergence and to record these languages before language shift, driven by contact with other sign languages, alters their unique features ( Jaraisy & Stamp 2022 ).
Evidence from conventionalization experiments and emerging sign languages demonstrates that the manual modality presents no barriers for the emergence and codification of linguistic structure. This makes gesture-first theories of language evolution more plausible.

Section: CONCLUSIONS

Gesture, like language, is woven into the fabric of human life. While I have covered only a small fraction of the work on gesture, the five areas I highlight demonstrate how gesture forms an integral part of human language and thought starting in early childhood; how it reflects and reinforces cultural and individual identities; and how gesture has been part of the human story since before the dawn of our species.
As a topic of study, gesture has the potential to bridge the traditional four fields of anthropology. It can be viewed as an outlet for self-expression; a connection to heritage and identity; a human universal; a culturally inflected semiotic tool; an evolutionary foundation of language; or a window onto cognition, ideologies, beliefs, and practices. Anthropological studies of gesture have been wide-ranging: highlighting the ways that Barack Obama indexes qualities such as “sharpness” in political discourse ( Lempert 2011 ), revealing aspects of identity formation and negotiation in Latina youth gangs ( Mendoza-Denton 2014 ), describing how girls embody race and class in ostracizing others during playground interactions ( Goodwin & Alim 2010 ), and uncovering ideologies of hierarchy depicted in artifacts from the Classic Maya period ( Bishop & Cartmill 2021 ).
There is much room for growth in anthropological studies of gesture. I predict that incorporating gesture in ethnographic, cognitive, and linguistic methodologies will become increasingly commonplace over the next 25 years. Advances in computer vision and machine learning promise to transform gesture transcription by automating some aspects of the laborious hand-coding process. Of course, just as word-to-text technology has not replaced linguists, automated gesture recognition will not replace gesture scholars; it will develop most effectively through close collaboration between gesture scholars and machine learning researchers. Making gesture part of standard transcription practices and reducing (though not eliminating) the transcription burden will encourage more researchers to embrace gesture, increasing methodological and theoretical diversity in the field. These efforts will benefit both gesture research and anthropology.
Researchers in all areas of anthropology consider gesture in their work, whether they view themselves as gesture researchers or not. Anthropologists have long embraced embodiment as a potential lens onto identity, interaction, and meaning-making. Gesture focuses that lens. As a unique bridge between action and symbol, between acting and thinking, gesture has enormous potential to shed light on what it means to be human.

Section: disclosure statement

The author is not aware of any affiliations, memberships, funding, or financial holdings that might be perceived as affecting the objectivity of this review.

Section: acknowledgments

My thinking about gesture has been strongly shaped by my time working with Susan Goldin-Meadow and her lab. My work has also been greatly enriched by many conversations with Richard Byrne, Kensy Cooperrider, Sandro Duranti, Lila Gleitman, Candy Goodwin, Chuck Goodwin, Cat Hobaiter, David McNeill, Norma Mendoza-Denton, and Elinor Ochs. I also thank Susan Goldin-Meadow, Candy Goodwin, Kensy Cooperrider, Kaye Brown, Matt Cartmill, and Jacob Foster for their comments on the manuscript; the Institute for Advanced Study for providing a vibrant atmosphere in which to conceptualize the piece; and Bonnibel Cartmill for her support during its writing.

Section: literature cited

