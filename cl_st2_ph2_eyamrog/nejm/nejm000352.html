<html lang="en" class="pb-page js" data-request-id="94d68cb4c580debe-GRU"><head data-pb-dropzone="head"><style type="text/css" nonce="94d68cb4c580debe-GRU">@font-face {font-family: "Source Sans Pro";src: url(https://consent.trustarc.com/get?name=SourceSansPro-Regular.ttf) format("truetype"),url(https://consent.trustarc.com/get?name=SourceSansPro-Regular.woff) format("woff"),url(https://consent.trustarc.com/get?name=SourceSansPro-Regular.otf) format("opentype"),url(https://consent.trustarc.com/get?name=SourceSansPro-Regular.eot) format("embedded-opentype");}.truste_cursor_pointer {cursor: pointer;}.truste_border_none {border: none;}.truste_accessible_link {font-family: "Source Sans Pro", sans-serif;color: #1D4ED8;font-size: 14px;font-weight: 600;text-decoration: underline;}.truste_accessible_link:hover {color: #1D4ED8;text-decoration: none !important;}.truste_accessible_link:focus-visible {outline: none;border-radius: 4px;box-shadow: 0 0 0 1px #FFFFFF, 0 0 0 4px #3699F1;}</style><script src="https://ssl-cdn.janraincapture.com/widget_data/flow.js:7h8bznq6j7bvyvzqcrwvyp8dfb:en-US:20240514181256512029:standard" type="text/javascript"></script><script src="https://cssjs.nejm.org/akamai/capture:login" type="text/javascript"></script><script src="https://ssl-widget-cdn.rpxnow.com/translations/login/en-US" type="text/javascript"></script><script type="text/javascript" id="janrainAuthWidget" src="https://cssjs.nejm.org/akamai/mms-prod.js"></script><script type="text/javascript" src="https://www.nejm.org/oohKzgkkqI7U-Rw91BgiLkn1KG2VhARqSmfWDZZR8jfG7XftmjNe42mJI4FuCr2A2LcdQgissN324bCcPuQjcQ=="></script>
            

<meta charset="UTF-8">






    
        
            
        
    
        
            
        
    
        
            
        
    
        
            
        
    
        
    
        
    
        
            
                
                
<title>Neuroprosthesis for Decoding Speech in a Paralyzed Person with Anarthria | New England Journal of Medicine</title>





                
            
        
    







    
        
            
        
    
        
            
        
    
        
            
                
                



                
            
        
    
        
            
        
    
        
    
        
    
        
            
        
    











    








    

    
    

    
    
    
    
        
            
                <link rel="stylesheet" type="text/css" href="/wro/1125813~article-metrics.css">
            
            
            
        
    

    
    
        
            <link rel="icon" href="/products/mms-nextgen/mms/releasedAssets/images/favicon/fav_nejm_1-994b0160d1eb33dc79517ef0295aab1b.ico" type="image/x-icon">
        
        
            <link rel="icon" href="/products/mms-nextgen/mms/releasedAssets/images/favicon/fav_16-4aa032aa775940f725817b7ff42f0e2c.png" type="image/png" sizes="16x16">
        
        
            <link rel="icon" href="/products/mms-nextgen/mms/releasedAssets/images/favicon/fav_32-0a94fa44823476ffa0bb15bdb320fb34.png" type="image/png" sizes="32x32">
        
        
            <link rel="apple-touch-icon" href="/products/mms-nextgen/mms/releasedAssets/images/favicon/fav_152-d6c3522864a8e483996b7e9c132c901a.png" sizes="152x152">
        
        
            <link rel="apple-touch-icon" href="/products/mms-nextgen/mms/releasedAssets/images/favicon/fav_180-f2538afc53a365d4cd3f10ab73c56aad.png" sizes="180x180">
        
        
            <link rel="apple-touch-icon" href="/products/mms-nextgen/mms/releasedAssets/images/favicon/fav_167-8e888012bbdd31a00c3e54bc5b8ca5b6.png" sizes="167x167">
        
    

    
    
            <link rel="stylesheet" href="/products/mms-nextgen/mms/releasedAssets/css/build-5b89b331018866a4a965.css" media="all">
        <link rel="stylesheet" href="/products/mms-nextgen/mms/releasedAssets/css/print-5b89b331018866a4a965.css" media="print">
           <link rel="stylesheet" href="/products/mms-nextgen/mms/releasedAssets/css/build-article-5b89b331018866a4a965.css" media="all" id="article-style-sheet">
    
        <script nonce="94d68cb4c580debe-GRU">
        try {
            document.documentElement.classList.add('js');
        } catch (e) {
        }
    </script>
     
    

















    
        
            
                
                
                
                    
                    <!-- TrustArc Scripts -->
<script async="async" src="https://consent.trustarc.com/notice?domain=nejm.com&amp;c=teconsent&amp;js=nj&amp;noticeType=bb&amp;gtm=1&amp;text=true&amp;pcookie" crossorigin="" id="truste_0.26677907352869246"></script>
<script src="https://consent.trustarc.com/autoblockasset/core.min.js?domain=nejm.com"></script>
<script src="https://consent.trustarc.com/autoblockoptout?domain=nejm.com"></script>
<!-- /TrustArc Scripts -->
<!-- BlueConic Scripts -->
<script src="https://bc.nejm.org/script.js"></script>
    <!-- /BlueConic Scripts -->
<!-- Printing Meta Tags -->
    <meta name="Specialties" content="Psychiatry|Neurology/Neurosurgery|Genetics">
<meta name="articleType" content="Original Article">
<meta name="articleCategory" content="Research">
<meta name="topics" content="Psychiatry General|Neurology/Neurosurgery General|Neuroscience"><script type="text/javascript">var mmsData = {"access":{"isFreeCountry":"n"},"ad":{"category":"article"},"imageChallenge":{"id":null},"article":{"doi":"10.1056/NEJMoa2027540","title":"Neuroprosthesis for Decoding Speech in a Paralyzed Person with Anarthria","category":"Research","type":"Original Article","topics":"Psychiatry General|Neurology/Neurosurgery General|Neuroscience","specialties":"Psychiatry|Neurology/Neurosurgery|Genetics","seriesTitle":"","viewType":"Full","age":"2Years-1990","issueDate":"2021-07-15T00:00Z","isFree":"y","broadTopics":"","perspectiveTopics":"","granularTopics":"","methodologicalArea":"","isOnlineFirst":"n","isCurrentIssue":"n","metaTags":"\u003cmeta name\u003d\"Specialties\" content\u003d\"Psychiatry|Neurology/Neurosurgery|Genetics\"/\u003e\n\u003cmeta name\u003d\"articleType\" content\u003d\"Original Article\"/\u003e\n\u003cmeta name\u003d\"articleCategory\" content\u003d\"Research\"/\u003e\n\u003cmeta name\u003d\"topics\" content\u003d\"Psychiatry General|Neurology/Neurosurgery General|Neuroscience\"/\u003e"},"page":{"activity":"showFullText","url":"www.nejm.org/doi/full/10.1056/NEJMoa2027540","viewType":"desktop","journal":"NEJM"},"user":{"ucid":null,"audienceSegment":null,"specialtyGroupCode":null,"meterCountRemaining":null,"totalMeterCount":null},"object":[{"type":"Research Summary","title":"Neuroprosthesis for Decoding Speech in a Paralyzed Person with Anarthria","doi":"10.1056/NEJMdo006090","issueDate":"2021-07-15T00:00Z","age":"6Months-1990","isFree":"n","topics":"Neuroscience|Psychiatry General|Neurology/Neurosurgery General","viewType":"Full","specialties":"Psychiatry|Genetics|Neurology/Neurosurgery"},{"type":"Quick Take","title":"Decoding Speech in a Paralyzed Person with Anarthria","doi":"10.1056/NEJMdo006089","issueDate":"2021-07-15T00:00Z","age":"6Months-1990","isFree":"n","topics":"Neuroscience|Psychiatry General|Neurology/Neurosurgery General","viewType":"Full","specialties":"Psychiatry|Genetics|Neurology/Neurosurgery"},{"type":"Video","title":"Real-Time Conversational and Sentence Decoding in a Paralyzed Adult with Anarthria","doi":"10.1056/NEJMdo006054","issueDate":"2021-07-15T00:00Z","age":"6Months-1990","isFree":"y","topics":"Neuroscience|Psychiatry General|Neurology/Neurosurgery General","viewType":"Full","specialties":"Psychiatry|Genetics|Neurology/Neurosurgery"}]};</script>
    <script type="text/javascript">var mmsDataAdd = {"user":{"customerType":"null","accessInstitutionID":"null"}};</script>
    <!-- Prehiding snippet for Adobe Target with asynchronous Launch deployment -->
    <!-- placeholder id=null, description=Adobe-Target-Prehiding-Snippet --><!--
  Adobe Target - Prehiding Snippet
  v2.0.0
-->
<script nonce="94d68cb4c580debe-GRU">
function tgtNoFlicker(e,n,t,o,i,c,l,r){function d(){return n.getElementsByTagName("head")[0]}function a(e,t){if(e){var o=n.getElementById(t);o&&e.removeChild(o)}}function f(e,o){!function(e,t,o){if(e){var i=n.createElement("style");i.id=t,i.innerHTML=o,e.appendChild(i)}}(d(),t,e),setTimeout(function(){a(d(),t)},o)}var m;n.location.href.indexOf(c)>-1?f(l,r):f(o,i),n.location.href.indexOf("mboxDisable")>-1?(a(d(),t),console.log("[TARGET] - Disabled, removing prehiding style")):(m=function(e){e&&(a(d(),t),console.log("[TARGET] - Blocked, removing prehiding style"))},fetch("//cdn.tt.omtrdc.net/cdn/target-vec.js",{method:"HEAD",mode:"no-cors"}).then(e=>m(!1)).catch(e=>m(!0)))}

tgtNoFlicker(window, document, 'at-body-style', 'div[data-location-name="Anonymous Module"], div[data-location-name="Anonymous Banner"], main > div.page-body > div > div > div > div.col-md-2-3.o-col.o-col--primary > div[class*="u-hide"], main > div.page-body > div > div > div > div.col-md-1-3.o-col.o-col--secondary > aside, header > h1#mainContent, a.m-article__link[href*="/10.1056/NEJMoa2116747"] > span.m-article__blurb > p, li.g-nejm-group__user-tool-secondary {opacity: 0 !important}', 3000);

tgtNoFlicker(window, document, 'at-mbox-style', '.N-ad-global-top-right, #N-ad-myNEJM-contextual-top, .N-ad-recentArticles, #N-ad-article-rightRail-1, #N-ad-siteWide-rightRail-1, #N-ad-imageChallenge-rightRail-2 {opacity: 0 !important}', 3000);
</script><!-- /Prehiding snippet for Adobe Target with asynchronous Launch deployment -->
    <!-- Launch Header Embed Code -->
    <script src="//assets.adobedtm.com/launch-ENcd6450fae3ae4870becbe6a2b01ab2e1.min.js" async="" type="ta-blocked" data-ta-blocked="1"></script>
    <!-- /Launch Header Embed Code -->

                    
                
            
        
    
        
            
                
                
                
                    
                    <link rel="schema.DC" href="http://purl.org/DC/elements/1.0/"><meta name="citation_journal_title" content="New England Journal of Medicine"><meta name="dc.Title" content="Neuroprosthesis for Decoding Speech in a Paralyzed Person with Anarthria"><meta name="dc.Creator" content="David A. Moses"><meta name="dc.Creator" content="Sean L. Metzger"><meta name="dc.Creator" content="Jessie R. Liu"><meta name="dc.Creator" content="Gopala K. Anumanchipalli"><meta name="dc.Creator" content="Joseph G. Makin"><meta name="dc.Creator" content="Pengfei F. Sun"><meta name="dc.Creator" content="Josh Chartier"><meta name="dc.Creator" content="Maximilian E. Dougherty"><meta name="dc.Creator" content="Patricia M. Liu"><meta name="dc.Creator" content="Gary M. Abrams"><meta name="dc.Creator" content="Adelyn Tu-Chan"><meta name="dc.Creator" content="Karunesh Ganguly"><meta name="dc.Creator" content="Edward F. Chang"><meta name="dc.Description" content="Technology to restore the ability to communicate in paralyzed persons who cannot speak has the potential to improve autonomy and quality of life. An approach that decodes words and sentences direct..."><meta name="Description" content="Technology to restore the ability to communicate in paralyzed persons who cannot speak has the potential to improve autonomy and quality of life. An approach that decodes words and sentences direct..."><meta name="dc.Publisher" content="Massachusetts Medical Society"><meta name="dc.Date" scheme="WTN8601" content="2021-07-15"><meta name="dc.Type" content="research-article"><meta name="dc.Format" content="text/HTML"><meta name="dc.Identifier" scheme="doi" content="10.1056/NEJMoa2027540"><meta name="dc.Identifier" scheme="publisher-id" content="NJ202107153850306"><meta name="dc.Language" content="EN"><meta name="dc.Relation" content="10.1056/NEJMe2106392"><meta name="dc.Relation" content="YXQYoa2027540"><meta name="dc.Coverage" content="world"><meta name="dc.Rights" content="Copyright © 2021 Massachusetts Medical Society. All rights reserved.">




<link rel="meta" type="application/atom+xml" href="https://doi.org/10.1056%2FNEJMoa2027540">
<link rel="meta" type="application/rdf+json" href="https://doi.org/10.1056%2FNEJMoa2027540">
<link rel="meta" type="application/unixref+xml" href="https://doi.org/10.1056%2FNEJMoa2027540">


                    
                
            
        
    
        
            
                
                
                
                
                
            
        
    
        
            
                
                
                
                    
                    





<meta name="robots" content="noarchive">





    





    
    
        
        <meta name="twitter:title" content="Neuroprosthesis for Decoding Speech in a Paralyzed Person with Anarthria | NEJM">
        <meta property="og:title" content="Neuroprosthesis for Decoding Speech in a Paralyzed Person with Anarthria | NEJM">
    


    <meta property="og:type" content="article">


    
    
        <meta property="og:url" content="https://www.nejm.org/doi/full/10.1056/NEJMoa2027540">
    
    


    
    
        <meta property="og:image" content="https://www.nejm.org/cms/asset/72b2e583-fb17-48c8-9cd1-62c7af874aa5/nejmoa2027540_f0.jpg">
        <meta name="twitter:image" content="https://www.nejm.org/cms/asset/72b2e583-fb17-48c8-9cd1-62c7af874aa5/nejmoa2027540_f0.jpg">
    



    <meta property="og:site_name" content="The New England Journal of Medicine">


    
    
        
        <meta property="og:description" content="Technology to restore the ability to communicate in paralyzed persons who cannot speak
has the potential to improve autonomy and quality of life. An approach that decodes
words and sentences direct...">
        <meta name="twitter:description" content="Technology to restore the ability to communicate in paralyzed persons who cannot speak
has the potential to improve autonomy and quality of life. An approach that decodes
words and sentences direct...">
    


    
    
        <meta property="og:image:width" content="2640">
    


    
    
        <meta property="og:image:height" content="3416">
    


    <meta name="twitter:card" content="summary">


    <meta name="twitter:site" content="@NEJM">


<meta name="viewport" content="width=device-width,initial-scale=1"><meta name="publication_doi" content="10.1056/NEJMoa2027540">


    















                    
                
            
        
    
        
    
        
    
        
            
                
                
                
                
                
            
        
    




<meta name="format-detection" content="telephone=no">

<meta http-equiv="X-UA-Compatible" content="IE=edge">
    




    
        
        
        <link rel="canonical" href="https://www.nejm.org/doi/full/10.1056/NEJMoa2027540">
    
    







<meta name="pbContext" content=";requestedJournal:journal:nejm;page:string:Article/Chapter View;ctype:string:Journal Content;article:article:doi\:10.1056/NEJMoa2027540;wgroup:string:MMS NextGen Website Group;issue:issue:doi\:10.1056/nejm_2021.385.issue-3;pageGroup:string:Publication Pages;subPage:string:Full Text;website:website:mms-site;journal:journal:nejms">
        <script id="altmetric-embed-js" src="https://d1bxh8uas1mnw7.cloudfront.net/assets/altmetric_badges-288192a491f0ad9cc434f05ea175659426f5ab0cfd6befb3f3592f96bb90b0d1.js"></script><link rel="stylesheet" type="text/css" href="https://cssjs.nejm.org/custreg-933-8e181dff8b36ea01dc4c.css"><link rel="stylesheet" type="text/css" href="https://cssjs.nejm.org/custreg-34-6ea546d794fb7a1cea52.css"><link rel="stylesheet" type="text/css" href="https://cssjs.nejm.org/custreg-743-ddd329e1530654ec0846.css"><link rel="stylesheet" type="text/css" href="https://cssjs.nejm.org/custreg-305-9eee37798fdfe5196307.css"><link rel="stylesheet" type="text/css" href="https://cssjs.nejm.org/custreg-388-bb098c62445f518c0b46.css"><link rel="stylesheet" type="text/css" href="https://cssjs.nejm.org/custreg-556-8e58ca05fb5497e541ef.css"><script charset="utf-8" src="https://www.nejm.org/products/mms-nextgen/mms/releasedAssets/js/0-dfd243c732a07d3608f6.js"></script><script charset="utf-8" src="https://www.nejm.org/products/mms-nextgen/mms/releasedAssets/js/7-10d355ba95f7ec1fddf2.js"></script><script charset="utf-8" src="https://www.nejm.org/products/mms-nextgen/mms/releasedAssets/js/11-04bf2a0da30146b4a5d0.js"></script><script src="https://static.addtoany.com/menu/modules/core.pt5ow5lr.js" type="module"></script><style type="text/css">.a2a_hide{display:none}.a2a_logo_color{background-color:#0166ff}.a2a_menu,.a2a_menu *{-moz-box-sizing:content-box;-webkit-box-sizing:content-box;box-sizing:content-box;float:none;margin:0;padding:0;position:static;height:auto;width:auto}.a2a_menu{border-radius:6px;display:none;direction:ltr;background:#FFF;font:16px sans-serif-light,HelveticaNeue-Light,"Helvetica Neue Light","Helvetica Neue",Arial,Helvetica,"Liberation Sans",sans-serif;color:#000;line-height:12px;border:1px solid #CCC;vertical-align:baseline;overflow:hidden}.a2a_mini{min-width:200px;position:absolute;width:300px;z-index:9999997}.a2a_overlay{display:none;background:#616c7deb;backdrop-filter:blur(4px);-webkit-backdrop-filter:blur(4px);position:fixed;top:0;right:0;left:0;bottom:0;z-index:9999998;-webkit-tap-highlight-color:transparent;transition:opacity .14s,backdrop-filter .14s}.a2a_full{background:#FFF;border:1px solid #FFF;box-shadow:#2a2a2a1a 0 0 20px 10px;height:auto;height:calc(320px);top:15%;left:50%;margin-left:-320px;position:fixed;text-align:center;width:640px;z-index:9999999;transition:transform .14s,opacity .14s}.a2a_full_footer,.a2a_full_header,.a2a_full_services{border:0;margin:0;padding:12px;box-sizing:border-box}.a2a_full_header{padding-bottom:8px}.a2a_full_services{height:280px;overflow-y:scroll;padding:0 12px;-webkit-overflow-scrolling:touch}.a2a_full_services .a2a_i{display:inline-block;float:none;width:181px;width:calc(33.334% - 18px)}div.a2a_full_footer{font-size:12px;text-align:center;padding:8px 14px}div.a2a_full_footer a,div.a2a_full_footer a:visited{display:inline;font-size:12px;line-height:14px;padding:8px 14px}div.a2a_full_footer a:focus,div.a2a_full_footer a:hover{background:0 0;border:0;color:#0166FF}div.a2a_full_footer a span.a2a_s_a2a,div.a2a_full_footer a span.a2a_w_a2a{background-size:14px;border-radius:3px;display:inline-block;height:14px;line-height:14px;margin:0 3px 0 0;vertical-align:top;width:14px}.a2a_modal{height:0;left:50%;margin-left:-320px;position:fixed;text-align:center;top:15%;width:640px;z-index:9999999;transition:transform .14s,opacity .14s;-webkit-tap-highlight-color:transparent}.a2a_modal_body{background:0 0;border:0;font:24px sans-serif-light,HelveticaNeue-Light,"Helvetica Neue Light","Helvetica Neue",Arial,Helvetica,"Liberation Sans",sans-serif;position:relative;height:auto;width:auto}.a2a_thanks{color:#fff;height:auto;margin-top:20px;width:auto}.a2a_thanks>div:first-child{margin:0 0 40px 0}.a2a_thanks div *{height:inherit}#a2a_copy_link{background:#FFF;border:1px solid #FFF;cursor:pointer;margin-top:15%}label.a2a_s_link#a2a_copy_link_icon,label.a2a_w_link#a2a_copy_link_icon{background-size:48px;border-radius:0;display:inline-block;height:48px;left:0;line-height:48px;margin:0 3px 0 0;position:absolute;vertical-align:top;width:48px}#a2a_modal input#a2a_copy_link_text{background-color:transparent;border:0;color:#2A2A2A;cursor:pointer;font:inherit;height:48px;left:62px;max-width:initial;min-height:auto;padding:0;position:relative;width:564px;width:calc(100% - 76px)}#a2a_copy_link_copied{background-color:#0166ff;color:#fff;display:none;font:inherit;font-size:16px;margin-top:1px;padding:3px 8px}@media (forced-colors:active){.a2a_color_buttons a,.a2a_svg{forced-color-adjust:none}}@media (prefers-color-scheme:dark){.a2a_menu a,.a2a_menu a.a2a_i,.a2a_menu a.a2a_i:visited,.a2a_menu a.a2a_more,i.a2a_i{border-color:#2a2a2a!important;color:#fff!important}.a2a_menu a.a2a_i:active,.a2a_menu a.a2a_i:focus,.a2a_menu a.a2a_i:hover,.a2a_menu a.a2a_more:active,.a2a_menu a.a2a_more:focus,.a2a_menu a.a2a_more:hover,.a2a_menu_find_container{border-color:#444!important;background-color:#444!important}.a2a_menu:not(.a2a_thanks){background-color:#2a2a2a;border-color:#2a2a2a}.a2a_menu_find{color:#fff!important}.a2a_menu label.a2a_s_find svg{background-color:transparent!important}.a2a_menu label.a2a_s_find svg path{fill:#fff!important}.a2a_full{box-shadow:#00000066 0 0 20px 10px}.a2a_overlay{background-color:#373737eb}}@media print{.a2a_floating_style,.a2a_menu,.a2a_overlay{visibility:hidden}}@keyframes a2aFadeIn{from{opacity:0}to{opacity:1}}.a2a_starting{opacity:0}.a2a_starting.a2a_full,.a2a_starting.a2a_modal{transform:scale(.8)}@media (max-width:639px){.a2a_full{border-radius:0;top:15%;left:0;margin-left:auto;width:100%}.a2a_modal{left:0;margin-left:10px;width:calc(100% - 20px)}}@media (min-width:318px) and (max-width:437px){.a2a_full .a2a_full_services .a2a_i{width:calc(50% - 18px)}}@media (max-width:317px){.a2a_full .a2a_full_services .a2a_i{width:calc(100% - 18px)}}@media (max-height:436px){.a2a_full{bottom:40px;height:auto;top:40px}}@media (max-height:550px){.a2a_modal{top:30px}}@media (max-height:360px){.a2a_modal{top:20px}.a2a_thanks>div:first-child{margin-bottom:20px}}.a2a_menu a{color:#0166FF;text-decoration:none;font:16px sans-serif-light,HelveticaNeue-Light,"Helvetica Neue Light","Helvetica Neue",Arial,Helvetica,"Liberation Sans",sans-serif;line-height:14px;height:auto;width:auto;outline:0}.a2a_menu a.a2a_i:visited,.a2a_menu a.a2a_more{color:#0166FF}.a2a_menu a.a2a_i:active,.a2a_menu a.a2a_i:focus,.a2a_menu a.a2a_i:hover,.a2a_menu a.a2a_more:active,.a2a_menu a.a2a_more:focus,.a2a_menu a.a2a_more:hover{color:#2A2A2A;border-color:#EEE;border-style:solid;background-color:#EEE;text-decoration:none}.a2a_menu label.a2a_s_find{background-size:24px;height:24px;left:8px;pointer-events:auto;position:absolute;top:7px;width:24px}.a2a_menu label.a2a_s_find svg{background-color:#FFF}.a2a_menu label.a2a_s_find svg path{fill:#CCC}#a2a_menu_container{display:inline-block}.a2a_menu_find_container{border:1px solid #CCC;border-radius:6px;padding:2px 24px 2px 0;position:relative;text-align:left}.a2a_cols_container .a2a_col1{overflow-x:hidden;overflow-y:auto;-webkit-overflow-scrolling:touch}#a2a_modal input,#a2a_modal input[type=text],.a2a_menu input,.a2a_menu input[type=text]{display:block;background-image:none;box-shadow:none;line-height:100%;margin:0;outline:0;overflow:hidden;padding:0;-moz-box-shadow:none;-webkit-box-shadow:none;-webkit-appearance:none}#a2afeed_find_container input,#a2afeed_find_container input[type=text],#a2apage_find_container input,#a2apage_find_container input[type=text]{background-color:transparent;border:0;box-sizing:content-box;color:#2A2A2A;float:none;font:inherit;font-size:16px;height:28px;line-height:20px;left:38px;outline:0;margin:0;max-width:initial;min-height:initial;padding:2px 0;position:relative;width:99%}.a2a_clear{clear:both}.a2a_svg{background-repeat:no-repeat;display:block;overflow:hidden;height:32px;line-height:32px;padding:0;pointer-events:none;width:32px}.a2a_svg svg{background-repeat:no-repeat;background-position:50% 50%;border:none;display:block;left:0;margin:0 auto;overflow:hidden;padding:0;position:relative;top:0;width:auto;height:auto}a.a2a_i,i.a2a_i{display:block;float:left;border:1px solid #FFF;line-height:24px;padding:6px 8px;text-align:left;white-space:nowrap;overflow:hidden;text-overflow:ellipsis;width:132px}a.a2a_i span,a.a2a_more span{display:inline-block;overflow:hidden;vertical-align:top}a.a2a_i .a2a_svg{margin:0 6px 0 0}a.a2a_i .a2a_svg,a.a2a_more .a2a_svg{background-size:24px;height:24px;line-height:24px;width:24px}a.a2a_sss:hover{border-left:1px solid #CCC}a.a2a_more{border-bottom:1px solid #FFF;border-left:0;border-right:0;line-height:24px;margin:6px 0 0;padding:6px;-webkit-touch-callout:none}a.a2a_more span{height:24px;margin:0 6px 0 0}.a2a_kit .a2a_svg{background-repeat:repeat}.a2a_default_style a:empty,.a2a_flex_style a:empty,.a2a_floating_style a:empty,.a2a_overlay_style a:empty{display:none}.a2a_color_buttons a,.a2a_floating_style a{text-decoration:none}.a2a_default_style:not(.a2a_flex_style) a{float:left;line-height:16px;padding:0 2px}.a2a_default_style a:hover .a2a_svg,.a2a_floating_style a:hover .a2a_svg,.a2a_overlay_style a:hover .a2a_svg svg{opacity:.7}.a2a_overlay_style.a2a_default_style a:hover .a2a_svg{opacity:1}.a2a_default_style .a2a_count,.a2a_default_style .a2a_svg,.a2a_floating_style .a2a_svg,.a2a_menu .a2a_svg,.a2a_vertical_style .a2a_count,.a2a_vertical_style .a2a_svg{border-radius:4px}.a2a_default_style .a2a_counter img,.a2a_default_style .a2a_dd,.a2a_default_style .a2a_svg{float:left}.a2a_default_style .a2a_img_text{margin-right:4px}.a2a_default_style .a2a_divider{border-left:1px solid #000;display:inline;float:left;height:16px;line-height:16px;margin:0 5px}.a2a_kit a{cursor:pointer;transition:none}.a2a_floating_style{background-color:#fff;border-radius:6px;position:fixed;z-index:9999995}.a2a_overlay_style{z-index:2147483647}.a2a_floating_style,.a2a_overlay_style{animation:a2aFadeIn .2s ease-in;padding:4px}.a2a_vertical_style:not(.a2a_flex_style) a{clear:left;display:block;overflow:hidden;padding:4px}.a2a_floating_style.a2a_default_style{bottom:0}.a2a_floating_style.a2a_default_style a,.a2a_overlay_style.a2a_default_style a{padding:4px}.a2a_count{background-color:#fff;border:1px solid #ccc;box-sizing:border-box;color:#2a2a2a;display:block;float:left;font:12px Arial,Helvetica,sans-serif;height:16px;margin-left:4px;position:relative;text-align:center;width:50px}.a2a_count:after,.a2a_count:before{border:solid transparent;border-width:4px 4px 4px 0;content:"";height:0;left:0;line-height:0;margin:-4px 0 0 -4px;position:absolute;top:50%;width:0}.a2a_count:before{border-right-color:#ccc}.a2a_count:after{border-right-color:#fff;margin-left:-3px}.a2a_count span{animation:a2aFadeIn .14s ease-in}.a2a_vertical_style .a2a_counter img{display:block}.a2a_vertical_style .a2a_count{float:none;margin-left:0;margin-top:6px}.a2a_vertical_style .a2a_count:after,.a2a_vertical_style .a2a_count:before{border:solid transparent;border-width:0 4px 4px 4px;content:"";height:0;left:50%;line-height:0;margin:-4px 0 0 -4px;position:absolute;top:0;width:0}.a2a_vertical_style .a2a_count:before{border-bottom-color:#ccc}.a2a_vertical_style .a2a_count:after{border-bottom-color:#fff;margin-top:-3px}.a2a_color_buttons .a2a_count,.a2a_color_buttons .a2a_count:after,.a2a_color_buttons .a2a_count:before,.a2a_color_buttons.a2a_vertical_style .a2a_count:after,.a2a_color_buttons.a2a_vertical_style .a2a_count:before{background-color:transparent;border:none;color:#fff;float:none;width:auto}.a2a_color_buttons.a2a_vertical_style .a2a_count{margin-top:0}.a2a_flex_style{display:flex;align-items:flex-start;gap:0}.a2a_default_style.a2a_flex_style{left:0;right:0;width:100%}.a2a_vertical_style.a2a_flex_style{flex-direction:column;top:0;bottom:0}.a2a_flex_style a{display:flex;justify-content:center;flex:1;padding:4px}.a2a_flex_style.a2a_vertical_style a{flex-direction:column}.a2a_floating_style.a2a_color_buttons,.a2a_floating_style.a2a_flex_style{border-radius:0;padding:0}.a2a_floating_style.a2a_default_style.a2a_flex_style{bottom:0}.a2a_kit.a2a_flex_style .a2a_counter img,.a2a_kit.a2a_flex_style .a2a_dd,.a2a_kit.a2a_flex_style .a2a_svg{float:none}.a2a_nowrap{white-space:nowrap}.a2a_note{margin:0 auto;padding:9px;font-size:12px;text-align:center}.a2a_note .a2a_note_note{margin:0;color:#2A2A2A}.a2a_wide a{display:block;margin-top:3px;border-top:1px solid #EEE;text-align:center}.a2a_label{position:absolute!important;clip-path:polygon(0px 0px,0px 0px,0px 0px);-webkit-clip-path:polygon(0px 0px,0px 0px,0px 0px);overflow:hidden;height:1px;width:1px}.a2a_kit,.a2a_menu,.a2a_modal,.a2a_overlay{-ms-touch-action:manipulation;touch-action:manipulation;outline:0}.a2a_dd{-webkit-user-drag:none}.a2a_dd img{border:0}.a2a_button_facebook_like iframe{max-width:none}</style><link rel="preconnect" href="https://use.typekit.net"><meta http-equiv="P3P" content="CP=&quot;NOI DSP ADM OUR IND OTC&quot;"><link rel="stylesheet" href="https://quilt-cdn.janrain.com/HEAD/providers.css" type="text/css"><link id="altmetric-embed-css" rel="stylesheet" type="text/css" href="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed-59614f5c46b49b21eeef3bb28c4fb38d1e7069e8d014752fcb66e84942556802.css"></head>
    

    



    
        
        
        
            <body class="pb-ui website-mms-site loaded">
            






    
    
        





    
    
        
        
    
    
    







<input type="hidden" id="isRoMode" name="isRoMode" value="false">

        <div id="pb-page-content" data-ng-non-bindable="">
                
            <div data-pb-dropzone="main" data-pb-dropzone-name="Main">
                
                    
                        



        
        <header data-sticky="false" class="ng-header js_stickyAd"><a href="#mainContent" class="ng-skipToMainContent">Skip to main content</a><div class="ng-header_topAd"><div class="ng-header_topAd-content d-flex justify-content-center align-items-center">



        
        <div id="DTM_Position_Topbanner" class="ad">
 <!--emptycomment-->
</div>
</div></div><div class="ng-header_journal-navbar"><div class="ng-header_journal-navbar-content"><div class="container-fluid"><div class="row"><div class="ng-header_journal-navbar_left col-lg-8 col-sm-12 pr-lg-0 d-flex align-items-center"><div data-location="nejm_group_product_nav" class="ng-header_journalNavMenu">



        
        <nav data-location="nejm_group_product_nav" role="navigation" class="ng-journalNavMenu">
<ul class="ng-journalNavMenu_list">
<li class="ng-journalNavMenu_list-item"><a href="/" class="ng-journalNavMenu_mainLink active" aria-current="page" aria-label="The New England Journal of Medicine selected item"><span class="ng-journalNavMenu_mainLink-text d-lg-block d-none">The New England Journal of Medicine</span><span class="ng-journalNavMenu_mainLink-text d-lg-none d-block">NEJM</span></a></li>
<li class="ng-journalNavMenu_list-item"><a href="https://evidence.nejm.org/" class="ng-journalNavMenu_mainLink"><span class="ng-journalNavMenu_mainLink-text"><span class="ng-journalNavMenu_mainLink-text-firstWord">NEJM</span> Evidence</span></a></li>
<li class="ng-journalNavMenu_list-item"><a href="https://ai.nejm.org/" class="ng-journalNavMenu_mainLink"><span class="ng-journalNavMenu_mainLink-text"><span class="ng-journalNavMenu_mainLink-text-firstWord">NEJM</span> AI</span></a></li>
<li class="ng-journalNavMenu_list-item"><a href="https://catalyst.nejm.org/" class="ng-journalNavMenu_mainLink"><span class="ng-journalNavMenu_mainLink-text"><span class="ng-journalNavMenu_mainLink-text-firstWord">NEJM</span> Catalyst</span></a></li>
<li class="ng-journalNavMenu_list-item"><a href="https://www.jwatch.org/" class="ng-journalNavMenu_mainLink"><span class="ng-journalNavMenu_mainLink-text"><span class="ng-journalNavMenu_mainLink-text-firstWord">NEJM</span> Journal Watch</span></a></li>
</ul>
</nav>

</div></div><div class="ng-header_journal-navbar_right col-lg-4 pl-lg-0 d-none d-xl-flex align-items-center justify-content-end"><div class="ng-header_loginBar d-xl-flex align-items-lg-center">



        
        <div data-location="authstring_nav" class="ng-header_loginBar-menu"><span class="ng-simple-menu_mainLink-icon signIn newIcon-2"><span class="icon-component"><svg aria-hidden="true"><use xlink:href="/specs/products/mms-nextgen/mms/releasedAssets/icons/icons.spritemap.svg#user2"></use></svg></span></span><span class="ng-header_loginBar-signIn"><a href="/sign-in?uri=/doi/full/10.1056/NEJMoa2027540" class="ng-header_loginBar-signIn-link">Sign In</a></span><span class="ng-header_loginBar-separator">|</span><span class="ng-header_loginBar-createAcc"><a href="/action/storeProxy?action=register&amp;promo=ONFLNRC1" class="ng-header_loginBar-createAcc-link ro-mode_disabled">Create Account</a></span></div><div data-location="authstring_nav" class="ng-header_loginBar-subscribe pl-xl-16"><a href="/action/storeProxy?action=subscribe&amp;promo=ONF4NRS1" class="ng-header_loginBar-subscribe-btn ng-btn_primary ro-mode_disabled">Subscribe</a></div>
</div></div></div></div></div></div><div class="ng-header_instBanner d-none d-lg-block"></div><div class="ng-header_logoBar"><div class="container-fluid"><div class="row"><div data-location="logo" class="ng-header_logoBar_left col-lg-4 col-6 d-flex align-items-center justify-content-start"><a href="/" title="The New England Journal of Medicine homepage" class="ng-header_logo-link"><img src="/specs/products/mms-nextgen/mms/releasedAssets/images/other-images/nejm-logo-166667e91992a5212bc723b03e45d39f.svg" alt="The New England Journal of Medicine homepage" width="366" height="58" class="ng-header_logo-image"></a></div><div class="ng-header_logoBar_right ng-header_navBar col-lg-8 col-sm-12 p-lg-0 align-items-center justify-content-end"><div class="ng-header_navBar-content"><div class="container-fluid"><div class="row"><div class="ng-header_instBanner-md col-12 d-block d-lg-none"></div><div class="ng-header_loginBar-md col-12 d-block d-xl-none">



        
        <div data-location="authstring_nav" class="ng-header_loginBar-menu"><span class="ng-simple-menu_mainLink-icon signIn newIcon-2"><span class="icon-component"><svg aria-hidden="true"><use xlink:href="/specs/products/mms-nextgen/mms/releasedAssets/icons/icons.spritemap.svg#user2"></use></svg></span></span><span class="ng-header_loginBar-signIn"><a href="/sign-in?uri=/doi/full/10.1056/NEJMoa2027540" class="ng-header_loginBar-signIn-link">Sign In</a></span><span class="ng-header_loginBar-separator">|</span><span class="ng-header_loginBar-createAcc"><a href="/action/storeProxy?action=register&amp;promo=ONFLNRC1" class="ng-header_loginBar-createAcc-link ro-mode_disabled">Create Account</a></span></div><div data-location="authstring_nav" class="ng-header_loginBar-subscribe pl-xl-16"><a href="/action/storeProxy?action=subscribe&amp;promo=ONF4NRS1" class="ng-header_loginBar-subscribe-btn ng-btn_primary ro-mode_disabled">Subscribe</a></div>
</div><div class="ng-header_navBar_left col-lg-8 col-sm-12 d-flex align-items-center"><div class="ng-header_stickyLogo mr-32"><a href="/" title="The New England Journal of Medicine homepage" class="ng-header_stickyLogo-link"><img src="/specs/products/mms-nextgen/mms/releasedAssets/images/other-images/nejm-small-logo-070df7a3f4d8cfa2e71c3c45bb4b172f.svg" alt="The New England Journal of Medicine homepage" class="ng-header_stickyLogo-image"></a></div><div class="ng-header_mainMenu">









    
    
        <div data-widget-def="menuWidget" data-widget-id="97fb3983-db63-4b0b-97dd-d9bb7929fce1" data-location="main_nav">
        



        
        <nav class="ng-menu"><ul class="ng-menu_list ng-simple-menu"><li class="ng-menu_list-item ng-simple-menu_item hasChildren"><a href="/toc/nejm/current" class="ng-simple-menu_mainLink"><span class="ng-simple-menu_mainLink-text">current issue</span><span class="ng-simple-menu_mainLink-arrowIcon"><span class="icon-component "><svg aria-hidden="true" style=""><use xlink:href="/specs/products/mms-nextgen/mms/releasedAssets/icons/icons-3acb348e68a3edd0c676698e8d598c68.spritemap.svg#arrows-down"></use></svg></span></span></a><div class="ng-simple-menu_dropblock"><div class="ng-simple-menu_dropblock-cont"><div class="ng-simple-menu_list"><ul class="ng-simple-menu_list-items"><li class="ng-simple-menu_list-item"><a href="/toc/nejm/current" class="ng-simple-menu_list-link">VIEW CURRENT ISSUE</a></li><li class="ng-simple-menu_list-item"><a href="/toc/nejm/recently-published" class="ng-simple-menu_list-link">BROWSE RECENTLY PUBLISHED</a></li><li class="ng-simple-menu_list-item"><a href="/loi/nejm" class="ng-simple-menu_list-link">BROWSE ALL ISSUES</a></li></ul></div></div></div></li><li class="ng-menu_list-item ng-simple-menu_item hasChildren"><a href="/medical-specialties" class="ng-simple-menu_mainLink"><span class="ng-simple-menu_mainLink-text">SPECIALTIES</span><span class="ng-simple-menu_mainLink-arrowIcon"><span class="icon-component "><svg aria-hidden="true" style=""><use xlink:href="/specs/products/mms-nextgen/mms/releasedAssets/icons/icons-3acb348e68a3edd0c676698e8d598c68.spritemap.svg#arrows-down"></use></svg></span></span></a><div class="ng-simple-menu_dropblock"><div class="ng-simple-menu_dropblock-cont"><div class="ng-simple-menu_list"><ul class="ng-simple-menu_list-items"><li class="ng-simple-menu_list-item"><a href="/browse/specialty/cardiology" class="ng-simple-menu_list-link">Cardiology</a></li><li class="ng-simple-menu_list-item"><a href="/browse/specialty/clinical-medicine" class="ng-simple-menu_list-link">Clinical Medicine</a></li><li class="ng-simple-menu_list-item"><a href="/browse/specialty/endocrinology" class="ng-simple-menu_list-link">Endocrinology</a></li><li class="ng-simple-menu_list-item"><a href="/browse/specialty/gastroenterology" class="ng-simple-menu_list-link">Gastroenterology</a></li><li class="ng-simple-menu_list-item"><a href="/browse/specialty/hematology-oncology" class="ng-simple-menu_list-link">Hematology/Oncology</a></li><li class="ng-simple-menu_list-item"><a href="/browse/specialty/infectious-disease" class="ng-simple-menu_list-link">Infectious Disease</a></li><li class="ng-simple-menu_list-item"><a href="/browse/specialty/nephrology" class="ng-simple-menu_list-link">Nephrology</a></li><li class="ng-simple-menu_list-item"><a href="/browse/specialty/neurology-neurosurgery" class="ng-simple-menu_list-link">Neurology/Neurosurgery</a></li><li class="ng-simple-menu_list-item"><a href="/browse/specialty/obstetrics-gynecology" class="ng-simple-menu_list-link">Obstetrics/Gynecology</a></li><li class="ng-simple-menu_list-item"><a href="/browse/specialty/pediatrics" class="ng-simple-menu_list-link">Pediatrics</a></li><li class="ng-simple-menu_list-item"><a href="/browse/specialty/pulmonary-critical-care" class="ng-simple-menu_list-link">Pulmonary/Critical Care</a></li><li class="ng-simple-menu_list-item"><a href="/browse/specialty/surgery" class="ng-simple-menu_list-link">Surgery</a></li><li class="ng-simple-menu_list-item"><a href="/medical-specialties" class="ng-simple-menu_list-link">View All Specialties</a></li></ul></div></div></div></li><li class="ng-menu_list-item ng-simple-menu_item hasChildren"><a href="/topics" class="ng-simple-menu_mainLink"><span class="ng-simple-menu_mainLink-text">TOPICS</span><span class="ng-simple-menu_mainLink-arrowIcon"><span class="icon-component "><svg aria-hidden="true" style=""><use xlink:href="/specs/products/mms-nextgen/mms/releasedAssets/icons/icons-3acb348e68a3edd0c676698e8d598c68.spritemap.svg#arrows-down"></use></svg></span></span></a><div class="ng-simple-menu_dropblock"><div class="ng-simple-menu_dropblock-cont"><div class="ng-simple-menu_list"><ul class="ng-simple-menu_list-items"><li class="ng-simple-menu_list-item"><a href="/ai-in-medicine" class="ng-simple-menu_list-link">AI in Medicine</a></li><li class="ng-simple-menu_list-item"><a href="/browse/specialty/climate-change" class="ng-simple-menu_list-link">Climate Change</a></li><li class="ng-simple-menu_list-item"><a href="/coronavirus" class="ng-simple-menu_list-link">Coronavirus</a></li><li class="ng-simple-menu_list-item"><a href="/equity" class="ng-simple-menu_list-link">Efforts toward Equity</a></li><li class="ng-simple-menu_list-item"><a href="/firearm-injury-prevention" class="ng-simple-menu_list-link">Firearm Injury Prevention</a></li><li class="ng-simple-menu_list-item"><a href="/nam" class="ng-simple-menu_list-link">From the National Academy of Medicine</a></li><li class="ng-simple-menu_list-item"><a href="/fundamentals-of-medical-ethics" class="ng-simple-menu_list-link">Fundamentals of Medical Ethics</a></li><li class="ng-simple-menu_list-item"><a href="/gray-matters" class="ng-simple-menu_list-link">Gray Matters</a></li><li class="ng-simple-menu_list-item"><a href="/browse/specialty/health-policy" class="ng-simple-menu_list-link">Health Policy</a></li><li class="ng-simple-menu_list-item"><a href="/medicine-and-society" class="ng-simple-menu_list-link">Medicine and Society</a></li><li class="ng-simple-menu_list-item"><a href="/nutrition-in-medicine" class="ng-simple-menu_list-link">Nutrition in Medicine</a></li><li class="ng-simple-menu_list-item"><a href="/outbreaks" class="ng-simple-menu_list-link">Outbreaks Center</a></li><li class="ng-simple-menu_list-item"><a href="/race-and-medicine" class="ng-simple-menu_list-link">Race and Medicine</a></li><li class="ng-simple-menu_list-item"><a href="/recognizing-historical-injustices" class="ng-simple-menu_list-link">Recognizing Historical Injustices and the Journal</a></li><li class="ng-simple-menu_list-item"><a href="/tobacco-use-reduction" class="ng-simple-menu_list-link">Tobacco Use Reduction</a></li><li class="ng-simple-menu_list-item"><a href="/topics" class="ng-simple-menu_list-link">View All Topics</a></li></ul></div></div></div></li><li class="ng-menu_list-item ng-simple-menu_item hasChildren"><a href="/multimedia" class="ng-simple-menu_mainLink"><span class="ng-simple-menu_mainLink-text">MULTIMEDIA</span><span class="ng-simple-menu_mainLink-arrowIcon"><span class="icon-component "><svg aria-hidden="true" style=""><use xlink:href="/specs/products/mms-nextgen/mms/releasedAssets/icons/icons-3acb348e68a3edd0c676698e8d598c68.spritemap.svg#arrows-down"></use></svg></span></span></a><div class="ng-simple-menu_dropblock"><div class="ng-simple-menu_dropblock-cont"><div class="ng-simple-menu_list"><ul class="ng-simple-menu_list-items"><li class="ng-simple-menu_list-item"><a href="/rss-feed" class="ng-simple-menu_list-link">Podcasts</a></li><li class="ng-simple-menu_list-item"><a href="/double-take" class="ng-simple-menu_list-link">Double Takes</a></li><li class="ng-simple-menu_list-item"><a href="https://illustrated-glossary.nejm.org/" class="ng-simple-menu_list-link">Illustrated Glossary</a></li><li class="ng-simple-menu_list-item"><a href="/image-challenge" class="ng-simple-menu_list-link">Image Challenge</a></li><li class="ng-simple-menu_list-item"><a href="/browse/nejm-media-type/images-in-clinical-medicine" class="ng-simple-menu_list-link">Images in Clinical Medicine</a></li><li class="ng-simple-menu_list-item"><a href="/browse/nejm-media-type/interactive-medical-case" class="ng-simple-menu_list-link">Interactive Medical Cases</a></li><li class="ng-simple-menu_list-item"><a href="/plain-language-research-summaries" class="ng-simple-menu_list-link">Plain Language/Research Summaries</a></li><li class="ng-simple-menu_list-item"><a href="/multimedia/quick-take-video" class="ng-simple-menu_list-link">Quick Takes</a></li><li class="ng-simple-menu_list-item"><a href="/browse/nejm-media-type/videos-in-clinical-medicine" class="ng-simple-menu_list-link">Videos in Clinical Medicine</a></li><li class="ng-simple-menu_list-item"><a href="/multimedia" class="ng-simple-menu_list-link">View All Multimedia</a></li></ul></div></div></div></li><li class="ng-menu_list-item ng-simple-menu_item hasChildren"><a href="/learning" class="ng-simple-menu_mainLink"><span class="ng-simple-menu_mainLink-text">LEARNING/CME</span><span class="ng-simple-menu_mainLink-arrowIcon"><span class="icon-component "><svg aria-hidden="true" style=""><use xlink:href="/specs/products/mms-nextgen/mms/releasedAssets/icons/icons-3acb348e68a3edd0c676698e8d598c68.spritemap.svg#arrows-down"></use></svg></span></span></a><div class="ng-simple-menu_dropblock"><div class="ng-simple-menu_dropblock-cont"><div class="ng-simple-menu_list"><ul class="ng-simple-menu_list-items"><li class="ng-simple-menu_list-item"><a href="/continuing-medical-education" class="ng-simple-menu_list-link">Weekly CME</a></li><li class="ng-simple-menu_list-item"><a href="/cme-ce/obesity" class="ng-simple-menu_list-link">Obesity CME/CE</a></li><li class="ng-simple-menu_list-item"><a href="/learning" class="ng-simple-menu_list-link">VIEW ALL LEARNING/CME</a></li></ul></div></div></div></li><li class="ng-menu_list-item ng-simple-menu_item"><a href="/author-center/home" class="ng-simple-menu_mainLink"><span class="ng-simple-menu_mainLink-text">AUTHOR CENTER</span></a></li></ul></nav>

        </div>
    

</div><button aria-label="Search" class="ng-header_searchBtn searchBtnNav d-block ml-24"><span class="icon-component "><svg aria-hidden="true" style=""><use xlink:href="/specs/products/mms-nextgen/mms/releasedAssets/icons/icons-3acb348e68a3edd0c676698e8d598c68.spritemap.svg#search"></use></svg></span></button></div><div class="ng-header_loginBar ng-header_loginBar-sticky col-4">



        
        <div data-location="authstring_nav" class="ng-header_loginBar-menu"><span class="ng-simple-menu_mainLink-icon signIn newIcon-2"><span class="icon-component"><svg aria-hidden="true"><use xlink:href="/specs/products/mms-nextgen/mms/releasedAssets/icons/icons.spritemap.svg#user2"></use></svg></span></span><span class="ng-header_loginBar-signIn"><a href="/sign-in?uri=/doi/full/10.1056/NEJMoa2027540" class="ng-header_loginBar-signIn-link">Sign In</a></span><span class="ng-header_loginBar-separator">|</span><span class="ng-header_loginBar-createAcc"><a href="/action/storeProxy?action=register&amp;promo=ONFLNRC1" class="ng-header_loginBar-createAcc-link ro-mode_disabled">Create Account</a></span></div><div data-location="authstring_nav" class="ng-header_loginBar-subscribe pl-xl-16"><a href="/action/storeProxy?action=subscribe&amp;promo=ONF4NRS1" class="ng-header_loginBar-subscribe-btn ng-btn_primary ro-mode_disabled">Subscribe</a></div>
</div></div></div></div></div><div class="ng-header_logoBar_right-lg col-lg-8 col-6 d-flex align-items-center justify-content-end d-xl-none"><button aria-label="Search" class="ng-header_searchBtn d-flex justify-content-end"><span class="icon-component "><svg aria-hidden="true" style=""><use xlink:href="/specs/products/mms-nextgen/mms/releasedAssets/icons/icons-3acb348e68a3edd0c676698e8d598c68.spritemap.svg#search"></use></svg></span></button><div class="ng-header_openCloseBtns d-flex align-items-center justify-content-end"><button aria-label="Open" class="ng-header_openBtn"><span class="icon-component "><svg aria-hidden="true" style=""><use xlink:href="/specs/products/mms-nextgen/mms/releasedAssets/icons/icons-3acb348e68a3edd0c676698e8d598c68.spritemap.svg#burger"></use></svg></span></button><button aria-label="Close" class="ng-header_closeBtn"><span class="icon-component "><svg aria-hidden="true" style=""><use xlink:href="/specs/products/mms-nextgen/mms/releasedAssets/icons/icons-3acb348e68a3edd0c676698e8d598c68.spritemap.svg#close"></use></svg></span></button></div></div><div class="ng-header_quickSearch col-12"><div class="ng-header_quickSearch-content">



        
        <div class="ng-quick-search js-ng-quick-search"><form action="/search" method="get" class="ng-quick-search_form js-form"><div class="ng-quick-search_inputArea js-inputArea"><input type="search" name="q" placeholder="Enter keyword, author, title or citation" autocomplete="off" value="" required="required" class="ng-quick-search_allField ng-large-text-input js-allField js-allField-def-tmpl ui-autocomplete-input"><button type="submit" aria-label="Search Button" class="ng-quick-search_iconBtn d-xl-none d-block js-submitBtn"><span class="icon-component "><svg aria-hidden="true" style=""><use xlink:href="/specs/products/mms-nextgen/mms/releasedAssets/icons/icons-3acb348e68a3edd0c676698e8d598c68.spritemap.svg#search"></use></svg></span></button><ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></div><div class="ng-quick-search_btnsArea d-none d-xl-flex align-items-center justify-content-end"><a href="/search/advanced" class="ng-quick-search_advSearchLink ng-btn_link js-advancedSearchLink">Advanced Search</a><button type="submit" class="ng-quick-search_textBtn ng-btn_secondary ng-btn_iconRight js-submitBtn"><span class="ng-btn_text">SEARCH</span><span class="icon-component "><svg aria-hidden="true" style=""><use xlink:href="/specs/products/mms-nextgen/mms/releasedAssets/icons/icons-3acb348e68a3edd0c676698e8d598c68.spritemap.svg#arrows-right"></use></svg></span></button></div></form></div>
</div></div></div></div></div></header><div class="ng-header_overlay"></div><div class="ng-header_after">









    
    
        <div data-widget-def="literatumAd" data-widget-id="4931ddbd-d46e-4597-b4fd-92549e9847ca" id="ad-global-banner-FULLx64-1">
        



        
        



    

    

    
        
    



        </div>
    

</div>

                    
                        



        
        <div>









    
    
        <main data-widget-def="axelPublicationContent" data-widget-id="fcdb5261-d6a2-4a9c-81d5-3a3e2304e9c1" id="mainContent">
        



        
        <div class="article-tools__savePopup"><div class="ng-save"><input type="hidden" value="/action/getSavedTags" class="getKeywordsServiceUrl"><input type="hidden" value="/action/mmsSaveItemsService?itemType=article" class="saveServiceUrl"><input type="hidden" value="article" class="saveType"><input type="hidden" value="10.1056/NEJMoa2027540" class="inputDoi"><input type="hidden" value="D.A. Moses and Others" class="inputAuthor"><input type="hidden" value="N Engl J Med 2021;385:217-227" class="inputCitation"><input type="hidden" value="07-14-2021" class="inputEPubDate"><input type="hidden" value="July 2021" class="inputCoverDate"><input type="hidden" value="Original Article" class="inputContentType"><input type="hidden" value="Neuroprosthesis for Decoding Speech in a Paralyzed Person with Anarthria" class="inputArticleTitle"><input type="hidden" value="/browse/nejm-article-type/original-article" class="inputContentTypeUrl"><button type="button" id="saveArticleShowPopupBtn" aria-hidden="true" tabindex="-1" class="ng-save-btn ng-btn_secondary isLoggedOut">Save</button></div></div><div class="article-tools__articleAlertPopup"><div id="articleAlertModal" tabindex="-1" role="dialog" aria-labelledby="exampleModalCenterTitle" aria-hidden="true" class="ng-modal modal"><div role="document" class="ng-modal_dialog modal-dialog modal-dialog-centered"><div class="ng-modal_content modal-content"><div class="ng-modal_header modal-header"><h5 id="articleAlertModalTitle" class="ng-modal_title modal-title">Create an E-mail Alert for This Article</h5><button type="button" data-dismiss="modal" aria-label="Close" class="ng-modal_close close"><span aria-hidden="true"><span class="icon-component "><svg aria-hidden="true" style=""><use xlink:href="/specs/products/mms-nextgen/mms/releasedAssets/icons/icons-3acb348e68a3edd0c676698e8d598c68.spritemap.svg#close"></use></svg></span></span></button></div><div class="ng-modal_body modal-body"></div></div></div></div></div><div class="ng-do-media_popup"><div id="doPopup" tabindex="-1" role="dialog" aria-labelledby="exampleModalCenterTitle" aria-hidden="true" class="ng-modal modal"><div role="document" class="ng-modal_dialog modal-dialog modal-dialog-centered"><div class="ng-modal_content modal-content"><div class="ng-modal_header modal-header"><button type="button" data-dismiss="modal" aria-label="Close" class="ng-modal_close close"><span aria-hidden="true"><span class="icon-component "><svg aria-hidden="true" style=""><use xlink:href="/specs/products/mms-nextgen/mms/releasedAssets/icons/icons-3acb348e68a3edd0c676698e8d598c68.spritemap.svg#close"></use></svg></span></span></button></div><div class="ng-modal_body modal-body"></div></div></div></div></div><link id="build-style-article" rel="stylesheet" type="text/css" href="/products/mms-nextgen/mms/releasedAssets/css/build-article-5b89b331018866a4a965.css"><article xmlns="http://www.w3.org/1999/xhtml" data-design="pill" data-has="right-rail" data-type="research-article" vocab="http://schema.org/" typeof="ScholarlyArticle" lang="en" dir="ltr"><header data-extent="frontmatter" data-location="header_article"><div class="core-container"><div data-article-access="free" data-article-access-type="free" class="meta-panel"><div class="meta-panel__left-content"><div class="meta-panel__type"><a href="/browse/nejm-article-type/original-article">Original Article</a></div></div><div class="meta-panel__right-content"><div class="meta-panel__share">









    
    
        <div data-widget-def="UX3share" data-widget-id="eee5f139-16f2-48f8-97ea-1b114367da16" data-location="share_tools_article">
        



        
        <!-- Go to https://www.addtoany.com/buttons/customize/ to customize your tools --><script type="text/javascript" defer="defer" src="https://static.addtoany.com/menu/page.js" nonce="94d68cb4c580debe-GRU"></script><div class="share"><div class="share__block share__inline-links"><div class="pb-dropzone" data-pb-dropzone="shareBlock" title="shareBlock"></div><span class="sr-only">Share on</span><ul class="d-flex list-unstyled a2a a2a_kit a2a_default_style mb-0 a2a_kit_size_32" style="line-height: 32px;"><li class="a2a_listitem_custom"><a role="link" title="Facebook" data-interactiontype="social" class="share__link a2a_button_facebook" target="_blank" rel="nofollow noopener" href="/#facebook"><span class="icon-component " style="height: 24px; width: 24px"><svg aria-hidden="true" style="height: 24px; width: 24px"><use xlink:href="/specs/products/mms-nextgen/mms/releasedAssets/icons/icons-3acb348e68a3edd0c676698e8d598c68.spritemap.svg#social-facebook"></use></svg></span></a></li><li class="a2a_listitem_custom"><a role="link" title="X (formerly Twitter)" data-interactiontype="social" class="share__link a2a_button_twitter" target="_blank" rel="nofollow noopener" href="/#twitter"><span class="icon-component " style="height: 24px; width: 24px"><svg aria-hidden="true" style="height: 24px; width: 24px"><use xlink:href="/specs/products/mms-nextgen/mms/releasedAssets/icons/icons-3acb348e68a3edd0c676698e8d598c68.spritemap.svg#social-twitter"></use></svg></span></a></li><li class="a2a_listitem_custom"><a role="link" title="Linked In" data-interactiontype="social" class="share__link a2a_button_linkedin" target="_blank" rel="nofollow noopener" href="/#linkedin"><span class="icon-component " style="height: 24px; width: 24px"><svg aria-hidden="true" style="height: 24px; width: 24px"><use xlink:href="/specs/products/mms-nextgen/mms/releasedAssets/icons/icons-3acb348e68a3edd0c676698e8d598c68.spritemap.svg#social-linkedin"></use></svg></span></a></li><li class="a2a_listitem_custom"><a role="link" title="Email" data-interactiontype="content_email_click" class="share__link a2a_button_email" target="_blank" rel="nofollow noopener" href="/#email"><span class="icon-component " style="height: 24px; width: 24px"><svg aria-hidden="true" style="height: 24px; width: 24px"><use xlink:href="/specs/products/mms-nextgen/mms/releasedAssets/icons/icons-3acb348e68a3edd0c676698e8d598c68.spritemap.svg#social-email"></use></svg></span></a></li><li class="a2a_listitem_custom"><a role="link" title="Bluesky" data-interactiontype="social" class="share__link a2a_button_bluesky" target="_blank" rel="nofollow noopener" href="/#bluesky"><span class="icon-component " style="height: 24px; width: 24px"><svg aria-hidden="true" style="height: 24px; width: 24px"><use xlink:href="/specs/products/mms-nextgen/mms/releasedAssets/icons/icons-3acb348e68a3edd0c676698e8d598c68.spritemap.svg#social-bluesky"></use></svg></span></a></li></ul></div></div>

        </div>
    

</div></div></div><h1 property="name">Neuroprosthesis for Decoding Speech in a Paralyzed Person with Anarthria</h1><div class="core-relations my-3"></div><div class="contributors"><span class="authors"><span class="heading">Authors</span>: <span role="list"><span property="author" typeof="Person" role="listitem"><span property="givenName">David A.</span> <span property="familyName">Moses</span>, <span property="honorificSuffix">Ph.D.</span> <a class="orcid-id" href="https://orcid.org/0000-0002-5786-5334" property="identifier" aria-label="ORCID identifier" target="_blank">https://orcid.org/0000-0002-5786-5334</a></span>, <span property="author" typeof="Person" role="listitem"><span property="givenName">Sean L.</span> <span property="familyName">Metzger</span>, <span property="honorificSuffix">M.S.</span></span>, <span property="author" typeof="Person" role="listitem"><span property="givenName">Jessie R.</span> <span property="familyName">Liu</span>, <span property="honorificSuffix">B.S.</span></span>, <span property="author" typeof="Person" role="listitem"><span property="givenName">Gopala K.</span> <span property="familyName">Anumanchipalli</span>, <span property="honorificSuffix">Ph.D.</span></span>, <span property="author" typeof="Person" role="listitem"><span property="givenName">Joseph G.</span> <span property="familyName">Makin</span>, <span property="honorificSuffix">Ph.D.</span></span>, <span property="author" typeof="Person" role="listitem"><span property="givenName">Pengfei F.</span> <span property="familyName">Sun</span>, <span property="honorificSuffix">Ph.D.</span> <a class="orcid-id" href="https://orcid.org/0000-0002-4101-9416" property="identifier" aria-label="ORCID identifier" target="_blank">https://orcid.org/0000-0002-4101-9416</a></span>, <span property="author" typeof="Person" role="listitem"><span property="givenName">Josh</span> <span property="familyName">Chartier</span>, <span property="honorificSuffix">Ph.D.</span></span><span data-displayed-on="all">, <span data-action="reveal" tabindex="0" role="listitem">+5</span> </span><span data-hidden-on="all">, <span property="author" typeof="Person" role="listitem"><span property="givenName">Maximilian E.</span> <span property="familyName">Dougherty</span>, <span property="honorificSuffix">B.A.</span></span></span><span data-hidden-on="all">, <span property="author" typeof="Person" role="listitem"><span property="givenName">Patricia M.</span> <span property="familyName">Liu</span>, <span property="honorificSuffix">M.A.</span></span></span><span data-hidden-on="all">, <span property="author" typeof="Person" role="listitem"><span property="givenName">Gary M.</span> <span property="familyName">Abrams</span>, <span property="honorificSuffix">M.D.</span></span></span><span data-hidden-on="all">, <span property="author" typeof="Person" role="listitem"><span property="givenName">Adelyn</span> <span property="familyName">Tu-Chan</span>, <span property="honorificSuffix">D.O.</span></span></span><span data-hidden-on="all">, <span property="author" typeof="Person" role="listitem"><span property="givenName">Karunesh</span> <span property="familyName">Ganguly</span>, <span property="honorificSuffix">M.D., Ph.D.</span></span></span>, and <span property="author" typeof="Person" role="listitem"><span property="givenName">Edward F.</span> <span property="familyName">Chang</span>, <span property="honorificSuffix">M.D.</span></span><span data-displayed-on="none" data-on-display="all" aria-hidden="true"> <span data-action="hide" tabindex="0" role="listitem">-5</span></span></span></span><a href="#tab-contributors" class="to-authors-affiliations" data-id="article-authors-viewall">Author Info &amp; Affiliations</a></div><div class="core-self-citation"><div class="core-date-published">Published <span property="datePublished">July 14, 2021</span></div><div property="isPartOf" typeof="Periodical"><span property="name">N Engl J Med</span> 2021<span property="isPartOf" typeof="PublicationVolume">;<span property="volumeNumber">385</span></span>:<span property="pageStart">217</span>-<span property="pageEnd">227</span></div><div class="doi">DOI: 10.1056/NEJMoa2027540</div><div class="core-enumeration"><a href="/toc/nejm/385/3"><span property="isPartOf" typeof="PublicationVolume">VOL. <span property="volumeNumber">385</span></span> <span property="isPartOf" typeof="PublicationIssue">NO. <span property="issueNumber">3</span></span></a></div><div><a href="#tab-information">Copyright © 2021</a></div></div><div class="info-panel"><div class="info-panel__left-content"><div class="info-panel__metrics info-panel__item"></div></div><div data-location="tools_article" class="info-panel__right-content"><div class="info-panel__article_tools info-panel__item">



        
        <div data-permission="/servlet/linkout?type=rightslink&amp;url=publisherName%3Dmassmed%26author%3DDavid%2BA.%2BMoses%252C%2BSean%2BL.%2BMetzger%252C%2BJessie%2BR.%2BLiu%252C%2Bet%2Bal%26publication%3Dnejm%26orderBeanReset%3Dtrue%26volumeNum%3D385%26issueNum%3D3%26contentID%3D10.1056%252FNEJMoa2027540%26title%3DNeuroprosthesis%2Bfor%2BDecoding%2BSpeech%2Bin%2Ba%2BParalyzed%2BPerson%2Bwith%2BAnarthria%26publicationDate%3D07%252F15%252F2021" class="article-tools"><button id="articleToolsAlertBtn" data-url="/action/addCitationAlert?doi=10.1056%2FNEJMoa2027540" data-toggle="" data-target="#articleAlertModal" aria-label="Sign in or create account to add an article alert" data-interactiontype="article_alert" class="article-tools__citation btn btn--slim isLoggedOut"><span title="" data-toggle="tooltip" class="d-inline-block" data-original-title="Sign in or create account to add an article alert"><span class="icon-component "><svg aria-hidden="true" style=""><use xlink:href="/specs/products/mms-nextgen/mms/releasedAssets/icons/icons-3acb348e68a3edd0c676698e8d598c68.spritemap.svg#alerts"></use></svg></span></span></button><button id="articleToolsSaveBtn" data-toggle="modal" data-target="#saveArticle" aria-label="Sign in or create account to save this article" data-interactiontype="article_tools_save_click" class="article-tools__favorite btn btn--slim isLoggedOut"><span title="" data-toggle="tooltip" class="d-inline-block" data-original-title="Sign in or create account to save this article"><span class="icon-component "><svg aria-hidden="true" style=""><use xlink:href="/specs/products/mms-nextgen/mms/releasedAssets/icons/icons-3acb348e68a3edd0c676698e8d598c68.spritemap.svg#bookmarkFilled"></use></svg></span></span></button><a href="/servlet/linkout?type=rightslink&amp;url=publisherName%3Dmassmed%26author%3DDavid%2BA.%2BMoses%252C%2BSean%2BL.%2BMetzger%252C%2BJessie%2BR.%2BLiu%252C%2Bet%2Bal%26publication%3Dnejm%26orderBeanReset%3Dtrue%26volumeNum%3D385%26issueNum%3D3%26contentID%3D10.1056%252FNEJMoa2027540%26title%3DNeuroprosthesis%2Bfor%2BDecoding%2BSpeech%2Bin%2Ba%2BParalyzed%2BPerson%2Bwith%2BAnarthria%26publicationDate%3D07%252F15%252F2021" target="_blank" title="" data-toggle="tooltip" aria-label="Permissions" data-interactiontype="article_tools_permissions_click" class="article-tools__permissions btn btn--slim" data-original-title="Permissions"><span class="icon-component "><svg aria-hidden="true" style=""><use xlink:href="/specs/products/mms-nextgen/mms/releasedAssets/icons/icons-3acb348e68a3edd0c676698e8d598c68.spritemap.svg#permissions"></use></svg></span></a><a href="/about-nejm/reprints" title="" data-toggle="tooltip" aria-label="Reprints" data-interactiontype="article_tools_reprints_click" class="article-tools__reprints btn btn--slim" data-original-title="Reprints"><span class="icon-component "><svg aria-hidden="true" style=""><use xlink:href="/specs/products/mms-nextgen/mms/releasedAssets/icons/icons-3acb348e68a3edd0c676698e8d598c68.spritemap.svg#reprints"></use></svg></span></a><a href="/cms/asset/cf3bf606-a5a2-4937-aa75-85bcf4f00d9b/nejmoa2027540.pptx" target="_blank" title="" data-toggle="tooltip" aria-label="Download Slides" data-interactiontype="article_tools_slide_set_download" data-multimedia-type="Article Slideset" data-multimedia-filename="nejmoa2027540.pptx" class="article-tools__downloadSlides btn btn--slim" data-original-title="Download Slides"><span class="icon-component "><svg aria-hidden="true" style=""><use xlink:href="/specs/products/mms-nextgen/mms/releasedAssets/icons/icons-3acb348e68a3edd0c676698e8d598c68.spritemap.svg#download"></use></svg></span></a><div class="article-tools__permissionsPopup"><div id="permissionsModal" tabindex="-1" role="dialog" aria-labelledby="exampleModalCenterTitle" aria-hidden="true" class="ng-modal modal"><div role="document" class="ng-modal_dialog modal-dialog modal-dialog-centered"><div class="ng-modal_content modal-content"><div class="ng-modal_header modal-header"><h5 id="permissionsModalTitle" class="ng-modal_title modal-title">Permissions</h5><button type="button" data-dismiss="modal" aria-label="Close" class="ng-modal_close close"><span aria-hidden="true"><span class="icon-component "><svg aria-hidden="true" style=""><use xlink:href="/specs/products/mms-nextgen/mms/releasedAssets/icons/icons-3acb348e68a3edd0c676698e8d598c68.spritemap.svg#close"></use></svg></span></span></button></div><div class="ng-modal_body modal-body">For permission requests, please contact NEJM Reprints at <a href="mailto:reprints@nejm.org">reprints@nejm.org</a></div></div></div></div></div></div>
</div><div class="info-panel__citations info-panel__item"><a href="#tab-citations" class="btn btn--slim" aria-label="View Citations" data-toggle="tooltip" data-original-title="View Citations" data-interactiontype="article_tools_citation_download" data-multimedia-type="Citation"><i aria-hidden="true" class="icon-format_quote"></i></a></div><div class="info-panel__formats info-panel__item"><a href="https://www.nejm.org/doi/pdf/10.1056/NEJMoa2027540" class="btn btn--pdf btn--slim" aria-label="View PDF" data-toggle="tooltip" data-original-title="View PDF" data-behavior="trackDownloadEvent" data-doi="10.1056/NEJMoa2027540" data-interactiontype="article_tools_download_pdf" data-multimedia-type="Article PDF" data-multimedia-filename="nejmoa2027540.pdf"><i aria-hidden="true" class="icon-PDF"></i></a></div></div></div></div></header><div data-core-nav="header" data-extent="frontmatter"><div class="core-nav-wrapper core-container" aria-label="Article navigation"><div class="core-sections-menu"><button data-id="article-toolbar-showhide" aria-controls="article_sections_menu" aria-expanded="false" aria-label="Toggle section navigation menu" style="margin-top: 0px;"><i class="icon-list" aria-hidden="true"></i><span>Contents</span></button><nav id="article_sections_menu" aria-label="Contents" data-core-nav="article" style="margin-top: 0px;"><ul><li><a href="#summary-abstract" aria-current="true">Abstract</a></li><li><a href="#sec-1" aria-current="false">Methods</a></li><li><a href="#sec-2" aria-current="false">Results</a></li><li><a href="#sec-3" aria-current="false">Discussion</a></li><li class="bordered"><a href="#backnotes" aria-current="false">Notes</a></li><li><a href="#supplementary-materials" aria-current="false">Supplementary Material</a></li><li><a href="#bibliography" aria-current="false">References</a></li></ul></nav></div><nav id="article_collateral_menu"><ul data-core-nav="collateral" class="collateral-pill" style="margin-top: 0px;"><li><a href="#core-collateral-info" data-id="article-nav-menubar-info" title="" tabindex="0" data-toggle="tooltip" data-placement="left" data-offset="4px, 16px" data-original-title="Information &amp; Authors"><i aria-hidden="true" class="icon-info"></i><span class="sr-only">Information &amp; Authors</span></a></li><li><a href="#core-collateral-metrics" data-id="article-nav-menubar-metrics" title="" tabindex="0" data-toggle="tooltip" data-placement="left" data-offset="4px, 16px" data-original-title="Metrics &amp; Citations"><i aria-hidden="true" class="icon-timeline"></i><span class="sr-only">Metrics &amp; Citations</span></a></li><li><a href="#core-collateral-fulltext-options" data-id="article-nav-menubar-metrics" title="" tabindex="0" data-toggle="tooltip" data-placement="left" data-offset="4px, 16px" data-original-title="View Options"><i aria-hidden="true" class="icon-eye"></i><span class="sr-only">View Options</span></a></li><li><a href="#core-collateral-references" data-id="article-nav-menubar-references" title="" tabindex="0" data-toggle="tooltip" data-placement="left" data-offset="4px, 16px" data-original-title="References"><i aria-hidden="true" class="icon-references"></i><span class="sr-only">References</span></a></li><li><a href="#core-collateral-media" data-id="article-nav-menubar-media" title="" tabindex="0" data-toggle="tooltip" data-placement="left" data-offset="4px, 16px" data-original-title="Media"><i aria-hidden="true" class="icon-photo"></i><span class="sr-only">Media</span></a></li><li title="No tables available"><a href="#core-collateral-tables" data-id="article-nav-menubar-tables" disabled="true" aria-disabled="true" title="" tabindex="-1" data-toggle="tooltip" data-placement="left" data-offset="4px, 16px" data-original-title="Tables"><i aria-hidden="true" class="icon-tables"></i><span class="sr-only">Tables</span></a></li><li><a href="#core-collateral-share" data-id="article-nav-menubar-share" title="" tabindex="0" data-toggle="tooltip" data-placement="left" data-offset="4px, 16px" data-original-title="Share"><i aria-hidden="true" class="icon-share"></i><span class="sr-only">Share</span></a></li></ul></nav></div></div><div data-core-wrapper="content"><div id="abstracts" data-extent="frontmatter" data-location="articleTab_article"><div class="core-container"><section id="summary-abstract" property="abstract" typeof="Text" role="doc-abstract"><h2 property="name">Abstract</h2><section id="abs-sec-1"><h3>Background</h3><div role="paragraph">Technology to restore the ability to communicate in paralyzed persons who cannot speak has the potential to improve autonomy and quality of life. An approach that decodes words and sentences directly from the cerebral cortical activity of such patients may represent an advancement over existing methods for assisted communication.</div></section><section id="abs-sec-2"><h3>Methods</h3><div role="paragraph">We implanted a subdural, high-density, multielectrode array over the area of the sensorimotor cortex that controls speech in a person with anarthria (the loss of the ability to articulate speech) and spastic quadriparesis caused by a brain-stem stroke. Over the course of 48 sessions, we recorded 22 hours of cortical activity while the participant attempted to say individual words from a vocabulary set of 50 words. We used deep-learning algorithms to create computational models for the detection and classification of words from patterns in the recorded cortical activity. We applied these computational models, as well as a natural-language model that yielded next-word probabilities given the preceding words in a sequence, to decode full sentences as the participant attempted to say them.</div><div class="figure-wrap" data-presentation="diminished-in-flow"><header><!-- There is no content. --><nav><a href="#f0" title="Open in viewer" class="open-in-viewer" data-index="0" data-interactiontype="multimedia_click" data-multimedia-type="Figure" data-multimedia-filename="nejmoa2027540_f0.jpg"><i aria-hidden="true" class="icon-expand"></i></a></nav></header><figure id="f0" class="graphic"><a aria-label="Open figure in viewer" class="open-in-viewer" data-index="0" href="#f0" data-interactiontype="multimedia_click" data-multimedia-type="Figure" data-multimedia-filename="nejmoa2027540_f0.jpg"><img src="/cms/10.1056/NEJMoa2027540/asset/72b2e583-fb17-48c8-9cd1-62c7af874aa5/assets/images/large/nejmoa2027540_f0.jpg" height="3416" width="2640" aria-labelledby="f0" loading="lazy"></a><figcaption>Download a PDF of the <a href="#ap0">Research Summary</a>.</figcaption></figure></div></section><section id="abs-sec-3"><h3>Results</h3><div role="paragraph">We decoded sentences from the participant’s cortical activity in real time at a median rate of 15.2 words per minute, with a median word error rate of 25.6%. In post hoc analyses, we detected 98% of the attempts by the participant to produce individual words, and we classified words with 47.1% accuracy using cortical signals that were stable throughout the 81-week study period.</div></section><section id="abs-sec-4"><h3>Conclusions</h3><div role="paragraph">In a person with anarthria and spastic quadriparesis caused by a brain-stem stroke, words and sentences were decoded directly from cortical activity during attempted speech with the use of deep-learning models and a natural-language model. (Funded by Facebook and others; ClinicalTrials.gov number, <a href="http://clinicaltrials.gov/show/NCT03698149" target="_blank">NCT03698149</a>.)</div></section></section><div class="core-digital-object quick-take">
<div class="ng-do-media" style="border-top: 1px solid #e5e5e5; padding-top: 1.5rem;" data-location="inlineArticlePreview">
    <div class="ng-do-media_item">
        <div class="ng-do-media_item-left">
            <a href="/do/10.1056/NEJMdo006089/full/" class="ng-do-media_item-img-link">
                <img src="/cms/asset/5c90d59d-2b9a-4cba-9d8f-a945de19ad5d/media/NEJMdo006089_300x200.jpg" class="ng-do-media_item-img">
                <span class="icon-component"><svg aria-hidden="true"><use xlink:href="/specs/products/mms-nextgen/mms/releasedAssets/icons/icons.spritemap.svg#tooltip-video"></use></svg></span>
            </a>
        </div>
        <div class="ng-do-media_item-right">
            <div class="ng-do-media_item-type">
                <a href="/browse/nejm-media-type/quick-take" class="ng-do-media_item-type-link">Quick Take</a>
            </div>
            <h6 class="ng-do-media_item-title">
                <a href="/do/10.1056/NEJMdo006089/full/" class="ng-do-media_item-title-link">Decoding Speech in a Paralyzed Person with Anarthria</a>
            </h6>
            <div class="ng-do-media_item-duration">2m 45s</div>
        </div>
    </div>
</div>
</div></div></div><section id="bodymatter" data-extent="bodymatter" property="articleBody" typeof="Text" data-location="articleTab_article"><div class="core-container"><div id="v1" class="core-digital-object component-video">
<div class="ng-do-interactive">
    <div class="ng-do-interactive_label">Video</div>
    <button data-toggle="modal" data-target="#doPopup" class="ng-do-interactive_btn"></button>
    <div data-ajaxurl="/do/10.1056/NEJMdo006054/full/?ajaxRequest=true" class="ng-do-interactive_item">
        <div class="ng-do-interactive_item-left">
            <a href="#" class="ng-do-interactive_img-link" data-interactiontype="multimedia_click" data-multimedia-type="Video" data-multimedia-contentid="10.1056/NEJMdo006054">
                <img src="/cms/asset/962ae8b4-9e0b-4f50-a7ab-2b87b665a741/media/NEJMdo006054_300x200.jpg" class="ng-do-interactive_img">
                <span class="icon-component"><svg aria-hidden="true"><use xlink:href="/specs/products/mms-nextgen/mms/releasedAssets/icons/icons.spritemap.svg#tooltip-video"></use></svg></span>
            </a>
        </div>
        <div class="ng-do-interactive_item-right">
            <a href="#" class="ng-do-interactive_link" data-interactiontype="multimedia_click" data-multimedia-type="Video" data-multimedia-contentid="10.1056/NEJMdo006054">Real-Time Conversational and Sentence Decoding in a Paralyzed Adult with Anarthria</a>
            <span class="ng-do-interactive_duration">4m 18s</span>
        </div>
    </div>
</div>

</div><div role="paragraph">Anarthria is the loss of the ability to articulate speech. It can result from a variety of conditions, including stroke and amyotrophic lateral sclerosis.<sup><a href="#core-r1" role="doc-biblioref" data-xml-rid="r1" id="body-ref-r1" href-manipulated="true" aria-label="Reference 1">1</a></sup> Patients with anarthria may have intact language skills and cognition, and some are able to produce limited oral movements and undifferentiated vocalizations when attempting to speak.<sup><a href="#core-r2" role="doc-biblioref" data-xml-rid="r2" id="body-ref-r2" href-manipulated="true" aria-label="Reference 2">2</a></sup> However, paralyzed persons may be unable to operate assistive devices because of severe impairment of movement. Anarthria hinders communication with family, friends, and caregivers, thereby reducing patient-reported quality of life.<sup><a href="#core-r3" role="doc-biblioref" data-xml-rid="r3" id="body-ref-r3" href-manipulated="true" aria-label="Reference 3">3</a></sup> Advances have been made with typing-based brain–computer interfaces that allow speech-impaired persons to spell out messages by controlling a computer cursor.<sup><a href="#core-r4" role="doc-biblioref" data-xml-rid="r4 r5 r6 r7 r8" id="body-ref-r8" href-manipulated="true">4-8</a></sup> However, letter-by-letter selection through interfaces driven by neural signal recordings is slow and effortful. A more efficient and natural approach may be to directly decode whole words from brain areas that control speech. Our understanding of how the area of the sensorimotor cortex that controls speech orchestrates the rapid articulatory movements of the vocal tract has expanded.<sup><a href="#core-r9" role="doc-biblioref" data-xml-rid="r9 r10 r11 r12 r13 r14" id="body-ref-r14-1" href-manipulated="true">9-14</a></sup> Engineering efforts have used these neurobiologic findings, together with advances in machine learning, to show that speech can be decoded from brain activity in persons without speech impairments.<sup><a href="#core-r15" role="doc-biblioref" data-xml-rid="r15 r16 r17 r18 r19" id="body-ref-r19-1" href-manipulated="true">15-19</a></sup></div><div role="paragraph">In paralyzed persons who cannot speak, recordings of neural activity cannot be precisely aligned with intended speech because of the absence of speech output, which poses an obstacle for training computational models.<sup><a href="#core-r20" role="doc-biblioref" data-xml-rid="r20" id="body-ref-r20" href-manipulated="true" aria-label="Reference 20">20</a></sup> In addition, it is unclear whether neural signals underlying speech control are still intact in persons who have not spoken for years or decades. In earlier work, a paralyzed person used an implanted, intracortical, two-channel microelectrode device and an audiovisual interface to generate vowel sounds and phonemes but not full words.<sup><a href="#core-r21" role="doc-biblioref" data-xml-rid="r21 r22" id="body-ref-r22" href-manipulated="true">21,22</a></sup> To determine whether speech can be directly decoded to produce language from the neural activity of a person who is unable to speak, we tested real-time decoding of words and sentences from the cortical activity of a person with limb paralysis and anarthria caused by a brain-stem stroke.</div><section id="sec-1" data-type="methods"><h2>Methods</h2><section id="sec-1-1"><h3>Study Overview</h3><div role="paragraph">This work was performed as part of the BCI Restoration of Arm and Voice (BRAVO) study, which is a single-institution clinical study to evaluate the potential of electrocorticography, a method for recording neural activity from the cerebral cortex with the use of electrodes placed on the surface of the cerebral hemisphere, and custom decoding techniques to enable communication and mobility. An investigational device exemption for the device used in this study was approved by the Food and Drug Administration. As of this writing, the device had been implanted only in the participant described here. Because of regulatory and clinical considerations regarding the proper handling of the percutaneous connector, the participant did not have the opportunity to use the system independently for daily activities but underwent testing at his home.</div><div role="paragraph">This work was approved by the Committee on Human Research at the University of California, San Francisco, and was supported in part by a research contract under Facebook’s Sponsored Academic Research Agreement. All the authors were involved in the design and execution of the clinical study; the collection, storage, analysis, and interpretation of the data; and the writing of the manuscript. No study hardware or data were transferred to any sponsor, and we did not receive any hardware or software from a sponsor to use in this work. All the authors vouch for the accuracy and completeness of the data and for the fidelity of the study to the <a href="#ap1">protocol</a> (available with the full text of this article at NEJM.org) and confirm that the study was conducted ethically. Informed consent was obtained from the participant after the reason for and nature of implantation and the training procedures and risks were thoroughly explained to him.</div></section><section id="sec-1-2"><h3>Participant</h3><div role="paragraph">The participant was a right-handed man who was 36 years of age at the start of the study. At 20 years of age, he had had an extensive pontine stroke associated with a dissection of the right vertebral artery, which resulted in severe spastic quadriparesis and anarthria, as confirmed by a speech–language pathologist and neurologists (<a href="#v1">Video 1</a> and Fig. S1 in the <a href="#ap2">Supplementary Appendix</a>, both available at NEJM.org). His cognitive function was intact, and he had a score of 26 on the Mini–Mental State Examination (scores range from 0 to 30, with higher scores indicating better mental performance); because of his paralysis, it was not physically possible for his score to reach 30. He was able to vocalize grunts and moans but was unable to produce intelligible speech; eye movement was unaffected. He normally communicated using an assistive computer-based typing interface controlled by his residual head movements; his typing speed was approximately 5 correct words or 18 correct characters per minute (Section S1).</div></section><section id="sec-1-3"><h3>Implant Device</h3><div role="paragraph">The neural implant used to acquire brain signals from the participant was a customized combination of a high-density electrocorticography electrode array (manufactured by PMT) and a percutaneous connector (manufactured by Blackrock Microsystems). The rectangular electrode array was 6.7 cm long, 3.5 cm wide, and 0.51 mm thick and consisted of 128 flat, disk-shaped electrodes arranged in a 16-by-8 lattice formation, with a center-to-center distance between adjacent electrodes of 4 mm. During surgical implantation, general anesthesia was used, and the sensorimotor cortex of the left hemisphere, as identified by anatomical landmarks of the central sulcus, was exposed through craniotomy. The electrode array was laid on the pial surface of the brain in the subdural space. The electrode coverage enabled sampling from multiple cortical regions that have been implicated in speech processing, including portions of the left precentral gyrus, postcentral gyrus, posterior middle frontal gyrus, and posterior inferior frontal gyrus.<sup><a href="#core-r9" role="doc-biblioref" data-xml-rid="r9 r11 r12 r13" id="body-ref-r13-2" href-manipulated="true">9,11–13</a></sup> The dura was closed with sutures, and the cranial bone flap was replaced. The percutaneous connector was placed extracranially on the contralateral skull convexity and anchored to the cranium. This percutaneous connector conducts cortical signals from the implanted electrode array through externally accessible contacts to a detachable digital link and cable, enabling transmission of the acquired brain activity to a computer (Fig. S2). The participant underwent surgical implantation of the device in February 2019 and had no complications. The procedure lasted approximately 3 hours. We began to collect data for this study in April 2019.</div></section><section id="sec-1-4"><h3>Real-Time Acquisition and Processing of Neural Data</h3><div role="paragraph">A digital-signal processing system (NeuroPort System, Blackrock Microsystems) was used to acquire signals from all 128 electrodes of the implant device and transmit them to a computer running custom software for real-time signal analysis (Section S2 and Figs. S2 and S3).<sup><a href="#core-r18" role="doc-biblioref" data-xml-rid="r18 r23" id="body-ref-r23" href-manipulated="true">18,23</a></sup> As informed by previous research that had correlated neural activity in the 70 to 150 Hz (high-gamma) frequency range with speech processing,<sup><a href="#core-r9" role="doc-biblioref" data-xml-rid="r9 r12 r13 r14 r18" id="body-ref-r18-3" href-manipulated="true">9,12–14,18</a></sup> we measured activity in the high-gamma band for each channel to use in subsequent analyses and during real-time decoding.</div></section><section id="sec-1-5"><h3>Word and Sentence Task Design</h3><div role="paragraph">The study consisted of 50 sessions over the course of 81 weeks and took place at the participant’s residence or a nearby office. The participant engaged in two types of tasks: an isolated-word task and a sentence task (Section S3 and Fig. S4). On average, we collected approximately 27 minutes of neural activity during these tasks at each session. In each trial of each task, a target word or sentence was presented visually to the participant as text on a screen, and then the participant attempted to produce (say aloud) that target.</div><div role="paragraph">In the isolated-word task, the participant attempted to produce individual words from a set of 50 English words. This word set contained common English words that can be used to create a variety of sentences, including words that are relevant to caregiving and words requested by the participant. In each trial, the participant was presented with one of these 50 words, and, after a 2-second delay, he attempted to produce that word when the text of the word on the screen turned green. We collected 22 hours of data from 9800 trials of the isolated-word task performed by the participant in the first 48 of the 50 sessions.</div><div role="paragraph">In the sentence task, the participant attempted to produce word sequences from a set of 50 English sentences consisting of words from the 50-word set (Sections S4 and S5). In each trial, the participant was presented with a target sentence and attempted to produce the words in that sentence (in order) at the fastest speed he could perform comfortably. Throughout the trial, the word sequence decoded from neural activity was updated in real time and displayed as feedback to the participant. We collected data from 250 trials of the sentence task performed by the participant in 7 of the final 8 sessions. This task is shown in <a href="#v1">Video 2</a>. A conversational variant of this task, in which the participant was presented with prompts and attempted to respond to them, is shown in <a href="#f1">Figure 1</a> and <a href="#v1">Video 1</a>.</div><div class="figure-wrap" data-presentation="diminished-in-flow"><header><div class="label">Figure 1</div><nav><a href="#f1" title="Open in viewer" class="open-in-viewer" data-index="0" data-interactiontype="multimedia_click" data-multimedia-type="Figure" data-multimedia-filename="nejmoa2027540_f1.jpg"><i aria-hidden="true" class="icon-expand"></i></a></nav></header><figure id="f1" class="graphic"><a aria-label="Open figure in viewer" class="open-in-viewer" data-index="0" href="#f1" data-interactiontype="multimedia_click" data-multimedia-type="Figure" data-multimedia-filename="nejmoa2027540_f1.jpg"><img src="/cms/10.1056/NEJMoa2027540/asset/40605166-4f5e-447f-bf37-ab63f494c50e/assets/images/large/nejmoa2027540_f1.jpg" height="3341" width="2640" aria-labelledby="f1" loading="lazy"></a><figcaption><div class="caption">Schematic Overview of the Direct Speech Brain–Computer Interface.</div><div class="notes"><div role="doc-footnote">Shown is how neural activity acquired from an investigational electrocorticography electrode array implanted in a clinical study participant with severe paralysis is used to directly decode words and sentences in real time. In a conversational demonstration, the participant is visually prompted with a statement or question (A) and is instructed to attempt to respond using words from a predefined vocabulary set of 50 words. Simultaneously, cortical signals are acquired from the surface of the brain through the electrode array (B) and processed in real time (C). The processed neural signals are analyzed sample by sample with the use of a speech-detection model to detect the participant’s attempts to speak (D). A classifier computes word probabilities (across the 50 possible words) from each detected window of relevant neural activity (E). A Viterbi decoding algorithm uses these probabilities in conjunction with word-sequence probabilities from a separately trained natural-language model to decode the most likely sentence given the neural activity data (F). The predicted sentence, which is updated each time a word is decoded, is displayed as feedback to the participant (G). Before real-time decoding, the models were trained with data collected as the participant attempted to say individual words from the 50-word set as part of a separate task (not depicted). This conversational demonstration is a variant of the standard sentence task used in this work, in that it allows the participant to compose his own unique responses to the prompts.</div></div></figcaption></figure></div></section><section id="sec-1-6"><h3>Modeling</h3><div role="paragraph">We used neural activity data collected during the tasks to train, fine-tune, and evaluate custom models (Sections S6 and S7 and Table S1). Specifically, we created speech-detection and word-classification models that used deep-learning techniques to make predictions from the neural activity. To decode sentences from the participant’s neural activity in real time during the sentence task, we also used a natural-language model and a Viterbi decoder (<a href="#f1">Figure 1</a>). The speech-detection model processed each time point of neural activity during a task and detected onsets and offsets of word-production attempts in real time (Section S8 and Fig. S5). We fitted this model using neural activity data and task-timing information collected only during the isolated-word task.</div><div role="paragraph">For each attempt that was detected, the word-classification model predicted a set of word probabilities by processing the neural activity spanning from 1 second before to 3 seconds after the detected onset of attempted speech (Section S9 and Fig. S6). The predicted probability associated with each word in the 50-word set quantified how likely it was that the participant was attempting to say that word during the detected attempt. We fitted this model to neural data collected during the isolated-word task.</div><div role="paragraph">In English, certain sequences of words are more likely than others. To use this underlying linguistic structure, we created a natural-language model that yielded next-word probabilities given the previous words in a sequence (Section S10).<sup><a href="#core-r24" role="doc-biblioref" data-xml-rid="r24 r25" id="body-ref-r25" href-manipulated="true">24,25</a></sup> We trained this model on a collection of sentences that included only words from the 50-word set; the sentences were obtained with the use of a custom task on a crowd-sourcing platform (Section S4).</div><div role="paragraph">The final component in the decoding approach involved the use of a custom Viterbi decoder, which is a type of model that determines the most likely sequence of words given predicted word probabilities from the word classifier and word-sequence probabilities from the natural-language model (Section S11 and Fig. S7).<sup><a href="#core-r26" role="doc-biblioref" data-xml-rid="r26" id="body-ref-r26" href-manipulated="true" aria-label="Reference 26">26</a></sup> With the incorporation of the language model, the Viterbi decoder was capable of decoding more plausible sentences than what would result from simply stringing together the predicted words from the word classifier.</div></section><section id="sec-1-7"><h3>Evaluations</h3><div role="paragraph">To evaluate the performance of our decoding approach, we analyzed the sentences that were decoded in real time using two metrics: the word error rate and the number of words decoded per minute (Section S12). The word error rate of a decoded sentence was defined as the number of word errors made by the decoder divided by the number of words in the target sentence.</div><div role="paragraph">To further characterize the detection and classification of word-production attempts from the participant’s neural activity, we processed the collected isolated-word data with the speech-detection and word-classification models in offline analyses performed after the recording sessions had been completed (Section S13). We measured classification accuracy as the percentage of trials in which the word classifier correctly predicted the target word that the participant attempted to produce. We also measured electrode contributions as the size of the effect that each individual electrode had on the predictions made by the detection and classification models.<sup><a href="#core-r19" role="doc-biblioref" data-xml-rid="r19 r27" id="body-ref-r27" href-manipulated="true">19,27</a></sup></div><div role="paragraph">To investigate the viability of our approach for a long-term application, we evaluated the stability of the acquired cortical signals over time using the isolated-word data (Section S14). By sampling neural data from four different date ranges spanning the 81-week study period, we assessed whether classification accuracy on a subset of data collected in the final sessions could be improved by including data from earlier subsets as part of the training set for the classification model; such improvement would indicate that training data accumulated across months or years of recording could be used to reduce the need for frequent model recalibration in practical applications of our approach.</div></section><section id="sec-1-8"><h3>Statistical Analyses</h3><div role="paragraph">Results for each experimental condition are presented with 95% confidence intervals when appropriate (Section S15). No adjustments were made for multiple comparisons. The evaluation metrics (word error rate, number of words decoded per minute, and classification accuracy) were specified before the start of data collection. Analyses to assess the long-term stability of speech-detection and word-classification performance with our implant device were designed post hoc.</div></section></section><section id="sec-2" data-type="results"><h2>Results</h2><section id="sec-2-1"><h3>Sentence Decoding</h3><div role="paragraph">During real-time sentence decoding, the median word error rate across 15 sentence blocks (each block comprised 10 trials) was 60.5% (95% confidence interval [CI], 51.4 to 67.6) without language modeling and 25.6% (95% CI, 17.1 to 37.1) with language modeling (<a href="#f2">Figure 2A</a>, top). The lowest word error rate observed for a single sentence block was 7.0% (with language modeling). When chance performance was measured with the use of sentences that had been randomly generated by the natural-language model (Section S12), the median word error rate was 92.1% (95% CI, 85.7 to 97.2). Across all 150 trials, the median number of words decoded per minute was 15.2 with the inclusion of all decoded words and 12.5 with the inclusion of only correctly decoded words (with language modeling) (<a href="#f2">Figure 2A</a>, middle). In 92.0% of the trials, the number of detected words was equal to the number of words in the target sentence (<a href="#f2">Figure 2A</a>, bottom). Across all 15 sentence blocks, five speech attempts were erroneously detected before the first trial in the block and were excluded from real-time decoding and analysis (all other detected speech attempts were included). For almost all target sentences, the mean number of word errors decreased when the natural-language model was used (<a href="#f2">Figure 2B</a>), and in 80 of 150 trials with language modeling, sentences were decoded without error. Use of the natural-language model during decoding improved performance by correcting grammatically and semantically implausible word sequences in the predictions (<a href="#f2">Figure 2C</a>). Real-time demonstrations are shown in <a href="#v1">Videos 1 and 2</a>.</div><div class="figure-wrap" data-presentation="diminished-in-flow"><header><div class="label">Figure 2</div><nav><a href="#f2" title="Open in viewer" class="open-in-viewer" data-index="0" data-interactiontype="multimedia_click" data-multimedia-type="Figure" data-multimedia-filename="nejmoa2027540_f2.jpg"><i aria-hidden="true" class="icon-expand"></i></a></nav></header><figure id="f2" class="graphic"><a aria-label="Open figure in viewer" class="open-in-viewer" data-index="0" href="#f2" data-interactiontype="multimedia_click" data-multimedia-type="Figure" data-multimedia-filename="nejmoa2027540_f2.jpg"><img src="/cms/10.1056/NEJMoa2027540/asset/c5a8b906-d545-42ff-a7ee-d8700e98a7e1/assets/images/large/nejmoa2027540_f2.jpg" height="3438" width="2629" aria-labelledby="f2" loading="lazy"></a><figcaption><div class="caption">Decoding a Variety of Sentences in Real Time through Neural Signal Processing and Language Modeling.</div><div class="notes"><div role="doc-footnote">Panel A shows the word error rates, the numbers of words decoded per minute, and the decoded sentence lengths. The top plot shows the median word error rate (defined as the number of word errors made by the decoder divided by the number of words in the target sentence, with a lower rate indicating better performance) derived from the word sequences decoded from the participant’s cortical activity during the performance of the sentence task. Data points represent sentence blocks (each block comprises 10 trials); the median rate, as indicated by the horizontal line within a box, is shown across 15 sentence blocks. The upper and lower sides of the box represent the interquartile range, and the 𝙸 bars 1.5 times the interquartile range. Chance performance was measured by computing the word error rate on sentences randomly generated from the natural-language model. The middle plot shows the median number of words decoded per minute, as derived across all 150 trials (each data point represents a trial). The rates are shown for the analysis that included all words that were correctly or incorrectly decoded with the natural-language model and for the analysis that included only correctly decoded words. Each violin distribution was created with the use of kernel density estimation based on Scott’s rule for computing the estimator bandwidth; the thick horizontal lines represent the median number of words decoded per minute, and the thinner horizontal lines the range (with the exclusion of outliers that were more than 4 standard deviations below or above the mean, which was the case for one trial). In the bottom chart, the decoded sentence lengths show whether the number of detected words was equal to the number of words in the target sentence in each of the 150 trials. Panel B shows the number of word errors in the sentences decoded with or without the natural-language model across all trials and all 50 sentence targets. Each small vertical dash represents the number of word errors in a single trial (there are 3 trials per target sentence; marks for identical error counts are staggered horizontally for visualization purposes). Each dot represents the mean number of errors for that target sentence across the 3 trials. The histogram at the bottom shows the error counts across all 150 trials. Panel C shows seven target sentence examples along with the corresponding sentences decoded with and without the natural-language model. Correctly decoded words are shown in black and incorrect words in red.</div></div></figcaption></figure></div></section><section id="sec-2-2"><h3>Word Detection and Classification</h3><div role="paragraph">In the offline analyses that included data from 9000 attempts to produce isolated words (and excluded the use of the natural-language model), the mean classification accuracy was 47.1% with the use of the speech detector and word classifier to predict the identity of the target word from cortical activity. The accuracy of chance performance (without the use of any models) was 2%. Additional results of the isolated-word analyses are provided in Figures S8 and S9. A total of 98% of these word-production attempts were successfully detected (191 attempts were not detected), and 968 detected attempts were spurious (not associated with a speech attempt) (Section S8). Electrodes in the most ventral aspect of the ventral sensorimotor cortex contributed to word-classification performance to a greater extent than electrodes in the dorsal aspect of the ventral sensorimotor cortex, whereas the electrodes in the dorsal aspect contributed more to speech-detection performance (<a href="#f3">Figure 3A</a>). Classification accuracy was consistent across most of the target words (mean [±SD] classification accuracy across the 50 target words, 47.1±14.5%) (<a href="#f3">Figure 3B</a>).</div><div class="figure-wrap" data-presentation="diminished-in-flow"><header><div class="label">Figure 3</div><nav><a href="#f3" title="Open in viewer" class="open-in-viewer" data-index="0" data-interactiontype="multimedia_click" data-multimedia-type="Figure" data-multimedia-filename="nejmoa2027540_f3.jpg"><i aria-hidden="true" class="icon-expand"></i></a></nav></header><figure id="f3" class="graphic"><a aria-label="Open figure in viewer" class="open-in-viewer" data-index="0" href="#f3" data-interactiontype="multimedia_click" data-multimedia-type="Figure" data-multimedia-filename="nejmoa2027540_f3.jpg"><img src="/cms/10.1056/NEJMoa2027540/asset/68f0e6d1-b465-47d5-b6fc-47ee4ea610e9/assets/images/large/nejmoa2027540_f3.jpg" height="3438" width="2629" aria-labelledby="f3" loading="lazy"></a><figcaption><div class="caption">Distinct Neural Activity Patterns during Word-Production Attempts.</div><div class="notes"><div role="doc-footnote">Panel A shows the participant’s brain reconstruction overlaid with the locations of the implanted electrodes and their contributions to the speech-detection and word-classification models. Plotted electrode size (area) and opacity are scaled by relative contribution (important electrodes appear larger and more opaque than other electrodes). Each set of contributions is normalized to sum to 1. For anatomical reference, the precentral gyrus is highlighted in light green. Panel B shows word confusion values computed with the use of the isolated-word data. For each target word (each row), the confusion value measures how often the word classifier predicted (regardless of whether the prediction was correct) each of the 50 possible words (each column) while the participant was attempting to say that target word. The confusion value is computed as a percentage relative to the total number of isolated-word trials for each target word, with the values in each row summing to 100%. Values along the diagonal correspond to correct classifications, and off-diagonal values correspond to incorrect classifications. The natural-language model was not used in this analysis.</div></div></figcaption></figure></div></section><section id="sec-2-3"><h3>Long-Term Stability of Acquired Cortical Signals</h3><div role="paragraph">The long-term stability of the speech-related cortical activity patterns recorded during attempts to produce isolated words showed that the speech-detection and word-classification models performed consistently throughout the 81-week study period without daily or weekly recalibration (Fig. S10). When the models were used to analyze cortical activity recorded at the end of the study period, classification accuracy increased when the data set used to train the classification models contained data recorded throughout the study period, including data recorded more than a year before the collection of the data used to test the models (<a href="#f4">Figure 4</a>).</div><div class="figure-wrap" data-presentation="diminished-in-flow"><header><div class="label">Figure 4</div><nav><a href="#f4" title="Open in viewer" class="open-in-viewer" data-index="0" data-interactiontype="multimedia_click" data-multimedia-type="Figure" data-multimedia-filename="nejmoa2027540_f4.jpg"><i aria-hidden="true" class="icon-expand"></i></a></nav></header><figure id="f4" class="graphic"><a aria-label="Open figure in viewer" class="open-in-viewer" data-index="0" href="#f4" data-interactiontype="multimedia_click" data-multimedia-type="Figure" data-multimedia-filename="nejmoa2027540_f4.jpg"><img src="/cms/10.1056/NEJMoa2027540/asset/886e2498-6fe3-44f0-8e25-3fb0878aae38/assets/images/large/nejmoa2027540_f4.jpg" height="1390" width="2231" aria-labelledby="f4" loading="lazy"></a><figcaption><div class="caption">Signal Stability and Long-Term Accumulation of Training Data to Improve Decoder Performance.</div><div class="notes"><div role="doc-footnote">Each bar depicts the mean classification accuracy (the percentage of trials in which the target word was correctly predicted) from isolated-word data sampled from the final weeks of the study period (weeks 79 through 81) after speech-detection and word-classification models were trained on different samples of the isolated-word data from various week ranges. Each result was computed with the use of a 10-fold cross-validation evaluation approach. In this approach, the available data were partitioned into 10 equally sized, nonoverlapping subsets. In the first cross-validation “fold,” one of these data subsets is used as the testing set, and the remaining 9 are used for model training. This was repeated 9 more times until each subset was used for testing (after training on the other subsets). This approach ensures that models were never evaluated on the data used during training (Sections S6 and S14). 𝙸 bars indicate the 95% confidence interval of the mean, each computed across the 10 cross-validation folds. The data quantities specify the average amount of data used to train the word-classification models across cross-validation folds. Week 0 denotes the first week during which data for this study was collected, which occurred 9 weeks after surgical implantation of the study device. Accuracy of chance performance was calculated as 1 divided by the number of possible words and is indicated by a horizontal dashed line.</div></div></figcaption></figure></div></section></section><section id="sec-3" data-type="discussion"><h2>Discussion</h2><div role="paragraph">We showed that high-density recordings of cortical activity in the speech-production area of the sensorimotor cortex of an anarthric and paralyzed person can be used to decode full words and sentences in real time. Our deep-learning models were able to use the participant’s neural activity to detect and classify his attempts to produce words from a 50-word set, and we could use these models, together with language-modeling techniques, to decode a variety of meaningful sentences. Our models, enabled by the long-term stability of recordings from the implanted device, could use data accumulated throughout the 81-week study period to improve decoding performance when evaluating data recorded near the end of the study.</div><div role="paragraph">Previous demonstrations of word and sentence decoding from cortical neural activity have been conducted with participants who could speak without the need for assistive technology to communicate.<sup><a href="#core-r15" role="doc-biblioref" data-xml-rid="r15 r16 r17 r18 r19" id="body-ref-r19-3" href-manipulated="true">15-19</a></sup> Similar to the problem of decoding intended movements in someone who is paralyzed, the lack of precise time alignment between intended speech and neural activity poses a challenge during model training. We addressed this time-alignment problem with speech-detection approaches<sup><a href="#core-r18" role="doc-biblioref" data-xml-rid="r18 r28 r29" id="body-ref-r29" href-manipulated="true">18,28,29</a></sup> and word classifiers that used machine-learning techniques, such as model ensembling and data augmentation (Section S9), to increase reliability of the model to minor temporal variabilities in recorded signals.<sup><a href="#core-r30" role="doc-biblioref" data-xml-rid="r30 r31" id="body-ref-r31" href-manipulated="true">30,31</a></sup> Decoding performance was largely driven by neural-activity patterns in the ventral sensorimotor cortex, a finding consistent with previous work implicating this area in speech production.<sup><a href="#core-r9" role="doc-biblioref" data-xml-rid="r9 r12 r13" id="body-ref-r13-4" href-manipulated="true">9,12,13</a></sup> This finding may inform electrode placement in future studies. We were also able to show the preservation of functional cortical representations of speech in a person who had had anarthria for more than 15 years, a finding analogous to previous findings of limb-related cortical sensorimotor representations in tetraplegic persons years after the loss of limb movement.<sup><a href="#core-r32" role="doc-biblioref" data-xml-rid="r32 r33" id="body-ref-r33" href-manipulated="true">32,33</a></sup></div><div role="paragraph">The incorporation of language-modeling techniques in this study reduced the median word error rate by 35 percentage points and enabled perfect decoding in more than half the sentence trials. This improvement was facilitated through the use of all of the probabilistic information provided by the word classifier during decoding and by allowing the decoder to update previously predicted words each time a new word was decoded. These results show the benefit of integrating linguistic information when decoding speech from neural recordings. Speech-decoding approaches generally become usable at word error rates below 30%,<sup><a href="#core-r34" role="doc-biblioref" data-xml-rid="r34" id="body-ref-r34" href-manipulated="true" aria-label="Reference 34">34</a></sup> which suggests that our approach may be applicable in other clinical settings.</div><div role="paragraph">In previously reported brain–computer interface applications, decoding models often require daily recalibration before deployment with a user,<sup><a href="#core-r6" role="doc-biblioref" data-xml-rid="r6 r35" id="body-ref-r35-1" href-manipulated="true">6,35</a></sup> which can increase the variability of decoder performance across days and impede long-term adoption of the interface for real-world use.<sup><a href="#core-r35" role="doc-biblioref" data-xml-rid="r35 r36" id="body-ref-r36" href-manipulated="true">35,36</a></sup> Because of the relatively high signal stability of electrocorticographic recordings,<sup><a href="#core-r5" role="doc-biblioref" data-xml-rid="r5 r37 r38 r39" id="body-ref-r39" href-manipulated="true">5,37–39</a></sup> we could accumulate cortical activity acquired by the implanted electrodes across months of recording to train our decoding models. Overall, decoding performance was maintained or improved by the accumulation of large quantities of training data over time without daily recalibration, which suggests that high-density electrocorticography may be suitable for long-term direct-speech neuroprosthetic applications.</div></section>



        
        
</div></section><section id="backmatter" data-extent="backmatter" data-location="articleTab_article"><div class="core-container"><section id="backnotes" data-location="notes_article"><h2>Notes</h2><div data-type="data-sharing" role="paragraph">A <a href="#ap4">data sharing statement</a> provided by the authors is available with the full text of this article at NEJM.org.</div><div role="paragraph">Supported by a research contract under <span class="named-content" data-type="funder">Facebook’s Sponsored Academic Research Agreement</span>, the National Institutes of Health (grant <span class="named-content" data-type="funder">NIH</span> U01 DC018671-01A1), Joan and Sandy Weill and the Weill Family Foundation, the Bill and Susan Oberndorf Foundation, the <span class="named-content" data-type="funder">William K. Bowes, Jr. Foundation</span>, and the <span class="named-content" data-type="funder">Shurl and Kay Curci Foundation</span>.</div><div role="paragraph"><a href="#ap3">Disclosure forms</a> provided by the authors are available with the full text of this article at NEJM.org.</div><div role="paragraph">We thank the study participant “Bravo-1” for his dedication and commitment; the members of Karunesh Ganguly’s laboratory for help with the clinical study; Mark Chevillet, Emily Mugler, Ruben Sethi, and Stephanie Thacker for support and feedback; Nick Halper and Kian Torab for hardware technical support; Mariann Ward for clinical nursing support; Matthew Leonard, Heather Dawes, and Ilona Garner for feedback on an earlier version of the manuscript; Viv Her for administrative support; Kenneth Probst for illustrating an earlier version of Figure 1; Todd Dubnicoff for video editing; and the participant’s caregivers for logistic support.</div></section><section id="supplementary-materials" class="core-supplementary-materials"><h2>Supplementary Material</h2><div role="list"><div id="ap0" class="core-supplementary-material" role="listitem"><div class="core-description"><span class="core-label">Research Summary</span> <span class="core-filename">(nejmoa2027540_research-summary.pdf)</span></div><div class="core-link"><ul><li><a href="/doi/suppl/10.1056/NEJMoa2027540/suppl_file/nejmoa2027540_research-summary.pdf" download="nejmoa2027540_research-summary.pdf" data-interactiontype="multimedia_download" data-multimedia-type="Supplementary Material" data-behavior="trackDownloadEvent" data-multimedia-filename="nejmoa2027540_research-summary.pdf" data-doi="10.1056/NEJMoa2027540">Download</a></li><li>588.33 KB</li></ul></div></div><div id="ap1" class="core-supplementary-material" role="listitem"><div class="core-description"><span class="core-label">Protocol</span> <span class="core-filename">(nejmoa2027540_protocol.pdf)</span></div><div class="core-link"><ul><li><a href="/doi/suppl/10.1056/NEJMoa2027540/suppl_file/nejmoa2027540_protocol.pdf" download="nejmoa2027540_protocol.pdf" data-interactiontype="multimedia_download" data-multimedia-type="Supplementary Material" data-behavior="trackDownloadEvent" data-multimedia-filename="nejmoa2027540_protocol.pdf" data-doi="10.1056/NEJMoa2027540">Download</a></li><li>314.89 KB</li></ul></div></div><div id="ap2" class="core-supplementary-material" role="listitem"><div class="core-description"><span class="core-label">Supplementary Appendix</span> <span class="core-filename">(nejmoa2027540_appendix.pdf)</span></div><div class="core-link"><ul><li><a href="/doi/suppl/10.1056/NEJMoa2027540/suppl_file/nejmoa2027540_appendix.pdf" download="nejmoa2027540_appendix.pdf" data-interactiontype="multimedia_download" data-multimedia-type="Supplementary Material" data-behavior="trackDownloadEvent" data-multimedia-filename="nejmoa2027540_appendix.pdf" data-doi="10.1056/NEJMoa2027540">Download</a></li><li>8.54 MB</li></ul></div></div><div id="ap3" class="core-supplementary-material" role="listitem"><div class="core-description"><span class="core-label">Disclosure Forms</span> <span class="core-filename">(nejmoa2027540_disclosures.pdf)</span></div><div class="core-link"><ul><li><a href="/doi/suppl/10.1056/NEJMoa2027540/suppl_file/nejmoa2027540_disclosures.pdf" download="nejmoa2027540_disclosures.pdf" data-interactiontype="multimedia_download" data-multimedia-type="Supplementary Material" data-behavior="trackDownloadEvent" data-multimedia-filename="nejmoa2027540_disclosures.pdf" data-doi="10.1056/NEJMoa2027540">Download</a></li><li>365.57 KB</li></ul></div></div><div id="ap4" class="core-supplementary-material" role="listitem"><div class="core-description"><span class="core-label">Data Sharing Statement</span> <span class="core-filename">(nejmoa2027540_data-sharing.pdf)</span></div><div class="core-link"><ul><li><a href="/doi/suppl/10.1056/NEJMoa2027540/suppl_file/nejmoa2027540_data-sharing.pdf" download="nejmoa2027540_data-sharing.pdf" data-interactiontype="multimedia_download" data-multimedia-type="Supplementary Material" data-behavior="trackDownloadEvent" data-multimedia-filename="nejmoa2027540_data-sharing.pdf" data-doi="10.1056/NEJMoa2027540">Download</a></li><li>72.26 KB</li></ul></div></div></div></section><section id="bibliography" class="core-reference-list" role="doc-bibliography" data-location="references_article"><h2>References</h2><div role="list" data-method="clamp" id="collapsible-text"><div role="listitem" data-has="label"><div class="label">1.</div><div id="r1" class="citations"><div class="citation"><div class="citation-content">Beukelman DR, Fager S, Ball L, Dietz A. AAC for adults with acquired neurological conditions: a review. <em>Augment Altern Commun</em> 2007;23:230-242.</div><div class="external-links"><div class="to-citation__wrapper"><a class="to-citation" href="#body-ref-r1"><i aria-hidden="true" class="icon-return"></i><span>Go to Citation</span></a></div><div class="core-xlink-crossref"><a href="https://doi.org/10.1080/07434610701553668" target="_blank">Crossref</a></div><div class="core-xlink-pubmed"><a href="https://pubmed.ncbi.nlm.nih.gov/17701742/" target="_blank">PubMed</a></div><div class="core-xlink-isi"><a href="https://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2&amp;DestApp=WOS_CPL&amp;UsrCustomerID=5e3815c904498985e796fc91436abd9a&amp;SrcAuth=atyponcel&amp;SrcApp=literatum&amp;DestLinkType=FullRecord&amp;KeyUT=000249570700004" target="_blank">Web of Science</a></div><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=AAC+for+adults+with+acquired+neurological+conditions%3A+a+review.&amp;publication_year=2007&amp;journal=Augment+Altern+Commun&amp;pages=230-242&amp;doi=10.1080%2F07434610701553668&amp;pmid=17701742" target="_blank">Google Scholar</a></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">2.</div><div id="r2" class="citations"><div class="citation"><div class="citation-content">Nip I, Roth CR. Anarthria. In: Kreutzer J, DeLuca J, Caplan B, eds. <em>Encyclopedia of clinical neuropsychology. 2nd ed</em>. New York: Springer International Publishing, 2017:1-1.</div><div class="external-links"><div class="to-citation__wrapper"><a class="to-citation" href="#body-ref-r2"><i aria-hidden="true" class="icon-return"></i><span>Go to Citation</span></a></div><div class="core-xlink-crossref"><a href="https://doi.org/10.1007/978-3-319-56782-2_855-4" target="_blank">Crossref</a></div><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=Anarthria&amp;publication_year=2017&amp;pages=1-1&amp;doi=10.1007%2F978-3-319-56782-2_855-4" target="_blank">Google Scholar</a></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">3.</div><div id="r3" class="citations"><div class="citation"><div class="citation-content">Felgoise SH, Zaccheo V, Duff J, Simmons Z. Verbal communication impacts quality of life in patients with amyotrophic lateral sclerosis. <em>Amyotroph Lateral Scler Frontotemporal Degener</em> 2016;17:179-183.</div><div class="external-links"><div class="to-citation__wrapper"><a class="to-citation" href="#body-ref-r3"><i aria-hidden="true" class="icon-return"></i><span>Go to Citation</span></a></div><div class="core-xlink-crossref"><a href="https://doi.org/10.3109/21678421.2015.1125499" target="_blank">Crossref</a></div><div class="core-xlink-pubmed"><a href="https://pubmed.ncbi.nlm.nih.gov/27094742/" target="_blank">PubMed</a></div><div class="core-xlink-isi"><a href="https://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2&amp;DestApp=WOS_CPL&amp;UsrCustomerID=5e3815c904498985e796fc91436abd9a&amp;SrcAuth=atyponcel&amp;SrcApp=literatum&amp;DestLinkType=FullRecord&amp;KeyUT=000374776900003" target="_blank">Web of Science</a></div><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=Verbal+communication+impacts+quality+of+life+in+patients+with+amyotrophic+lateral+sclerosis.&amp;publication_year=2016&amp;journal=Amyotroph+Lateral+Scler+Frontotemporal+Degener&amp;pages=179-183&amp;doi=10.3109%2F21678421.2015.1125499&amp;pmid=27094742" target="_blank">Google Scholar</a></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">4.</div><div id="r4" class="citations"><div class="citation"><div class="citation-content">Sellers EW, Ryan DB, Hauser CK. Noninvasive brain–computer interface enables communication after brainstem stroke. <em>Sci Transl Med</em> 2014;6(257):257re7-257re7.</div><div class="external-links"><div class="to-citation__wrapper"><a class="to-citation" href="#body-ref-r8"><i aria-hidden="true" class="icon-return"></i><span>Go to Citation</span></a></div><div class="core-xlink-crossref"><a href="https://doi.org/10.1126/scitranslmed.3007801" target="_blank">Crossref</a></div><div class="core-xlink-pubmed"><a href="https://pubmed.ncbi.nlm.nih.gov/25298323/" target="_blank">PubMed</a></div><div class="core-xlink-isi"><a href="https://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2&amp;DestApp=WOS_CPL&amp;UsrCustomerID=5e3815c904498985e796fc91436abd9a&amp;SrcAuth=atyponcel&amp;SrcApp=literatum&amp;DestLinkType=FullRecord&amp;KeyUT=000343317900011" target="_blank">Web of Science</a></div><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=Noninvasive+brain%E2%80%93computer+interface+enables+communication+after+brainstem+stroke.&amp;publication_year=2014&amp;journal=Sci+Transl+Med&amp;pages=257re7-257re7&amp;doi=10.1126%2Fscitranslmed.3007801&amp;pmid=25298323" target="_blank">Google Scholar</a></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">5.</div><div id="r5" class="citations"><div class="citation"><div class="citation-content">Vansteensel MJ, Pels EGM, Bleichner MG, et al. Fully implanted brain–computer interface in a locked-in patient with ALS. <em>N Engl J Med</em> 2016;375:2060-2066.</div><div class="external-links"><div class="to-citation__wrapper"><button aria-controls="to-citation__accordion-r5" aria-expanded="false" aria-label="Toggle citations menu" class="to-citation__toggle"><i aria-hidden="true" class="icon-plus"></i><span data-expand-title="Hide Citations" data-collapsed-title="Show Citations" class="accordion__toggle__title"></span></button></div><div class="core-xlink-crossref"><a href="/servlet/linkout?suffix=e_1_3_5_6_2&amp;dbid=4&amp;doi=10.1056%2FNEJMoa2027540&amp;key=10.1056%2FNEJMoa1608085&amp;site=mms-site" target="_blank">Crossref</a></div><div class="core-xlink-pubmed"><a href="https://pubmed.ncbi.nlm.nih.gov/27959736/" target="_blank">PubMed</a></div><div class="core-xlink-isi"><a href="https://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2&amp;DestApp=WOS_CPL&amp;UsrCustomerID=5e3815c904498985e796fc91436abd9a&amp;SrcAuth=atyponcel&amp;SrcApp=literatum&amp;DestLinkType=FullRecord&amp;KeyUT=000388464300008" target="_blank">Web of Science</a></div><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=Fully+implanted+brain%E2%80%93computer+interface+in+a+locked-in+patient+with+ALS.&amp;publication_year=2016&amp;journal=N+Engl+J+Med&amp;pages=2060-2066&amp;doi=10.1056%2FNEJMoa1608085&amp;pmid=27959736" target="_blank">Google Scholar</a></div><div role="menu" aria-label="links" class="to-citation__accordion no-separator" id="to-citation__accordion-r5" style="display: none;"><ul role="none"><li role="none"><a class="to-citation" href="#body-ref-r8" role="menuitem"><i aria-hidden="true" class="icon-return"></i><span>a [...] messages by controlling a computer cursor. </span></a></li><li role="none"><a class="to-citation" href="#body-ref-r39" role="menuitem"><i aria-hidden="true" class="icon-return"></i><span>b [...] of electrocorticographic recordings, </span></a></li></ul></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">6.</div><div id="r6" class="citations"><div class="citation"><div class="citation-content">Pandarinath C, Nuyujukian P, Blabe CH, et al. High performance communication by people with paralysis using an intracortical brain–computer interface. <em>Elife</em> 2017;6:e18554-e18554.</div><div class="external-links"><div class="to-citation__wrapper"><button aria-controls="to-citation__accordion-r6" aria-expanded="false" aria-label="Toggle citations menu" class="to-citation__toggle"><i aria-hidden="true" class="icon-plus"></i><span data-expand-title="Hide Citations" data-collapsed-title="Show Citations" class="accordion__toggle__title"></span></button></div><div class="core-xlink-crossref"><a href="https://doi.org/10.7554/eLife.18554" target="_blank">Crossref</a></div><div class="core-xlink-pubmed"><a href="https://pubmed.ncbi.nlm.nih.gov/28220753/" target="_blank">PubMed</a></div><div class="core-xlink-isi"><a href="https://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2&amp;DestApp=WOS_CPL&amp;UsrCustomerID=5e3815c904498985e796fc91436abd9a&amp;SrcAuth=atyponcel&amp;SrcApp=literatum&amp;DestLinkType=FullRecord&amp;KeyUT=000395185000001" target="_blank">Web of Science</a></div><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=High+performance+communication+by+people+with+paralysis+using+an+intracortical+brain%E2%80%93computer+interface.&amp;publication_year=2017&amp;journal=Elife&amp;pages=e18554-e18554&amp;doi=10.7554%2FeLife.18554&amp;pmid=28220753" target="_blank">Google Scholar</a></div><div role="menu" aria-label="links" class="to-citation__accordion no-separator" id="to-citation__accordion-r6" style="display: none;"><ul role="none"><li role="none"><a class="to-citation" href="#body-ref-r8" role="menuitem"><i aria-hidden="true" class="icon-return"></i><span>a [...] messages by controlling a computer cursor. </span></a></li><li role="none"><a class="to-citation" href="#body-ref-r35-1" role="menuitem"><i aria-hidden="true" class="icon-return"></i><span>b [...] before deployment with a user, </span></a></li></ul></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">7.</div><div id="r7" class="citations"><div class="citation"><div class="citation-content">Brumberg JS, Pitt KM, Mantie-Kozlowski A, Burnison JD. Brain–computer interfaces for augmentative and alternative communication: a tutorial. <em>Am J Speech Lang Pathol</em> 2018;27:1-12.</div><div class="external-links"><div class="to-citation__wrapper"><a class="to-citation" href="#body-ref-r8"><i aria-hidden="true" class="icon-return"></i><span>Go to Citation</span></a></div><div class="core-xlink-crossref"><a href="https://doi.org/10.1044/2017_AJSLP-16-0244" target="_blank">Crossref</a></div><div class="core-xlink-pubmed"><a href="https://pubmed.ncbi.nlm.nih.gov/29318256/" target="_blank">PubMed</a></div><div class="core-xlink-isi"><a href="https://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2&amp;DestApp=WOS_CPL&amp;UsrCustomerID=5e3815c904498985e796fc91436abd9a&amp;SrcAuth=atyponcel&amp;SrcApp=literatum&amp;DestLinkType=FullRecord&amp;KeyUT=000425847000001" target="_blank">Web of Science</a></div><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=Brain%E2%80%93computer+interfaces+for+augmentative+and+alternative+communication%3A+a+tutorial.&amp;publication_year=2018&amp;journal=Am+J+Speech+Lang+Pathol&amp;pages=1-12&amp;doi=10.1044%2F2017_AJSLP-16-0244&amp;pmid=29318256" target="_blank">Google Scholar</a></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">8.</div><div id="r8" class="citations"><div class="citation"><div class="citation-content">Linse K, Aust E, Joos M, Hermann A. Communication matters — pitfalls and promise of hightech communication devices in palliative care of severely physically disabled patients with amyotrophic lateral sclerosis. <em>Front Neurol</em> 2018;9:603-603.</div><div class="external-links"><div class="to-citation__wrapper"><a class="to-citation" href="#body-ref-r8"><i aria-hidden="true" class="icon-return"></i><span>Go to Citation</span></a></div><div class="core-xlink-crossref"><a href="https://doi.org/10.3389/fneur.2018.00603" target="_blank">Crossref</a></div><div class="core-xlink-pubmed"><a href="https://pubmed.ncbi.nlm.nih.gov/30100896/" target="_blank">PubMed</a></div><div class="core-xlink-isi"><a href="https://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2&amp;DestApp=WOS_CPL&amp;UsrCustomerID=5e3815c904498985e796fc91436abd9a&amp;SrcAuth=atyponcel&amp;SrcApp=literatum&amp;DestLinkType=FullRecord&amp;KeyUT=000440028800001" target="_blank">Web of Science</a></div><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=Communication+matters+%E2%80%94+pitfalls+and+promise+of+hightech+communication+devices+in+palliative+care+of+severely+physically+disabled+patients+with+amyotrophic+lateral+sclerosis.&amp;publication_year=2018&amp;journal=Front+Neurol&amp;pages=603-603&amp;doi=10.3389%2Ffneur.2018.00603&amp;pmid=30100896" target="_blank">Google Scholar</a></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">9.</div><div id="r9" class="citations"><div class="citation"><div class="citation-content">Bouchard KE, Mesgarani N, Johnson K, Chang EF. Functional organization of human sensorimotor cortex for speech articulation. <em>Nature</em> 2013;495:327-332.</div><div class="external-links"><div class="to-citation__wrapper"><button aria-controls="to-citation__accordion-r9" aria-expanded="false" aria-label="Toggle citations menu" class="to-citation__toggle"><i aria-hidden="true" class="icon-plus"></i><span data-expand-title="Hide Citations" data-collapsed-title="Show Citations" class="accordion__toggle__title"></span></button></div><div class="core-xlink-crossref"><a href="https://doi.org/10.1038/nature11911" target="_blank">Crossref</a></div><div class="core-xlink-pubmed"><a href="https://pubmed.ncbi.nlm.nih.gov/23426266/" target="_blank">PubMed</a></div><div class="core-xlink-isi"><a href="https://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2&amp;DestApp=WOS_CPL&amp;UsrCustomerID=5e3815c904498985e796fc91436abd9a&amp;SrcAuth=atyponcel&amp;SrcApp=literatum&amp;DestLinkType=FullRecord&amp;KeyUT=000316650500034" target="_blank">Web of Science</a></div><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=Functional+organization+of+human+sensorimotor+cortex+for+speech+articulation.&amp;publication_year=2013&amp;journal=Nature&amp;pages=327-332&amp;doi=10.1038%2Fnature11911&amp;pmid=23426266" target="_blank">Google Scholar</a></div><div role="menu" aria-label="links" class="to-citation__accordion no-separator" id="to-citation__accordion-r9" style="display: none;"><ul role="none"><li role="none"><a class="to-citation" href="#body-ref-r14-1" role="menuitem"><i aria-hidden="true" class="icon-return"></i><span>a [...] movements of the vocal tract has expanded. </span></a></li><li role="none"><a class="to-citation" href="#body-ref-r13-2" role="menuitem"><i aria-hidden="true" class="icon-return"></i><span>b [...] and posterior inferior frontal gyrus. </span></a></li><li role="none"><a class="to-citation" href="#body-ref-r18-3" role="menuitem"><i aria-hidden="true" class="icon-return"></i><span>c [...] frequency range with speech processing, </span></a></li><li role="none"><a class="to-citation" href="#body-ref-r13-4" role="menuitem"><i aria-hidden="true" class="icon-return"></i><span>d [...] implicating this area in speech production. </span></a></li></ul></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">10.</div><div id="r10" class="citations"><div class="citation"><div class="citation-content">Lotte F, Brumberg JS, Brunner P, et al. Electrocorticographic representations of segmental features in continuous speech. <em>Front Hum Neurosci</em> 2015;9:97-97.</div><div class="external-links"><div class="to-citation__wrapper"><a class="to-citation" href="#body-ref-r14-1"><i aria-hidden="true" class="icon-return"></i><span>Go to Citation</span></a></div><div class="core-xlink-crossref"><a href="https://doi.org/10.3389/fnhum.2015.00097" target="_blank">Crossref</a></div><div class="core-xlink-pubmed"><a href="https://pubmed.ncbi.nlm.nih.gov/25759647/" target="_blank">PubMed</a></div><div class="core-xlink-isi"><a href="https://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2&amp;DestApp=WOS_CPL&amp;UsrCustomerID=5e3815c904498985e796fc91436abd9a&amp;SrcAuth=atyponcel&amp;SrcApp=literatum&amp;DestLinkType=FullRecord&amp;KeyUT=000349949100001" target="_blank">Web of Science</a></div><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=Electrocorticographic+representations+of+segmental+features+in+continuous+speech.&amp;publication_year=2015&amp;journal=Front+Hum+Neurosci&amp;pages=97-97&amp;doi=10.3389%2Ffnhum.2015.00097&amp;pmid=25759647" target="_blank">Google Scholar</a></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">11.</div><div id="r11" class="citations"><div class="citation"><div class="citation-content">Guenther FH, Hickok G. Neural models of motor speech control. In: Hickok G, Small S, eds.<em>Neurobiology of language</em>. Cambridge, MA: Academic Press, 2015:725-740.</div><div class="external-links"><div class="to-citation__wrapper"><button aria-controls="to-citation__accordion-r11" aria-expanded="false" aria-label="Toggle citations menu" class="to-citation__toggle"><i aria-hidden="true" class="icon-plus"></i><span data-expand-title="Hide Citations" data-collapsed-title="Show Citations" class="accordion__toggle__title"></span></button></div><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=Neural+models+of+motor+speech+control&amp;publication_year=2015&amp;pages=725-740" target="_blank">Google Scholar</a></div><div role="menu" aria-label="links" class="to-citation__accordion no-separator" id="to-citation__accordion-r11" style="display: none;"><ul role="none"><li role="none"><a class="to-citation" href="#body-ref-r14-1" role="menuitem"><i aria-hidden="true" class="icon-return"></i><span>a [...] movements of the vocal tract has expanded. </span></a></li><li role="none"><a class="to-citation" href="#body-ref-r13-2" role="menuitem"><i aria-hidden="true" class="icon-return"></i><span>b [...] and posterior inferior frontal gyrus. </span></a></li></ul></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">12.</div><div id="r12" class="citations"><div class="citation"><div class="citation-content">Mugler EM, Tate MC, Livescu K, Templer JW, Goldrick MA, Slutzky MW. Differential representation of articulatory gestures and phonemes in precentral and inferior frontal gyri. <em>J Neurosci</em> 2018;38:9803-9813.</div><div class="external-links"><div class="to-citation__wrapper"><button aria-controls="to-citation__accordion-r12" aria-expanded="false" aria-label="Toggle citations menu" class="to-citation__toggle"><i aria-hidden="true" class="icon-plus"></i><span data-expand-title="Hide Citations" data-collapsed-title="Show Citations" class="accordion__toggle__title"></span></button></div><div class="core-xlink-crossref"><a href="https://doi.org/10.1523/JNEUROSCI.1206-18.2018" target="_blank">Crossref</a></div><div class="core-xlink-pubmed"><a href="https://pubmed.ncbi.nlm.nih.gov/30257858/" target="_blank">PubMed</a></div><div class="core-xlink-isi"><a href="https://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2&amp;DestApp=WOS_CPL&amp;UsrCustomerID=5e3815c904498985e796fc91436abd9a&amp;SrcAuth=atyponcel&amp;SrcApp=literatum&amp;DestLinkType=FullRecord&amp;KeyUT=000450072200001" target="_blank">Web of Science</a></div><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=Differential+representation+of+articulatory+gestures+and+phonemes+in+precentral+and+inferior+frontal+gyri.&amp;publication_year=2018&amp;journal=J+Neurosci&amp;pages=9803-9813&amp;doi=10.1523%2FJNEUROSCI.1206-18.2018&amp;pmid=30257858" target="_blank">Google Scholar</a></div><div role="menu" aria-label="links" class="to-citation__accordion no-separator" id="to-citation__accordion-r12" style="display: none;"><ul role="none"><li role="none"><a class="to-citation" href="#body-ref-r14-1" role="menuitem"><i aria-hidden="true" class="icon-return"></i><span>a [...] movements of the vocal tract has expanded. </span></a></li><li role="none"><a class="to-citation" href="#body-ref-r13-2" role="menuitem"><i aria-hidden="true" class="icon-return"></i><span>b [...] and posterior inferior frontal gyrus. </span></a></li><li role="none"><a class="to-citation" href="#body-ref-r18-3" role="menuitem"><i aria-hidden="true" class="icon-return"></i><span>c [...] frequency range with speech processing, </span></a></li><li role="none"><a class="to-citation" href="#body-ref-r13-4" role="menuitem"><i aria-hidden="true" class="icon-return"></i><span>d [...] implicating this area in speech production. </span></a></li></ul></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">13.</div><div id="r13" class="citations"><div class="citation"><div class="citation-content">Chartier J, Anumanchipalli GK, Johnson K, Chang EF. Encoding of articulatory kinematic trajectories in human speech sensorimotor cortex. <em>Neuron</em> 2018;98(5):1042.e4-1054.e4.</div><div class="external-links"><div class="to-citation__wrapper"><button aria-controls="to-citation__accordion-r13" aria-expanded="false" aria-label="Toggle citations menu" class="to-citation__toggle"><i aria-hidden="true" class="icon-plus"></i><span data-expand-title="Hide Citations" data-collapsed-title="Show Citations" class="accordion__toggle__title"></span></button></div><div class="core-xlink-crossref"><a href="https://doi.org/10.1016/j.neuron.2018.04.031" target="_blank">Crossref</a></div><div class="core-xlink-pubmed"><a href="https://pubmed.ncbi.nlm.nih.gov/29779940/" target="_blank">PubMed</a></div><div class="core-xlink-isi"><a href="https://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2&amp;DestApp=WOS_CPL&amp;UsrCustomerID=5e3815c904498985e796fc91436abd9a&amp;SrcAuth=atyponcel&amp;SrcApp=literatum&amp;DestLinkType=FullRecord&amp;KeyUT=000436585500020" target="_blank">Web of Science</a></div><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=Encoding+of+articulatory+kinematic+trajectories+in+human+speech+sensorimotor+cortex.&amp;publication_year=2018&amp;journal=Neuron&amp;pages=1042.e4-1054.e4&amp;doi=10.1016%2Fj.neuron.2018.04.031&amp;pmid=29779940" target="_blank">Google Scholar</a></div><div role="menu" aria-label="links" class="to-citation__accordion no-separator" id="to-citation__accordion-r13" style="display: none;"><ul role="none"><li role="none"><a class="to-citation" href="#body-ref-r14-1" role="menuitem"><i aria-hidden="true" class="icon-return"></i><span>a [...] movements of the vocal tract has expanded. </span></a></li><li role="none"><a class="to-citation" href="#body-ref-r13-2" role="menuitem"><i aria-hidden="true" class="icon-return"></i><span>b [...] and posterior inferior frontal gyrus. </span></a></li><li role="none"><a class="to-citation" href="#body-ref-r18-3" role="menuitem"><i aria-hidden="true" class="icon-return"></i><span>c [...] frequency range with speech processing, </span></a></li><li role="none"><a class="to-citation" href="#body-ref-r13-4" role="menuitem"><i aria-hidden="true" class="icon-return"></i><span>d [...] implicating this area in speech production. </span></a></li></ul></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">14.</div><div id="r14" class="citations"><div class="citation"><div class="citation-content">Salari E, Freudenburg ZV, Branco MP, Aarnoutse EJ, Vansteensel MJ, Ramsey NF. Classification of articulator movements and movement direction from sensorimotor cortex activity. <em>Sci Rep</em> 2019;9:14165-14165.</div><div class="external-links"><div class="to-citation__wrapper"><button aria-controls="to-citation__accordion-r14" aria-expanded="false" aria-label="Toggle citations menu" class="to-citation__toggle"><i aria-hidden="true" class="icon-plus"></i><span data-expand-title="Hide Citations" data-collapsed-title="Show Citations" class="accordion__toggle__title"></span></button></div><div class="core-xlink-crossref"><a href="https://doi.org/10.1038/s41598-019-50834-5" target="_blank">Crossref</a></div><div class="core-xlink-pubmed"><a href="https://pubmed.ncbi.nlm.nih.gov/31578420/" target="_blank">PubMed</a></div><div class="core-xlink-isi"><a href="https://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2&amp;DestApp=WOS_CPL&amp;UsrCustomerID=5e3815c904498985e796fc91436abd9a&amp;SrcAuth=atyponcel&amp;SrcApp=literatum&amp;DestLinkType=FullRecord&amp;KeyUT=000488481500028" target="_blank">Web of Science</a></div><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=Classification+of+articulator+movements+and+movement+direction+from+sensorimotor+cortex+activity.&amp;publication_year=2019&amp;journal=Sci+Rep&amp;pages=14165-14165&amp;doi=10.1038%2Fs41598-019-50834-5&amp;pmid=31578420" target="_blank">Google Scholar</a></div><div role="menu" aria-label="links" class="to-citation__accordion no-separator" id="to-citation__accordion-r14" style="display: none;"><ul role="none"><li role="none"><a class="to-citation" href="#body-ref-r14-1" role="menuitem"><i aria-hidden="true" class="icon-return"></i><span>a [...] movements of the vocal tract has expanded. </span></a></li><li role="none"><a class="to-citation" href="#body-ref-r18-3" role="menuitem"><i aria-hidden="true" class="icon-return"></i><span>b [...] frequency range with speech processing, </span></a></li></ul></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">15.</div><div id="r15" class="citations"><div class="citation"><div class="citation-content">Herff C, Heger D, de Pesters A, et al. Brain-to-text: decoding spoken phrases from phone representations in the brain. <em>Front Neurosci</em> 2015;9:217-217.</div><div class="external-links"><div class="to-citation__wrapper"><button aria-controls="to-citation__accordion-r15" aria-expanded="false" aria-label="Toggle citations menu" class="to-citation__toggle"><i aria-hidden="true" class="icon-plus"></i><span data-expand-title="Hide Citations" data-collapsed-title="Show Citations" class="accordion__toggle__title"></span></button></div><div class="core-xlink-crossref"><a href="https://doi.org/10.3389/fnins.2015.00217" target="_blank">Crossref</a></div><div class="core-xlink-pubmed"><a href="https://pubmed.ncbi.nlm.nih.gov/26124702/" target="_blank">PubMed</a></div><div class="core-xlink-isi"><a href="https://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2&amp;DestApp=WOS_CPL&amp;UsrCustomerID=5e3815c904498985e796fc91436abd9a&amp;SrcAuth=atyponcel&amp;SrcApp=literatum&amp;DestLinkType=FullRecord&amp;KeyUT=000362002000001" target="_blank">Web of Science</a></div><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=Brain-to-text%3A+decoding+spoken+phrases+from+phone+representations+in+the+brain.&amp;publication_year=2015&amp;journal=Front+Neurosci&amp;pages=217-217&amp;doi=10.3389%2Ffnins.2015.00217&amp;pmid=26124702" target="_blank">Google Scholar</a></div><div role="menu" aria-label="links" class="to-citation__accordion no-separator" id="to-citation__accordion-r15" style="display: none;"><ul role="none"><li role="none"><a class="to-citation" href="#body-ref-r19-1" role="menuitem"><i aria-hidden="true" class="icon-return"></i><span>a [...] in persons without speech impairments. </span></a></li><li role="none"><a class="to-citation" href="#body-ref-r19-3" role="menuitem"><i aria-hidden="true" class="icon-return"></i><span>b [...] for assistive technology to communicate. </span></a></li></ul></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">16.</div><div id="r16" class="citations"><div class="citation"><div class="citation-content">Angrick M, Herff C, Mugler E, et al. Speech synthesis from ECoG using densely connected 3D convolutional neural networks. <em>J Neural Eng</em> 2019;16:036019-036019.</div><div class="external-links"><div class="to-citation__wrapper"><button aria-controls="to-citation__accordion-r16" aria-expanded="false" aria-label="Toggle citations menu" class="to-citation__toggle"><i aria-hidden="true" class="icon-plus"></i><span data-expand-title="Hide Citations" data-collapsed-title="Show Citations" class="accordion__toggle__title"></span></button></div><div class="core-xlink-crossref"><a href="https://doi.org/10.1088/1741-2552/ab0c59" target="_blank">Crossref</a></div><div class="core-xlink-pubmed"><a href="https://pubmed.ncbi.nlm.nih.gov/30831567/" target="_blank">PubMed</a></div><div class="core-xlink-isi"><a href="https://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2&amp;DestApp=WOS_CPL&amp;UsrCustomerID=5e3815c904498985e796fc91436abd9a&amp;SrcAuth=atyponcel&amp;SrcApp=literatum&amp;DestLinkType=FullRecord&amp;KeyUT=000465010800005" target="_blank">Web of Science</a></div><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=Speech+synthesis+from+ECoG+using+densely+connected+3D+convolutional+neural+networks.&amp;publication_year=2019&amp;journal=J+Neural+Eng&amp;pages=036019-036019&amp;doi=10.1088%2F1741-2552%2Fab0c59&amp;pmid=30831567" target="_blank">Google Scholar</a></div><div role="menu" aria-label="links" class="to-citation__accordion no-separator" id="to-citation__accordion-r16" style="display: none;"><ul role="none"><li role="none"><a class="to-citation" href="#body-ref-r19-1" role="menuitem"><i aria-hidden="true" class="icon-return"></i><span>a [...] in persons without speech impairments. </span></a></li><li role="none"><a class="to-citation" href="#body-ref-r19-3" role="menuitem"><i aria-hidden="true" class="icon-return"></i><span>b [...] for assistive technology to communicate. </span></a></li></ul></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">17.</div><div id="r17" class="citations"><div class="citation"><div class="citation-content">Anumanchipalli GK, Chartier J, Chang EF. Speech synthesis from neural decoding of spoken sentences. <em>Nature</em> 2019;568:493-498.</div><div class="external-links"><div class="to-citation__wrapper"><button aria-controls="to-citation__accordion-r17" aria-expanded="false" aria-label="Toggle citations menu" class="to-citation__toggle"><i aria-hidden="true" class="icon-plus"></i><span data-expand-title="Hide Citations" data-collapsed-title="Show Citations" class="accordion__toggle__title"></span></button></div><div class="core-xlink-crossref"><a href="https://doi.org/10.1038/s41586-019-1119-1" target="_blank">Crossref</a></div><div class="core-xlink-pubmed"><a href="https://pubmed.ncbi.nlm.nih.gov/31019317/" target="_blank">PubMed</a></div><div class="core-xlink-isi"><a href="https://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2&amp;DestApp=WOS_CPL&amp;UsrCustomerID=5e3815c904498985e796fc91436abd9a&amp;SrcAuth=atyponcel&amp;SrcApp=literatum&amp;DestLinkType=FullRecord&amp;KeyUT=000465594200040" target="_blank">Web of Science</a></div><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=Speech+synthesis+from+neural+decoding+of+spoken+sentences.&amp;publication_year=2019&amp;journal=Nature&amp;pages=493-498&amp;doi=10.1038%2Fs41586-019-1119-1&amp;pmid=31019317" target="_blank">Google Scholar</a></div><div role="menu" aria-label="links" class="to-citation__accordion no-separator" id="to-citation__accordion-r17" style="display: none;"><ul role="none"><li role="none"><a class="to-citation" href="#body-ref-r19-1" role="menuitem"><i aria-hidden="true" class="icon-return"></i><span>a [...] in persons without speech impairments. </span></a></li><li role="none"><a class="to-citation" href="#body-ref-r19-3" role="menuitem"><i aria-hidden="true" class="icon-return"></i><span>b [...] for assistive technology to communicate. </span></a></li></ul></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">18.</div><div id="r18" class="citations"><div class="citation"><div class="citation-content">Moses DA, Leonard MK, Makin JG, Chang EF. Real-time decoding of question-and-answer speech dialogue using human cortical activity. <em>Nat Commun</em> 2019;10:3096-3096.</div><div class="external-links"><div class="to-citation__wrapper"><button aria-controls="to-citation__accordion-r18" aria-expanded="false" aria-label="Toggle citations menu" class="to-citation__toggle"><i aria-hidden="true" class="icon-plus"></i><span data-expand-title="Hide Citations" data-collapsed-title="Show Citations" class="accordion__toggle__title"></span></button></div><div class="core-xlink-crossref"><a href="https://doi.org/10.1038/s41467-019-10994-4" target="_blank">Crossref</a></div><div class="core-xlink-pubmed"><a href="https://pubmed.ncbi.nlm.nih.gov/31363096/" target="_blank">PubMed</a></div><div class="core-xlink-isi"><a href="https://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2&amp;DestApp=WOS_CPL&amp;UsrCustomerID=5e3815c904498985e796fc91436abd9a&amp;SrcAuth=atyponcel&amp;SrcApp=literatum&amp;DestLinkType=FullRecord&amp;KeyUT=000477859900001" target="_blank">Web of Science</a></div><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=Real-time+decoding+of+question-and-answer+speech+dialogue+using+human+cortical+activity.&amp;publication_year=2019&amp;journal=Nat+Commun&amp;pages=3096-3096&amp;doi=10.1038%2Fs41467-019-10994-4&amp;pmid=31363096" target="_blank">Google Scholar</a></div><div role="menu" aria-label="links" class="to-citation__accordion no-separator" id="to-citation__accordion-r18" style="display: none;"><ul role="none"><li role="none"><a class="to-citation" href="#body-ref-r19-1" role="menuitem"><i aria-hidden="true" class="icon-return"></i><span>a [...] in persons without speech impairments. </span></a></li><li role="none"><a class="to-citation" href="#body-ref-r23" role="menuitem"><i aria-hidden="true" class="icon-return"></i><span>b [...] analysis (Section S2 and Figs. S2 and S3). </span></a></li><li role="none"><a class="to-citation" href="#body-ref-r18-3" role="menuitem"><i aria-hidden="true" class="icon-return"></i><span>c [...] frequency range with speech processing, </span></a></li><li role="none"><a class="to-citation" href="#body-ref-r19-3" role="menuitem"><i aria-hidden="true" class="icon-return"></i><span>d [...] for assistive technology to communicate. </span></a></li><li role="none"><a class="to-citation" href="#body-ref-r29" role="menuitem"><i aria-hidden="true" class="icon-return"></i><span>e [...] problem with speech-detection approaches </span></a></li></ul></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">19.</div><div id="r19" class="citations"><div class="citation"><div class="citation-content">Makin JG, Moses DA, Chang EF. Machine translation of cortical activity to text with an encoder-decoder framework. <em>Nat Neurosci</em> 2020;23:575-582.</div><div class="external-links"><div class="to-citation__wrapper"><button aria-controls="to-citation__accordion-r19" aria-expanded="false" aria-label="Toggle citations menu" class="to-citation__toggle"><i aria-hidden="true" class="icon-plus"></i><span data-expand-title="Hide Citations" data-collapsed-title="Show Citations" class="accordion__toggle__title"></span></button></div><div class="core-xlink-crossref"><a href="https://doi.org/10.1038/s41593-020-0608-8" target="_blank">Crossref</a></div><div class="core-xlink-pubmed"><a href="https://pubmed.ncbi.nlm.nih.gov/32231340/" target="_blank">PubMed</a></div><div class="core-xlink-isi"><a href="https://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2&amp;DestApp=WOS_CPL&amp;UsrCustomerID=5e3815c904498985e796fc91436abd9a&amp;SrcAuth=atyponcel&amp;SrcApp=literatum&amp;DestLinkType=FullRecord&amp;KeyUT=000522382600003" target="_blank">Web of Science</a></div><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=Machine+translation+of+cortical+activity+to+text+with+an+encoder-decoder+framework.&amp;publication_year=2020&amp;journal=Nat+Neurosci&amp;pages=575-582&amp;doi=10.1038%2Fs41593-020-0608-8&amp;pmid=32231340" target="_blank">Google Scholar</a></div><div role="menu" aria-label="links" class="to-citation__accordion no-separator" id="to-citation__accordion-r19" style="display: none;"><ul role="none"><li role="none"><a class="to-citation" href="#body-ref-r19-1" role="menuitem"><i aria-hidden="true" class="icon-return"></i><span>a [...] in persons without speech impairments. </span></a></li><li role="none"><a class="to-citation" href="#body-ref-r27" role="menuitem"><i aria-hidden="true" class="icon-return"></i><span>b [...] by the detection and classification models. </span></a></li><li role="none"><a class="to-citation" href="#body-ref-r19-3" role="menuitem"><i aria-hidden="true" class="icon-return"></i><span>c [...] for assistive technology to communicate. </span></a></li></ul></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">20.</div><div id="r20" class="citations"><div class="citation"><div class="citation-content">Martin S, Iturrate I, Millán JDR, Knight RT, Pasley BN. Decoding inner speech using electrocorticography: progress and challenges toward a speech prosthesis. <em>Front Neurosci</em> 2018;12:422-422.</div><div class="external-links"><div class="to-citation__wrapper"><a class="to-citation" href="#body-ref-r20"><i aria-hidden="true" class="icon-return"></i><span>Go to Citation</span></a></div><div class="core-xlink-crossref"><a href="https://doi.org/10.3389/fnins.2018.00422" target="_blank">Crossref</a></div><div class="core-xlink-pubmed"><a href="https://pubmed.ncbi.nlm.nih.gov/29977189/" target="_blank">PubMed</a></div><div class="core-xlink-isi"><a href="https://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2&amp;DestApp=WOS_CPL&amp;UsrCustomerID=5e3815c904498985e796fc91436abd9a&amp;SrcAuth=atyponcel&amp;SrcApp=literatum&amp;DestLinkType=FullRecord&amp;KeyUT=000435844500001" target="_blank">Web of Science</a></div><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=Decoding+inner+speech+using+electrocorticography%3A+progress+and+challenges+toward+a+speech+prosthesis.&amp;publication_year=2018&amp;journal=Front+Neurosci&amp;pages=422-422&amp;doi=10.3389%2Ffnins.2018.00422&amp;pmid=29977189" target="_blank">Google Scholar</a></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">21.</div><div id="r21" class="citations"><div class="citation"><div class="citation-content">Guenther FH, Brumberg JS, Wright EJ, et al. A wireless brain–machine interface for real-time speech synthesis. <em>PLoS One</em> 2009;4(12):e8218-e8218.</div><div class="external-links"><div class="to-citation__wrapper"><a class="to-citation" href="#body-ref-r22"><i aria-hidden="true" class="icon-return"></i><span>Go to Citation</span></a></div><div class="core-xlink-crossref"><a href="https://doi.org/10.1371/journal.pone.0008218" target="_blank">Crossref</a></div><div class="core-xlink-pubmed"><a href="https://pubmed.ncbi.nlm.nih.gov/20011034/" target="_blank">PubMed</a></div><div class="core-xlink-isi"><a href="https://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2&amp;DestApp=WOS_CPL&amp;UsrCustomerID=5e3815c904498985e796fc91436abd9a&amp;SrcAuth=atyponcel&amp;SrcApp=literatum&amp;DestLinkType=FullRecord&amp;KeyUT=000272829800009" target="_blank">Web of Science</a></div><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=A+wireless+brain%E2%80%93machine+interface+for+real-time+speech+synthesis.&amp;publication_year=2009&amp;journal=PLoS+One&amp;pages=e8218-e8218&amp;doi=10.1371%2Fjournal.pone.0008218&amp;pmid=20011034" target="_blank">Google Scholar</a></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">22.</div><div id="r22" class="citations"><div class="citation"><div class="citation-content">Brumberg JS, Wright EJ, Andreasen DS, Guenther FH, Kennedy PR. Classification of intended phoneme production from chronic intracortical microelectrode recordings in speech-motor cortex. <em>Front Neurosci</em> 2011;5:65-65.</div><div class="external-links"><div class="to-citation__wrapper"><a class="to-citation" href="#body-ref-r22"><i aria-hidden="true" class="icon-return"></i><span>Go to Citation</span></a></div><div class="core-xlink-pubmed"><a href="https://pubmed.ncbi.nlm.nih.gov/21629876/" target="_blank">PubMed</a></div><div class="core-xlink-isi"><a href="https://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2&amp;DestApp=WOS_CPL&amp;UsrCustomerID=5e3815c904498985e796fc91436abd9a&amp;SrcAuth=atyponcel&amp;SrcApp=literatum&amp;DestLinkType=FullRecord&amp;KeyUT=000209200600061" target="_blank">Web of Science</a></div><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=Classification+of+intended+phoneme+production+from+chronic+intracortical+microelectrode+recordings+in+speech-motor+cortex.&amp;publication_year=2011&amp;journal=Front+Neurosci&amp;pages=65-65&amp;pmid=21629876" target="_blank">Google Scholar</a></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">23.</div><div id="r23" class="citations"><div class="citation"><div class="citation-content">Moses DA, Leonard MK, Chang EF. Real-time classification of auditory sentences using evoked cortical activity in humans. <em>J Neural Eng</em> 2018;15:036005-036005.</div><div class="external-links"><div class="to-citation__wrapper"><a class="to-citation" href="#body-ref-r23"><i aria-hidden="true" class="icon-return"></i><span>Go to Citation</span></a></div><div class="core-xlink-crossref"><a href="https://doi.org/10.1088/1741-2552/aaab6f" target="_blank">Crossref</a></div><div class="core-xlink-pubmed"><a href="https://pubmed.ncbi.nlm.nih.gov/29378977/" target="_blank">PubMed</a></div><div class="core-xlink-isi"><a href="https://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2&amp;DestApp=WOS_CPL&amp;UsrCustomerID=5e3815c904498985e796fc91436abd9a&amp;SrcAuth=atyponcel&amp;SrcApp=literatum&amp;DestLinkType=FullRecord&amp;KeyUT=000426274400005" target="_blank">Web of Science</a></div><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=Real-time+classification+of+auditory+sentences+using+evoked+cortical+activity+in+humans.&amp;publication_year=2018&amp;journal=J+Neural+Eng&amp;pages=036005-036005&amp;doi=10.1088%2F1741-2552%2Faaab6f&amp;pmid=29378977" target="_blank">Google Scholar</a></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">24.</div><div id="r24" class="citations"><div class="citation"><div class="citation-content">Kneser R, Ney H. Improved backing-off for M-gram language modeling. In: <em>Conference proceedings: 1995 International Conference on Acoustics, Speech, and Signal Processing. Vol. 1</em>. New York: Institute of Electrical and Electronics Engineers, 1995:181-184.</div><div class="external-links"><div class="to-citation__wrapper"><a class="to-citation" href="#body-ref-r25"><i aria-hidden="true" class="icon-return"></i><span>Go to Citation</span></a></div><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=Improved+backing-off+for+M-gram+language+modeling.&amp;publication_year=1995&amp;pages=181-184" target="_blank">Google Scholar</a></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">25.</div><div id="r25" class="citations"><div class="citation"><div class="citation-content">Chen SF, Goodman J. An empirical study of smoothing techniques for language modeling. <em>Comput Speech Lang</em> 1999;13:359-394.</div><div class="external-links"><div class="to-citation__wrapper"><a class="to-citation" href="#body-ref-r25"><i aria-hidden="true" class="icon-return"></i><span>Go to Citation</span></a></div><div class="core-xlink-crossref"><a href="https://doi.org/10.1006/csla.1999.0128" target="_blank">Crossref</a></div><div class="core-xlink-isi"><a href="https://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2&amp;DestApp=WOS_CPL&amp;UsrCustomerID=5e3815c904498985e796fc91436abd9a&amp;SrcAuth=atyponcel&amp;SrcApp=literatum&amp;DestLinkType=FullRecord&amp;KeyUT=000083093200003" target="_blank">Web of Science</a></div><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=An+empirical+study+of+smoothing+techniques+for+language+modeling.&amp;publication_year=1999&amp;journal=Comput+Speech+Lang&amp;pages=359-394&amp;doi=10.1006%2Fcsla.1999.0128" target="_blank">Google Scholar</a></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">26.</div><div id="r26" class="citations"><div class="citation"><div class="citation-content">Viterbi AJ. Error bounds for convolutional codes and an asymptotically optimum decoding algorithm. <em>IEEE Trans Inf Theory</em> 1967;13:260-269.</div><div class="external-links"><div class="to-citation__wrapper"><a class="to-citation" href="#body-ref-r26"><i aria-hidden="true" class="icon-return"></i><span>Go to Citation</span></a></div><div class="core-xlink-crossref"><a href="https://doi.org/10.1109/TIT.1967.1054010" target="_blank">Crossref</a></div><div class="core-xlink-isi"><a href="https://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2&amp;DestApp=WOS_CPL&amp;UsrCustomerID=5e3815c904498985e796fc91436abd9a&amp;SrcAuth=atyponcel&amp;SrcApp=literatum&amp;DestLinkType=FullRecord&amp;KeyUT=A19679497100016" target="_blank">Web of Science</a></div><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=Error+bounds+for+convolutional+codes+and+an+asymptotically+optimum+decoding+algorithm.&amp;publication_year=1967&amp;journal=IEEE+Trans+Inf+Theory&amp;pages=260-269&amp;doi=10.1109%2FTIT.1967.1054010" target="_blank">Google Scholar</a></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">27.</div><div id="r27" class="citations"><div class="citation"><div class="citation-content">Simonyan K, Vedaldi A, Zisserman A. Deep inside convolutional networks: visualising image classification models and saliency maps. In: Bengio Y, LeCun Y, eds. <em>Workshop at the International Conference on Learning Representations</em>. Banff, AB, Canada: ICLR Workshop, 2014.</div><div class="external-links"><div class="to-citation__wrapper"><a class="to-citation" href="#body-ref-r27"><i aria-hidden="true" class="icon-return"></i><span>Go to Citation</span></a></div><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=Deep+inside+convolutional+networks%3A+visualising+image+classification+models+and+saliency+maps&amp;publication_year=2014" target="_blank">Google Scholar</a></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">28.</div><div id="r28" class="citations"><div class="citation"><div class="citation-content">Kanas VG, Mporas I, Benz HL, Sgarbas KN, Bezerianos A, Crone NE. Real-time voice activity detection for ECoG-based speech brain machine interfaces. In: <em>19th International Conference on Digital Signal Processing: proceedings</em>. New York: Institute of Electrical and Electronics Engineers, 2014:862-865.</div><div class="external-links"><div class="to-citation__wrapper"><a class="to-citation" href="#body-ref-r29"><i aria-hidden="true" class="icon-return"></i><span>Go to Citation</span></a></div><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=Real-time+voice+activity+detection+for+ECoG-based+speech+brain+machine+interfaces&amp;publication_year=2014&amp;pages=862-865" target="_blank">Google Scholar</a></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">29.</div><div id="r29" class="citations"><div class="citation"><div class="citation-content">Dash D, Ferrari P, Dutta S, Wang J. NeuroVAD: real-time voice activity detection from non-invasive neuromagnetic signals. <em>Sensors (Basel)</em> 2020;20:2248-2248.</div><div class="external-links"><div class="to-citation__wrapper"><a class="to-citation" href="#body-ref-r29"><i aria-hidden="true" class="icon-return"></i><span>Go to Citation</span></a></div><div class="core-xlink-crossref"><a href="https://doi.org/10.3390/s20082248" target="_blank">Crossref</a></div><div class="core-xlink-pubmed"><a href="https://pubmed.ncbi.nlm.nih.gov/32316162/" target="_blank">PubMed</a></div><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=NeuroVAD%3A+real-time+voice+activity+detection+from+non-invasive+neuromagnetic+signals.&amp;publication_year=2020&amp;journal=Sensors+%28Basel%29&amp;pages=2248-2248&amp;doi=10.3390%2Fs20082248&amp;pmid=32316162" target="_blank">Google Scholar</a></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">30.</div><div id="r30" class="citations"><div class="citation"><div class="citation-content">Sollich P, Krogh A. Learning with ensembles: how overfitting can be useful. In: Touretzky DS, Mozer MC, Hasselmo ME, eds. <em>Advances in neural information processing systems 8</em>. Cambridge, MA: MIT Press, 1996:190-196.</div><div class="external-links"><div class="to-citation__wrapper"><a class="to-citation" href="#body-ref-r31"><i aria-hidden="true" class="icon-return"></i><span>Go to Citation</span></a></div><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=Learning+with+ensembles%3A+how+overfitting+can+be+useful&amp;publication_year=1996&amp;pages=190-196" target="_blank">Google Scholar</a></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">31.</div><div id="r31" class="citations"><div class="citation"><div class="citation-content">Krizhevsky A, Sutskever I, Hinton GE. ImageNet classification with deep convolutional neural networks. In: Bartlett P, Pereira FCN, Burges CJC, Bottou L, Weinberger KQ, eds. <em>Advances in neural information processing systems 25</em>. Red Hook, NY: Curran Associates, 2012:1097-1105.</div><div class="external-links"><div class="to-citation__wrapper"><a class="to-citation" href="#body-ref-r31"><i aria-hidden="true" class="icon-return"></i><span>Go to Citation</span></a></div><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=ImageNet+classification+with+deep+convolutional+neural+networks&amp;publication_year=2012&amp;pages=1097-1105" target="_blank">Google Scholar</a></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">32.</div><div id="r32" class="citations"><div class="citation"><div class="citation-content">Shoham S, Halgren E, Maynard EM, Normann RA. Motor-cortical activity in tetraplegics. <em>Nature</em> 2001;413:793-793.</div><div class="external-links"><div class="to-citation__wrapper"><a class="to-citation" href="#body-ref-r33"><i aria-hidden="true" class="icon-return"></i><span>Go to Citation</span></a></div><div class="core-xlink-crossref"><a href="https://doi.org/10.1038/35101651" target="_blank">Crossref</a></div><div class="core-xlink-pubmed"><a href="https://pubmed.ncbi.nlm.nih.gov/11677592/" target="_blank">PubMed</a></div><div class="core-xlink-isi"><a href="https://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2&amp;DestApp=WOS_CPL&amp;UsrCustomerID=5e3815c904498985e796fc91436abd9a&amp;SrcAuth=atyponcel&amp;SrcApp=literatum&amp;DestLinkType=FullRecord&amp;KeyUT=000171750200031" target="_blank">Web of Science</a></div><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=Motor-cortical+activity+in+tetraplegics.&amp;publication_year=2001&amp;journal=Nature&amp;pages=793-793&amp;doi=10.1038%2F35101651&amp;pmid=11677592" target="_blank">Google Scholar</a></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">33.</div><div id="r33" class="citations"><div class="citation"><div class="citation-content">Hochberg LR, Serruya MD, Friehs GM, et al. Neuronal ensemble control of prosthetic devices by a human with tetraplegia. <em>Nature</em> 2006;442:164-171.</div><div class="external-links"><div class="to-citation__wrapper"><a class="to-citation" href="#body-ref-r33"><i aria-hidden="true" class="icon-return"></i><span>Go to Citation</span></a></div><div class="core-xlink-crossref"><a href="https://doi.org/10.1038/nature04970" target="_blank">Crossref</a></div><div class="core-xlink-pubmed"><a href="https://pubmed.ncbi.nlm.nih.gov/16838014/" target="_blank">PubMed</a></div><div class="core-xlink-isi"><a href="https://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2&amp;DestApp=WOS_CPL&amp;UsrCustomerID=5e3815c904498985e796fc91436abd9a&amp;SrcAuth=atyponcel&amp;SrcApp=literatum&amp;DestLinkType=FullRecord&amp;KeyUT=000238979700039" target="_blank">Web of Science</a></div><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=Neuronal+ensemble+control+of+prosthetic+devices+by+a+human+with+tetraplegia.&amp;publication_year=2006&amp;journal=Nature&amp;pages=164-171&amp;doi=10.1038%2Fnature04970&amp;pmid=16838014" target="_blank">Google Scholar</a></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">34.</div><div id="r34" class="citations"><div class="citation"><div class="citation-content">Watanabe S, Delcroix M, Metze F, Hershey JR, eds. <em>New era for robust speech recognition: exploiting deep learning</em>. Berlin: Springer-Verlag, 2017.</div><div class="external-links"><div class="to-citation__wrapper"><a class="to-citation" href="#body-ref-r34"><i aria-hidden="true" class="icon-return"></i><span>Go to Citation</span></a></div><div class="core-xlink-crossref"><a href="https://doi.org/10.1007/978-3-319-64680-0" target="_blank">Crossref</a></div><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=New+era+for+robust+speech+recognition%3A+exploiting+deep+learning&amp;publication_year=2017&amp;doi=10.1007%2F978-3-319-64680-0" target="_blank">Google Scholar</a></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">35.</div><div id="r35" class="citations"><div class="citation"><div class="citation-content">Wolpaw JR, Bedlack RS, Reda DJ, et al. Independent home use of a brain–computer interface by people with amyotrophic lateral sclerosis. <em>Neurology</em> 2018;91(3):e258-e267.</div><div class="external-links"><div class="to-citation__wrapper"><button aria-controls="to-citation__accordion-r35" aria-expanded="false" aria-label="Toggle citations menu" class="to-citation__toggle"><i aria-hidden="true" class="icon-plus"></i><span data-expand-title="Hide Citations" data-collapsed-title="Show Citations" class="accordion__toggle__title"></span></button></div><div class="core-xlink-crossref"><a href="https://doi.org/10.1212/WNL.0000000000005812" target="_blank">Crossref</a></div><div class="core-xlink-pubmed"><a href="https://pubmed.ncbi.nlm.nih.gov/29950436/" target="_blank">PubMed</a></div><div class="core-xlink-isi"><a href="https://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2&amp;DestApp=WOS_CPL&amp;UsrCustomerID=5e3815c904498985e796fc91436abd9a&amp;SrcAuth=atyponcel&amp;SrcApp=literatum&amp;DestLinkType=FullRecord&amp;KeyUT=000440906800008" target="_blank">Web of Science</a></div><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=Independent+home+use+of+a+brain%E2%80%93computer+interface+by+people+with+amyotrophic+lateral+sclerosis.&amp;publication_year=2018&amp;journal=Neurology&amp;pages=e258-e267&amp;doi=10.1212%2FWNL.0000000000005812&amp;pmid=29950436" target="_blank">Google Scholar</a></div><div role="menu" aria-label="links" class="to-citation__accordion no-separator" id="to-citation__accordion-r35" style="display: none;"><ul role="none"><li role="none"><a class="to-citation" href="#body-ref-r35-1" role="menuitem"><i aria-hidden="true" class="icon-return"></i><span>a [...] before deployment with a user, </span></a></li><li role="none"><a class="to-citation" href="#body-ref-r36" role="menuitem"><i aria-hidden="true" class="icon-return"></i><span>b [...] of the interface for real-world use. </span></a></li></ul></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">36.</div><div id="r36" class="citations"><div class="citation"><div class="citation-content">Silversmith DB, Abiri R, Hardy NF, et al. Plug-and-play control of a brain–computer interface through neural map stabilization. <em>Nat Biotechnol</em> 2021;39:326-335.</div><div class="external-links"><div class="to-citation__wrapper"><a class="to-citation" href="#body-ref-r36"><i aria-hidden="true" class="icon-return"></i><span>Go to Citation</span></a></div><div class="core-xlink-crossref"><a href="https://doi.org/10.1038/s41587-020-0662-5" target="_blank">Crossref</a></div><div class="core-xlink-pubmed"><a href="https://pubmed.ncbi.nlm.nih.gov/32895549/" target="_blank">PubMed</a></div><div class="core-xlink-isi"><a href="https://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2&amp;DestApp=WOS_CPL&amp;UsrCustomerID=5e3815c904498985e796fc91436abd9a&amp;SrcAuth=atyponcel&amp;SrcApp=literatum&amp;DestLinkType=FullRecord&amp;KeyUT=000566877800003" target="_blank">Web of Science</a></div><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=Plug-and-play+control+of+a+brain%E2%80%93computer+interface+through+neural+map+stabilization.&amp;publication_year=2021&amp;journal=Nat+Biotechnol&amp;pages=326-335&amp;doi=10.1038%2Fs41587-020-0662-5&amp;pmid=32895549" target="_blank">Google Scholar</a></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">37.</div><div id="r37" class="citations"><div class="citation"><div class="citation-content">Chao ZC, Nagasaka Y, Fujii N. Long-term asynchronous decoding of arm motion using electrocorticographic signals in monkeys. <em>Front Neuroeng</em> 2010;3:3-3.</div><div class="external-links"><div class="to-citation__wrapper"><a class="to-citation" href="#body-ref-r39"><i aria-hidden="true" class="icon-return"></i><span>Go to Citation</span></a></div><div class="core-xlink-pubmed"><a href="https://pubmed.ncbi.nlm.nih.gov/20407639/" target="_blank">PubMed</a></div><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=Long-term+asynchronous+decoding+of+arm+motion+using+electrocorticographic+signals+in+monkeys.&amp;publication_year=2010&amp;journal=Front+Neuroeng&amp;pages=3-3&amp;pmid=20407639" target="_blank">Google Scholar</a></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">38.</div><div id="r38" class="citations"><div class="citation"><div class="citation-content">Rao VR, Leonard MK, Kleen JK, Lucas BA, Mirro EA, Chang EF. Chronic ambulatory electrocorticography from human speech cortex. <em>Neuroimage</em> 2017;153:273-282.</div><div class="external-links"><div class="to-citation__wrapper"><a class="to-citation" href="#body-ref-r39"><i aria-hidden="true" class="icon-return"></i><span>Go to Citation</span></a></div><div class="core-xlink-crossref"><a href="https://doi.org/10.1016/j.neuroimage.2017.04.008" target="_blank">Crossref</a></div><div class="core-xlink-pubmed"><a href="https://pubmed.ncbi.nlm.nih.gov/28396294/" target="_blank">PubMed</a></div><div class="core-xlink-isi"><a href="https://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2&amp;DestApp=WOS_CPL&amp;UsrCustomerID=5e3815c904498985e796fc91436abd9a&amp;SrcAuth=atyponcel&amp;SrcApp=literatum&amp;DestLinkType=FullRecord&amp;KeyUT=000403384500023" target="_blank">Web of Science</a></div><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=Chronic+ambulatory+electrocorticography+from+human+speech+cortex.&amp;publication_year=2017&amp;journal=Neuroimage&amp;pages=273-282&amp;doi=10.1016%2Fj.neuroimage.2017.04.008&amp;pmid=28396294" target="_blank">Google Scholar</a></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">39.</div><div id="r39" class="citations"><div class="citation"><div class="citation-content">Pels EGM, Aarnoutse EJ, Leinders S, et al. Stability of a chronic implanted brain–computer interface in late-stage amyotrophic lateral sclerosis. <em>Clin Neurophysiol</em> 2019;130:1798-1803.</div><div class="external-links"><div class="to-citation__wrapper"><a class="to-citation" href="#body-ref-r39"><i aria-hidden="true" class="icon-return"></i><span>Go to Citation</span></a></div><div class="core-xlink-crossref"><a href="https://doi.org/10.1016/j.clinph.2019.07.020" target="_blank">Crossref</a></div><div class="core-xlink-pubmed"><a href="https://pubmed.ncbi.nlm.nih.gov/31401488/" target="_blank">PubMed</a></div><div class="core-xlink-isi"><a href="https://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2&amp;DestApp=WOS_CPL&amp;UsrCustomerID=5e3815c904498985e796fc91436abd9a&amp;SrcAuth=atyponcel&amp;SrcApp=literatum&amp;DestLinkType=FullRecord&amp;KeyUT=000485832400008" target="_blank">Web of Science</a></div><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=Stability+of+a+chronic+implanted+brain%E2%80%93computer+interface+in+late-stage+amyotrophic+lateral+sclerosis.&amp;publication_year=2019&amp;journal=Clin+Neurophysiol&amp;pages=1798-1803&amp;doi=10.1016%2Fj.clinph.2019.07.020&amp;pmid=31401488" target="_blank">Google Scholar</a></div></div></div></div></div></div><div class="citations-truncation"><button data-label-expand="Show all references" data-label-collapse="Show fewer" data-label-remaining="references remaining" class="btn btn--secondary" aria-expanded="false" aria-controls="collapsible-text"><span>Show all references</span></button></div></section></div></section></div><div class="core-collateral"><div id="core-collateral-info" role="tabpanel" data-core-tabs="core-collateral-info" tabindex="-1" aria-labelledby="pane-core-collateral-info"><header><h2 id="pane-core-collateral-info"><i class="icon-info" aria-hidden="true"></i>Information &amp; Authors</h2><button data-close="collateral" aria-label="Close"><i class="icon-close"></i></button></header><div role="tablist"><button aria-controls="tab-information" role="tab" id="tab-information-label" aria-selected="true" class="active">Information</button><button aria-controls="tab-contributors" role="tab" id="tab-contributors-label" tabindex="-1" aria-selected="false">Authors</button></div><section id="tab-information" aria-labelledby="tab-information-label" role="tabpanel" tabindex="0"><h3>Information</h3><section class="core-self-citation"><h4>Published In</h4><div class="core-journal-presentation"><div class="core-journal-description"><div property="isPartOf" typeof="Periodical"><span property="name">New England Journal of Medicine</span></div><div class="core-enumeration"><a href="/toc/nejm/385/3"><span property="isPartOf" typeof="PublicationVolume">Volume <span property="volumeNumber">385</span></span> • <span property="isPartOf" typeof="PublicationIssue">Number <span property="issueNumber">3</span></span> • <span property="datePublished">July 15, 2021</span></a></div><div class="core-pagination"><span class="heading">Pages</span>: <span class="content"><span property="pageStart">217</span>-<span property="pageEnd">227</span></span></div></div></div></section><section class="core-copyright"><h4>Copyright</h4><div role="paragraph">Copyright © 2021 Massachusetts Medical Society. All rights reserved.</div><div>For personal use only. Any commercial reuse of NEJM Group content requires <a href="mailto:permissions@nejm.org">permission</a>.</div></section><section data-translation="YXQYoa2027540" class="core-component-translation"><h4>Translation</h4><div role="paragraph"><a target="_blank" href="https://nejmqianyan.cn/article/YXQYoa2027540?sg=AbW1N">Chinese Translation 中文翻译</a></div></section><section class="core-history"><h4>History</h4><div><b class="core-label">Published online</b>: July 14, 2021</div><div><b class="core-label">Published in issue</b>: July 15, 2021</div></section><section data-location="recirc_topics_article" class="core-classifications"><h4>Topics</h4><div class="keywords"><ol><li><a href="/browse/topic/neurology-neurosurgery-general" alt="View article keyword Neurology/Neurosurgery General" data-interactiontype="article_recirculation_click">Neurology/Neurosurgery General</a></li><li role="presentation" aria-hidden="true" class="list-line-break"></li><li><a href="/browse/topic/neuroscience" alt="View article keyword Neuroscience" data-interactiontype="article_recirculation_click">Neuroscience</a></li><li role="presentation" aria-hidden="true" class="list-line-break"></li><li><a href="/browse/topic/psychiatry-general" alt="View article keyword Psychiatry General" data-interactiontype="article_recirculation_click">Psychiatry General</a></li><li role="presentation" aria-hidden="true" class="list-line-break"></li></ol></div></section></section><section id="tab-contributors" aria-labelledby="tab-contributors-label" role="tabpanel" tabindex="-1"><h3>Authors</h3><section class="core-authors"><h4>Authors</h4><div role="paragraph"><span property="author" typeof="Person"><span property="givenName">David A.</span> <span property="familyName">Moses</span>, <span property="honorificSuffix">Ph.D.</span> <a class="orcid-id" href="https://orcid.org/0000-0002-5786-5334" property="identifier" aria-label="ORCID identifier" target="_blank">https://orcid.org/0000-0002-5786-5334</a></span>, <span property="author" typeof="Person"><span property="givenName">Sean L.</span> <span property="familyName">Metzger</span>, <span property="honorificSuffix">M.S.</span></span>, <span property="author" typeof="Person"><span property="givenName">Jessie R.</span> <span property="familyName">Liu</span>, <span property="honorificSuffix">B.S.</span></span>, <span property="author" typeof="Person"><span property="givenName">Gopala K.</span> <span property="familyName">Anumanchipalli</span>, <span property="honorificSuffix">Ph.D.</span></span>, <span property="author" typeof="Person"><span property="givenName">Joseph G.</span> <span property="familyName">Makin</span>, <span property="honorificSuffix">Ph.D.</span></span>, <span property="author" typeof="Person"><span property="givenName">Pengfei F.</span> <span property="familyName">Sun</span>, <span property="honorificSuffix">Ph.D.</span> <a class="orcid-id" href="https://orcid.org/0000-0002-4101-9416" property="identifier" aria-label="ORCID identifier" target="_blank">https://orcid.org/0000-0002-4101-9416</a></span>, <span property="author" typeof="Person"><span property="givenName">Josh</span> <span property="familyName">Chartier</span>, <span property="honorificSuffix">Ph.D.</span></span>, <span property="author" typeof="Person"><span property="givenName">Maximilian E.</span> <span property="familyName">Dougherty</span>, <span property="honorificSuffix">B.A.</span></span>, <span property="author" typeof="Person"><span property="givenName">Patricia M.</span> <span property="familyName">Liu</span>, <span property="honorificSuffix">M.A.</span></span>, <span property="author" typeof="Person"><span property="givenName">Gary M.</span> <span property="familyName">Abrams</span>, <span property="honorificSuffix">M.D.</span></span>, <span property="author" typeof="Person"><span property="givenName">Adelyn</span> <span property="familyName">Tu-Chan</span>, <span property="honorificSuffix">D.O.</span></span>, <span property="author" typeof="Person"><span property="givenName">Karunesh</span> <span property="familyName">Ganguly</span>, <span property="honorificSuffix">M.D., Ph.D.</span></span>, and <span property="author" typeof="Person"><span property="givenName">Edward F.</span> <span property="familyName">Chang</span>, <span property="honorificSuffix">M.D.</span></span></div></section><section class="core-affiliations"><h4>Affiliations</h4><div property="affiliation" typeof="Organization"><span property="name">From the Department of Neurological Surgery (D.A.M., S.L.M., J.R.L., G.K.A., J.G.M., P.F.S., J.C., M.E.D., E.F.C.), the Weill Institute for Neuroscience (D.A.M., S.L.M., J.R.L., G.K.A., J.G.M., P.F.S., J.C., K.G., E.F.C.), and the Departments of Rehabilitation Services (P.M.L.) and Neurology (G.M.A., A.T.-C., K.G.), University of California, San Francisco (UCSF), San Francisco, and the Graduate Program in Bioengineering, University of California, Berkeley–UCSF, Berkeley (S.L.M., J.R.L., E.F.C.).</span></div></section><section class="core-authors-notes"><h4>Notes</h4><div role="doc-footnote">Address reprint requests to Dr. Chang at <a href="mailto:edward.chang@ucsf.edu">edward.chang@ucsf.edu</a>.</div><div role="doc-footnote"><div id="fn1" role="paragraph">Dr. Moses, Mr. Metzger, and Ms. Liu contributed equally to this article.</div></div></section></section></div><div id="core-collateral-metrics" role="tabpanel" data-core-tabs="core-collateral-metrics" tabindex="-1" aria-labelledby="pane-core-collateral-metrics"><header><h2 id="pane-core-collateral-metrics"><i class="icon-timeline" aria-hidden="true"></i>Metrics &amp; Citations</h2><button data-close="collateral" aria-label="Close"><i class="icon-close"></i></button></header><div role="tablist"><button aria-controls="tab-metrics-inner" role="tab" id="tab-metrics-inner-label" aria-selected="true" class="active" data-interactiontype="article_tab" data-tabname="metricsWindow">Metrics</button><button aria-controls="tab-citations" role="tab" id="tab-citations-label" tabindex="-1" aria-selected="false" data-interactiontype="article_tab" data-tabname="metricsWindow">Citations<span class="citations-count">286</span></button></div><section id="tab-metrics-inner" aria-labelledby="tab-metrics-inner-label" role="tabpanel" tabindex="0"><h3>Metrics</h3><section>









    
    
        <div data-widget-def="UX3HTMLWidget" data-widget-id="95ea9f58-ec0e-4db2-b2ab-280fc876af53" data-location="article_metrics_article">
        



        
            <h4 class="">
                Altmetrics
            </h4>
        
        <div data-badge-details="right" data-badge-type="large-donut" data-doi="10.1056/NEJMoa2027540" data-hide-no-mentions="true" data-link-target="_blank" class="altmetric-embed" data-uuid="2c29c13d-8ccf-dcb0-acf1-21144dbf591e"><div style="overflow:hidden;">
    <div class="altmetric-normal-legend">
        <a target="_blank" href="https://www.altmetric.com/details.php?domain=www.nejm.org&amp;citation_id=109504267" style="display:inline-block;">
                <img alt="Article has an altmetric score of 2929" src="https://badges.altmetric.com/?size=320&amp;score=2929&amp;types=mabrtwfd" width="180" height="180" style="border:0; margin:0; max-width: none;">
        </a>
        <p class="altmetric-see-more-details" style="padding-top: 10px; text-align: center;"><a target="_blank" href="https://www.altmetric.com/details.php?domain=www.nejm.org&amp;citation_id=109504267">See more details</a></p>
    </div>
    <div id="_altmetric_popover_el_2c29c13d-8ccf-dcb0-acf1-21144dbf591e" class="altmetric-embed right" style="margin:0; padding:0; display:inline-block; float:left; position:relative;">
        <div class="altmetric_container">
            <div class="altmetric-embed altmetric-popover-inner right">
                <div style="padding:0; margin: 0;" class="altmetric-embed altmetric-popover-content">
                        <div style="padding-left: 10px; line-height:18px; border-left: 16px solid #FF0000;">
      <a class="link-to-altmetric-details-tab" target="_blank" href="https://www.altmetric.com/details.php?domain=www.nejm.org&amp;citation_id=109504267&amp;tab=news">
          Picked up by <b>251</b> news outlets
      </a>
    </div>
    <div style="padding-left: 10px; line-height:18px; border-left: 16px solid #ffd140;">
      <a class="link-to-altmetric-details-tab" target="_blank" href="https://www.altmetric.com/details.php?domain=www.nejm.org&amp;citation_id=109504267&amp;tab=blogs">
          Blogged by <b>27</b>
      </a>
    </div>
    <div style="padding-left: 10px; line-height:18px; border-left: 16px solid #9f79f2;">
      <a class="link-to-altmetric-details-tab" target="_blank" href="https://www.altmetric.com/details.php?domain=www.nejm.org&amp;citation_id=109504267&amp;tab=policy-documents">
          Referenced in <b>1</b> policy sources
      </a>
    </div>
    <div style="padding-left: 10px; line-height:18px; border-left: 16px solid #74CFED;">
      <a class="link-to-altmetric-details-tab" target="_blank" href="https://www.altmetric.com/details.php?domain=www.nejm.org&amp;citation_id=109504267&amp;tab=twitter">
          Posted by <b>1291</b> X users
      </a>
    </div>
    <div style="padding-left: 10px; line-height:18px; border-left: 16px solid #f27700;">
      <a class="link-to-altmetric-details-tab" target="_blank" href="https://www.altmetric.com/details.php?domain=www.nejm.org&amp;citation_id=109504267&amp;tab=patents">
          Referenced in <b>1</b> patents
      </a>
    </div>
    <div style="padding-left: 10px; line-height:18px; border-left: 16px solid #2445bd;">
      <a class="link-to-altmetric-details-tab" target="_blank" href="https://www.altmetric.com/details.php?domain=www.nejm.org&amp;citation_id=109504267&amp;tab=facebook">
          On <b>8</b> Facebook pages
      </a>
    </div>
    <div style="padding-left: 10px; line-height:18px; border-left: 16px solid #958899;">
      <a class="link-to-altmetric-details-tab" target="_blank" href="https://www.altmetric.com/details.php?domain=www.nejm.org&amp;citation_id=109504267&amp;tab=wikipedia">
          Referenced in <b>6</b> Wikipedia pages
      </a>
    </div>
    <div style="padding-left: 10px; line-height:18px; border-left: 16px solid #D5E8F0;">
      <a class="link-to-altmetric-details-tab" target="_blank" href="https://www.altmetric.com/details.php?domain=www.nejm.org&amp;citation_id=109504267&amp;tab=reddit">
          Reddited by <b>4</b>
      </a>
    </div>
    <div style="padding-left: 10px; line-height:18px; border-left: 16px solid #94DB5E;">
      <a class="link-to-altmetric-details-tab" target="_blank" href="https://www.altmetric.com/details.php?domain=www.nejm.org&amp;citation_id=109504267&amp;tab=video">
          On <b>1</b> videos
      </a>
    </div>
    <div style="padding-left: 10px; line-height:18px; border-left: 16px solid #70B1FF;">
      <a class="link-to-altmetric-details-tab" target="_blank" href="https://www.altmetric.com/details.php?domain=www.nejm.org&amp;citation_id=109504267&amp;tab=bluesky">
          Referenced by <b>1</b> Bluesky users
      </a>
    </div>

    <div class="altmetric-embed readers" style="margin-top: 10px;">
          <div class="altmetric-embed tip_mendeley" style="padding-left: 10px; line-height:18px; border-left: 16px solid #A60000;">
              <b>472</b> readers on Mendeley
          </div>
    </div>

                </div>
            </div>
        </div>
    </div>
</div></div>
<script async="" type="text/javascript" src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js" nonce="94d68cb4c580debe-GRU"></script>

        </div>
    

</section></section><section id="tab-citations" aria-labelledby="tab-citations-label" role="tabpanel" tabindex="-1"><h3>Citations</h3><section>



        
            <h4 class="">
                Export citation
            </h4>
        
        <div class="citation-download cd-sec">
<p class="citation-download_msg">Select the format you want to export the citation of this publication.</p>
<form action="/action/downloadCitation" name="frmCitmgr" method="post" target="_self" class="citation-download_form"><input type="hidden" name="doi" value="10.1056/NEJMoa2027540"> <input type="hidden" name="downloadFileName" value="csp_385_"> <input type="hidden" name="include" value="abs">
<div class="dropdown dropdown-selectable dropdown-selectable--form-control"><input type="hidden" name="format" value=""> <label class="form-label">Format*</label> <button id="slct_format" type="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false" class="btn dropdown-toggle d-flex align-items-center justify-content-between">Please Select </button>
<div aria-labelledby="slct_format" role="listbox" class="dropdown-menu"><a href="#" data-value="ris" class="dropdown-item">RIS (ProCite, Reference Manager)</a><a href="#" data-value="endnote" class="dropdown-item">EndNote</a><a href="#" data-value="bibtex" class="dropdown-item">BibTex</a><a href="#" data-value="medlars" class="dropdown-item">Medlars</a><a href="#" data-value="refworks" class="dropdown-item">RefWorks</a></div>
<div class="invalid-feedback">Please select an item in the list</div>
</div>
<div class="citation-download_checkbox"><label class="checkbox--primary"><input type="checkbox" name="direct" value="true"><span class="checkbox--primary-icons"><span class="checkbox--primary-unchecked"><span class="icon-component "><svg aria-hidden="true"><use xlink:href="/specs/products/mms-nextgen/mms/releasedAssets/icons/icons.spritemap.svg#toggles-checboxUnchecked"></use></svg></span></span><span class="checkbox--primary-checked"><span class="icon-component "><svg aria-hidden="true"><use xlink:href="/specs/products/mms-nextgen/mms/releasedAssets/icons/icons.spritemap.svg#toggles-checboxChecked"></use></svg></span></span></span><span class="checkbox--primary-label"><span class="checkbox--primary-label-text">Direct Import</span></span></label></div>
<div class="citation-download_btn"><button type="submit" name="submit" value="Download" class="ng-btn_default ng-btn_iconLeft" data-interactiontype="article_tools_citation_download" data-multimedia-type="Citation"><span class="icon-component "><svg aria-hidden="true"><use xlink:href="/specs/products/mms-nextgen/mms/releasedAssets/icons/icons.spritemap.svg#citations"></use></svg></span><span class="ng-btn_text">Export citation</span></button></div>
</form></div>
</section><section>









    
    
        <div data-widget-def="UX3CitedByWidget" data-widget-id="efb4df9a-8e1a-47f9-bfb7-271959277a9f" data-location="citedby_article">
        



        
            <h4 class="">
                Cited by
            </h4>
        
        <section id="cited-by" class="cited-by"><div class="cited-by__wrapper"><div id="cited-by__content" class="cited-by__content"><ol data-source="/pb/widgets/citedBy?page=1&amp;widgetId=efb4df9a-8e1a-47f9-bfb7-271959277a9f&amp;pbContext=%3BrequestedJournal%3Ajournal%3Anejm%3Bpage%3Astring%3AArticle%2FChapter+View%3Bctype%3Astring%3AJournal+Content%3Barticle%3Aarticle%3Adoi%5C%3A10.1056%2FNEJMoa2027540%3Bwgroup%3Astring%3AMMS+NextGen+Website+Group%3Bissue%3Aissue%3Adoi%5C%3A10.1056%2Fnejm_2021.385.issue-3%3BpageGroup%3Astring%3APublication+Pages%3BsubPage%3Astring%3AFull+Text%3Bwebsite%3Awebsite%3Amms-site%3Bjournal%3Ajournal%3Anejms" data-lazyload="false" data-total="286" class="cited-by__list list-unstyled"><li class="cited-by__entry border-bottom pb-16 mb-24"><ul class="cited-by__entry__authors list-inline"><li class="list-inline-item cited-by__entry__author">Adam M. Morgan, </li><li class="list-inline-item cited-by__entry__author">Orrin Devinsky, </li><li class="list-inline-item cited-by__entry__author">Werner K. Doyle, </li><li class="list-inline-item cited-by__entry__author">Patricia Dugan, </li><li class="list-inline-item cited-by__entry__author">Daniel Friedman, </li><li class="list-inline-item cited-by__entry__author">Adeen Flinker, </li></ul><span class="cited-by__entry__title">Decoding words during sentence production with ECoG reveals syntactic role encoding and structure-dependent&nbsp;temporal dynamics, </span><span class="cited-by__entry__series-title">Communications Psychology, </span><span class="cited-by__entry__volume"><strong>3</strong>, </span><span class="cited-by__entry__issue">1, </span><span class="cited-by__entry__pub-date">(2025).</span><a href="https://doi.org/10.1038/s44271-025-00270-1" title="Crossref" target="_blank" class="cited-by__entry__doi">https://doi.org/10.1038/s44271-025-00270-1</a><div class="cited-by__entry__extra-links"><a href="https://doi.org/10.1038/s44271-025-00270-1" target="_blank" class="cited-by__entry__visitable">Crossref</a></div></li><li class="cited-by__entry border-bottom pb-16 mb-24"><ul class="cited-by__entry__authors list-inline"><li class="list-inline-item cited-by__entry__author">Ran Wang, </li><li class="list-inline-item cited-by__entry__author">Zhe Sage Chen, </li></ul><span class="cited-by__entry__title">Large-scale foundation models and generative AI for BigData neuroscience, </span><span class="cited-by__entry__series-title">Neuroscience Research, </span><span class="cited-by__entry__volume"><strong>215</strong>, </span><span class="cited-by__entry__page-range">(3-14), </span><span class="cited-by__entry__pub-date">(2025).</span><a href="https://doi.org/10.1016/j.neures.2024.06.003" title="Crossref" target="_blank" class="cited-by__entry__doi">https://doi.org/10.1016/j.neures.2024.06.003</a><div class="cited-by__entry__extra-links"><a href="https://doi.org/10.1016/j.neures.2024.06.003" target="_blank" class="cited-by__entry__visitable">Crossref</a></div></li><li class="cited-by__entry border-bottom pb-16 mb-24"><ul class="cited-by__entry__authors list-inline"><li class="list-inline-item cited-by__entry__author">Nitzan Kenig, </li><li class="list-inline-item cited-by__entry__author">Javier Monton Echeverria, </li><li class="list-inline-item cited-by__entry__author">Aina Muntaner Vives, </li></ul><span class="cited-by__entry__title">Evaluating Surgical Results in Breast Cancer with Artificial Intelligence, </span><span class="cited-by__entry__series-title">Aesthetic Plastic Surgery, </span><span class="cited-by__entry__pub-date">(2025).</span><a href="https://doi.org/10.1007/s00266-025-04915-8" title="Crossref" target="_blank" class="cited-by__entry__doi">https://doi.org/10.1007/s00266-025-04915-8</a><div class="cited-by__entry__extra-links"><a href="https://doi.org/10.1007/s00266-025-04915-8" target="_blank" class="cited-by__entry__visitable">Crossref</a></div></li><li class="cited-by__entry border-bottom pb-16 mb-24"><ul class="cited-by__entry__authors list-inline"><li class="list-inline-item cited-by__entry__author">Tyler Singer-Clark, </li><li class="list-inline-item cited-by__entry__author">Xianda Hou, </li><li class="list-inline-item cited-by__entry__author">Nicholas S Card, </li><li class="list-inline-item cited-by__entry__author">Maitreyee Wairagkar, </li><li class="list-inline-item cited-by__entry__author">Carrina Iacobacci, </li><li class="list-inline-item cited-by__entry__author">Hamza Peracha, </li><li class="list-inline-item cited-by__entry__author">Leigh R Hochberg, </li><li class="list-inline-item cited-by__entry__author">Sergey D Stavisky, </li><li class="list-inline-item cited-by__entry__author">David M Brandman, </li></ul><span class="cited-by__entry__title">Speech motor cortex enables BCI cursor control and click, </span><span class="cited-by__entry__series-title">Journal of Neural Engineering, </span><span class="cited-by__entry__volume"><strong>22</strong>, </span><span class="cited-by__entry__issue">3, </span><span class="cited-by__entry__page-range">(036015), </span><span class="cited-by__entry__pub-date">(2025).</span><a href="https://doi.org/10.1088/1741-2552/add0e5" title="Crossref" target="_blank" class="cited-by__entry__doi">https://doi.org/10.1088/1741-2552/add0e5</a><div class="cited-by__entry__extra-links"><a href="https://doi.org/10.1088/1741-2552/add0e5" target="_blank" class="cited-by__entry__visitable">Crossref</a></div></li><li class="cited-by__entry border-bottom pb-16 mb-24"><ul class="cited-by__entry__authors list-inline"><li class="list-inline-item cited-by__entry__author">Sergey D. Stavisky, </li></ul><span class="cited-by__entry__title">Restoring Speech Using Brain–Computer Interfaces, </span><span class="cited-by__entry__series-title">Annual Review of Biomedical Engineering, </span><span class="cited-by__entry__volume"><strong>27</strong>, </span><span class="cited-by__entry__issue">1, </span><span class="cited-by__entry__page-range">(29-54), </span><span class="cited-by__entry__pub-date">(2025).</span><a href="https://doi.org/10.1146/annurev-bioeng-110122-012818" title="Crossref" target="_blank" class="cited-by__entry__doi">https://doi.org/10.1146/annurev-bioeng-110122-012818</a><div class="cited-by__entry__extra-links"><a href="https://doi.org/10.1146/annurev-bioeng-110122-012818" target="_blank" class="cited-by__entry__visitable">Crossref</a></div></li><li class="cited-by__entry border-bottom pb-16 mb-24"><ul class="cited-by__entry__authors list-inline"><li class="list-inline-item cited-by__entry__author">Chen Feng, </li><li class="list-inline-item cited-by__entry__author">Lu Cao, </li><li class="list-inline-item cited-by__entry__author">Di Wu, </li><li class="list-inline-item cited-by__entry__author">En Zhang, </li><li class="list-inline-item cited-by__entry__author">Ting Wang, </li><li class="list-inline-item cited-by__entry__author">Xiaowei Jiang, </li><li class="list-inline-item cited-by__entry__author">Jinbo Chen, </li><li class="list-inline-item cited-by__entry__author">Hui Wu, </li><li class="list-inline-item cited-by__entry__author">Siyu Lin, </li><li class="list-inline-item cited-by__entry__author">Qiming Hou, </li><li class="list-inline-item cited-by__entry__author">Junming Zhu, </li><li class="list-inline-item cited-by__entry__author">Jie Yang, </li><li class="list-inline-item cited-by__entry__author">Mohamad Sawan, </li><li class="list-inline-item cited-by__entry__author">Yue Zhang, </li></ul><span class="cited-by__entry__title">Acoustic Inspired Brain-to-Sentence Decoder for Logosyllabic Language, </span><span class="cited-by__entry__series-title">Cyborg and Bionic Systems, </span><span class="cited-by__entry__volume"><strong>6</strong>, </span><span class="cited-by__entry__pub-date">(2025).</span><a href="https://doi.org/10.34133/cbsystems.0257" title="Crossref" target="_blank" class="cited-by__entry__doi">https://doi.org/10.34133/cbsystems.0257</a><div class="cited-by__entry__extra-links"><a href="https://doi.org/10.34133/cbsystems.0257" target="_blank" class="cited-by__entry__visitable">Crossref</a></div></li><li class="cited-by__entry border-bottom pb-16 mb-24"><ul class="cited-by__entry__authors list-inline"><li class="list-inline-item cited-by__entry__author">Hans Kankam, </li><li class="list-inline-item cited-by__entry__author">Hans Kankam, </li></ul><span class="cited-by__entry__title">Cognitive Neuroscience and Neuropsychology, </span><span class="cited-by__entry__series-title">A Brief Excursion into Human Cognition, </span><span class="cited-by__entry__page-range">(113-131), </span><span class="cited-by__entry__pub-date">(2025).</span><a href="https://doi.org/10.1007/978-3-031-89752-8_10" title="Crossref" target="_blank" class="cited-by__entry__doi">https://doi.org/10.1007/978-3-031-89752-8_10</a><div class="cited-by__entry__extra-links"><a href="https://doi.org/10.1007/978-3-031-89752-8_10" target="_blank" class="cited-by__entry__visitable">Crossref</a></div></li><li class="cited-by__entry border-bottom pb-16 mb-24"><ul class="cited-by__entry__authors list-inline"><li class="list-inline-item cited-by__entry__author">Antonio Araújo, </li></ul><span class="cited-by__entry__title">ChatGPT-based posthumous memories of a terminally ill patient: metabioethics and generative AI at the service of palliative medicine, </span><span class="cited-by__entry__series-title">AI and Ethics, </span><span class="cited-by__entry__pub-date">(2025).</span><a href="https://doi.org/10.1007/s43681-025-00737-1" title="Crossref" target="_blank" class="cited-by__entry__doi">https://doi.org/10.1007/s43681-025-00737-1</a><div class="cited-by__entry__extra-links"><a href="https://doi.org/10.1007/s43681-025-00737-1" target="_blank" class="cited-by__entry__visitable">Crossref</a></div></li><li class="cited-by__entry border-bottom pb-16 mb-24"><ul class="cited-by__entry__authors list-inline"><li class="list-inline-item cited-by__entry__author">Thorsten Rudroff, </li></ul><span class="cited-by__entry__title">Non-Invasive Brain Stimulation and Artificial Intelligence in Communication Neuroprosthetics: A Bidirectional Approach for Speech and Hearing Impairments, </span><span class="cited-by__entry__series-title">Brain Sciences, </span><span class="cited-by__entry__volume"><strong>15</strong>, </span><span class="cited-by__entry__issue">5, </span><span class="cited-by__entry__page-range">(449), </span><span class="cited-by__entry__pub-date">(2025).</span><a href="https://doi.org/10.3390/brainsci15050449" title="Crossref" target="_blank" class="cited-by__entry__doi">https://doi.org/10.3390/brainsci15050449</a><div class="cited-by__entry__extra-links"><a href="https://doi.org/10.3390/brainsci15050449" target="_blank" class="cited-by__entry__visitable">Crossref</a></div></li><li class="cited-by__entry border-bottom pb-16 mb-24"><ul class="cited-by__entry__authors list-inline"><li class="list-inline-item cited-by__entry__author">Tianyu He, </li><li class="list-inline-item cited-by__entry__author">Mingyi Wei, </li><li class="list-inline-item cited-by__entry__author">Ruicong Wang, </li><li class="list-inline-item cited-by__entry__author">Renzhi Wang, </li><li class="list-inline-item cited-by__entry__author">Shiwei Du, </li><li class="list-inline-item cited-by__entry__author">Siqi Cai, </li><li class="list-inline-item cited-by__entry__author">Wei Tao, </li><li class="list-inline-item cited-by__entry__author">Haizhou Li, </li></ul><span class="cited-by__entry__title">VocalMind: A Stereotactic EEG Dataset for Vocalized, Mimed, and Imagined Speech in Tonal Language, </span><span class="cited-by__entry__series-title">Scientific Data, </span><span class="cited-by__entry__volume"><strong>12</strong>, </span><span class="cited-by__entry__issue">1, </span><span class="cited-by__entry__pub-date">(2025).</span><a href="https://doi.org/10.1038/s41597-025-04741-2" title="Crossref" target="_blank" class="cited-by__entry__doi">https://doi.org/10.1038/s41597-025-04741-2</a><div class="cited-by__entry__extra-links"><a href="https://doi.org/10.1038/s41597-025-04741-2" target="_blank" class="cited-by__entry__visitable">Crossref</a></div></li><li class="cited-by__entry--see-more"><a href="javascript:void(0)" data-source="/pb/widgets/citedBy?page=1&amp;widgetId=efb4df9a-8e1a-47f9-bfb7-271959277a9f&amp;pbContext=%3BrequestedJournal%3Ajournal%3Anejm%3Bpage%3Astring%3AArticle%2FChapter+View%3Bctype%3Astring%3AJournal+Content%3Barticle%3Aarticle%3Adoi%5C%3A10.1056%2FNEJMoa2027540%3Bwgroup%3Astring%3AMMS+NextGen+Website+Group%3Bissue%3Aissue%3Adoi%5C%3A10.1056%2Fnejm_2021.385.issue-3%3BpageGroup%3Astring%3APublication+Pages%3BsubPage%3Astring%3AFull+Text%3Bwebsite%3Awebsite%3Amms-site%3Bjournal%3Ajournal%3Anejms" class="cited-by__see-more">See more</a></li></ol></div><div class="cited-by__spinner justify-content-center align-items-center d-none"><div role="status" class="spinner-border text-gray"><span class="sr-only">Loading...</span></div></div></div></section>

        </div>
    

</section></section></div><div id="core-collateral-fulltext-options" role="tabpanel" data-core-tabs="core-collateral-fulltext-options" tabindex="-1" aria-labelledby="pane-core-collateral-fulltext-options"><header><h2 id="pane-core-collateral-fulltext-options"><i class="icon-eye" aria-hidden="true"></i>View Options</h2><button data-close="collateral" aria-label="Close"><i class="icon-close"></i></button></header><div class="section--wrapper"><h3>View options</h3><section class="format--pdf"><h4> <abbr title="Portable Document Format">PDF</abbr></h4><a href="https://www.nejm.org/doi/pdf/10.1056/NEJMoa2027540" class="btn btn--pdf" aria-label="View PDF" data-behavior="trackDownloadEvent" data-doi="10.1056/NEJMoa2027540" data-interactiontype="article_tools_download_pdf" data-multimedia-type="Article PDF" data-multimedia-filename="nejmoa2027540.pdf"><i aria-hidden="true" class="icon-pdf"></i><span>View PDF</span></a></section></div><!-- Its needed to duplicate this for PB check Collateral.js as well--></div><div id="core-collateral-media" role="tabpanel" data-core-tabs="core-collateral-media" tabindex="-1" aria-labelledby="pane-core-collateral-media"><header><h2 id="pane-core-collateral-media"><i class="icon-photo" aria-hidden="true"></i>Media</h2><button data-close="collateral" aria-label="Close"><i class="icon-close"></i></button></header><div role="tablist"><button aria-controls="tab-figures" role="tab" id="tab-figures-label" aria-selected="true" class="active">Figures</button><button aria-controls="tab-other" role="tab" id="tab-other-label" tabindex="-1" aria-selected="false" class="inactive" aria-disabled="true">Other</button></div><section id="tab-figures" aria-labelledby="tab-figures-label" role="tabpanel" tabindex="0"><h3>Figures</h3><div class="text-right"><a class="btn btn--inverse  open-in-viewer" href="#figures"><span>Open all in viewer</span><i class="icon-open_in_new" aria-hidden="true"></i></a></div><div id="core-f0"><figure class="graphic"><a class="open-in-viewer" href="#f0" data-index="0" data-interactiontype="multimedia_click" data-multimedia-type="Figure" data-multimedia-filename="nejmoa2027540_f0.jpg"><img src="/cms/10.1056/NEJMoa2027540/asset/72b2e583-fb17-48c8-9cd1-62c7af874aa5/assets/images/large/nejmoa2027540_f0.jpg" height="3416" width="2640" aria-labelledby="f0" loading="lazy"></a><figcaption>Download a PDF of the <a href="#ap0">Research Summary</a>.</figcaption></figure><div class="external-links"><a class="pill__to-original" href="#f0"><i class="icon-return" aria-hidden="true"></i><span>Go to Figure</span></a><a class="open-in-viewer" href="#f0" data-interactiontype="multimedia_click" data-multimedia-type="Figure" data-multimedia-filename="nejmoa2027540_f0.jpg"><span>Open in Viewer</span><i class="icon-expand" aria-hidden="true"></i></a></div></div><div id="core-f1"><figure class="graphic"><a class="open-in-viewer" href="#f1" data-index="0" data-interactiontype="multimedia_click" data-multimedia-type="Figure" data-multimedia-filename="nejmoa2027540_f1.jpg"><img src="/cms/10.1056/NEJMoa2027540/asset/40605166-4f5e-447f-bf37-ab63f494c50e/assets/images/large/nejmoa2027540_f1.jpg" height="3341" width="2640" aria-labelledby="f1" loading="lazy"></a><figcaption><div class="caption">Schematic Overview of the Direct Speech Brain–Computer Interface.</div><div class="notes"><div role="doc-footnote">Shown is how neural activity acquired from an investigational electrocorticography electrode array implanted in a clinical study participant with severe paralysis is used to directly decode words and sentences in real time. In a conversational demonstration, the participant is visually prompted with a statement or question (A) and is instructed to attempt to respond using words from a predefined vocabulary set of 50 words. Simultaneously, cortical signals are acquired from the surface of the brain through the electrode array (B) and processed in real time (C). The processed neural signals are analyzed sample by sample with the use of a speech-detection model to detect the participant’s attempts to speak (D). A classifier computes word probabilities (across the 50 possible words) from each detected window of relevant neural activity (E). A Viterbi decoding algorithm uses these probabilities in conjunction with word-sequence probabilities from a separately trained natural-language model to decode the most likely sentence given the neural activity data (F). The predicted sentence, which is updated each time a word is decoded, is displayed as feedback to the participant (G). Before real-time decoding, the models were trained with data collected as the participant attempted to say individual words from the 50-word set as part of a separate task (not depicted). This conversational demonstration is a variant of the standard sentence task used in this work, in that it allows the participant to compose his own unique responses to the prompts.</div></div></figcaption></figure><div class="external-links"><a class="pill__to-original" href="#f1"><i class="icon-return" aria-hidden="true"></i><span>Go to Figure</span></a><a class="open-in-viewer" href="#f1" data-interactiontype="multimedia_click" data-multimedia-type="Figure" data-multimedia-filename="nejmoa2027540_f1.jpg"><span>Open in Viewer</span><i class="icon-expand" aria-hidden="true"></i></a></div></div><div id="core-f2"><figure class="graphic"><a class="open-in-viewer" href="#f2" data-index="0" data-interactiontype="multimedia_click" data-multimedia-type="Figure" data-multimedia-filename="nejmoa2027540_f2.jpg"><img src="/cms/10.1056/NEJMoa2027540/asset/c5a8b906-d545-42ff-a7ee-d8700e98a7e1/assets/images/large/nejmoa2027540_f2.jpg" height="3438" width="2629" aria-labelledby="f2" loading="lazy"></a><figcaption><div class="caption">Decoding a Variety of Sentences in Real Time through Neural Signal Processing and Language Modeling.</div><div class="notes"><div role="doc-footnote">Panel A shows the word error rates, the numbers of words decoded per minute, and the decoded sentence lengths. The top plot shows the median word error rate (defined as the number of word errors made by the decoder divided by the number of words in the target sentence, with a lower rate indicating better performance) derived from the word sequences decoded from the participant’s cortical activity during the performance of the sentence task. Data points represent sentence blocks (each block comprises 10 trials); the median rate, as indicated by the horizontal line within a box, is shown across 15 sentence blocks. The upper and lower sides of the box represent the interquartile range, and the 𝙸 bars 1.5 times the interquartile range. Chance performance was measured by computing the word error rate on sentences randomly generated from the natural-language model. The middle plot shows the median number of words decoded per minute, as derived across all 150 trials (each data point represents a trial). The rates are shown for the analysis that included all words that were correctly or incorrectly decoded with the natural-language model and for the analysis that included only correctly decoded words. Each violin distribution was created with the use of kernel density estimation based on Scott’s rule for computing the estimator bandwidth; the thick horizontal lines represent the median number of words decoded per minute, and the thinner horizontal lines the range (with the exclusion of outliers that were more than 4 standard deviations below or above the mean, which was the case for one trial). In the bottom chart, the decoded sentence lengths show whether the number of detected words was equal to the number of words in the target sentence in each of the 150 trials. Panel B shows the number of word errors in the sentences decoded with or without the natural-language model across all trials and all 50 sentence targets. Each small vertical dash represents the number of word errors in a single trial (there are 3 trials per target sentence; marks for identical error counts are staggered horizontally for visualization purposes). Each dot represents the mean number of errors for that target sentence across the 3 trials. The histogram at the bottom shows the error counts across all 150 trials. Panel C shows seven target sentence examples along with the corresponding sentences decoded with and without the natural-language model. Correctly decoded words are shown in black and incorrect words in red.</div></div></figcaption></figure><div class="external-links"><a class="pill__to-original" href="#f2"><i class="icon-return" aria-hidden="true"></i><span>Go to Figure</span></a><a class="open-in-viewer" href="#f2" data-interactiontype="multimedia_click" data-multimedia-type="Figure" data-multimedia-filename="nejmoa2027540_f2.jpg"><span>Open in Viewer</span><i class="icon-expand" aria-hidden="true"></i></a></div></div><div id="core-f3"><figure class="graphic"><a class="open-in-viewer" href="#f3" data-index="0" data-interactiontype="multimedia_click" data-multimedia-type="Figure" data-multimedia-filename="nejmoa2027540_f3.jpg"><img src="/cms/10.1056/NEJMoa2027540/asset/68f0e6d1-b465-47d5-b6fc-47ee4ea610e9/assets/images/large/nejmoa2027540_f3.jpg" height="3438" width="2629" aria-labelledby="f3" loading="lazy"></a><figcaption><div class="caption">Distinct Neural Activity Patterns during Word-Production Attempts.</div><div class="notes"><div role="doc-footnote">Panel A shows the participant’s brain reconstruction overlaid with the locations of the implanted electrodes and their contributions to the speech-detection and word-classification models. Plotted electrode size (area) and opacity are scaled by relative contribution (important electrodes appear larger and more opaque than other electrodes). Each set of contributions is normalized to sum to 1. For anatomical reference, the precentral gyrus is highlighted in light green. Panel B shows word confusion values computed with the use of the isolated-word data. For each target word (each row), the confusion value measures how often the word classifier predicted (regardless of whether the prediction was correct) each of the 50 possible words (each column) while the participant was attempting to say that target word. The confusion value is computed as a percentage relative to the total number of isolated-word trials for each target word, with the values in each row summing to 100%. Values along the diagonal correspond to correct classifications, and off-diagonal values correspond to incorrect classifications. The natural-language model was not used in this analysis.</div></div></figcaption></figure><div class="external-links"><a class="pill__to-original" href="#f3"><i class="icon-return" aria-hidden="true"></i><span>Go to Figure</span></a><a class="open-in-viewer" href="#f3" data-interactiontype="multimedia_click" data-multimedia-type="Figure" data-multimedia-filename="nejmoa2027540_f3.jpg"><span>Open in Viewer</span><i class="icon-expand" aria-hidden="true"></i></a></div></div><div id="core-f4"><figure class="graphic"><a class="open-in-viewer" href="#f4" data-index="0" data-interactiontype="multimedia_click" data-multimedia-type="Figure" data-multimedia-filename="nejmoa2027540_f4.jpg"><img src="/cms/10.1056/NEJMoa2027540/asset/886e2498-6fe3-44f0-8e25-3fb0878aae38/assets/images/large/nejmoa2027540_f4.jpg" height="1390" width="2231" aria-labelledby="f4" loading="lazy"></a><figcaption><div class="caption">Signal Stability and Long-Term Accumulation of Training Data to Improve Decoder Performance.</div><div class="notes"><div role="doc-footnote">Each bar depicts the mean classification accuracy (the percentage of trials in which the target word was correctly predicted) from isolated-word data sampled from the final weeks of the study period (weeks 79 through 81) after speech-detection and word-classification models were trained on different samples of the isolated-word data from various week ranges. Each result was computed with the use of a 10-fold cross-validation evaluation approach. In this approach, the available data were partitioned into 10 equally sized, nonoverlapping subsets. In the first cross-validation “fold,” one of these data subsets is used as the testing set, and the remaining 9 are used for model training. This was repeated 9 more times until each subset was used for testing (after training on the other subsets). This approach ensures that models were never evaluated on the data used during training (Sections S6 and S14). 𝙸 bars indicate the 95% confidence interval of the mean, each computed across the 10 cross-validation folds. The data quantities specify the average amount of data used to train the word-classification models across cross-validation folds. Week 0 denotes the first week during which data for this study was collected, which occurred 9 weeks after surgical implantation of the study device. Accuracy of chance performance was calculated as 1 divided by the number of possible words and is indicated by a horizontal dashed line.</div></div></figcaption></figure><div class="external-links"><a class="pill__to-original" href="#f4"><i class="icon-return" aria-hidden="true"></i><span>Go to Figure</span></a><a class="open-in-viewer" href="#f4" data-interactiontype="multimedia_click" data-multimedia-type="Figure" data-multimedia-filename="nejmoa2027540_f4.jpg"><span>Open in Viewer</span><i class="icon-expand" aria-hidden="true"></i></a></div></div></section><section id="tab-other" aria-labelledby="tab-other-label" role="tabpanel" tabindex="-1"><h3>Other</h3></section></div><div id="core-collateral-tables" role="tabpanel" data-core-tabs="core-collateral-tables" tabindex="-1" aria-labelledby="pane-core-collateral-tables"><header><h2 id="pane-core-collateral-tables"><i class="icon-tables" aria-hidden="true"></i>Tables</h2><button data-close="collateral" aria-label="Close"><i class="icon-close"></i></button></header><!-- There is no content. --></div><div id="core-collateral-share" role="tabpanel" data-core-tabs="core-collateral-share" tabindex="-1" aria-labelledby="pane-core-collateral-share"><header><h2 id="pane-core-collateral-share"><i class="icon-share" aria-hidden="true"></i>Share</h2><button data-close="collateral" aria-label="Close"><i class="icon-close"></i></button></header><h3>Share</h3><div class="section--wrapper"><section><h4>CONTENT LINK</h4><div id="share-self"><p data-id="article-share-self-link" class="share-self__source">https://www.nejm.org/doi/full/10.1056/NEJMoa2027540</p><button data-id="article-share-access" aria-label="CONTENT LINK" class="share-self__action btn btn--inverse"><i aria-hidden="true" class="icon-copy-o"></i><span>Copy Link</span></button><div aria-live="polite" class="share-self__status"><p class="share-self__success"><i aria-hidden="true" class="icon-check_circle"></i><span>Copied!</span></p><p class="share-self__failed"><i aria-hidden="true" class="icon-x_btnclose"></i><span>Copying failed.</span></p></div></div></section><section data-location="share_tools_article"><h4>Share</h4><div class="share-buttons a2a a2a_kit" style="line-height: 16px;"><a href="/#facebook" aria-label="Share on Facebook" data-id="article-share-facebook" rel="nofollow noopener" role="link" target="_blank" title="Share on Facebook" class="btn btn--facebook a2a_button_facebook" data-interactiontype="social"><i aria-hidden="true" class="icon-facebook"></i><span>Facebook</span></a><a href="/#twitter" aria-label="Share on X (formerly Twitter)" data-id="article-share-twitter" rel="nofollow noopener" role="link" target="_blank" title="Share on X (formerly Twitter)" class="btn btn--twitter a2a_button_twitter" data-interactiontype="social"><i aria-hidden="true" class="icon-twitter"></i><span>X (formerly Twitter)</span></a><a href="/#linkedin" aria-label="Share on LinkedIn" data-id="article-share-linkedin" rel="nofollow noopener" role="link" target="_blank" title="Share on LinkedIn" class="btn btn--linkedin a2a_button_linkedin" data-interactiontype="social"><i aria-hidden="true" class="icon-linkedin"></i><span>LinkedIn</span></a><a href="/#email" aria-label="Share on email" data-id="article-share-email" rel="nofollow noopener" role="link" target="_blank" title="Share on email" class="btn btn--email a2a_button_email" data-interactiontype="content_email_click"><i aria-hidden="true" class="icon-mail"></i><span>email</span></a><a href="/#bluesky" aria-label="Share on Bluesky" data-id="article-share-bluesky" rel="nofollow noopener" role="link" target="_blank" title="Share on Bluesky" class="btn btn--bluesky a2a_button_bluesky" data-interactiontype="social"><i aria-hidden="true" class="icon-bluesky"></i><span>Bluesky</span></a></div></section></div></div><div data-location="references_article" id="core-collateral-references" role="tabpanel" aria-labelledby="pane-core-collateral-references" data-core-tabs="core-collateral-references" tabindex="-1"><header><h2 id="pane-core-collateral-references"><i aria-hidden="true" class="icon-references"></i>References</h2><button data-close="collateral" aria-label="Close"><i class="icon-close"></i></button></header><h3>References</h3><div role="list" class="section--wrapper"><div role="listitem" data-has="label"><div class="label">1.</div><div id="core-r1" class="citations"><div class="citation"><div class="citation-content">Beukelman DR, Fager S, Ball L, Dietz A. AAC for adults with acquired neurological conditions: a review. <em>Augment Altern Commun</em> 2007;23:230-242.</div><div class="external-links"><div class="to-citation__wrapper"><a class="to-citation" href="#body-ref-r1"><i aria-hidden="true" class="icon-return"></i><span>Go to Citation</span></a></div><div class="core-xlink-crossref"><a href="https://doi.org/10.1080/07434610701553668" target="_blank">Crossref</a></div><div class="core-xlink-pubmed"><a href="https://pubmed.ncbi.nlm.nih.gov/17701742/" target="_blank">PubMed</a></div><div class="core-xlink-isi"><a href="https://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2&amp;DestApp=WOS_CPL&amp;UsrCustomerID=5e3815c904498985e796fc91436abd9a&amp;SrcAuth=atyponcel&amp;SrcApp=literatum&amp;DestLinkType=FullRecord&amp;KeyUT=000249570700004" target="_blank">Web of Science</a></div><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=AAC+for+adults+with+acquired+neurological+conditions%3A+a+review.&amp;publication_year=2007&amp;journal=Augment+Altern+Commun&amp;pages=230-242&amp;doi=10.1080%2F07434610701553668&amp;pmid=17701742" target="_blank">Google Scholar</a></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">2.</div><div id="core-r2" class="citations"><div class="citation"><div class="citation-content">Nip I, Roth CR. Anarthria. In: Kreutzer J, DeLuca J, Caplan B, eds. <em>Encyclopedia of clinical neuropsychology. 2nd ed</em>. New York: Springer International Publishing, 2017:1-1.</div><div class="external-links"><div class="to-citation__wrapper"><a class="to-citation" href="#body-ref-r2"><i aria-hidden="true" class="icon-return"></i><span>Go to Citation</span></a></div><div class="core-xlink-crossref"><a href="https://doi.org/10.1007/978-3-319-56782-2_855-4" target="_blank">Crossref</a></div><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=Anarthria&amp;publication_year=2017&amp;pages=1-1&amp;doi=10.1007%2F978-3-319-56782-2_855-4" target="_blank">Google Scholar</a></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">3.</div><div id="core-r3" class="citations"><div class="citation"><div class="citation-content">Felgoise SH, Zaccheo V, Duff J, Simmons Z. Verbal communication impacts quality of life in patients with amyotrophic lateral sclerosis. <em>Amyotroph Lateral Scler Frontotemporal Degener</em> 2016;17:179-183.</div><div class="external-links"><div class="to-citation__wrapper"><a class="to-citation" href="#body-ref-r3"><i aria-hidden="true" class="icon-return"></i><span>Go to Citation</span></a></div><div class="core-xlink-crossref"><a href="https://doi.org/10.3109/21678421.2015.1125499" target="_blank">Crossref</a></div><div class="core-xlink-pubmed"><a href="https://pubmed.ncbi.nlm.nih.gov/27094742/" target="_blank">PubMed</a></div><div class="core-xlink-isi"><a href="https://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2&amp;DestApp=WOS_CPL&amp;UsrCustomerID=5e3815c904498985e796fc91436abd9a&amp;SrcAuth=atyponcel&amp;SrcApp=literatum&amp;DestLinkType=FullRecord&amp;KeyUT=000374776900003" target="_blank">Web of Science</a></div><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=Verbal+communication+impacts+quality+of+life+in+patients+with+amyotrophic+lateral+sclerosis.&amp;publication_year=2016&amp;journal=Amyotroph+Lateral+Scler+Frontotemporal+Degener&amp;pages=179-183&amp;doi=10.3109%2F21678421.2015.1125499&amp;pmid=27094742" target="_blank">Google Scholar</a></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">4.</div><div id="core-r4" class="citations"><div class="citation"><div class="citation-content">Sellers EW, Ryan DB, Hauser CK. Noninvasive brain–computer interface enables communication after brainstem stroke. <em>Sci Transl Med</em> 2014;6(257):257re7-257re7.</div><div class="external-links"><div class="to-citation__wrapper"><a class="to-citation" href="#body-ref-r8"><i aria-hidden="true" class="icon-return"></i><span>Go to Citation</span></a></div><div class="core-xlink-crossref"><a href="https://doi.org/10.1126/scitranslmed.3007801" target="_blank">Crossref</a></div><div class="core-xlink-pubmed"><a href="https://pubmed.ncbi.nlm.nih.gov/25298323/" target="_blank">PubMed</a></div><div class="core-xlink-isi"><a href="https://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2&amp;DestApp=WOS_CPL&amp;UsrCustomerID=5e3815c904498985e796fc91436abd9a&amp;SrcAuth=atyponcel&amp;SrcApp=literatum&amp;DestLinkType=FullRecord&amp;KeyUT=000343317900011" target="_blank">Web of Science</a></div><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=Noninvasive+brain%E2%80%93computer+interface+enables+communication+after+brainstem+stroke.&amp;publication_year=2014&amp;journal=Sci+Transl+Med&amp;pages=257re7-257re7&amp;doi=10.1126%2Fscitranslmed.3007801&amp;pmid=25298323" target="_blank">Google Scholar</a></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">5.</div><div id="core-r5" class="citations"><div class="citation"><div class="citation-content">Vansteensel MJ, Pels EGM, Bleichner MG, et al. Fully implanted brain–computer interface in a locked-in patient with ALS. <em>N Engl J Med</em> 2016;375:2060-2066.</div><div class="external-links"><div class="to-citation__wrapper"><button aria-controls="to-citation__accordion-r5-core" aria-expanded="false" aria-label="Toggle citations menu" class="to-citation__toggle"><i aria-hidden="true" class="icon-plus"></i><span data-expand-title="Hide Citations" data-collapsed-title="Show Citations" class="accordion__toggle__title"></span></button></div><div class="core-xlink-crossref"><a href="/servlet/linkout?suffix=e_1_3_5_6_2&amp;dbid=4&amp;doi=10.1056%2FNEJMoa2027540&amp;key=10.1056%2FNEJMoa1608085&amp;site=mms-site" target="_blank">Crossref</a></div><div class="core-xlink-pubmed"><a href="https://pubmed.ncbi.nlm.nih.gov/27959736/" target="_blank">PubMed</a></div><div class="core-xlink-isi"><a href="https://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2&amp;DestApp=WOS_CPL&amp;UsrCustomerID=5e3815c904498985e796fc91436abd9a&amp;SrcAuth=atyponcel&amp;SrcApp=literatum&amp;DestLinkType=FullRecord&amp;KeyUT=000388464300008" target="_blank">Web of Science</a></div><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=Fully+implanted+brain%E2%80%93computer+interface+in+a+locked-in+patient+with+ALS.&amp;publication_year=2016&amp;journal=N+Engl+J+Med&amp;pages=2060-2066&amp;doi=10.1056%2FNEJMoa1608085&amp;pmid=27959736" target="_blank">Google Scholar</a></div><div role="menu" aria-label="links" class="to-citation__accordion no-separator" id="to-citation__accordion-r5-core" style="display: none;"><ul role="none"><li role="none"><a class="to-citation" href="#body-ref-r8" role="menuitem"><i aria-hidden="true" class="icon-return"></i><span>a [...] messages by controlling a computer cursor. </span></a></li><li role="none"><a class="to-citation" href="#body-ref-r39" role="menuitem"><i aria-hidden="true" class="icon-return"></i><span>b [...] of electrocorticographic recordings, </span></a></li></ul></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">6.</div><div id="core-r6" class="citations"><div class="citation"><div class="citation-content">Pandarinath C, Nuyujukian P, Blabe CH, et al. High performance communication by people with paralysis using an intracortical brain–computer interface. <em>Elife</em> 2017;6:e18554-e18554.</div><div class="external-links"><div class="to-citation__wrapper"><button aria-controls="to-citation__accordion-r6-core" aria-expanded="false" aria-label="Toggle citations menu" class="to-citation__toggle"><i aria-hidden="true" class="icon-plus"></i><span data-expand-title="Hide Citations" data-collapsed-title="Show Citations" class="accordion__toggle__title"></span></button></div><div class="core-xlink-crossref"><a href="https://doi.org/10.7554/eLife.18554" target="_blank">Crossref</a></div><div class="core-xlink-pubmed"><a href="https://pubmed.ncbi.nlm.nih.gov/28220753/" target="_blank">PubMed</a></div><div class="core-xlink-isi"><a href="https://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2&amp;DestApp=WOS_CPL&amp;UsrCustomerID=5e3815c904498985e796fc91436abd9a&amp;SrcAuth=atyponcel&amp;SrcApp=literatum&amp;DestLinkType=FullRecord&amp;KeyUT=000395185000001" target="_blank">Web of Science</a></div><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=High+performance+communication+by+people+with+paralysis+using+an+intracortical+brain%E2%80%93computer+interface.&amp;publication_year=2017&amp;journal=Elife&amp;pages=e18554-e18554&amp;doi=10.7554%2FeLife.18554&amp;pmid=28220753" target="_blank">Google Scholar</a></div><div role="menu" aria-label="links" class="to-citation__accordion no-separator" id="to-citation__accordion-r6-core" style="display: none;"><ul role="none"><li role="none"><a class="to-citation" href="#body-ref-r8" role="menuitem"><i aria-hidden="true" class="icon-return"></i><span>a [...] messages by controlling a computer cursor. </span></a></li><li role="none"><a class="to-citation" href="#body-ref-r35-1" role="menuitem"><i aria-hidden="true" class="icon-return"></i><span>b [...] before deployment with a user, </span></a></li></ul></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">7.</div><div id="core-r7" class="citations"><div class="citation"><div class="citation-content">Brumberg JS, Pitt KM, Mantie-Kozlowski A, Burnison JD. Brain–computer interfaces for augmentative and alternative communication: a tutorial. <em>Am J Speech Lang Pathol</em> 2018;27:1-12.</div><div class="external-links"><div class="to-citation__wrapper"><a class="to-citation" href="#body-ref-r8"><i aria-hidden="true" class="icon-return"></i><span>Go to Citation</span></a></div><div class="core-xlink-crossref"><a href="https://doi.org/10.1044/2017_AJSLP-16-0244" target="_blank">Crossref</a></div><div class="core-xlink-pubmed"><a href="https://pubmed.ncbi.nlm.nih.gov/29318256/" target="_blank">PubMed</a></div><div class="core-xlink-isi"><a href="https://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2&amp;DestApp=WOS_CPL&amp;UsrCustomerID=5e3815c904498985e796fc91436abd9a&amp;SrcAuth=atyponcel&amp;SrcApp=literatum&amp;DestLinkType=FullRecord&amp;KeyUT=000425847000001" target="_blank">Web of Science</a></div><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=Brain%E2%80%93computer+interfaces+for+augmentative+and+alternative+communication%3A+a+tutorial.&amp;publication_year=2018&amp;journal=Am+J+Speech+Lang+Pathol&amp;pages=1-12&amp;doi=10.1044%2F2017_AJSLP-16-0244&amp;pmid=29318256" target="_blank">Google Scholar</a></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">8.</div><div id="core-r8" class="citations"><div class="citation"><div class="citation-content">Linse K, Aust E, Joos M, Hermann A. Communication matters — pitfalls and promise of hightech communication devices in palliative care of severely physically disabled patients with amyotrophic lateral sclerosis. <em>Front Neurol</em> 2018;9:603-603.</div><div class="external-links"><div class="to-citation__wrapper"><a class="to-citation" href="#body-ref-r8"><i aria-hidden="true" class="icon-return"></i><span>Go to Citation</span></a></div><div class="core-xlink-crossref"><a href="https://doi.org/10.3389/fneur.2018.00603" target="_blank">Crossref</a></div><div class="core-xlink-pubmed"><a href="https://pubmed.ncbi.nlm.nih.gov/30100896/" target="_blank">PubMed</a></div><div class="core-xlink-isi"><a href="https://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2&amp;DestApp=WOS_CPL&amp;UsrCustomerID=5e3815c904498985e796fc91436abd9a&amp;SrcAuth=atyponcel&amp;SrcApp=literatum&amp;DestLinkType=FullRecord&amp;KeyUT=000440028800001" target="_blank">Web of Science</a></div><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=Communication+matters+%E2%80%94+pitfalls+and+promise+of+hightech+communication+devices+in+palliative+care+of+severely+physically+disabled+patients+with+amyotrophic+lateral+sclerosis.&amp;publication_year=2018&amp;journal=Front+Neurol&amp;pages=603-603&amp;doi=10.3389%2Ffneur.2018.00603&amp;pmid=30100896" target="_blank">Google Scholar</a></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">9.</div><div id="core-r9" class="citations"><div class="citation"><div class="citation-content">Bouchard KE, Mesgarani N, Johnson K, Chang EF. Functional organization of human sensorimotor cortex for speech articulation. <em>Nature</em> 2013;495:327-332.</div><div class="external-links"><div class="to-citation__wrapper"><button aria-controls="to-citation__accordion-r9-core" aria-expanded="false" aria-label="Toggle citations menu" class="to-citation__toggle"><i aria-hidden="true" class="icon-plus"></i><span data-expand-title="Hide Citations" data-collapsed-title="Show Citations" class="accordion__toggle__title"></span></button></div><div class="core-xlink-crossref"><a href="https://doi.org/10.1038/nature11911" target="_blank">Crossref</a></div><div class="core-xlink-pubmed"><a href="https://pubmed.ncbi.nlm.nih.gov/23426266/" target="_blank">PubMed</a></div><div class="core-xlink-isi"><a href="https://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2&amp;DestApp=WOS_CPL&amp;UsrCustomerID=5e3815c904498985e796fc91436abd9a&amp;SrcAuth=atyponcel&amp;SrcApp=literatum&amp;DestLinkType=FullRecord&amp;KeyUT=000316650500034" target="_blank">Web of Science</a></div><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=Functional+organization+of+human+sensorimotor+cortex+for+speech+articulation.&amp;publication_year=2013&amp;journal=Nature&amp;pages=327-332&amp;doi=10.1038%2Fnature11911&amp;pmid=23426266" target="_blank">Google Scholar</a></div><div role="menu" aria-label="links" class="to-citation__accordion no-separator" id="to-citation__accordion-r9-core" style="display: none;"><ul role="none"><li role="none"><a class="to-citation" href="#body-ref-r14-1" role="menuitem"><i aria-hidden="true" class="icon-return"></i><span>a [...] movements of the vocal tract has expanded. </span></a></li><li role="none"><a class="to-citation" href="#body-ref-r13-2" role="menuitem"><i aria-hidden="true" class="icon-return"></i><span>b [...] and posterior inferior frontal gyrus. </span></a></li><li role="none"><a class="to-citation" href="#body-ref-r18-3" role="menuitem"><i aria-hidden="true" class="icon-return"></i><span>c [...] frequency range with speech processing, </span></a></li><li role="none"><a class="to-citation" href="#body-ref-r13-4" role="menuitem"><i aria-hidden="true" class="icon-return"></i><span>d [...] implicating this area in speech production. </span></a></li></ul></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">10.</div><div id="core-r10" class="citations"><div class="citation"><div class="citation-content">Lotte F, Brumberg JS, Brunner P, et al. Electrocorticographic representations of segmental features in continuous speech. <em>Front Hum Neurosci</em> 2015;9:97-97.</div><div class="external-links"><div class="to-citation__wrapper"><a class="to-citation" href="#body-ref-r14-1"><i aria-hidden="true" class="icon-return"></i><span>Go to Citation</span></a></div><div class="core-xlink-crossref"><a href="https://doi.org/10.3389/fnhum.2015.00097" target="_blank">Crossref</a></div><div class="core-xlink-pubmed"><a href="https://pubmed.ncbi.nlm.nih.gov/25759647/" target="_blank">PubMed</a></div><div class="core-xlink-isi"><a href="https://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2&amp;DestApp=WOS_CPL&amp;UsrCustomerID=5e3815c904498985e796fc91436abd9a&amp;SrcAuth=atyponcel&amp;SrcApp=literatum&amp;DestLinkType=FullRecord&amp;KeyUT=000349949100001" target="_blank">Web of Science</a></div><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=Electrocorticographic+representations+of+segmental+features+in+continuous+speech.&amp;publication_year=2015&amp;journal=Front+Hum+Neurosci&amp;pages=97-97&amp;doi=10.3389%2Ffnhum.2015.00097&amp;pmid=25759647" target="_blank">Google Scholar</a></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">11.</div><div id="core-r11" class="citations"><div class="citation"><div class="citation-content">Guenther FH, Hickok G. Neural models of motor speech control. In: Hickok G, Small S, eds.<em>Neurobiology of language</em>. Cambridge, MA: Academic Press, 2015:725-740.</div><div class="external-links"><div class="to-citation__wrapper"><button aria-controls="to-citation__accordion-r11-core" aria-expanded="false" aria-label="Toggle citations menu" class="to-citation__toggle"><i aria-hidden="true" class="icon-plus"></i><span data-expand-title="Hide Citations" data-collapsed-title="Show Citations" class="accordion__toggle__title"></span></button></div><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=Neural+models+of+motor+speech+control&amp;publication_year=2015&amp;pages=725-740" target="_blank">Google Scholar</a></div><div role="menu" aria-label="links" class="to-citation__accordion no-separator" id="to-citation__accordion-r11-core" style="display: none;"><ul role="none"><li role="none"><a class="to-citation" href="#body-ref-r14-1" role="menuitem"><i aria-hidden="true" class="icon-return"></i><span>a [...] movements of the vocal tract has expanded. </span></a></li><li role="none"><a class="to-citation" href="#body-ref-r13-2" role="menuitem"><i aria-hidden="true" class="icon-return"></i><span>b [...] and posterior inferior frontal gyrus. </span></a></li></ul></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">12.</div><div id="core-r12" class="citations"><div class="citation"><div class="citation-content">Mugler EM, Tate MC, Livescu K, Templer JW, Goldrick MA, Slutzky MW. Differential representation of articulatory gestures and phonemes in precentral and inferior frontal gyri. <em>J Neurosci</em> 2018;38:9803-9813.</div><div class="external-links"><div class="to-citation__wrapper"><button aria-controls="to-citation__accordion-r12-core" aria-expanded="false" aria-label="Toggle citations menu" class="to-citation__toggle"><i aria-hidden="true" class="icon-plus"></i><span data-expand-title="Hide Citations" data-collapsed-title="Show Citations" class="accordion__toggle__title"></span></button></div><div class="core-xlink-crossref"><a href="https://doi.org/10.1523/JNEUROSCI.1206-18.2018" target="_blank">Crossref</a></div><div class="core-xlink-pubmed"><a href="https://pubmed.ncbi.nlm.nih.gov/30257858/" target="_blank">PubMed</a></div><div class="core-xlink-isi"><a href="https://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2&amp;DestApp=WOS_CPL&amp;UsrCustomerID=5e3815c904498985e796fc91436abd9a&amp;SrcAuth=atyponcel&amp;SrcApp=literatum&amp;DestLinkType=FullRecord&amp;KeyUT=000450072200001" target="_blank">Web of Science</a></div><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=Differential+representation+of+articulatory+gestures+and+phonemes+in+precentral+and+inferior+frontal+gyri.&amp;publication_year=2018&amp;journal=J+Neurosci&amp;pages=9803-9813&amp;doi=10.1523%2FJNEUROSCI.1206-18.2018&amp;pmid=30257858" target="_blank">Google Scholar</a></div><div role="menu" aria-label="links" class="to-citation__accordion no-separator" id="to-citation__accordion-r12-core" style="display: none;"><ul role="none"><li role="none"><a class="to-citation" href="#body-ref-r14-1" role="menuitem"><i aria-hidden="true" class="icon-return"></i><span>a [...] movements of the vocal tract has expanded. </span></a></li><li role="none"><a class="to-citation" href="#body-ref-r13-2" role="menuitem"><i aria-hidden="true" class="icon-return"></i><span>b [...] and posterior inferior frontal gyrus. </span></a></li><li role="none"><a class="to-citation" href="#body-ref-r18-3" role="menuitem"><i aria-hidden="true" class="icon-return"></i><span>c [...] frequency range with speech processing, </span></a></li><li role="none"><a class="to-citation" href="#body-ref-r13-4" role="menuitem"><i aria-hidden="true" class="icon-return"></i><span>d [...] implicating this area in speech production. </span></a></li></ul></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">13.</div><div id="core-r13" class="citations"><div class="citation"><div class="citation-content">Chartier J, Anumanchipalli GK, Johnson K, Chang EF. Encoding of articulatory kinematic trajectories in human speech sensorimotor cortex. <em>Neuron</em> 2018;98(5):1042.e4-1054.e4.</div><div class="external-links"><div class="to-citation__wrapper"><button aria-controls="to-citation__accordion-r13-core" aria-expanded="false" aria-label="Toggle citations menu" class="to-citation__toggle"><i aria-hidden="true" class="icon-plus"></i><span data-expand-title="Hide Citations" data-collapsed-title="Show Citations" class="accordion__toggle__title"></span></button></div><div class="core-xlink-crossref"><a href="https://doi.org/10.1016/j.neuron.2018.04.031" target="_blank">Crossref</a></div><div class="core-xlink-pubmed"><a href="https://pubmed.ncbi.nlm.nih.gov/29779940/" target="_blank">PubMed</a></div><div class="core-xlink-isi"><a href="https://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2&amp;DestApp=WOS_CPL&amp;UsrCustomerID=5e3815c904498985e796fc91436abd9a&amp;SrcAuth=atyponcel&amp;SrcApp=literatum&amp;DestLinkType=FullRecord&amp;KeyUT=000436585500020" target="_blank">Web of Science</a></div><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=Encoding+of+articulatory+kinematic+trajectories+in+human+speech+sensorimotor+cortex.&amp;publication_year=2018&amp;journal=Neuron&amp;pages=1042.e4-1054.e4&amp;doi=10.1016%2Fj.neuron.2018.04.031&amp;pmid=29779940" target="_blank">Google Scholar</a></div><div role="menu" aria-label="links" class="to-citation__accordion no-separator" id="to-citation__accordion-r13-core" style="display: none;"><ul role="none"><li role="none"><a class="to-citation" href="#body-ref-r14-1" role="menuitem"><i aria-hidden="true" class="icon-return"></i><span>a [...] movements of the vocal tract has expanded. </span></a></li><li role="none"><a class="to-citation" href="#body-ref-r13-2" role="menuitem"><i aria-hidden="true" class="icon-return"></i><span>b [...] and posterior inferior frontal gyrus. </span></a></li><li role="none"><a class="to-citation" href="#body-ref-r18-3" role="menuitem"><i aria-hidden="true" class="icon-return"></i><span>c [...] frequency range with speech processing, </span></a></li><li role="none"><a class="to-citation" href="#body-ref-r13-4" role="menuitem"><i aria-hidden="true" class="icon-return"></i><span>d [...] implicating this area in speech production. </span></a></li></ul></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">14.</div><div id="core-r14" class="citations"><div class="citation"><div class="citation-content">Salari E, Freudenburg ZV, Branco MP, Aarnoutse EJ, Vansteensel MJ, Ramsey NF. Classification of articulator movements and movement direction from sensorimotor cortex activity. <em>Sci Rep</em> 2019;9:14165-14165.</div><div class="external-links"><div class="to-citation__wrapper"><button aria-controls="to-citation__accordion-r14-core" aria-expanded="false" aria-label="Toggle citations menu" class="to-citation__toggle"><i aria-hidden="true" class="icon-plus"></i><span data-expand-title="Hide Citations" data-collapsed-title="Show Citations" class="accordion__toggle__title"></span></button></div><div class="core-xlink-crossref"><a href="https://doi.org/10.1038/s41598-019-50834-5" target="_blank">Crossref</a></div><div class="core-xlink-pubmed"><a href="https://pubmed.ncbi.nlm.nih.gov/31578420/" target="_blank">PubMed</a></div><div class="core-xlink-isi"><a href="https://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2&amp;DestApp=WOS_CPL&amp;UsrCustomerID=5e3815c904498985e796fc91436abd9a&amp;SrcAuth=atyponcel&amp;SrcApp=literatum&amp;DestLinkType=FullRecord&amp;KeyUT=000488481500028" target="_blank">Web of Science</a></div><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=Classification+of+articulator+movements+and+movement+direction+from+sensorimotor+cortex+activity.&amp;publication_year=2019&amp;journal=Sci+Rep&amp;pages=14165-14165&amp;doi=10.1038%2Fs41598-019-50834-5&amp;pmid=31578420" target="_blank">Google Scholar</a></div><div role="menu" aria-label="links" class="to-citation__accordion no-separator" id="to-citation__accordion-r14-core" style="display: none;"><ul role="none"><li role="none"><a class="to-citation" href="#body-ref-r14-1" role="menuitem"><i aria-hidden="true" class="icon-return"></i><span>a [...] movements of the vocal tract has expanded. </span></a></li><li role="none"><a class="to-citation" href="#body-ref-r18-3" role="menuitem"><i aria-hidden="true" class="icon-return"></i><span>b [...] frequency range with speech processing, </span></a></li></ul></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">15.</div><div id="core-r15" class="citations"><div class="citation"><div class="citation-content">Herff C, Heger D, de Pesters A, et al. Brain-to-text: decoding spoken phrases from phone representations in the brain. <em>Front Neurosci</em> 2015;9:217-217.</div><div class="external-links"><div class="to-citation__wrapper"><button aria-controls="to-citation__accordion-r15-core" aria-expanded="false" aria-label="Toggle citations menu" class="to-citation__toggle"><i aria-hidden="true" class="icon-plus"></i><span data-expand-title="Hide Citations" data-collapsed-title="Show Citations" class="accordion__toggle__title"></span></button></div><div class="core-xlink-crossref"><a href="https://doi.org/10.3389/fnins.2015.00217" target="_blank">Crossref</a></div><div class="core-xlink-pubmed"><a href="https://pubmed.ncbi.nlm.nih.gov/26124702/" target="_blank">PubMed</a></div><div class="core-xlink-isi"><a href="https://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2&amp;DestApp=WOS_CPL&amp;UsrCustomerID=5e3815c904498985e796fc91436abd9a&amp;SrcAuth=atyponcel&amp;SrcApp=literatum&amp;DestLinkType=FullRecord&amp;KeyUT=000362002000001" target="_blank">Web of Science</a></div><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=Brain-to-text%3A+decoding+spoken+phrases+from+phone+representations+in+the+brain.&amp;publication_year=2015&amp;journal=Front+Neurosci&amp;pages=217-217&amp;doi=10.3389%2Ffnins.2015.00217&amp;pmid=26124702" target="_blank">Google Scholar</a></div><div role="menu" aria-label="links" class="to-citation__accordion no-separator" id="to-citation__accordion-r15-core" style="display: none;"><ul role="none"><li role="none"><a class="to-citation" href="#body-ref-r19-1" role="menuitem"><i aria-hidden="true" class="icon-return"></i><span>a [...] in persons without speech impairments. </span></a></li><li role="none"><a class="to-citation" href="#body-ref-r19-3" role="menuitem"><i aria-hidden="true" class="icon-return"></i><span>b [...] for assistive technology to communicate. </span></a></li></ul></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">16.</div><div id="core-r16" class="citations"><div class="citation"><div class="citation-content">Angrick M, Herff C, Mugler E, et al. Speech synthesis from ECoG using densely connected 3D convolutional neural networks. <em>J Neural Eng</em> 2019;16:036019-036019.</div><div class="external-links"><div class="to-citation__wrapper"><button aria-controls="to-citation__accordion-r16-core" aria-expanded="false" aria-label="Toggle citations menu" class="to-citation__toggle"><i aria-hidden="true" class="icon-plus"></i><span data-expand-title="Hide Citations" data-collapsed-title="Show Citations" class="accordion__toggle__title"></span></button></div><div class="core-xlink-crossref"><a href="https://doi.org/10.1088/1741-2552/ab0c59" target="_blank">Crossref</a></div><div class="core-xlink-pubmed"><a href="https://pubmed.ncbi.nlm.nih.gov/30831567/" target="_blank">PubMed</a></div><div class="core-xlink-isi"><a href="https://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2&amp;DestApp=WOS_CPL&amp;UsrCustomerID=5e3815c904498985e796fc91436abd9a&amp;SrcAuth=atyponcel&amp;SrcApp=literatum&amp;DestLinkType=FullRecord&amp;KeyUT=000465010800005" target="_blank">Web of Science</a></div><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=Speech+synthesis+from+ECoG+using+densely+connected+3D+convolutional+neural+networks.&amp;publication_year=2019&amp;journal=J+Neural+Eng&amp;pages=036019-036019&amp;doi=10.1088%2F1741-2552%2Fab0c59&amp;pmid=30831567" target="_blank">Google Scholar</a></div><div role="menu" aria-label="links" class="to-citation__accordion no-separator" id="to-citation__accordion-r16-core" style="display: none;"><ul role="none"><li role="none"><a class="to-citation" href="#body-ref-r19-1" role="menuitem"><i aria-hidden="true" class="icon-return"></i><span>a [...] in persons without speech impairments. </span></a></li><li role="none"><a class="to-citation" href="#body-ref-r19-3" role="menuitem"><i aria-hidden="true" class="icon-return"></i><span>b [...] for assistive technology to communicate. </span></a></li></ul></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">17.</div><div id="core-r17" class="citations"><div class="citation"><div class="citation-content">Anumanchipalli GK, Chartier J, Chang EF. Speech synthesis from neural decoding of spoken sentences. <em>Nature</em> 2019;568:493-498.</div><div class="external-links"><div class="to-citation__wrapper"><button aria-controls="to-citation__accordion-r17-core" aria-expanded="false" aria-label="Toggle citations menu" class="to-citation__toggle"><i aria-hidden="true" class="icon-plus"></i><span data-expand-title="Hide Citations" data-collapsed-title="Show Citations" class="accordion__toggle__title"></span></button></div><div class="core-xlink-crossref"><a href="https://doi.org/10.1038/s41586-019-1119-1" target="_blank">Crossref</a></div><div class="core-xlink-pubmed"><a href="https://pubmed.ncbi.nlm.nih.gov/31019317/" target="_blank">PubMed</a></div><div class="core-xlink-isi"><a href="https://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2&amp;DestApp=WOS_CPL&amp;UsrCustomerID=5e3815c904498985e796fc91436abd9a&amp;SrcAuth=atyponcel&amp;SrcApp=literatum&amp;DestLinkType=FullRecord&amp;KeyUT=000465594200040" target="_blank">Web of Science</a></div><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=Speech+synthesis+from+neural+decoding+of+spoken+sentences.&amp;publication_year=2019&amp;journal=Nature&amp;pages=493-498&amp;doi=10.1038%2Fs41586-019-1119-1&amp;pmid=31019317" target="_blank">Google Scholar</a></div><div role="menu" aria-label="links" class="to-citation__accordion no-separator" id="to-citation__accordion-r17-core" style="display: none;"><ul role="none"><li role="none"><a class="to-citation" href="#body-ref-r19-1" role="menuitem"><i aria-hidden="true" class="icon-return"></i><span>a [...] in persons without speech impairments. </span></a></li><li role="none"><a class="to-citation" href="#body-ref-r19-3" role="menuitem"><i aria-hidden="true" class="icon-return"></i><span>b [...] for assistive technology to communicate. </span></a></li></ul></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">18.</div><div id="core-r18" class="citations"><div class="citation"><div class="citation-content">Moses DA, Leonard MK, Makin JG, Chang EF. Real-time decoding of question-and-answer speech dialogue using human cortical activity. <em>Nat Commun</em> 2019;10:3096-3096.</div><div class="external-links"><div class="to-citation__wrapper"><button aria-controls="to-citation__accordion-r18-core" aria-expanded="false" aria-label="Toggle citations menu" class="to-citation__toggle"><i aria-hidden="true" class="icon-plus"></i><span data-expand-title="Hide Citations" data-collapsed-title="Show Citations" class="accordion__toggle__title"></span></button></div><div class="core-xlink-crossref"><a href="https://doi.org/10.1038/s41467-019-10994-4" target="_blank">Crossref</a></div><div class="core-xlink-pubmed"><a href="https://pubmed.ncbi.nlm.nih.gov/31363096/" target="_blank">PubMed</a></div><div class="core-xlink-isi"><a href="https://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2&amp;DestApp=WOS_CPL&amp;UsrCustomerID=5e3815c904498985e796fc91436abd9a&amp;SrcAuth=atyponcel&amp;SrcApp=literatum&amp;DestLinkType=FullRecord&amp;KeyUT=000477859900001" target="_blank">Web of Science</a></div><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=Real-time+decoding+of+question-and-answer+speech+dialogue+using+human+cortical+activity.&amp;publication_year=2019&amp;journal=Nat+Commun&amp;pages=3096-3096&amp;doi=10.1038%2Fs41467-019-10994-4&amp;pmid=31363096" target="_blank">Google Scholar</a></div><div role="menu" aria-label="links" class="to-citation__accordion no-separator" id="to-citation__accordion-r18-core" style="display: none;"><ul role="none"><li role="none"><a class="to-citation" href="#body-ref-r19-1" role="menuitem"><i aria-hidden="true" class="icon-return"></i><span>a [...] in persons without speech impairments. </span></a></li><li role="none"><a class="to-citation" href="#body-ref-r23" role="menuitem"><i aria-hidden="true" class="icon-return"></i><span>b [...] analysis (Section S2 and Figs. S2 and S3). </span></a></li><li role="none"><a class="to-citation" href="#body-ref-r18-3" role="menuitem"><i aria-hidden="true" class="icon-return"></i><span>c [...] frequency range with speech processing, </span></a></li><li role="none"><a class="to-citation" href="#body-ref-r19-3" role="menuitem"><i aria-hidden="true" class="icon-return"></i><span>d [...] for assistive technology to communicate. </span></a></li><li role="none"><a class="to-citation" href="#body-ref-r29" role="menuitem"><i aria-hidden="true" class="icon-return"></i><span>e [...] problem with speech-detection approaches </span></a></li></ul></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">19.</div><div id="core-r19" class="citations"><div class="citation"><div class="citation-content">Makin JG, Moses DA, Chang EF. Machine translation of cortical activity to text with an encoder-decoder framework. <em>Nat Neurosci</em> 2020;23:575-582.</div><div class="external-links"><div class="to-citation__wrapper"><button aria-controls="to-citation__accordion-r19-core" aria-expanded="false" aria-label="Toggle citations menu" class="to-citation__toggle"><i aria-hidden="true" class="icon-plus"></i><span data-expand-title="Hide Citations" data-collapsed-title="Show Citations" class="accordion__toggle__title"></span></button></div><div class="core-xlink-crossref"><a href="https://doi.org/10.1038/s41593-020-0608-8" target="_blank">Crossref</a></div><div class="core-xlink-pubmed"><a href="https://pubmed.ncbi.nlm.nih.gov/32231340/" target="_blank">PubMed</a></div><div class="core-xlink-isi"><a href="https://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2&amp;DestApp=WOS_CPL&amp;UsrCustomerID=5e3815c904498985e796fc91436abd9a&amp;SrcAuth=atyponcel&amp;SrcApp=literatum&amp;DestLinkType=FullRecord&amp;KeyUT=000522382600003" target="_blank">Web of Science</a></div><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=Machine+translation+of+cortical+activity+to+text+with+an+encoder-decoder+framework.&amp;publication_year=2020&amp;journal=Nat+Neurosci&amp;pages=575-582&amp;doi=10.1038%2Fs41593-020-0608-8&amp;pmid=32231340" target="_blank">Google Scholar</a></div><div role="menu" aria-label="links" class="to-citation__accordion no-separator" id="to-citation__accordion-r19-core" style="display: none;"><ul role="none"><li role="none"><a class="to-citation" href="#body-ref-r19-1" role="menuitem"><i aria-hidden="true" class="icon-return"></i><span>a [...] in persons without speech impairments. </span></a></li><li role="none"><a class="to-citation" href="#body-ref-r27" role="menuitem"><i aria-hidden="true" class="icon-return"></i><span>b [...] by the detection and classification models. </span></a></li><li role="none"><a class="to-citation" href="#body-ref-r19-3" role="menuitem"><i aria-hidden="true" class="icon-return"></i><span>c [...] for assistive technology to communicate. </span></a></li></ul></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">20.</div><div id="core-r20" class="citations"><div class="citation"><div class="citation-content">Martin S, Iturrate I, Millán JDR, Knight RT, Pasley BN. Decoding inner speech using electrocorticography: progress and challenges toward a speech prosthesis. <em>Front Neurosci</em> 2018;12:422-422.</div><div class="external-links"><div class="to-citation__wrapper"><a class="to-citation" href="#body-ref-r20"><i aria-hidden="true" class="icon-return"></i><span>Go to Citation</span></a></div><div class="core-xlink-crossref"><a href="https://doi.org/10.3389/fnins.2018.00422" target="_blank">Crossref</a></div><div class="core-xlink-pubmed"><a href="https://pubmed.ncbi.nlm.nih.gov/29977189/" target="_blank">PubMed</a></div><div class="core-xlink-isi"><a href="https://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2&amp;DestApp=WOS_CPL&amp;UsrCustomerID=5e3815c904498985e796fc91436abd9a&amp;SrcAuth=atyponcel&amp;SrcApp=literatum&amp;DestLinkType=FullRecord&amp;KeyUT=000435844500001" target="_blank">Web of Science</a></div><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=Decoding+inner+speech+using+electrocorticography%3A+progress+and+challenges+toward+a+speech+prosthesis.&amp;publication_year=2018&amp;journal=Front+Neurosci&amp;pages=422-422&amp;doi=10.3389%2Ffnins.2018.00422&amp;pmid=29977189" target="_blank">Google Scholar</a></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">21.</div><div id="core-r21" class="citations"><div class="citation"><div class="citation-content">Guenther FH, Brumberg JS, Wright EJ, et al. A wireless brain–machine interface for real-time speech synthesis. <em>PLoS One</em> 2009;4(12):e8218-e8218.</div><div class="external-links"><div class="to-citation__wrapper"><a class="to-citation" href="#body-ref-r22"><i aria-hidden="true" class="icon-return"></i><span>Go to Citation</span></a></div><div class="core-xlink-crossref"><a href="https://doi.org/10.1371/journal.pone.0008218" target="_blank">Crossref</a></div><div class="core-xlink-pubmed"><a href="https://pubmed.ncbi.nlm.nih.gov/20011034/" target="_blank">PubMed</a></div><div class="core-xlink-isi"><a href="https://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2&amp;DestApp=WOS_CPL&amp;UsrCustomerID=5e3815c904498985e796fc91436abd9a&amp;SrcAuth=atyponcel&amp;SrcApp=literatum&amp;DestLinkType=FullRecord&amp;KeyUT=000272829800009" target="_blank">Web of Science</a></div><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=A+wireless+brain%E2%80%93machine+interface+for+real-time+speech+synthesis.&amp;publication_year=2009&amp;journal=PLoS+One&amp;pages=e8218-e8218&amp;doi=10.1371%2Fjournal.pone.0008218&amp;pmid=20011034" target="_blank">Google Scholar</a></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">22.</div><div id="core-r22" class="citations"><div class="citation"><div class="citation-content">Brumberg JS, Wright EJ, Andreasen DS, Guenther FH, Kennedy PR. Classification of intended phoneme production from chronic intracortical microelectrode recordings in speech-motor cortex. <em>Front Neurosci</em> 2011;5:65-65.</div><div class="external-links"><div class="to-citation__wrapper"><a class="to-citation" href="#body-ref-r22"><i aria-hidden="true" class="icon-return"></i><span>Go to Citation</span></a></div><div class="core-xlink-pubmed"><a href="https://pubmed.ncbi.nlm.nih.gov/21629876/" target="_blank">PubMed</a></div><div class="core-xlink-isi"><a href="https://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2&amp;DestApp=WOS_CPL&amp;UsrCustomerID=5e3815c904498985e796fc91436abd9a&amp;SrcAuth=atyponcel&amp;SrcApp=literatum&amp;DestLinkType=FullRecord&amp;KeyUT=000209200600061" target="_blank">Web of Science</a></div><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=Classification+of+intended+phoneme+production+from+chronic+intracortical+microelectrode+recordings+in+speech-motor+cortex.&amp;publication_year=2011&amp;journal=Front+Neurosci&amp;pages=65-65&amp;pmid=21629876" target="_blank">Google Scholar</a></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">23.</div><div id="core-r23" class="citations"><div class="citation"><div class="citation-content">Moses DA, Leonard MK, Chang EF. Real-time classification of auditory sentences using evoked cortical activity in humans. <em>J Neural Eng</em> 2018;15:036005-036005.</div><div class="external-links"><div class="to-citation__wrapper"><a class="to-citation" href="#body-ref-r23"><i aria-hidden="true" class="icon-return"></i><span>Go to Citation</span></a></div><div class="core-xlink-crossref"><a href="https://doi.org/10.1088/1741-2552/aaab6f" target="_blank">Crossref</a></div><div class="core-xlink-pubmed"><a href="https://pubmed.ncbi.nlm.nih.gov/29378977/" target="_blank">PubMed</a></div><div class="core-xlink-isi"><a href="https://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2&amp;DestApp=WOS_CPL&amp;UsrCustomerID=5e3815c904498985e796fc91436abd9a&amp;SrcAuth=atyponcel&amp;SrcApp=literatum&amp;DestLinkType=FullRecord&amp;KeyUT=000426274400005" target="_blank">Web of Science</a></div><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=Real-time+classification+of+auditory+sentences+using+evoked+cortical+activity+in+humans.&amp;publication_year=2018&amp;journal=J+Neural+Eng&amp;pages=036005-036005&amp;doi=10.1088%2F1741-2552%2Faaab6f&amp;pmid=29378977" target="_blank">Google Scholar</a></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">24.</div><div id="core-r24" class="citations"><div class="citation"><div class="citation-content">Kneser R, Ney H. Improved backing-off for M-gram language modeling. In: <em>Conference proceedings: 1995 International Conference on Acoustics, Speech, and Signal Processing. Vol. 1</em>. New York: Institute of Electrical and Electronics Engineers, 1995:181-184.</div><div class="external-links"><div class="to-citation__wrapper"><a class="to-citation" href="#body-ref-r25"><i aria-hidden="true" class="icon-return"></i><span>Go to Citation</span></a></div><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=Improved+backing-off+for+M-gram+language+modeling.&amp;publication_year=1995&amp;pages=181-184" target="_blank">Google Scholar</a></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">25.</div><div id="core-r25" class="citations"><div class="citation"><div class="citation-content">Chen SF, Goodman J. An empirical study of smoothing techniques for language modeling. <em>Comput Speech Lang</em> 1999;13:359-394.</div><div class="external-links"><div class="to-citation__wrapper"><a class="to-citation" href="#body-ref-r25"><i aria-hidden="true" class="icon-return"></i><span>Go to Citation</span></a></div><div class="core-xlink-crossref"><a href="https://doi.org/10.1006/csla.1999.0128" target="_blank">Crossref</a></div><div class="core-xlink-isi"><a href="https://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2&amp;DestApp=WOS_CPL&amp;UsrCustomerID=5e3815c904498985e796fc91436abd9a&amp;SrcAuth=atyponcel&amp;SrcApp=literatum&amp;DestLinkType=FullRecord&amp;KeyUT=000083093200003" target="_blank">Web of Science</a></div><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=An+empirical+study+of+smoothing+techniques+for+language+modeling.&amp;publication_year=1999&amp;journal=Comput+Speech+Lang&amp;pages=359-394&amp;doi=10.1006%2Fcsla.1999.0128" target="_blank">Google Scholar</a></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">26.</div><div id="core-r26" class="citations"><div class="citation"><div class="citation-content">Viterbi AJ. Error bounds for convolutional codes and an asymptotically optimum decoding algorithm. <em>IEEE Trans Inf Theory</em> 1967;13:260-269.</div><div class="external-links"><div class="to-citation__wrapper"><a class="to-citation" href="#body-ref-r26"><i aria-hidden="true" class="icon-return"></i><span>Go to Citation</span></a></div><div class="core-xlink-crossref"><a href="https://doi.org/10.1109/TIT.1967.1054010" target="_blank">Crossref</a></div><div class="core-xlink-isi"><a href="https://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2&amp;DestApp=WOS_CPL&amp;UsrCustomerID=5e3815c904498985e796fc91436abd9a&amp;SrcAuth=atyponcel&amp;SrcApp=literatum&amp;DestLinkType=FullRecord&amp;KeyUT=A19679497100016" target="_blank">Web of Science</a></div><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=Error+bounds+for+convolutional+codes+and+an+asymptotically+optimum+decoding+algorithm.&amp;publication_year=1967&amp;journal=IEEE+Trans+Inf+Theory&amp;pages=260-269&amp;doi=10.1109%2FTIT.1967.1054010" target="_blank">Google Scholar</a></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">27.</div><div id="core-r27" class="citations"><div class="citation"><div class="citation-content">Simonyan K, Vedaldi A, Zisserman A. Deep inside convolutional networks: visualising image classification models and saliency maps. In: Bengio Y, LeCun Y, eds. <em>Workshop at the International Conference on Learning Representations</em>. Banff, AB, Canada: ICLR Workshop, 2014.</div><div class="external-links"><div class="to-citation__wrapper"><a class="to-citation" href="#body-ref-r27"><i aria-hidden="true" class="icon-return"></i><span>Go to Citation</span></a></div><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=Deep+inside+convolutional+networks%3A+visualising+image+classification+models+and+saliency+maps&amp;publication_year=2014" target="_blank">Google Scholar</a></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">28.</div><div id="core-r28" class="citations"><div class="citation"><div class="citation-content">Kanas VG, Mporas I, Benz HL, Sgarbas KN, Bezerianos A, Crone NE. Real-time voice activity detection for ECoG-based speech brain machine interfaces. In: <em>19th International Conference on Digital Signal Processing: proceedings</em>. New York: Institute of Electrical and Electronics Engineers, 2014:862-865.</div><div class="external-links"><div class="to-citation__wrapper"><a class="to-citation" href="#body-ref-r29"><i aria-hidden="true" class="icon-return"></i><span>Go to Citation</span></a></div><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=Real-time+voice+activity+detection+for+ECoG-based+speech+brain+machine+interfaces&amp;publication_year=2014&amp;pages=862-865" target="_blank">Google Scholar</a></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">29.</div><div id="core-r29" class="citations"><div class="citation"><div class="citation-content">Dash D, Ferrari P, Dutta S, Wang J. NeuroVAD: real-time voice activity detection from non-invasive neuromagnetic signals. <em>Sensors (Basel)</em> 2020;20:2248-2248.</div><div class="external-links"><div class="to-citation__wrapper"><a class="to-citation" href="#body-ref-r29"><i aria-hidden="true" class="icon-return"></i><span>Go to Citation</span></a></div><div class="core-xlink-crossref"><a href="https://doi.org/10.3390/s20082248" target="_blank">Crossref</a></div><div class="core-xlink-pubmed"><a href="https://pubmed.ncbi.nlm.nih.gov/32316162/" target="_blank">PubMed</a></div><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=NeuroVAD%3A+real-time+voice+activity+detection+from+non-invasive+neuromagnetic+signals.&amp;publication_year=2020&amp;journal=Sensors+%28Basel%29&amp;pages=2248-2248&amp;doi=10.3390%2Fs20082248&amp;pmid=32316162" target="_blank">Google Scholar</a></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">30.</div><div id="core-r30" class="citations"><div class="citation"><div class="citation-content">Sollich P, Krogh A. Learning with ensembles: how overfitting can be useful. In: Touretzky DS, Mozer MC, Hasselmo ME, eds. <em>Advances in neural information processing systems 8</em>. Cambridge, MA: MIT Press, 1996:190-196.</div><div class="external-links"><div class="to-citation__wrapper"><a class="to-citation" href="#body-ref-r31"><i aria-hidden="true" class="icon-return"></i><span>Go to Citation</span></a></div><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=Learning+with+ensembles%3A+how+overfitting+can+be+useful&amp;publication_year=1996&amp;pages=190-196" target="_blank">Google Scholar</a></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">31.</div><div id="core-r31" class="citations"><div class="citation"><div class="citation-content">Krizhevsky A, Sutskever I, Hinton GE. ImageNet classification with deep convolutional neural networks. In: Bartlett P, Pereira FCN, Burges CJC, Bottou L, Weinberger KQ, eds. <em>Advances in neural information processing systems 25</em>. Red Hook, NY: Curran Associates, 2012:1097-1105.</div><div class="external-links"><div class="to-citation__wrapper"><a class="to-citation" href="#body-ref-r31"><i aria-hidden="true" class="icon-return"></i><span>Go to Citation</span></a></div><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=ImageNet+classification+with+deep+convolutional+neural+networks&amp;publication_year=2012&amp;pages=1097-1105" target="_blank">Google Scholar</a></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">32.</div><div id="core-r32" class="citations"><div class="citation"><div class="citation-content">Shoham S, Halgren E, Maynard EM, Normann RA. Motor-cortical activity in tetraplegics. <em>Nature</em> 2001;413:793-793.</div><div class="external-links"><div class="to-citation__wrapper"><a class="to-citation" href="#body-ref-r33"><i aria-hidden="true" class="icon-return"></i><span>Go to Citation</span></a></div><div class="core-xlink-crossref"><a href="https://doi.org/10.1038/35101651" target="_blank">Crossref</a></div><div class="core-xlink-pubmed"><a href="https://pubmed.ncbi.nlm.nih.gov/11677592/" target="_blank">PubMed</a></div><div class="core-xlink-isi"><a href="https://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2&amp;DestApp=WOS_CPL&amp;UsrCustomerID=5e3815c904498985e796fc91436abd9a&amp;SrcAuth=atyponcel&amp;SrcApp=literatum&amp;DestLinkType=FullRecord&amp;KeyUT=000171750200031" target="_blank">Web of Science</a></div><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=Motor-cortical+activity+in+tetraplegics.&amp;publication_year=2001&amp;journal=Nature&amp;pages=793-793&amp;doi=10.1038%2F35101651&amp;pmid=11677592" target="_blank">Google Scholar</a></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">33.</div><div id="core-r33" class="citations"><div class="citation"><div class="citation-content">Hochberg LR, Serruya MD, Friehs GM, et al. Neuronal ensemble control of prosthetic devices by a human with tetraplegia. <em>Nature</em> 2006;442:164-171.</div><div class="external-links"><div class="to-citation__wrapper"><a class="to-citation" href="#body-ref-r33"><i aria-hidden="true" class="icon-return"></i><span>Go to Citation</span></a></div><div class="core-xlink-crossref"><a href="https://doi.org/10.1038/nature04970" target="_blank">Crossref</a></div><div class="core-xlink-pubmed"><a href="https://pubmed.ncbi.nlm.nih.gov/16838014/" target="_blank">PubMed</a></div><div class="core-xlink-isi"><a href="https://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2&amp;DestApp=WOS_CPL&amp;UsrCustomerID=5e3815c904498985e796fc91436abd9a&amp;SrcAuth=atyponcel&amp;SrcApp=literatum&amp;DestLinkType=FullRecord&amp;KeyUT=000238979700039" target="_blank">Web of Science</a></div><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=Neuronal+ensemble+control+of+prosthetic+devices+by+a+human+with+tetraplegia.&amp;publication_year=2006&amp;journal=Nature&amp;pages=164-171&amp;doi=10.1038%2Fnature04970&amp;pmid=16838014" target="_blank">Google Scholar</a></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">34.</div><div id="core-r34" class="citations"><div class="citation"><div class="citation-content">Watanabe S, Delcroix M, Metze F, Hershey JR, eds. <em>New era for robust speech recognition: exploiting deep learning</em>. Berlin: Springer-Verlag, 2017.</div><div class="external-links"><div class="to-citation__wrapper"><a class="to-citation" href="#body-ref-r34"><i aria-hidden="true" class="icon-return"></i><span>Go to Citation</span></a></div><div class="core-xlink-crossref"><a href="https://doi.org/10.1007/978-3-319-64680-0" target="_blank">Crossref</a></div><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=New+era+for+robust+speech+recognition%3A+exploiting+deep+learning&amp;publication_year=2017&amp;doi=10.1007%2F978-3-319-64680-0" target="_blank">Google Scholar</a></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">35.</div><div id="core-r35" class="citations"><div class="citation"><div class="citation-content">Wolpaw JR, Bedlack RS, Reda DJ, et al. Independent home use of a brain–computer interface by people with amyotrophic lateral sclerosis. <em>Neurology</em> 2018;91(3):e258-e267.</div><div class="external-links"><div class="to-citation__wrapper"><button aria-controls="to-citation__accordion-r35-core" aria-expanded="false" aria-label="Toggle citations menu" class="to-citation__toggle"><i aria-hidden="true" class="icon-plus"></i><span data-expand-title="Hide Citations" data-collapsed-title="Show Citations" class="accordion__toggle__title"></span></button></div><div class="core-xlink-crossref"><a href="https://doi.org/10.1212/WNL.0000000000005812" target="_blank">Crossref</a></div><div class="core-xlink-pubmed"><a href="https://pubmed.ncbi.nlm.nih.gov/29950436/" target="_blank">PubMed</a></div><div class="core-xlink-isi"><a href="https://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2&amp;DestApp=WOS_CPL&amp;UsrCustomerID=5e3815c904498985e796fc91436abd9a&amp;SrcAuth=atyponcel&amp;SrcApp=literatum&amp;DestLinkType=FullRecord&amp;KeyUT=000440906800008" target="_blank">Web of Science</a></div><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=Independent+home+use+of+a+brain%E2%80%93computer+interface+by+people+with+amyotrophic+lateral+sclerosis.&amp;publication_year=2018&amp;journal=Neurology&amp;pages=e258-e267&amp;doi=10.1212%2FWNL.0000000000005812&amp;pmid=29950436" target="_blank">Google Scholar</a></div><div role="menu" aria-label="links" class="to-citation__accordion no-separator" id="to-citation__accordion-r35-core" style="display: none;"><ul role="none"><li role="none"><a class="to-citation" href="#body-ref-r35-1" role="menuitem"><i aria-hidden="true" class="icon-return"></i><span>a [...] before deployment with a user, </span></a></li><li role="none"><a class="to-citation" href="#body-ref-r36" role="menuitem"><i aria-hidden="true" class="icon-return"></i><span>b [...] of the interface for real-world use. </span></a></li></ul></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">36.</div><div id="core-r36" class="citations"><div class="citation"><div class="citation-content">Silversmith DB, Abiri R, Hardy NF, et al. Plug-and-play control of a brain–computer interface through neural map stabilization. <em>Nat Biotechnol</em> 2021;39:326-335.</div><div class="external-links"><div class="to-citation__wrapper"><a class="to-citation" href="#body-ref-r36"><i aria-hidden="true" class="icon-return"></i><span>Go to Citation</span></a></div><div class="core-xlink-crossref"><a href="https://doi.org/10.1038/s41587-020-0662-5" target="_blank">Crossref</a></div><div class="core-xlink-pubmed"><a href="https://pubmed.ncbi.nlm.nih.gov/32895549/" target="_blank">PubMed</a></div><div class="core-xlink-isi"><a href="https://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2&amp;DestApp=WOS_CPL&amp;UsrCustomerID=5e3815c904498985e796fc91436abd9a&amp;SrcAuth=atyponcel&amp;SrcApp=literatum&amp;DestLinkType=FullRecord&amp;KeyUT=000566877800003" target="_blank">Web of Science</a></div><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=Plug-and-play+control+of+a+brain%E2%80%93computer+interface+through+neural+map+stabilization.&amp;publication_year=2021&amp;journal=Nat+Biotechnol&amp;pages=326-335&amp;doi=10.1038%2Fs41587-020-0662-5&amp;pmid=32895549" target="_blank">Google Scholar</a></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">37.</div><div id="core-r37" class="citations"><div class="citation"><div class="citation-content">Chao ZC, Nagasaka Y, Fujii N. Long-term asynchronous decoding of arm motion using electrocorticographic signals in monkeys. <em>Front Neuroeng</em> 2010;3:3-3.</div><div class="external-links"><div class="to-citation__wrapper"><a class="to-citation" href="#body-ref-r39"><i aria-hidden="true" class="icon-return"></i><span>Go to Citation</span></a></div><div class="core-xlink-pubmed"><a href="https://pubmed.ncbi.nlm.nih.gov/20407639/" target="_blank">PubMed</a></div><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=Long-term+asynchronous+decoding+of+arm+motion+using+electrocorticographic+signals+in+monkeys.&amp;publication_year=2010&amp;journal=Front+Neuroeng&amp;pages=3-3&amp;pmid=20407639" target="_blank">Google Scholar</a></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">38.</div><div id="core-r38" class="citations"><div class="citation"><div class="citation-content">Rao VR, Leonard MK, Kleen JK, Lucas BA, Mirro EA, Chang EF. Chronic ambulatory electrocorticography from human speech cortex. <em>Neuroimage</em> 2017;153:273-282.</div><div class="external-links"><div class="to-citation__wrapper"><a class="to-citation" href="#body-ref-r39"><i aria-hidden="true" class="icon-return"></i><span>Go to Citation</span></a></div><div class="core-xlink-crossref"><a href="https://doi.org/10.1016/j.neuroimage.2017.04.008" target="_blank">Crossref</a></div><div class="core-xlink-pubmed"><a href="https://pubmed.ncbi.nlm.nih.gov/28396294/" target="_blank">PubMed</a></div><div class="core-xlink-isi"><a href="https://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2&amp;DestApp=WOS_CPL&amp;UsrCustomerID=5e3815c904498985e796fc91436abd9a&amp;SrcAuth=atyponcel&amp;SrcApp=literatum&amp;DestLinkType=FullRecord&amp;KeyUT=000403384500023" target="_blank">Web of Science</a></div><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=Chronic+ambulatory+electrocorticography+from+human+speech+cortex.&amp;publication_year=2017&amp;journal=Neuroimage&amp;pages=273-282&amp;doi=10.1016%2Fj.neuroimage.2017.04.008&amp;pmid=28396294" target="_blank">Google Scholar</a></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">39.</div><div id="core-r39" class="citations"><div class="citation"><div class="citation-content">Pels EGM, Aarnoutse EJ, Leinders S, et al. Stability of a chronic implanted brain–computer interface in late-stage amyotrophic lateral sclerosis. <em>Clin Neurophysiol</em> 2019;130:1798-1803.</div><div class="external-links"><div class="to-citation__wrapper"><a class="to-citation" href="#body-ref-r39"><i aria-hidden="true" class="icon-return"></i><span>Go to Citation</span></a></div><div class="core-xlink-crossref"><a href="https://doi.org/10.1016/j.clinph.2019.07.020" target="_blank">Crossref</a></div><div class="core-xlink-pubmed"><a href="https://pubmed.ncbi.nlm.nih.gov/31401488/" target="_blank">PubMed</a></div><div class="core-xlink-isi"><a href="https://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2&amp;DestApp=WOS_CPL&amp;UsrCustomerID=5e3815c904498985e796fc91436abd9a&amp;SrcAuth=atyponcel&amp;SrcApp=literatum&amp;DestLinkType=FullRecord&amp;KeyUT=000485832400008" target="_blank">Web of Science</a></div><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=Stability+of+a+chronic+implanted+brain%E2%80%93computer+interface+in+late-stage+amyotrophic+lateral+sclerosis.&amp;publication_year=2019&amp;journal=Clin+Neurophysiol&amp;pages=1798-1803&amp;doi=10.1016%2Fj.clinph.2019.07.020&amp;pmid=31401488" target="_blank">Google Scholar</a></div></div></div></div></div></div></div></div><aside data-core-aside="right-rail">



        
        <div id="DTM_Position_MedRectangle" class="ad">
 <!--emptycomment-->
</div>




        
        <div class="ng-page_layout-sidebarSpacing"></div>










    
    
        <div data-widget-def="relatedArticlesWidget" data-widget-id="8206d5cd-cb8c-4ff9-8c46-3d22e0dee215" data-location="recirc_curatedRelated_article">
        



        
        <div class="ng-related-articles"><h3 class="ng-subsection-title"><span class="ng-subsection-title_text">Related articles</span></h3><ul class="ng-related-articles_list"><li class="ng-related-articles_item"><div class="issue-item issue-item_sm"><div class="issue-item_meta"><ul class="issue-item_meta-list clearfix"><li class="issue-item_meta-item"><a href="/browse/nejm-article-type/editorial" class="issue-item_type">Editorial</a></li><li class="issue-item_meta-item"><span class="issue-item_date">Jul 14, 2021</span></li></ul></div><div class="issue-item_row"><div class="issue-item_left"><div class="issue-item_content clearfix"><h4 class="issue-item_title"><a href="/doi/full/10.1056/NEJMe2106392" data-interactiontype="article_recirculation_click" class="issue-item_title-link animation-underline">Freedom of Speech</a></h4><div class="issue-item_authors-and-text"><span class="issue-item_authors">L.R. Hochberg and S.S. Cash</span></div></div></div></div></div></li><li class="ng-related-articles_item"><div class="issue-item issue-item_sm"><div class="issue-item_meta"><ul class="issue-item_meta-list clearfix"><li class="issue-item_meta-item"><a href="/browse/nejm-article-type/correspondence" class="issue-item_type">Correspondence</a></li><li class="issue-item_meta-item"><span class="issue-item_date">Oct 13, 2021</span></li></ul></div><div class="issue-item_row"><div class="issue-item_left"><div class="issue-item_content clearfix"><h4 class="issue-item_title"><a href="/doi/full/10.1056/NEJMc2113384" data-interactiontype="article_recirculation_click" class="issue-item_title-link animation-underline">Decoding Speech from Cortical Surface Electrical Activity</a></h4><div class="issue-item_authors-and-text"></div></div></div></div></div></li></ul></div>

        </div>
    





        
        <div class="ng-page_layout-sidebarSpacing"></div>




        
        <div id="nejm_jobs" class="nejm_jobs"> <!-- top red rectangle --><div id="nejm-widget" class="nejm-widget" style="display: block;"><div class="nejm-widget_logo">	<a target="nejm-win" href="https://www.nejmcareercenter.org/?query=fjw">		<img alt="CareerCenter" src="https://apps1.nejmcareercenter.org/images/nejmCCID-JobsWidget.gif" width="140" height="36">	</a></div><div class="nejm-widget_cont"> <!-- content --><div class="nejm-widget_title">PHYSICIAN JOBS</div><div class="nejm-widget_date">June 10, 2025</div><div class="nejm-widget_item"><div><span> New York City, New York</span></div><div><span>Surgery, Cardiovascular / Thoracic</span></div><div><a target="nejm-job-win" onmouseover="jlho(this);" onmouseout="jlou(this);" href="https://www.nejmcareercenter.org/job/703423/advanced-coronary-and-minimally-invasive-robotic-cardiac-surgery-fellowship-lenox-hill-hospital/?query=fjwp&amp;rid=3059">Advanced Coronary and Minimally Invasive Robotic Cardiac Surgery Fellowship - Lenox Hill Hospital</a></div></div><div class="nejm-widget_item"><div><span> Salem, New Hampshire</span></div><div><span>Cardiology</span></div><div><a target="nejm-job-win" onmouseover="jlho(this);" onmouseout="jlou(this);" href="https://www.nejmcareercenter.org/job/881815/non-invasive-cardiologist-merrimack-valley-and-southern-nh/?query=fjwp&amp;rid=428606">Non-Invasive Cardiologist, Merrimack Valley and Southern NH</a></div></div><div class="nejm-widget_item"><div><span> Texas</span></div><div><span>Primary Care</span></div><div><a target="nejm-job-win" onmouseover="jlho(this);" onmouseout="jlou(this);" href="https://www.nejmcareercenter.org/job/888998/outpatient-primary-care-physician-wellmed-at-paisano-el-paso-tx/?query=fjwf&amp;rid=220874">Outpatient Primary Care Physician - WellMed at Paisano - El Paso, TX</a></div></div><div class="nejm-widget_item"><div><span> North Carolina</span></div><div><span>Radiology</span></div><div><a target="nejm-job-win" onmouseover="jlho(this);" onmouseout="jlou(this);" href="https://www.nejmcareercenter.org/job/880523/msk-radiology-in-the-research-triangle-north-carolina/?query=fjwf&amp;rid=5127">MSK Radiology in the Research Triangle - North Carolina</a></div></div><div class="nejm-widget_item"><div><span> Coos Bay, Oregon</span></div><div><span>Cardiology</span></div><div><a target="nejm-job-win" onmouseover="jlho(this);" onmouseout="jlou(this);" href="https://www.nejmcareercenter.org/job/891362/general-cardiologist/?query=fjwf&amp;rid=626105">General Cardiologist</a></div></div><div class="nejm-widget_item"><div><span> East Providence, Rhode Island</span></div><div><span>Psychiatry</span></div><div><a target="nejm-job-win" onmouseover="jlho(this);" onmouseout="jlou(this);" href="https://www.nejmcareercenter.org/job/888310/adult-psychiatrist/?query=fjwf&amp;rid=377088">Adult Psychiatrist</a></div></div></div> <!-- content --> <!-- footer --></div> <!-- nejm-widget --></div><script src="https://apps1.nejmcareercenter.org/?width=300&amp;sp=all"></script>




        
        <div class="ng-page_layout-sidebarSpacing"></div>










    
    
        <div data-widget-def="literatumAd" data-widget-id="001e4aa7-b6fe-4b21-9d5b-5bde81227c67" id="ad-article-right-rail-300x250-1">
        



        
        



    
        <div class="pb-house-message adplaceholder exists">
            <a href="/action/clickThrough?id=128129&amp;url=https%3A%2F%2Fstore.nejm.org%2Fsignup%2Fnejm%2Fregister%2Falerts%3Fpromo%3DONFQSR51%26query%3Dcm_rr%26utm_source%3Dnejm%26utm_medium%3Dcm%26utm_campaign%3Dalerts23&amp;loc=%2Fdoi%2Ffull%2F10.1056%2FNEJMoa2027540&amp;pubId=41290624&amp;placeholderId=101337&amp;productId=1035"><img src="/sda/128129/rightRail--SpecialtyUpdates23-001.jpg" width="300" height="250"></a>
            
        </div>
    

    

    



        </div>
    





        
        <div class="ng-page_layout-sidebarSpacing"></div>




        
        <script src="https://widgets.nejm.org/onepub-widgets/loader/webcomponents-loader.js" async="" nonce="94d68cb4c580debe-GRU">
<script src="https://widgets.nejm.org/onepub-widgets/loader/polyfill-support.js"  nonce="94d68cb4c580debe-GRU"></script>
<script src="https://widgets.nejm.org/onepub-widgets/more-like-this.js" type="module" nonce="94d68cb4c580debe-GRU"></script>

<more-like-this class="onepub-widget" dataid="onepub-more-like-this" collections="catalyst-article, clinician-article, evidence-article, nejm-ai-article, nejm-article" headertitle="More Like This" maxitems="5"><!----><div class="more-like-this onepub-more-like-this_"><!--?lit$268271868$--><onepub-fonts><wc-fetch></wc-fetch><!--?lit$268271868$--><div class="mlt-wrapper"><div class="mlt-header-container"><div class="mlt-header-content-left"><div class="mlt-header-title-container"><span class="mlt-header-title">More Like This</span></div><!--?lit$268271868$--></div></div><div class="mlt-body"><!--?lit$268271868$--><!----><div class="mlt-article-container"><div class="mlt-article-container-header"><a data-location="recirc_Semantic" class="mlt-article-type nejm" href="https://www.nejm.org/browse/nejm-article-type/original-article" target="_self"><!--?lit$268271868$-->Original Article</a> <span class="mlt-article-site-label"><!--?lit$268271868$-->NEJM</span> <span class="mlt-article-pubdate"><!--?lit$268271868$-->Aug 15, 2024</span></div><div class="mlt-article-title"><a data-location="recirc_Semantic" href="https://www.nejm.org/doi/full/10.1056/NEJMoa2314132?query=recirc_Semantic" target="_self">An Accurate and Rapidly Calibrating Speech Neuroprosthesis</a></div><div class="mlt-article-authors"><!--?lit$268271868$-->N.S. Card and Others</div></div><!----><!----><div class="mlt-article-container"><div class="mlt-article-container-header"><a data-location="recirc_Semantic" class="mlt-article-type nejm" href="https://www.nejm.org/browse/nejm-article-type/original-article" target="_self"><!--?lit$268271868$-->Original Article</a> <span class="mlt-article-site-label"><!--?lit$268271868$-->NEJM</span> <span class="mlt-article-pubdate"><!--?lit$268271868$-->Aug 15, 2024</span></div><div class="mlt-article-title"><a data-location="recirc_Semantic" href="https://www.nejm.org/doi/full/10.1056/NEJMoa2314598?query=recirc_Semantic" target="_self">Brief Report: Longevity of a Brain–Computer Interface for Amyotrophic Lateral Sclerosis</a></div><div class="mlt-article-authors"><!--?lit$268271868$-->M.J. Vansteensel and Others</div></div><!----><!----><div class="mlt-article-container"><div class="mlt-article-container-header"><a data-location="recirc_Semantic" class="mlt-article-type nejm" href="https://www.nejm.org/browse/nejm-article-type/perspective" target="_self"><!--?lit$268271868$-->Perspective</a> <span class="mlt-article-site-label"><!--?lit$268271868$-->NEJM</span> <span class="mlt-article-pubdate"><!--?lit$268271868$-->Aug 15, 2024</span></div><div class="mlt-article-title"><a data-location="recirc_Semantic" href="https://www.nejm.org/doi/full/10.1056/NEJMp2407613?query=recirc_Semantic" target="_self">Intention to Treat: Restoring Lost Speech — ITT Episode 36</a></div><div class="mlt-article-authors"><!--?lit$268271868$--></div></div><!----><!----><div class="mlt-article-container"><div class="mlt-article-container-header"><a data-location="recirc_Semantic" class="mlt-article-type nejm" href="https://www.nejm.org/browse/nejm-article-type/editorial" target="_self"><!--?lit$268271868$-->Editorial</a> <span class="mlt-article-site-label"><!--?lit$268271868$-->NEJM</span> <span class="mlt-article-pubdate"><!--?lit$268271868$-->Aug 15, 2024</span></div><div class="mlt-article-title"><a data-location="recirc_Semantic" href="https://www.nejm.org/doi/full/10.1056/NEJMe2407363?query=recirc_Semantic" target="_self">Science behind the Study: Brain–Computer Interfaces for Restoring Communication</a></div><div class="mlt-article-authors"><!--?lit$268271868$-->E.F. Chang</div></div><!----><!----><div class="mlt-article-container"><div class="mlt-article-container-header"><a data-location="recirc_Semantic" class="mlt-article-type nejm" href="https://www.nejm.org/browse/nejm-article-type/points-of-view" target="_self"><!--?lit$268271868$-->Points of View</a> <span class="mlt-article-site-label"><!--?lit$268271868$-->NEJM</span> <span class="mlt-article-pubdate"><!--?lit$268271868$-->Dec 28, 2023</span></div><div class="mlt-article-title"><a data-location="recirc_Semantic" href="https://www.nejm.org/doi/full/10.1056/NEJMpv2311908?query=recirc_Semantic" target="_self">The Black Youth Hospital Crisis — A Call for Hate-Speech Protocols</a></div><div class="mlt-article-authors"><!--?lit$268271868$-->A.J. Calhoun</div></div><!----></div><div class="mlt-footer"></div></div></onepub-fonts><style>:host{display:block}@keyframes fadeIn{0%{opacity:0}100%{opacity:1}}.more-like-this{max-width:25rem}.more-like-this *{font-variant-numeric:lining-nums}.mlt-wrapper{animation:fadeIn 1s}.mlt-header-container{border-bottom:#4d4d4d solid .0625rem;border-top:#4d4d4d solid .125rem}.mlt-header-title{color:#1a1a1a;display:block;font-family:var(--sans-serif);font-size:1rem;font-weight:700;letter-spacing:.02rem;line-height:1.5rem;padding-bottom:.94rem;padding-top:.94rem;text-transform:uppercase}.mlt-header-description{color:#333;display:block;font-family:ff-scala-sans-pro;font-size:.75rem;letter-spacing:.05rem;margin-top:-.5rem;padding-bottom:1rem;text-transform:uppercase}.mlt-article-container{border-bottom:#e5e5e5 solid .0625rem;margin-top:1.38rem}.mlt-article-container-header{font-family:var(--sans-serif);font-size:.6875rem;letter-spacing:.04em;line-height:1.125rem;margin:0 0 1rem;text-transform:uppercase}.mlt-article-type{font-weight:700;line-height:1.25rem;letter-spacing:.04rem;text-decoration:none}.mlt-article-type:hover{text-decoration:underline}.nejm{color:#f30}.nejm-ai{color:#006197}.nejm-catalyst{color:#5708a6}.nejm-evidence{color:#69a323}.mlt-article-site-label::after,.mlt-article-type::after{border-right:1px solid #e5e5e5;content:'';display:inline;padding:.1875rem .375rem .125rem 0;margin:0 .375rem 0 0}.mlt-article-pubdate{color:#666;font-style:normal;font-weight:700;line-height:1.25rem;letter-spacing:.04em}.mlt-article-authors{color:#666;font-family:var(--sans-serif);font-size:1rem;font-style:normal;font-weight:400;letter-spacing:normal;line-height:1.5rem;margin-bottom:1.38rem}.mlt-article-site-label{color:#666;font-style:normal;font-weight:700;letter-spacing:.04em}.mlt-article-title{margin-bottom:.5rem}.mlt-article-title>a{background-image:linear-gradient(#f30,#f30);background-position:0 90%;background-repeat:no-repeat;background-size:0 0;color:#1a1a1a;font-family:var(--quadraat-web);font-size:1.25rem;font-style:normal;font-weight:700;letter-spacing:normal;line-height:1.8rem;margin:1.5rem 0 .35rem 0;text-decoration:none;transition:background .25s ease-in-out}.mlt-article-title>a:hover{background-position:0 98%;background-size:100% .125rem;text-decoration:none}.skeleton-card{box-shadow:0 0 4px 1px rgba(0,0,0,.1);margin:1rem 0;padding:1rem}</style></div></more-like-this>




        
        <div><div class="pb-dropzone" data-pb-dropzone="col-0" title="col-0"></div></div>










    
    
        <div data-widget-def="UX3HTMLWidget" data-widget-id="ad06db99-f228-4c92-9ad7-c4ae0fdbdbf1" id="bc-web-rec">
        



        
        <!-- BlueConic TEST empty HTML widget with DIV wrapper with id=bc-web-rec -->

        </div>
    

</aside></article><div data-extent="article-wrapper"><div class="core-container"></div><div class="after-credits"><div class="core-container"><a href="/doi/pdf/10.1056/NEJMoa2027540?download=true" id="downloadPdfUrl" data-doi="10.1056/NEJMoa2027540" data-behavior="trackDownloadEvent" data-interactiontype="article_tools_download_pdf" data-multimedia-type="Article PDF" data-multimedia-filename="nejmoa2027540.pdf"><span>Download PDF</span></a></div></div></div><script id="axel-publication-metadata" type="application/json">{"doi":"10.1056/NEJMoa2027540"}
</script><script type="text/javascript" data-ot-ignore="data-ot-ignore" defer="defer" src="https://static.addtoany.com/menu/page.js" class="optanon-category-C0004 ot-vscat-C0004"></script><div class="articles-nav"></div><template id="figure_nav_template"><nav><a href="#" title="Open in viewer" class="open-in-viewer"><i aria-hidden="true" class="icon-expand"></i></a></nav></template><template id="fv_panel_template" data-sharesocial="Share"><div class="fv__panel js--hidden"><div class="fv__panel__text"><div class="fv__panel__contentTitle"></div><div class="fv__panel__contentText"></div></div></div></template>
<template id="fv_directory_template" data-overlay="View figure"><div class="fv__directory"><div class="fv__header"><nav class="tab__nav"></nav><a href="#" title="Close figure viewer" class="fv__close"><i aria-hidden="true" class="icon-close"></i></a></div><div class="fv__content tab__content"></div></div></template><template id="fv_directory_tabItem_template" data-figures="Figures" data-others="Others" data-tables="Tables"><button role="tab" data-toggle="tab" class="tab__nav__item"></button></template>
<template id="fv_lightbox_template" data-sr-back="Go to figure location within the article" data-sr-closealt="Close" data-sr-download="Toggle download panel" data-sr-download-pptx="Download PPT" data-sr-info="Toggle information panel" data-sr-panel="Close panel" data-sr-share="Toggle share panel" data-sr-zoom="Zoom" data-text-close="Back to article" data-text-nav-figures="All figures" data-text-nav-others="All others" data-text-nav-tables="All tables" data-text-viewall="View all material" data-title-back="Back to article" data-title-closealt="Close" data-title-download="Download" data-title-download-pptx="Download PPT" data-title-info="Info" data-title-share="Share" data-title-zoom="Zoom"></template>
<template id="fv_toolbar_template"><div class="fv__toolbar__info"><strong class="fv__toolbar__contentTitle uppercase"></strong><p class="fv__toolbar__contentText"></p></div></template><template id="toCitationLink" data-citation="Citation" data-footnote="Footnote"><div class="to-citation__wrapper"><a class="to-citation"><i aria-hidden="true" class="icon-return"></i><span>Go to</span></a></div></template><template id="toCitationButton" data-citation="Citation" data-footnote="Footnote"><div class="to-citation__wrapper"><button class="to-citation"><i aria-hidden="true" class="icon-return"></i><span>Go to</span></button></div></template><template id="toCitationAccordion" data-collapse-citation="Hide Citations" data-expand-citation="Show Citations" data-collapse-footnote="Hide Footnotes" data-expand-footnote="Show Footnotes"><div class="to-citation__wrapper"><button aria-controls="aria-controls" aria-expanded="false" aria-label="Toggle citations menu" class="to-citation__toggle"><i aria-hidden="true" class="icon-plus"></i><span data-expand-title="data-expand-title" data-collapsed-title="data-collapsed-title" class="accordion__toggle__title"></span></button><div role="menu" aria-label="links" class="to-citation__accordion no-separator"><ul></ul></div></div></template><template id="toCitationAccordionItem"><li><a class="to-citation"><i aria-hidden="true" class="icon-return"></i><span></span></a></li></template><template id="citations_truncate_template"><div class="citations-truncation"><button data-label-expand="Show all references" data-label-collapse="Show fewer" data-label-remaining="references remaining" class="btn btn--secondary"><span>Show all references</span></button></div></template><template id="collateral_texts_template" data-references="References" data-figure="Go to Figure" data-media="Go to Media" data-more="More" data-original="Go to original" data-table="Go to Table" data-inviewer="Open in Viewer" data-allinviewer="Open all in viewer"><svg data-tags="copyright" viewBox="0 0 24 24"><path d="M12 20.016q3.281 0 5.648-2.368T20.016 12t-2.368-5.648T12 3.984 6.352 6.352 3.984 12t2.368 5.648T12 20.016zm0-18q4.125 0 7.055 2.93T21.985 12t-2.93 7.055T12 21.985t-7.055-2.93T2.015 12t2.93-7.055T12 2.015zm-.14 7.125q-1.876 0-1.876 2.718v.282q0 2.718 1.875 2.718.704 0 1.172-.398t.469-1.008h1.781q0 1.172-1.031 2.063-.984.843-2.39.843-1.876 0-2.86-1.125t-.984-3.093v-.282q0-1.921.937-3 1.125-1.265 2.906-1.265 1.547 0 2.438.89.984.985.984 2.297H13.5q0-.328-.14-.61-.235-.468-.329-.562-.469-.468-1.172-.468z"></path></svg><span>Request permissions</span><i aria-hidden="true" class="icon-open_in_new"></i></template><template id="collapsible_authors_template"><button aria-expanded="false" data-expandable="all" data-label-expand="Expand All" data-label-collapse="Collapse All" class="collateral-contributors-control"><span>Expand All</span></button></template>
<template id="collapsible_tables_collapse_template"><div class="collapsible-figure-btn__wrapper expanded"><button aria-expanded="true" class="btn collapsible-figure-btn btn--inverse"><i aria-hidden="true" class="icon-arrow-up"></i><span class="text-uppercase">Collapse</span></button></div></template>
<template id="collapsible_tables_expand_template"><div class="collapsible-figure-btn__wrapper collapsed"><button aria-expanded="false" class="btn collapsible-figure-btn btn--inverse"><i aria-hidden="true" class="icon-arrow-down"></i><span class="text-uppercase">Expand Table</span></button></div></template><template id="authorsAffiliationsLink"><a href="#tab-contributors" class="to-authors-affiliations">Authors Info &amp; Affiliations</a></template>

        <div role="navigation" aria-label="Sticky Navigation" class="st-header"><div class="st-header__content"><div class="st-header__item st-header__menu"></div><div class="st-header__current st-header__item"><div class="st-header__label">Now Reading:</div><div class="st-header__title">Neuroprosthesis for Decoding Speech in a Paralyzed Person with Anarthria</div></div><div class="st-header__share st-header__item"><div class="share-dropblock dropdown"><a id="sticky-header-dropBlock" href="#" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false" class="dropdown-toggle"><span title="" data-toggle="tooltip" data-trigger="hover" data-original-title="Share options"><span class="sr-only">Share</span><i aria-hidden="true" class="icon-share"></i></span></a><div aria-labelledby="sticky-header-dropBlock" data-location="share_tools_article" class="dropdown-menu"><ul class="rlist--inline a2a a2a_kit" style="line-height: 16px;"><li><a href="/#facebook" aria-label="Share on Facebook" data-id="article-share-facebook" rel="nofollow noopener" role="link" target="_blank" title="Share on Facebook" class="btn btn--facebook a2a_button_facebook" data-interactiontype="social"><i aria-hidden="true" class="icon-facebook"></i></a></li><li><a href="/#twitter" aria-label="Share on X (formerly Twitter)" data-id="article-share-twitter" rel="nofollow noopener" role="link" target="_blank" title="Share on X (formerly Twitter)" class="btn btn--twitter a2a_button_twitter" data-interactiontype="social"><i aria-hidden="true" class="icon-twitter"></i></a></li><li><a href="/#linkedin" aria-label="Share on LinkedIn" data-id="article-share-linkedin" rel="nofollow noopener" role="link" target="_blank" title="Share on LinkedIn" class="btn btn--linkedin a2a_button_linkedin" data-interactiontype="social"><i aria-hidden="true" class="icon-linkedin"></i></a></li><li><a href="/#email" aria-label="Share on email" data-id="article-share-email" rel="nofollow noopener" role="link" target="_blank" title="Share on email" class="btn btn--email a2a_button_email" data-interactiontype="content_email_click"><i aria-hidden="true" class="icon-mail"></i></a></li><li><a href="/#bluesky" aria-label="Share on Bluesky" data-id="article-share-bluesky" rel="nofollow noopener" role="link" target="_blank" title="Share on Bluesky" class="btn btn--bluesky a2a_button_bluesky" data-interactiontype="social"><i aria-hidden="true" class="icon-bluesky"></i></a></li></ul></div></div></div><div class="st-header__nav st-header__item"><div class="content-navigation"><a href="/doi/full/10.1056/NEJMoa2026141" aria-label="Previous article" aria-disabled="false" class="content-navigation__prev"><div aria-hidden="true" class="content-navigation__hint"><div class="content-navigation__hint__content"><h6>PREVIOUS ARTICLE</h6><div>Physical Rehabilitation for Older Patients Hospitalized for Heart Failure</div></div></div><i aria-hidden="true" class="icon-arrow-left"></i><span>Previous</span></a><a href="/doi/full/10.1056/NEJMoa2033122" aria-label="Next article" aria-disabled="false" class="content-navigation__next"><div aria-hidden="true" class="content-navigation__hint"><div class="content-navigation__hint__content"><h6>NEXT ARTICLE</h6><div>Ruxolitinib for Glucocorticoid-Refractory Chronic Graft-versus-Host Disease</div></div></div><span>Next</span><i aria-hidden="true" class="icon-arrow-right"></i></a></div></div></div><div class="st-header__track"><div id="progress-tracker" class="st-header__tracker" style="width: 0px;"></div></div></div><div class="fv figureViewer js--has-focus-mode"><div class="fv__directory" data-core-tabs="default" style="display: flex;"><div class="fv__header"><nav class="tab__nav" role="tablist"><button role="tab" data-toggle="tab" class="tab__nav__item active" aria-controls="#tab-pane-figures" aria-selected="true">Figures</button><button role="tab" data-toggle="tab" class="tab__nav__item inactive" aria-controls="#tab-pane-tables" tabindex="-1" aria-selected="false" aria-disabled="true">Tables</button></nav><a href="#" title="Close figure viewer" class="fv__close"><i aria-hidden="true" class="icon-close"></i></a></div><div class="fv__content tab__content"><div class="tab__pane fv__list fv__list--figures" id="tab-pane-figures" aria-label="All figures" tabindex="0" role="tabpanel"><div class="fv__item"><a class="fv__open-item fv__item__view fv__fit" href="#fv-f0" data-type="figures" data-interactiontype="multimedia_click" data-multimedia-type="Figure" data-multimedia-filename="nejmoa2027540_f0.jpg"><img src="/cms/10.1056/NEJMoa2027540/asset/72b2e583-fb17-48c8-9cd1-62c7af874aa5/assets/images/large/nejmoa2027540_f0.jpg" height="3416" width="2640" aria-labelledby="f0" loading="lazy"><span class="fv__fit--overlay"><span>View figure</span></span></a><div class="fv__item__title"></div><div class="fv__item__description"><figcaption>Download a PDF of the <a href="#ap0">Research Summary</a>.</figcaption></div></div><div class="fv__item"><a class="fv__open-item fv__item__view fv__fit" href="#fv-f1" data-type="figures" data-interactiontype="multimedia_click" data-multimedia-type="Figure" data-multimedia-filename="nejmoa2027540_f1.jpg"><img src="/cms/10.1056/NEJMoa2027540/asset/40605166-4f5e-447f-bf37-ab63f494c50e/assets/images/large/nejmoa2027540_f1.jpg" height="3341" width="2640" aria-labelledby="f1" loading="lazy"><span class="fv__fit--overlay"><span>View figure</span></span></a><div class="fv__item__title">Figure 1</div><div class="fv__item__description"><figcaption><div class="caption">Schematic Overview of the Direct Speech Brain–Computer Interface.</div><div class="notes"><div role="doc-footnote">Shown is how neural activity acquired from an investigational electrocorticography electrode array implanted in a clinical study participant with severe paralysis is used to directly decode words and sentences in real time. In a conversational demonstration, the participant is visually prompted with a statement or question (A) and is instructed to attempt to respond using words from a predefined vocabulary set of 50 words. Simultaneously, cortical signals are acquired from the surface of the brain through the electrode array (B) and processed in real time (C). The processed neural signals are analyzed sample by sample with the use of a speech-detection model to detect the participant’s attempts to speak (D). A classifier computes word probabilities (across the 50 possible words) from each detected window of relevant neural activity (E). A Viterbi decoding algorithm uses these probabilities in conjunction with word-sequence probabilities from a separately trained natural-language model to decode the most likely sentence given the neural activity data (F). The predicted sentence, which is updated each time a word is decoded, is displayed as feedback to the participant (G). Before real-time decoding, the models were trained with data collected as the participant attempted to say individual words from the 50-word set as part of a separate task (not depicted). This conversational demonstration is a variant of the standard sentence task used in this work, in that it allows the participant to compose his own unique responses to the prompts.</div></div></figcaption></div></div><div class="fv__item"><a class="fv__open-item fv__item__view fv__fit" href="#fv-f2" data-type="figures" data-interactiontype="multimedia_click" data-multimedia-type="Figure" data-multimedia-filename="nejmoa2027540_f2.jpg"><img src="/cms/10.1056/NEJMoa2027540/asset/c5a8b906-d545-42ff-a7ee-d8700e98a7e1/assets/images/large/nejmoa2027540_f2.jpg" height="3438" width="2629" aria-labelledby="f2" loading="lazy"><span class="fv__fit--overlay"><span>View figure</span></span></a><div class="fv__item__title">Figure 2</div><div class="fv__item__description"><figcaption><div class="caption">Decoding a Variety of Sentences in Real Time through Neural Signal Processing and Language Modeling.</div><div class="notes"><div role="doc-footnote">Panel A shows the word error rates, the numbers of words decoded per minute, and the decoded sentence lengths. The top plot shows the median word error rate (defined as the number of word errors made by the decoder divided by the number of words in the target sentence, with a lower rate indicating better performance) derived from the word sequences decoded from the participant’s cortical activity during the performance of the sentence task. Data points represent sentence blocks (each block comprises 10 trials); the median rate, as indicated by the horizontal line within a box, is shown across 15 sentence blocks. The upper and lower sides of the box represent the interquartile range, and the 𝙸 bars 1.5 times the interquartile range. Chance performance was measured by computing the word error rate on sentences randomly generated from the natural-language model. The middle plot shows the median number of words decoded per minute, as derived across all 150 trials (each data point represents a trial). The rates are shown for the analysis that included all words that were correctly or incorrectly decoded with the natural-language model and for the analysis that included only correctly decoded words. Each violin distribution was created with the use of kernel density estimation based on Scott’s rule for computing the estimator bandwidth; the thick horizontal lines represent the median number of words decoded per minute, and the thinner horizontal lines the range (with the exclusion of outliers that were more than 4 standard deviations below or above the mean, which was the case for one trial). In the bottom chart, the decoded sentence lengths show whether the number of detected words was equal to the number of words in the target sentence in each of the 150 trials. Panel B shows the number of word errors in the sentences decoded with or without the natural-language model across all trials and all 50 sentence targets. Each small vertical dash represents the number of word errors in a single trial (there are 3 trials per target sentence; marks for identical error counts are staggered horizontally for visualization purposes). Each dot represents the mean number of errors for that target sentence across the 3 trials. The histogram at the bottom shows the error counts across all 150 trials. Panel C shows seven target sentence examples along with the corresponding sentences decoded with and without the natural-language model. Correctly decoded words are shown in black and incorrect words in red.</div></div></figcaption></div></div><div class="fv__item"><a class="fv__open-item fv__item__view fv__fit" href="#fv-f3" data-type="figures" data-interactiontype="multimedia_click" data-multimedia-type="Figure" data-multimedia-filename="nejmoa2027540_f3.jpg"><img src="/cms/10.1056/NEJMoa2027540/asset/68f0e6d1-b465-47d5-b6fc-47ee4ea610e9/assets/images/large/nejmoa2027540_f3.jpg" height="3438" width="2629" aria-labelledby="f3" loading="lazy"><span class="fv__fit--overlay"><span>View figure</span></span></a><div class="fv__item__title">Figure 3</div><div class="fv__item__description"><figcaption><div class="caption">Distinct Neural Activity Patterns during Word-Production Attempts.</div><div class="notes"><div role="doc-footnote">Panel A shows the participant’s brain reconstruction overlaid with the locations of the implanted electrodes and their contributions to the speech-detection and word-classification models. Plotted electrode size (area) and opacity are scaled by relative contribution (important electrodes appear larger and more opaque than other electrodes). Each set of contributions is normalized to sum to 1. For anatomical reference, the precentral gyrus is highlighted in light green. Panel B shows word confusion values computed with the use of the isolated-word data. For each target word (each row), the confusion value measures how often the word classifier predicted (regardless of whether the prediction was correct) each of the 50 possible words (each column) while the participant was attempting to say that target word. The confusion value is computed as a percentage relative to the total number of isolated-word trials for each target word, with the values in each row summing to 100%. Values along the diagonal correspond to correct classifications, and off-diagonal values correspond to incorrect classifications. The natural-language model was not used in this analysis.</div></div></figcaption></div></div><div class="fv__item"><a class="fv__open-item fv__item__view fv__fit" href="#fv-f4" data-type="figures" data-interactiontype="multimedia_click" data-multimedia-type="Figure" data-multimedia-filename="nejmoa2027540_f4.jpg"><img src="/cms/10.1056/NEJMoa2027540/asset/886e2498-6fe3-44f0-8e25-3fb0878aae38/assets/images/large/nejmoa2027540_f4.jpg" height="1390" width="2231" aria-labelledby="f4" loading="lazy"><span class="fv__fit--overlay"><span>View figure</span></span></a><div class="fv__item__title">Figure 4</div><div class="fv__item__description"><figcaption><div class="caption">Signal Stability and Long-Term Accumulation of Training Data to Improve Decoder Performance.</div><div class="notes"><div role="doc-footnote">Each bar depicts the mean classification accuracy (the percentage of trials in which the target word was correctly predicted) from isolated-word data sampled from the final weeks of the study period (weeks 79 through 81) after speech-detection and word-classification models were trained on different samples of the isolated-word data from various week ranges. Each result was computed with the use of a 10-fold cross-validation evaluation approach. In this approach, the available data were partitioned into 10 equally sized, nonoverlapping subsets. In the first cross-validation “fold,” one of these data subsets is used as the testing set, and the remaining 9 are used for model training. This was repeated 9 more times until each subset was used for testing (after training on the other subsets). This approach ensures that models were never evaluated on the data used during training (Sections S6 and S14). 𝙸 bars indicate the 95% confidence interval of the mean, each computed across the 10 cross-validation folds. The data quantities specify the average amount of data used to train the word-classification models across cross-validation folds. Week 0 denotes the first week during which data for this study was collected, which occurred 9 weeks after surgical implantation of the study device. Accuracy of chance performance was calculated as 1 divided by the number of possible words and is indicated by a horizontal dashed line.</div></div></figcaption></div></div></div><div class="tab__pane fv__list fv__list--tables" id="tab-pane-tables" aria-label="All tables" tabindex="-1" role="tabpanel"></div></div></div></div><div class="references-pop-up fade" aria-hidden="true"><div class="references-pop-up__heading text-dark d-flex align-items-center"><div class="references-pop-up__title flex-grow-1">Reference <span class="references-pop-up__heading-number">1</span></div><a class="references-pop-up__close text-dark" href="#" title="close pop-up" tabindex="-1" aria-hidden="true"><i class="icon-close" aria-hidden="true"></i></a></div><div class="references-pop-up__items citations to-citation__accordion external-links"></div></div></main>
    

</div>

                    
                        



        
        <div class="ng-page_layout ng-page_layout-fullWidth"><div class="container-fluid"><div class="row"><div class="col-12">



        
        




        
        <div class="ng-page_layout-contentSpacing"></div>










    
    
        <div data-widget-def="oneSearchMultiSearch" data-widget-id="778b3ad8-1a8d-43d8-8196-63b03df4a138" data-location="recirc_inIssue_bottom_article">
        



        
        <div class="os-ms os-ms-more-from-issue"><h3 class="ng-subsection-title"><a href="/toc/nejm/385/3" class="ng-subsection-title_link animation-icon-shift"><span class="ng-subsection-title_text">More from Vol. 385 No. 3</span><span class="ng-subsection-title_icon"><span class="icon-component "><svg aria-hidden="true" style=""><use xlink:href="/specs/products/mms-nextgen/mms/releasedAssets/icons/icons-3acb348e68a3edd0c676698e8d598c68.spritemap.svg#arrows-longArrowRight"></use></svg></span></span></a></h3><ul class="os-ms-more-from-issue_list"><li class="os-ms-more-from-issue_item"><div class="issue-item issue-item_sm"><div class="issue-item_meta"><ul class="issue-item_meta-list clearfix"><li class="issue-item_meta-item"><a href="/browse/nejm-article-type/original-article" class="issue-item_type">Original Article</a></li><li class="issue-item_meta-item"><span class="issue-item_date">Jul 15, 2021</span></li><li class="issue-item_meta-item"><span class="issue-item_free">FREE</span></li></ul></div><div class="issue-item_row"><div class="issue-item_left"><div class="issue-item_content clearfix"><h4 class="issue-item_title"><a href="/doi/full/10.1056/NEJMoa2107456" data-interactiontype="article_recirculation_click" class="issue-item_title-link animation-underline">Safety, Immunogenicity, and Efficacy of the BNT162b2 Covid-19 Vaccine in Adolescents</a></h4><div class="issue-item_authors-and-text"><span class="issue-item_authors">R.W. Frenck, Jr., and Others</span></div></div></div></div></div></li><li class="os-ms-more-from-issue_item"><div class="issue-item issue-item_sm"><div class="issue-item_meta"><ul class="issue-item_meta-list clearfix"><li class="issue-item_meta-item"><a href="/browse/nejm-article-type/original-article" class="issue-item_type">Original Article</a></li><li class="issue-item_meta-item"><span class="issue-item_date">Jul 15, 2021</span></li><li data-toggle="tooltip" data-original-title="Video" class="issue-item_meta-item"><span role="img" aria-label="Video" tabindex="0" class="issue-item_video"><span class="icon-component "><svg aria-hidden="true" style=""><use xlink:href="/specs/products/mms-nextgen/mms/releasedAssets/icons/icons-3acb348e68a3edd0c676698e8d598c68.spritemap.svg#tooltip-video"></use></svg></span></span></li><li class="issue-item_meta-item"><span class="issue-item_free">FREE</span></li></ul></div><div class="issue-item_row"><div class="issue-item_left"><div class="issue-item_content clearfix"><h4 class="issue-item_title"><a href="/doi/full/10.1056/NEJMoa2026141" data-interactiontype="article_recirculation_click" class="issue-item_title-link animation-underline">Physical Rehabilitation for Older Patients Hospitalized for Heart Failure</a></h4><div class="issue-item_authors-and-text"><span class="issue-item_authors">D.W. Kitzman and Others</span></div></div></div></div></div></li><li class="os-ms-more-from-issue_item"><div class="issue-item issue-item_sm"><div class="issue-item_meta"><ul class="issue-item_meta-list clearfix"><li class="issue-item_meta-item"><a href="/browse/nejm-article-type/original-article" class="issue-item_type">Original Article</a></li><li class="issue-item_meta-item"><span class="issue-item_date">Jul 15, 2021</span></li><li data-toggle="tooltip" data-original-title="Visual Abstract" class="issue-item_meta-item"><span role="img" aria-label="Visual Abstract" tabindex="0" class="issue-item_visualAbstract"><span class="icon-component "><svg aria-hidden="true" style=""><use xlink:href="/specs/products/mms-nextgen/mms/releasedAssets/icons/icons-3acb348e68a3edd0c676698e8d598c68.spritemap.svg#tooltip-visual"></use></svg></span></span></li><li class="issue-item_meta-item"><span class="issue-item_free">FREE</span></li></ul></div><div class="issue-item_row"><div class="issue-item_left"><div class="issue-item_content clearfix"><h4 class="issue-item_title"><a href="/doi/full/10.1056/NEJMoa2033122" data-interactiontype="article_recirculation_click" class="issue-item_title-link animation-underline">Ruxolitinib for Glucocorticoid-Refractory Chronic Graft-versus-Host Disease</a></h4><div class="issue-item_authors-and-text"><span class="issue-item_authors">R. Zeiser and Others</span></div></div></div></div></div></li></ul></div>

        </div>
    

</div></div></div></div>

                    
                        



        
        <div class="ng-page_layout-bottomAd"><div class="container-fluid"><div class="row"><div class="col-12">









    
    
        <div data-widget-def="literatumAd" data-widget-id="7e022d0d-4a48-44a7-af66-033cf5c13eb8" id="ad-article-bottom-FULLx320-1">
        



        
        



    
        <div class="pb-house-message adplaceholder exists">
            <!-- START: Circulation Footer 3 -->
<aside class="g-cta-subscribe">
	<style>
.bads_footer-banner24-ONJQNRF1{background:url(/pb-assets/contextual_messaging/footer-yel-background-2x-1513629627453.jpg) center center no-repeat;padding:20px;display:block;margin:0;min-height:inherit;background-size:cover;text-decoration:none!important;color:#1a1a1a;text-align:left}.bads_footer-banner24-ONJQNRF1 .g-cta-subscribe__title{font-size:42px;line-height:44px;letter-spacing:.2px;margin:0 0 20px;font-family:ff-quadraat-web-pro,sans-serif;font-weight:600}.bads_footer-banner24-ONJQNRF1-inner{max-width:1300px;margin:0 auto}.bads_footer-banner24-ONJQNRF1-inner .g-cta-subscribe__actions .a-btn{width:130px;padding-left:12px}.bads_footer-banner24-ONJQNRF1-inner .g-cta-subscribe__login{position:static;color:#000;font-size:18px;line-height:27px;border:0}.bads_footer-banner24-ONJQNRF1-inner .g-cta-subscribe__actions{margin:20px 0 20px 0;list-style-type:none;padding:0}.bads_footer-banner24-ONJQNRF1-inner .g-cta-subscribe__login a{color:#0a68ad}.bads_clearfix:after{visibility:hidden;display:block;font-size:0;content:" ";clear:both;height:0}.bads_clearfix{display:block}.bads_footer-banner24-ONJQNRF1-inner .bads_subs-btn{float:left;width:50%;padding:30px 0}.bads_footer-banner24-ONJQNRF1-inner .bads_device-img{float:left;padding-left:30px;width:50%}.bads_footer-banner24-ONJQNRF1 .bads_device-img>img{display:block;max-width:100%;height:auto}.bads_footer-banner24-ONJQNRF1 .bads_h5{font-size:18px;text-transform:uppercase;line-height:24px;font-weight:600;margin:-15px 0 0;letter-spacing:.2px}@media only screen and (max-width:480px){.bads_footer-banner24-ONJQNRF1-inner .bads_device-img,.bads_footer-banner24-ONJQNRF1-inner .bads_subs-btn{width:100%;float:none}.bads_footer-banner24-ONJQNRF1-inner .bads_device-img{padding-left:0}.bads_footer-banner24-ONJQNRF1 .g-cta-subscribe__title{font-size:20px;line-height:27px;margin-bottom:10px}.bads_footer-banner24-ONJQNRF1-inner .bads_subs-btn{padding-top:0;padding-bottom:0}.bads_footer-banner24-ONJQNRF1{height:auto}.bads_footer-banner24-ONJQNRF1-inner .g-cta-subscribe__actions{margin:0 0 12px;list-style-type:none}.bads_footer-banner24-ONJQNRF1-inner .g-cta-subscribe__login{line-height:25px;font-size:15px;margin-bottom:10px}.bads_footer-banner24-ONJQNRF1 .bads_device-img{width:280px!important;margin:0 auto}.bads_footer-banner24-ONJQNRF1 .bads_h5{margin:0 0 3px;font-size:14px}}@media only screen and (min-width:480px) and (max-width:1024px){.bads_footer-banner24-ONJQNRF1 .g-cta-subscribe__title{font-size:20px;line-height:30px;margin-bottom:15px}.bads_footer-banner24-ONJQNRF1-inner .bads_subs-btn{padding:0}.bads_footer-banner24-ONJQNRF1-inner .g-cta-subscribe__login{font-size:14px}.bads_footer-banner24-ONJQNRF1 .bads_h5{font-size:13px;margin-top:0}}@media only screen and (min-width:1025px) and (max-width:1200px){.bads_footer-banner24-ONJQNRF1-inner .bads_subs-btn{padding:10px 0}.bads_footer-banner24-ONJQNRF1 .bads_h5{margin:0 0 5px}}@media only screen and (min-width:1401px){.bads_footer-banner24-ONJQNRF1 .bads_device-img>img{float:right}}
	</style>
	<div class="bads_footer-banner24-ONJQNRF1">
	  <div class="bads_footer-banner24-ONJQNRF1-inner bads_clearfix">
		 <div class="bads_subs-btn">
			<p class="g-cta-subscribe__title">Tap into groundbreaking research and clinically relevant insights</p>
			<ul class="g-cta-subscribe__actions">
				<li class="g-cta-subscribe__actions-primary">
				  <a href="/action/clickThrough?id=127716&amp;url=%2Faction%2FstoreProxy%3Faction%3Dsubscribe%26url%3Dhttps%253A%252F%252Fwww.nejm.org%252Fdoi%252Ffull%252F10.1056%252FNEJMoa2027540%26promo%3DONFQNRF1&amp;loc=%2Fdoi%2Ffull%2F10.1056%2FNEJMoa2027540&amp;pubId=41290624&amp;placeholderId=101336&amp;productId=1035" class="ng-btn_primary ng-btn_iconRight"><span class="ng-btn_text">Subscribe </span><span class="icon-component"><svg aria-hidden="true"><use xlink:href="/specs/products/mms-nextgen/mms/releasedAssets/icons/icons.spritemap.svg#arrows-longArrowRight"></use></svg></span></a>
				</li>
			</ul>
			<p class="g-cta-subscribe__login">Already a subscriber? <a href="/action/clickThrough?id=127716&amp;url=%2Faction%2FstoreProxy%3Faction%3Dactivate%26url%3Dhttps%253A%252F%252Fwww.nejm.org%252Fdoi%252Ffull%252F10.1056%252FNEJMoa2027540%26promo%3DONFQANR4&amp;loc=%2Fdoi%2Ffull%2F10.1056%2FNEJMoa2027540&amp;pubId=41290624&amp;placeholderId=101336&amp;productId=1035">Activate</a> your online access.</p>
		 </div>

		<div class="bads_device-img">
		   <img src="/sda/127716/footer-devices-2x.png" alt="Devices">
		</div>
	   </div>
	</div>
</aside>
<!--/END: Circulation Footer 3 -->
            
        </div>
    

    

    



        </div>
    

</div></div></div></div>

                    
                        



        
        <footer class="ng-footer footer__top" style="position: relative;"><div data-location="footer" class="ng-footer_columns"><div class="container-fluid"><div class="row"><div class="col-lg-4 col-md-6 col-sm-12 ng-footer_column"><div class="row"><div class="col-6 ng-footer_column-nested">



        
        <h4 class="ng-footer_column-title">ARTICLE CATEGORIES</h4>
<ul class="ng-footer_column-list">
    <li class="ng-footer_column-list-item">
        <a href="/browse/nejm-article-category/research" class="ng-footer_column-link animation-underline"><span class="ng-footer_column-link-text">Research</span></a></li>
    <li class="ng-footer_column-list-item"><a href="/browse/nejm-article-category/review" class="ng-footer_column-link animation-underline"><span class="ng-footer_column-link-text">Reviews</span></a></li>
    <li class="ng-footer_column-list-item"><a href="/browse/nejm-article-category/clinical-cases" class="ng-footer_column-link animation-underline"><span class="ng-footer_column-link-text">Clinical Cases</span></a></li>
    <li class="ng-footer_column-list-item"><a href="/browse/nejm-article-category/perspective" class="ng-footer_column-link animation-underline"><span class="ng-footer_column-link-text">Perspective</span></a></li>
    <li class="ng-footer_column-list-item"><a href="/browse/nejm-article-category/commentary" class="ng-footer_column-link animation-underline"><span class="ng-footer_column-link-text">Commentary</span></a></li>
    <li class="ng-footer_column-list-item"><a href="/browse/nejm-article-category/other" class="ng-footer_column-link animation-underline"><span class="ng-footer_column-link-text">Other</span></a></li>
    <li class="ng-footer_column-list-item"><a href="/medical-article-index" class="ng-footer_column-link animation-underline"><span class="ng-footer_column-link-text">Browse all Articles</span></a></li>
    <li class="ng-footer_column-list-item"><a href="/toc/nejm/current" class="ng-footer_column-link animation-underline"><span class="ng-footer_column-link-text">Current Issue</span></a></li>
    <li class="ng-footer_column-list-item"><a href="/loi/nejm" class="ng-footer_column-link animation-underline"><span class="ng-footer_column-link-text">Issue Index</span></a></li>
</ul>
</div><div class="col-6 ng-footer_column-nested">



        
        <h4 class="ng-footer_column-title">RESOURCES</h4>
<ul class="ng-footer_column-list">
    <li class="ng-footer_column-list-item"><a href="/author-center/home" class="ng-footer_column-link animation-underline"><span class="ng-footer_column-link-text">Authors &amp; Reviewers</span></a></li>
    <li class="ng-footer_column-list-item"><a href="/author-center/home" class="ng-footer_column-link animation-underline"><span class="ng-footer_column-link-text">Submit a Manuscript</span></a></li>
    <li class="ng-footer_column-list-item"><a href="/about-nejm/products-and-services" class="ng-footer_column-link animation-underline"><span class="ng-footer_column-link-text">Subscribers</span></a></li>
    <li class="ng-footer_column-list-item"><a href="https://tools.ovid.com/ovidtools/nejm.html" target="_blank" rel="noopener" class="ng-footer_column-link animation-underline"><span class="ng-footer_column-link-text">Institutional Administrators</span></a></li>
    <li class="ng-footer_column-list-item"><a href="/media" class="ng-footer_column-link animation-underline"><span class="ng-footer_column-link-text">Media</span></a></li>
    <li class="ng-footer_column-list-item"><a href="/about-nejm/how-to-advertise" class="ng-footer_column-link animation-underline"><span class="ng-footer_column-link-text">Advertisers</span></a></li>
    <li class="ng-footer_column-list-item"><a href="/information-for-subscription-agents" class="ng-footer_column-link animation-underline"><span class="ng-footer_column-link-text">Agents</span></a></li>
    <li class="ng-footer_column-list-item"><a href="/about-nejm/permissions" class="ng-footer_column-link animation-underline"><span class="ng-footer_column-link-text">Permissions &amp; Licensing</span></a></li>
    <li class="ng-footer_column-list-item"><a href="/about-nejm/reprints" class="ng-footer_column-link animation-underline"><span class="ng-footer_column-link-text">Reprints</span></a></li>
    <li class="ng-footer_column-list-item"><a href="https://www.nejmcareercenter.org" target="_blank" rel="noopener" class="ng-footer_column-link animation-underline"><span class="ng-footer_column-link-text">NEJM CareerCenter</span></a>
    </li>
</ul>
</div></div></div><div class="col-lg-4 col-md-6 col-sm-12 ng-footer_column"><div class="row"><div class="col-6 ng-footer_column-nested">



        
        <h4 class="ng-footer_column-title" aria-label="About us">ABOUT US</h4>
<ul class="ng-footer_column-list">
    <li class="ng-footer_column-list-item"><a href="/about-nejm/about-nejm" class="ng-footer_column-link animation-underline"><span class="ng-footer_column-link-text">About NEJM</span></a></li>
    <li class="ng-footer_column-list-item"><a href="https://www.nejmgroup.org/" target="_blank" rel="noopener" class="ng-footer_column-link animation-underline"><span class="ng-footer_column-link-text">NEJM Group</span></a></li>
    <li class="ng-footer_column-list-item"><a href="/about-nejm/products-and-services" class="ng-footer_column-link animation-underline"><span class="ng-footer_column-link-text">Products &amp; Services</span></a></li>
    <li class="ng-footer_column-list-item"><a href="/about-nejm/editors-and-publishers" class="ng-footer_column-link animation-underline"><span class="ng-footer_column-link-text">Editors &amp; Publishers</span></a></li>
    <li class="ng-footer_column-list-item"><a href="/about-nejm/advertising-policies" class="ng-footer_column-link animation-underline"><span class="ng-footer_column-link-text">Advertising Policies</span></a></li>
    <li class="ng-footer_column-list-item"><a href="/contact-nejm" class="ng-footer_column-link animation-underline"><span class="ng-footer_column-link-text" aria-label="Contact us">Contact Us</span></a></li>
    <li class="ng-footer_column-list-item"><a href="/about-nejm/frequently-asked-questions?#Accessibility" class="ng-footer_column-link animation-underline"><span class="ng-footer_column-link-text">Accessibility</span></a></li>
    <li class="ng-footer_column-list-item"><a href="/about-nejm/frequently-asked-questions" class="ng-footer_column-link animation-underline"><span class="ng-footer_column-link-text">FAQs</span></a></li>
    <li class="ng-footer_column-list-item"><a href="/about-nejm/help" class="ng-footer_column-link animation-underline"><span class="ng-footer_column-link-text">Help</span></a></li>
    <li class="ng-footer_column-list-item"><a href="mailto:sitefeedback@nejm.org" class="ng-footer_column-link animation-underline"><span class="ng-footer_column-link-text">Site Feedback</span></a></li>
</ul>
</div><div class="col-6 ng-footer_column-nested">



        
        <h4 class="ng-footer_column-title">SUBSCRIPTIONS</h4>
<ul class="ng-footer_column-list">
    <li class="ng-footer_column-list-item"><a href="/action/storeProxy?action=subscribe&amp;promo=ONF4NRS3" class="ng-footer_column-link animation-underline ro-mode_disabled"><span class="ng-footer_column-link-text">Subscribe</span></a></li>
    <li class="ng-footer_column-list-item"><a href="/action/storeProxy?action=renew&amp;product=nejm&amp;promo=ONFLNRR3&amp;prc=ONFARN52" class="ng-footer_column-link animation-underline ro-mode_disabled"><span class="ng-footer_column-link-text">Renew</span></a></li>
    <li class="ng-footer_column-list-item"><a href="/action/storeProxy?action=activate&amp;promo=ONFLNAA1" class="ng-footer_column-link animation-underline ro-mode_disabled"><span class="ng-footer_column-link-text">Activate Subscription</span></a></li>
    <li class="ng-footer_column-list-item"><a href="/action/storeProxy?action=register&amp;promo=ONFLNRC4" class="ng-footer_column-link animation-underline ro-mode_disabled"><span class="ng-footer_column-link-text">Create Account</span></a></li>
    <li class="ng-footer_column-list-item"><a href="https://myaccount.nejm.org" class="ng-footer_column-link animation-underline"><span class="ng-footer_column-link-text">Manage Account</span></a></li>
    <li class="ng-footer_column-list-item"><a href="/action/storeProxy?action=paybill&amp;product=nejm&amp;promo=BNFLPBA1" class="ng-footer_column-link animation-underline ro-mode_disabled"><span class="ng-footer_column-link-text">Pay Bill</span></a></li>
    <li class="ng-footer_column-list-item"><a href="https://www.wolterskluwer.com/en/solutions/ovid/nejm-complete-collection" target="_blank" rel="noopener" class="ng-footer_column-link animation-underline"><span class="ng-footer_column-link-text">Institutional Sales</span></a></li>    
    <li class="ng-footer_column-list-item"><a href="https://myaccount.nejm.org/special-content" class="ng-footer_column-link animation-underline"><span class="ng-footer_column-link-text">Special Content</span></a></li>
</ul>
</div></div></div><div class="col-lg-4 col-md-12 ng-footer_column"><div class="row"><div class="col-6 ng-footer_column-nested">



        
        <h4 class="ng-footer_column-title">STAY CONNECTED</h4>
<ul class="ng-footer_column-list">
    <li class="ng-footer_column-list-item"><a href="https://myaccount.nejm.org/emails?section=NEJM" class="ng-footer_column-link animation-underline"><span class="ng-footer_column-link-text">Email Alerts</span></a></li>
    <li class="ng-footer_column-list-item"><a href="/action/storeProxy?action=register&amp;promo=ONFLNRC3" class="ng-footer_column-link animation-underline ro-mode_disabled"><span class="ng-footer_column-link-text">Create Account</span></a></li>
    <li class="ng-footer_column-list-item"><a href="/about-nejm/products-and-services" class="ng-footer_column-link animation-underline"><span class="ng-footer_column-link-text">Apps</span></a></li>
    <li class="ng-footer_column-list-item"><a href="https://www.nejmcareercenter.org" target="_blank" rel="noopener" class="ng-footer_column-link animation-underline"><span class="ng-footer_column-link-text">NEJM CareerCenter</span></a></li>
    <li class="ng-footer_column-list-item"><a href="/rss-feed/" class="ng-footer_column-link animation-underline"><span class="ng-footer_column-link-text">Podcasts</span></a></li>
    <li class="ng-footer_column-list-item"><a href="/rss-feed/" class="ng-footer_column-link animation-underline"><span class="ng-footer_column-link-text">RSS Feed</span></a></li>
    <li class="ng-footer_column-list-item"><a href="/about-nejm/institutional-access" class="ng-footer_column-link animation-underline"><span class="ng-footer_column-link-text">Remote Access</span></a></li>
</ul>
</div><div class="col-6 ng-footer_column-nested">



        
        <h4 class="ng-footer_column-title" aria-label="Follow us">FOLLOW US</h4>
<ul class="ng-footer_column-list">
<li class="ng-footer_column-list-item"><a href="https://www.facebook.com/TheNewEnglandJournalofMedicine" target="_blank" rel="noopener" class="ng-footer_column-link animation-underline"><span class="ng-footer_column-link-icon"><span class="icon-component"><svg aria-hidden="true"><use xlink:href="/specs/products/mms-nextgen/mms/releasedAssets/icons/icons.spritemap.svg#social-facebook"></use></svg></span></span><span class="ng-footer_column-link-text">Facebook</span></a></li>
<li class="ng-footer_column-list-item"><a href="https://twitter.com/nejm" target="_blank" rel="noopener" class="ng-footer_column-link animation-underline"><span class="ng-footer_column-link-icon"><span class="icon-component"><svg aria-hidden="true"><use xlink:href="/specs/products/mms-nextgen/mms/releasedAssets/icons/icons.spritemap.svg#social-twitter"></use></svg></span></span><span class="ng-footer_column-link-text">X (formerly Twitter)</span></a></li>
<li class="ng-footer_column-list-item"><a href="https://www.instagram.com/nejm/" target="_blank" rel="noopener" class="ng-footer_column-link animation-underline"><span class="ng-footer_column-link-icon"><span class="icon-component"><svg aria-hidden="true"><use xlink:href="/specs/products/mms-nextgen/mms/releasedAssets/icons/icons.spritemap.svg#social-instagram"></use></svg></span></span><span class="ng-footer_column-link-text">Instagram</span></a></li>
<li class="ng-footer_column-list-item"><a href="https://www.youtube.com/user/NEJMvideo" target="_blank" rel="noopener" class="ng-footer_column-link animation-underline"><span class="ng-footer_column-link-icon"><span class="icon-component"><svg aria-hidden="true"><use xlink:href="/specs/products/mms-nextgen/mms/releasedAssets/icons/icons.spritemap.svg#social-youtube"></use></svg></span></span><span class="ng-footer_column-link-text">Youtube</span></a></li>
<li class="ng-footer_column-list-item"><a href="https://www.linkedin.com/company/nejm-group" target="_blank" rel="noopener" class="ng-footer_column-link animation-underline"><span class="ng-footer_column-link-icon"><span class="icon-component"><svg aria-hidden="true"><use xlink:href="/specs/products/mms-nextgen/mms/releasedAssets/icons/icons.spritemap.svg#social-linkedin"></use></svg></span></span><span class="ng-footer_column-link-text">LinkedIn</span></a></li>
<li class="ng-footer_column-list-item"><a href="https://bsky.app/profile/nejm.org" target="_blank" rel="noopener" class="ng-footer_column-link animation-underline"><span class="ng-footer_column-link-icon"><span class="icon-component"><svg aria-hidden="true"><use xlink:href="/specs/products/mms-nextgen/mms/releasedAssets/icons/icons.spritemap.svg#social-bluesky"></use></svg></span></span><span class="ng-footer_column-link-text">Bluesky</span></a></li>
<li class="ng-footer_column-list-item"><a href="https://www.tiktok.com/@nejm.org" target="_blank" rel="noopener" class="ng-footer_column-link animation-underline"><span class="ng-footer_column-link-icon"><span class="icon-component"><svg aria-hidden="true"><use xlink:href="/specs/products/mms-nextgen/mms/releasedAssets/icons/icons.spritemap.svg#social-tiktok"></use></svg></span></span><span class="ng-footer_column-link-text">TikTok</span></a></li>
</ul>
</div></div></div></div></div></div><div data-location="footer" class="ng-footer_journals"><div class="container-fluid"><div class="row"><div class="col-12">



        
        <h4 class="ng-footer_journals-label">JOURNALS</h4>
<ul class="ng-footer_journals-list">
<li class="ng-footer_journals-item"><a href="https://www.nejm.org/" target="_blank" rel="noopener" class="ng-footer_journals-link">The New England Journal of Medicine</a></li>
<li class="ng-footer_journals-item"><a href="https://catalyst.nejm.org/" target="_blank" rel="noopener" class="ng-footer_journals-link">NEJM Catalyst Innovations in Care Delivery</a></li>
<li class="ng-footer_journals-item"><a href="https://evidence.nejm.org/" target="_blank" rel="noopener" class="ng-footer_journals-link">NEJM Evidence</a></li>
<li class="ng-footer_journals-item"><a href="https://ai.nejm.org/" target="_blank" rel="noopener" class="ng-footer_journals-link">NEJM AI</a></li>
</ul>
</div></div></div></div><div data-location="legal" class="ng-footer_bottom"><div class="container-fluid"><div class="row"><div class="col-lg-7 col-md-6 ng-footer_bottom-left">



        
        <p>Copyright © 2025 <a href="https://www.massmed.org/" target="_blank" rel="noopener" class="ng-footer_bottom-link"><b>Massachusetts Medical Society</b></a>. All rights reserved, including those for text and data mining, AI training, and similar technologies. Electronic ISSN 1533-4406. Print ISSN 0028-4793.The content of this site is intended for health care professionals.</p>
</div><div class="col-lg-5 col-md-6 ng-footer_bottom-right">



        
        <style>
  #teconsent a {
    color: #666;
    text-decoration: none;
  }
  #teconsent a:hover {
    color: #666;
    text-decoration: underline;
  }
</style>
<ul class="ng-footer_bottom-list">
<li class="ng-footer_bottom-list-item"><a href="https://www.nejmgroup.org/legal/copyright-information.htm" target="_blank" rel="noopener" class="ng-footer_bottom-link">Copyright</a></li>
<li class="ng-footer_bottom-list-item"><a href="https://www.nejmgroup.org/legal/terms-of-use.htm" target="_blank" rel="noopener" class="ng-footer_bottom-link">Terms</a></li>
<li class="ng-footer_bottom-list-item"><a href="https://www.nejmgroup.org/legal/privacy-policy.htm" target="_blank" rel="noopener" class="ng-footer_bottom-link">Privacy Policy</a></li>
<li class="ng-footer_bottom-list-item"><span id="teconsent" consent="undefined" aria-label="Open Cookie Preferences Modal" role="complementary"><a role="link" id="icon-id09848836104968608" tabindex="0" lang="en" aria-haspopup="dialog" aria-label="Cookie Preferences, opens a dedicated popup modal window" class="truste_cursor_pointer">Cookie Preferences</a></span></li>
</ul>
<a href="https://www.nejmgroup.org/" title="NEJM Group" target="_blank" rel="noopener" class="ng-footer_logo-link"><img src="/specs/products/mms-nextgen/mms/releasedAssets/images/other-images/logo_group.svg" alt="NEJM Group logo" class="ng-footer_logo" loading="lazy" width="103" height="40"></a>
</div></div></div></div><div data-show-after="400" class="back-to-top back-to-top--align-right  "><button data-snap="footer__top" class="back-to-top__action position-relative p-0 m-0 border-0 d-flex flex-column align-items-center justify-content-center"><svg viewBox="0 0 36 36" class="position-relative"><path d="M18 2.0845 a 15.9155 15.9155 0 0 1 0 31.831 a 15.9155 15.9155 0 0 1 0 -31.831" class="back-to-top__action__ring-bg"></path><path d="M18 2.0845 a 15.9155 15.9155 0 0 1 0 31.831 a 15.9155 15.9155 0 0 1 0 -31.831" stroke-dasharray="0, 100" class="back-to-top__action__ring"></path></svg><span class="back-to-top__action-icon position-absolute d-flex"><span class="icon-component "><svg aria-hidden="true" style=""><use xlink:href="/specs/products/mms-nextgen/mms/releasedAssets/icons/icons-3acb348e68a3edd0c676698e8d598c68.spritemap.svg#arrows-up"></use></svg></span></span><span class="sr-only">Back to top</span></button></div></footer>

                    
                        



        
        <!-- TrustArc: Banner -->
<div id="consent_blackbar"><style>  #consent_blackbar{    position:relative;    width:100%;    z-index: 999999;  }    #trustarc-banner-overlay {  background-color: rgb(0, 0, 0);   opacity: 0.3;   position: fixed;   z-index: 1000000;   width: 100%;  height: 100%;   top: 0px;   left: 0px;   overflow: hidden;}.truste-title {  /*font-family: "Source Sans Pro", sans-serif;  font-size: 23px;  font-style: normal;  font-stretch: normal;*/  color: #222;  margin-bottom: 20px;  text-align: center;/*  font-weight:bold;*/}.truste-footer {  margin: 0 auto;      }.truste-left {  margin: 0px 0px 15px 15px;/*font-family: "Source Sans Pro", sans-serif;  font-size: 14px;    */}.truste-banner { margin: 0 auto; }.truste-messageColumn {/*font-family: "Source Sans Pro", sans-serif;  font-size: 14px;*/  color: #666666;  margin: 0px;}#truste-consent-button, #truste-consent-required {    background-color: #FF1E00;    color: #F2F1F1;    padding: 5px 10px;    border: 1px solid #FF1E00;    border-radius: 0px;    cursor: pointer;    text-transform:uppercase;/*    font-family: "Source Sans Pro",sans-serif;    font-size: 15px;*/  }      #truste-show-consent {    background-color: #FF1E00;    color: #F2F1F1;    border: 1px solid #FF1E00;    padding: 5px 10px;    border-radius: 0px;    cursor: pointer;    text-transform:uppercase;/*    font-family: "Source Sans Pro",sans-serif;    font-size: 15px;*/  }div.truste-consent-track-class {  position: fixed;  z-index:9999999;   background: #666;   border: 1px solid #333;    /*padding: 10px 60px;*/    bottom:0px;    right:0px;    left:0px;    margin: 10px;}.truste-left {  margin: 0;}div.text-content {  display: flex;  flex-direction: column;  align-self: baseline;}#truste-consent-text {    /*font-family: "Source Sans Pro", sans-serif;    font-size: 16px;*/    color: #fff;    margin: 15px 0px;}.truste-footer {  padding-top: 15px;}#truste-consent-content {  margin: 0 auto;    padding: 0 10px;    max-width: 1366px;}.truste-consent-footer {  display: none;}.flex-container {  display: block;  align-items: center;  justify-content: space-between;}#truste-consent-buttons {  float: right;  margin: 10px 5px 10px 0px;}#truste-show-consent { background: #F30 !important;}#truste-consent-button, #truste-consent-required { background: #F30 !important; } /* MEDIA QUERIES */  @media screen and (max-width: 500px) {  #truste-consent-track {    padding: 5px 20px;  }  }@media screen and (max-width: 375px) {  .truste-buttonsColumn {    float: none;    margin: 0;  }  #truste-consent-button, #truste-consent-required, #truste-show-consent {    width: 100%;    margin-bottom: 5px;  }          #truste-consent-buttons {  float: none;  margin: 10px 0px 10px 0px;	}}</style><div id="truste-consent-track" style="display: block; opacity: 1;">  <div id="trustarc-banner-overlay"></div>  <div class="truste-consent-track-class">    <div id="truste-consent-content" class="truste-banner">        <div class="flex-container">          <div class="text-content">            <div id="truste-consent-text" class="truste-messageColumn">This site uses cookies and related technologies, as described in our privacy policy, for purposes that may include site operation, analytics, enhanced user experience, or advertising. You may choose to consent to our use of these technologies, or manage your own preferences.                       </div>          </div>          <div id="truste-consent-buttons" class="truste-buttonsColumn">            <button id="truste-show-consent" aria-haspopup="dialog">Manage Settings</button>      <button id="truste-consent-button">Accept</button>      <!-- <button id="truste-consent-required">Decline All</button> -->          </div>        </div>                <div style="clear:both;"></div>    </div>  </div></div><!--emptycomment--></div>
<!-- /TrustArc: Banner -->

                    
                        



        
        <link rel="stylesheet" href="https://cssjs.nejm.org/mmsWidgets.css"><script nonce="94d68cb4c580debe-GRU" type="text/javascript" src="https://cssjs.nejm.org/mmsWidgets.js"></script><script nonce="94d68cb4c580debe-GRU" type="text/javascript">var litSSO = {
    "ucid": null,
    "accessToken": null,
    "authState": null
};

var loginUri = '/action/doSsoLogin';
var logoutUri = '/action/doLogout';

displayAuthenticatedMessage();

mmsWidgets.init({
    clientId: 'qsra7g4d6jwdsgn3zbe6udp6r6278mr9',
    origin: 'NEJM',
    xdReceiver: 'http://www.nejm.org/pb-assets/sso/xd.html',
    isFullPageSignIn: isSignInPage(),
    debug: true,

    onReady: function (e) {
        console.log('<<<<<<<<<< client: received onReady event.');
        $("A.litSsoLogin").click(function (e) {
            if (!$(e.currentTarget).hasClass("noMd") || $(e.currentTarget).parents(".header_sm-login").length === 0) {
                mmsWidgets.signIn(e);
                return false;
            }
        });
        $("A.litSsoLogout").click(function (e) {
            mmsWidgets.signOut(e);
            return false;
        });
        $("A.litSsoCreate").click(function (e) {
            mmsWidgets.showRegModal(e);
            return false;
        });
        $("A.litSsoSubscribe").click(function (e) {
            if (!$(e.currentTarget).hasClass("noMd") || $(e.currentTarget).parents(".header_sm-login").length === 0)
                location.assign(e.currentTarget.href);
            return false;
        });
        if (window.doSSOLogin) {
            window.setTimeout(function () {
                mmsWidgets.signIn();
            }, 500);
        }
        ;
    },
    onLoginSuccess: function (e) {
        console.log('<<<<<<<<<< client: received onLoginSuccess event.' + JSON.stringify(e));

        const redirectUrl = getRedirectUri(window.location.search, location.href.replace(window.location.origin, ""));
        document.cookie = "skipSso=; expires=; path=/";
        if (!litSSO.ucid || e.ucid != litSSO.ucid || !litSSO.accessToken || e.accessToken != litSSO.accessToken) {
            location.assign(loginUri + "?ucid=" + e.profile.ucid
                + "&accessToken=" + e.accessToken
                + "&authState=" + e.authState
                + "&email=" + encodeURIComponent(e.profile.email)
                + "&givenNames=" + e.profile.givenName
                + "&surname=" + e.profile.familyName
                + "&redirectUri=" + redirectUrl
                + "&uccLastUpdatedDate=" + encodeURIComponent(e.profile.uccLastUpdatedDate)
                + "&rememberMe=" + e.rememberMe);
        }
    },
    onAuthStateReady: function (e) {
        console.log('<<<<<<<<<< client: received onAuthStateReady event.' + JSON.stringify(e))

        var isMmsSsoAuthenticated = (e.authState && e.authState !== "anonymous" && e.authState !== "lead" && e.ucid && e.accessToken) ? true : false;
        var isLitSsoAuthenticated = (litSSO.ucid && litSSO.accessToken && litSSO.authState) ? true : false;
        console.log('           isMmsSsoAuthenticated=' + isMmsSsoAuthenticated + ', isLitSsoAuthenticated=' + isLitSsoAuthenticated);

        if (isMmsSsoAuthenticated) {
            if (!isLitSsoAuthenticated || litSSO.ucid != e.ucid) {
                if (window.skipSso)
                    document.cookie = "skipSso=" + encodeURIComponent(e.ucid) + "; expires=; path=/";

                if (!window.skipSso && document.cookie.indexOf("skipSso=" + encodeURIComponent(e.ucid)) == -1) {
                    location.assign(loginUri + "?ucid=" + e.profile.ucid
                        + "&accessToken=" + e.accessToken
                        + "&authState=" + e.authState
                        + "&email=" + encodeURIComponent(e.profile.email)
                        + "&givenNames=" + e.profile.givenName
                        + "&surname=" + e.profile.familyName
                        + "&redirectUri=" + location.href.replace(window.location.origin, "")
                        + "&uccLastUpdatedDate=" + encodeURIComponent(e.profile.uccLastUpdatedDate)
                        + "&rememberMe=" + e.rememberMe);
                } else
                    console.log('**** client: Skip SSO ****');
            } else if (e.accessToken !== litSSO.accessToken)
                updateLitSession(e.ucid, e.accessToken);
        } else if (isLitSsoAuthenticated)
            location.assign(logoutUri + "?redirectUri=" + encodeURIComponent(location.href.replace(window.location.origin, "")));

        if (document.getElementById("ssoerr-ucid"))
            document.getElementById("ssoerr-ucid").innerHTML = e.ucid;

    },
    onRegistrationSuccess: function (e) {
        console.log('<<<<<<<<<< client: received onRegistrationSuccess event.' + JSON.stringify(e))
        document.cookie = "skipSso=; expires=; path=/";
        var uccLastUpdatedDate = '1812-01-01 00:00:00.1 +0000';
        location.assign(loginUri + "?ucid=" + e.profile.ucid
            + "&accessToken=" + e.accessToken
            + "&authState=" + e.authState
            + "&email=" + encodeURIComponent(e.profile.email)
            + "&givenNames=" + e.profile.givenName
            + "&surname=" + e.profile.familyName
            + "&redirectUri=" + location.href.replace(window.location.origin, "")
            + "&uccLastUpdatedDate=" + encodeURIComponent(uccLastUpdatedDate)
            + "&rememberMe=" + e.rememberMe);
    },
    onLogoutSuccess: function (e) {
        console.log('<<<<<<<<<< client: received onLogoutSuccess event.' + JSON.stringify(e))

        document.cookie = "skipSso=; expires=; path=/";
        location.assign(logoutUri);
    },
});

function updateLitSession(ucid, accessToken) {
    $.ajax({
        method: "GET",
        url: "/action/doSsoSessionUpdate",
        data: {ucid: ucid, accessToken: accessToken},
        success: function (callData, textStatus) {
            console.log("Session accessToken updated")
            litSSO.accessToken = accessToken
        },
        error: function (jqXHR, textStatus, errorThrown) {
            alert("Your website session has expired and will now be reset.")
            console.log("Session update failed: " + jqXHR.responseText)
            location.assign(logoutUri + "?redirectUri=" + encodeURIComponent(location.href.replace(window.location.origin, "")));
        }
    });
}

function getRedirectUri(location, fallback) {
    const urlParams = new URLSearchParams(location);
    const uriUrlParam = urlParams.get('uri');
    if (uriUrlParam)
        return encodeURIComponent(uriUrlParam);
    else
        return encodeURIComponent(fallback);
}

function isSignInPage() {
    return document.querySelector('meta[name="pbContext"]').content.indexOf("customPage:string:/sign-in") > -1;
}

function displayAuthenticatedMessage() {
    if (isSignInPage()) {
        var div = document.getElementById('authMsg');
        if ("" === "PersonUser") {
            div.innerHTML += "You are already signed in to " + window.location.origin.replace("https://", "").replace("www.", "") + ". If you would like to sign in with a different email address, please use the form below.";
        } else {
            div.innerHTML = '';
        }
    }
}</script>

                    
                
            </div>
        </div><iframe name="trustarc_notice" id="trustarcNoticeFrame" title="Trustarc Cross-Domain Consent Frame" src="https://consent.trustarc.com/get?name=crossdomain.html&amp;domain=nejm.com" style="display: none;"></iframe><script src="https://consent.trustarc.com/asset/notice.js/v/v1.7-1576" async="async" crossorigin="" importance="high" nonce="94d68cb4c580debe-GRU"></script>
        


        
        

            <script src="/products/mms-nextgen/mms/releasedAssets/js/build.lazyload.bundle-c8c4e7d20884f81951fb.js" nonce="94d68cb4c580debe-GRU"></script>

        <script src="/products/mms-nextgen/mms/releasedAssets/js/main.bundle-3819a02ec7bc2aca01ec.js" nonce="94d68cb4c580debe-GRU"></script>
        


<div id="adModal" tabindex="-1" aria-labelledby="exampleModalCenterTitle" class="ng-modal modal" style="display: none;" aria-hidden="true">
    <div role="document" class="ng-modal_dialog modal-dialog modal-dialog-centered ad-promoLayer">
        <div class="ng-modal_content modal-content p-0">
            <div class="ng-modal_body modal-body m-0">
                <div class="ng-modal_header modal-header">
                    <button type="button" data-dismiss="modal" aria-label="Close" class="ng-modal_close close"><span aria-hidden="true"><span class="icon-component "><svg aria-hidden="true"><use xlink:href="/specs/products/mms-nextgen/mms/releasedAssets/icons/icons.spritemap.svg#close"></use></svg></span></span>
                    </button>
                </div>

            </div>
        </div>
    </div>
</div>
<script type="text/javascript" src="/wro/1125813~product.js" nonce="94d68cb4c580debe-GRU"></script>








<input id="showLayers" type="hidden" value="true">

    <!-- placeholder id=null, description=ad-layer-config -->
    <!-- placeholder id=null, description=ad-lauchLayer-1 -->
    <!-- placeholder id=null, description=ad-layer-promo-1 -->

    <input id="firstAd" type="hidden" value="">
    <input id="secondAd" type="hidden" value="">

    
    
    

    
    
    <input id="IsInstitution" type="hidden" value="false">
    <input id="IsSubscriber" type="hidden" value="true">
    <input id="CustomerId" type="hidden" value="">


<script type="text/javascript" nonce="94d68cb4c580debe-GRU">
  jQuery.extend(jQuery.mmsLayers.config, {
    rules: [{
      "name": "Launch Layer Ad",
      "frequency": 30,
      "showOnPage": 5,
      "enabled": false,
      "cookieName": "MarketingLaunchLayer",
      "styleClass": "launchLayer"
    },
    {
      "name": "Promo Layer Ad",
      "frequency": 14,
      "enabled": true,
      "cookieName": "PromoLayer",
      "styleClass": "promoLayer"
    },
    {
      "name": "Interstitial Ad",
      "frequency": 7,
      "enabled": false,
      "cookieName": "InterstitialAd"
    },
    {
      "name": "Iperceptions - Ion Layer Ad",
      "showOnPage": 1,
      "enabled": false,
      "test": false,
      "cookieName":"Iperceptions"
    }]
 });
</script>

















    <script type="text/javascript" nonce="94d68cb4c580debe-GRU">
        $(document).ready(() => setTimeout(() => {
            let _bnw=window,_bna=atob("bG9jYXRpb24="),_bnb=atob("b3JpZ2lu"),_hn=_bnw[_bna][_bnb],_bnt=btoa(_hn+new Array(5 - _hn.length % 4).join(" "));
            $.get("/resource/lodash?t="+_bnt);
        },4000));
    </script>












    

    
    

    
    
    
    
        
            
                <script type="text/javascript" src="/wro/1125813~article-metrics.js" nonce="94d68cb4c580debe-GRU"></script>
            
            
            
        
    




<script type="text/javascript" src="/wro/1125813~full-text-analytics.js" nonce="94d68cb4c580debe-GRU"></script>


    


            <script>(function(){function c(){var b=a.contentDocument||a.contentWindow.document;if(b){var d=b.createElement('script');d.innerHTML="window.__CF$cv$params={r:'94d68cb4bd5edebe',t:'MTc0OTUzNDE5MS4wMDAwMDA='};var a=document.createElement('script');a.nonce='';a.src='/cdn-cgi/challenge-platform/scripts/jsd/main.js';document.getElementsByTagName('head')[0].appendChild(a);";b.getElementsByTagName('head')[0].appendChild(d)}}if(document.body){var a=document.createElement('iframe');a.height=1;a.width=1;a.style.position='absolute';a.style.top=0;a.style.left=0;a.style.border='none';a.style.visibility='hidden';document.body.appendChild(a);if('loading'!==document.readyState)c();else if(window.addEventListener)document.addEventListener('DOMContentLoaded',c);else{var e=document.onreadystatechange||function(){};document.onreadystatechange=function(b){e(b);'loading'!==document.readyState&&(document.onreadystatechange=e,c())}}}})();</script><iframe height="1" width="1" style="position: absolute; top: 0px; left: 0px; border: none; visibility: hidden;"></iframe><script defer="" src="https://static.cloudflareinsights.com/beacon.min.js/vcd15cbe7772f49c399c6a5babf22c1241717689176015" integrity="sha512-ZpsOmlRQV6y907TI0dKBHq9Md29nnaEIPlkf84rnaERnq6zvWvPUqr2ft8M1aS28oN72PdrCzSjY4U6VaAw1EQ==" data-cf-beacon="{&quot;rayId&quot;:&quot;94d68cb4bd5edebe&quot;,&quot;serverTiming&quot;:{&quot;name&quot;:{&quot;cfExtPri&quot;:true,&quot;cfEdge&quot;:true,&quot;cfOrigin&quot;:true,&quot;cfL4&quot;:true,&quot;cfSpeedBrain&quot;:true,&quot;cfCacheStatus&quot;:true}},&quot;version&quot;:&quot;2025.5.0&quot;,&quot;token&quot;:&quot;f55e150c7a5f4a4ab9ef82f4a1c9c43c&quot;}" crossorigin="anonymous"></script><div style="display:none;" id="signInEmbedded" class="ucc-fullpage-signin ucc-widgets-nejm-next">
  <div class="capture_header">
    <h1>Sign In</h1>
  </div>    
  <div class="capture_signin">
    {* #signInForm *}
    <div class="ucc-form-inner-wrapper">
      {* signInEmailAddress *}
      {* currentPassword *}
      <div style="padding-top:10px;">
          <div class="capture_form_item capture_form_rememberme">
          <label class="ucc-form-checkbox">                
            <input checked="checked" id="ucc-remember-me-cb-embedded" name="ucc-remember-me-cb-embedded" type="checkbox" value="true">
            <span>Remember Me</span>
          </label>                           
          </div>
          <div class="capture_form_item capture_form_forgotpwd">
            <a role="button" class="ucc-anchor-button" data-capturescreen="forgotPassword">Forgot your password?</a>
          </div>
      </div>
      <div class="capture_form_item">      
        <button id="ucc-sign-in-submit-embedded" class="capture_primary capture-full-width-btn" type="submit">Sign In</button>
      </div>
      <div class="capture_form_item capture_form_footer">
        <div class="ucc-no-acct-msg">Don't have an account?</div>
        <div class="ucc-no-acct-msg-2">
          <a role="button" class="ucc-anchor-button" onclick="mmsWidgets.closeSignIn(event); mmsWidgets.showRegAuto(event);">Create Account</a>
          <span></span><a href="https://store.nejm.org/nejm?promo=ONF4NRS1">Subscribe</a>
        </div>
      </div>
      <div class="capture_form_item capture_form_submit">
        
      </div>      
    </div>
    {* /signInForm *}
  </div>
</div><div style="display:none;" id="forgotPassword" class="ucc-widgets-nejm-next">
  <div class="capture_header">
    <h1>Forgot Password</h1>
  </div>   
  <div class="ucc-form-inner-wrapper">
  <p style="color:black">Enter the email address associated with your account then click Continue. We will email you a link to a page where you can easily create a new password.</p>
  </div> 
  <div class="capture_forgotpassword">
    {* #forgotPasswordForm *}      
      <div class="ucc-form-inner-wrapper">
        {* forgotPasswordEmailAddress *}
        {* captcha *}
        <div class="capture_form_item" style="padding-top: 20px;">        
          <input id="ucc-widget-forgotpwd-submit" value="Continue" type="submit" class="capture_btn capture_primary capture-full-width-btn">
        </div>
      </div>
    {* /forgotPasswordForm *}
  </div>
  </div><div style="display:none;" id="forgotPasswordSuccess" class="ucc-widgets-nejm-next">
  <div class="capture_header">
    <h1>Create New Password</h1>
  </div>    
  <div class="capture_forgotpassword">
      <div class="ucc-form-inner-wrapper">
        <p style="padding-top: 30px; padding-bottom: 30px;">We've sent an email with instructions to create a new password. Your existing password has not been changed.</p>        
        <div class="capture_form_item">      
          <button class="capture_btn capture_primary capture-full-width-btn" onclick="janrain.capture.ui.modal.close()">CLOSE</button>
        </div>
      </div>
  </div>
  </div><div style="display:none;" id="resetPassword" class="ucc-widgets-nejm-next">
      <div class="row">      
        <div class="col-md-8 col-md-offset-2 reset-pwd-info"><p>To reset your password, enter a new password twice and click the 'Reset Password' button.</p></div>
      </div>
      <div class="col-md-4 col-md-offset-4">
        {* #changePasswordFormNoAuth *}
          {* newPassword *}
          {* newPasswordConfirm *}     
          <div class="capture_form_item">
            <input value="RESET PASSWORD" type="submit" class="capture_btn capture_primary capture-full-width-btn">
          </div>
          {* /changePasswordFormNoAuth *}
      </div>
    </div><div style="display:none;" id="resetPasswordSuccess">
        <div class="reset-pwd-info">
          <div class="reset-pwd-success-welcome"></div>
          <p class="reset-pwd-success-msg">Your password has been reset. You will need to <a href="/signin" onclick="mmsWidgets.signIn(event)">sign in</a> again using your new password to access site content and features.</p>
          <p class="reset-pwd-success-nav"></p>
        </div>      
    </div><div style="display:none;" id="resetPasswordRequestCode" class="ucc-widgets-nejm-next">
        {* #resetPasswordForm *}
        <div class="capture_form_error">The link that you followed to reset your password has expired.</div>
          <div class="col-md-8 col-md-offset-2">
            <p class="reset-pwd-info">Enter the email address associated with your account then click Continue. We will email you a link to a page where you can easily create a new password.</p>
          </div>
          <div class="col-md-4 col-md-offset-4">
            {* signInEmailAddress *}
            <div class="capture_form_item">
              <input value="continue" type="submit" class="capture_btn capture_primary capture-full-width-btn">
            </div>
          </div>
        {* /resetPasswordForm *}
    </div><div style="display:none;" id="resetPasswordRequestCodeSuccess">
      <div class="reset-pwd-info">
        <p>If the address matches an existing account, you will receive an email with instructions to reset your password.</p>
        <p class="reset-pwd-success-nav"></p>
      </div>
  </div>

        
        
    

<div id="addtoany" style="position: static;"><div class="a2a_overlay" id="a2a_overlay"></div><div id="a2a_modal" class="a2a_modal a2a_hide" role="dialog" tabindex="-1" aria-label=""><div class="a2a_modal_body a2a_menu a2a_hide" id="a2a_copy_link"><label for="a2a_copy_link_text" id="a2a_copy_link_icon" class="a2a_svg a2a_s_link a2a_logo_color"><svg focusable="false" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32"><title>Copy link</title><path fill="#FFF" d="M7.591 21.177c0-.36.126-.665.377-.917l2.804-2.804a1.235 1.235 0 0 1 .913-.378c.377 0 .7.144.97.43-.026.028-.11.11-.255.25-.144.14-.24.236-.29.29a2.82 2.82 0 0 0-.2.256 1.056 1.056 0 0 0-.177.344 1.43 1.43 0 0 0-.046.37c0 .36.126.666.377.918a1.25 1.25 0 0 0 .918.377c.126.001.251-.015.373-.047.125-.037.242-.096.345-.175.09-.06.176-.127.256-.2.1-.094.196-.19.29-.29.14-.142.223-.23.25-.254.297.28.445.607.445.984 0 .36-.126.664-.377.916l-2.778 2.79a1.242 1.242 0 0 1-.917.364c-.36 0-.665-.118-.917-.35l-1.982-1.97a1.223 1.223 0 0 1-.378-.9l-.001-.004Zm9.477-9.504c0-.36.126-.665.377-.917l2.777-2.79a1.235 1.235 0 0 1 .913-.378c.35 0 .656.12.917.364l1.984 1.968c.254.252.38.553.38.903 0 .36-.126.665-.38.917l-2.802 2.804a1.238 1.238 0 0 1-.916.364c-.377 0-.7-.14-.97-.418.026-.027.11-.11.255-.25a7.5 7.5 0 0 0 .29-.29c.072-.08.139-.166.2-.255.08-.103.14-.22.176-.344.032-.12.048-.245.047-.37 0-.36-.126-.662-.377-.914a1.247 1.247 0 0 0-.917-.377c-.136 0-.26.015-.37.046-.114.03-.23.09-.346.175a3.868 3.868 0 0 0-.256.2c-.054.05-.15.148-.29.29-.14.146-.222.23-.25.258-.294-.278-.442-.606-.442-.983v-.003ZM5.003 21.177c0 1.078.382 1.99 1.146 2.736l1.982 1.968c.745.75 1.658 1.12 2.736 1.12 1.087 0 2.004-.38 2.75-1.143l2.777-2.79c.75-.747 1.12-1.66 1.12-2.737 0-1.106-.392-2.046-1.183-2.818l1.186-1.185c.774.79 1.708 1.186 2.805 1.186 1.078 0 1.995-.376 2.75-1.13l2.803-2.81c.751-.754 1.128-1.671 1.128-2.748 0-1.08-.382-1.993-1.146-2.738L23.875 6.12C23.13 5.372 22.218 5 21.139 5c-1.087 0-2.004.382-2.75 1.146l-2.777 2.79c-.75.747-1.12 1.66-1.12 2.737 0 1.105.392 2.045 1.183 2.817l-1.186 1.186c-.774-.79-1.708-1.186-2.805-1.186-1.078 0-1.995.377-2.75 1.132L6.13 18.426c-.754.755-1.13 1.672-1.13 2.75l.003.001Z"></path></svg></label><input id="a2a_copy_link_text" type="text" title="Copy link" readonly=""><div id="a2a_copy_link_copied">✓</div></div><div class="a2a_modal_body a2a_menu a2a_thanks a2a_hide" id="a2a_thanks"><div class="a2a_localize" data-a2a-localize="inner,ThanksForSharing">Thanks for sharing!</div></div></div><div class="a2a_menu a2a_full a2a_localize" id="a2apage_full" role="dialog" tabindex="-1" aria-label="Share" data-a2a-localize="title,Share"><div class="a2a_full_header"><div id="a2apage_find_container" class="a2a_menu_find_container"><label for="a2apage_find" id="a2apage_find_icon" class="a2a_svg a2a_s_find"><svg focusable="false" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" aria-hidden="true"><title>Find any service</title><path fill="#CCC" d="M19.7 18.2l-4.5-4.5c.7-1.1 1.2-2.3 1.2-3.6 0-3.5-2.8-6.3-6.3-6.3s-6.3 2.8-6.3 6.3 2.8 6.3 6.3 6.3c1.4 0 2.6-.4 3.6-1.2l4.5 4.5c.6.6 1.3.7 1.7.2.5-.4.4-1.1-.2-1.7zm-9.6-3.6c-2.5 0-4.5-2.1-4.5-4.5 0-2.5 2.1-4.5 4.5-4.5 2.5 0 4.5 2.1 4.5 4.5s-2 4.5-4.5 4.5z"></path></svg></label><input id="a2apage_find" class="a2a_menu_find a2a_localize" type="text" autocomplete="off" title="Find any service" data-a2a-localize="title,FindAnyServiceToAddTo"></div></div><div class="a2a_full_services" id="a2apage_full_services" role="presentation"></div><div class="a2a_full_footer"><a href="https://www.addtoany.com" title="Share Buttons" rel="noopener" target="_blank"><span class="a2a_svg a2a_s__default a2a_s_a2a a2a_logo_color"><svg focusable="false" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32"><g fill="#FFF"><path d="M14 7h4v18h-4z"></path><path d="M7 14h18v4H7z"></path></g></svg></span>AddToAny</a></div></div><div id="a2apage_dropdown" class="a2a_menu a2a_mini a2a_localize a2a_hide" tabindex="-1" aria-label="Share" data-a2a-localize="label,Share"><div class="a2a_mini_services" id="a2apage_mini_services"></div><div id="a2apage_cols_container" class="a2a_cols_container"><div class="a2a_col1" id="a2apage_col1"></div><div id="a2apage_2_col1" class="a2a_hide"></div><div class="a2a_clear"></div></div><div class="a2apage_wide a2a_wide"><a href="#addtoany" id="a2apage_show_more_less" class="a2a_more a2a_localize" title="Show all" data-a2a-localize="title,ShowAll"><span class="a2a_svg a2a_s__default a2a_s_a2a a2a_logo_color"><svg focusable="false" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32"><g fill="#FFF"><path d="M14 7h4v18h-4z"></path><path d="M7 14h18v4H7z"></path></g></svg></span><span class="a2a_localize" data-a2a-localize="inner,More">More…</span></a></div></div><div style="height: 1px; width: 1px; position: absolute; z-index: 100000; top: 0px; visibility: hidden;"><iframe id="a2a_sm_ifr" title="AddToAny Utility Frame" aria-hidden="true" src="https://static.addtoany.com/menu/sm.25.html#type=core&amp;event=load" style="height: 1px; width: 1px; border: 0px; left: 0px; top: 0px; position: absolute; z-index: 100000; display: none;"></iframe></div></div><gtx-vbimeozerkgt></gtx-vbimeozerkgt><script type="text/javascript" src="https://api.altmetric.com/v1/internal-556fdf0f/doi/10.1056/nejmoa2027540?callback=_altmetric.embed_callback&amp;domain=www.nejm.org&amp;cache_until=2-10"></script><div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div><div id="janrainEngageEmbed" style="display: none;"><div class="janrainContent" style="width: 380px !important; height: 156px !important; padding-left: 5px !important; padding-right: 5px !important; box-sizing: content-box !important; background-color: rgb(255, 255, 255) !important; border: 1px solid rgb(192, 192, 192) !important; border-radius: 10px !important; overflow: hidden !important; position: relative !important;"><div id="janrainView"><div class="janrainHeader" style="background-color: rgb(255, 255, 255) !important; font-size: 14px !important; color: rgb(102, 102, 102) !important; position: relative !important; height: 20px !important; left: -5px !important; padding: 5px 5px 0px !important; white-space: nowrap !important; width: 380px !important; z-index: 100 !important; border-radius: 10px 10px 0px 0px !important; text-align: left !important;"><div style="padding-left: 1px !important; font-family: Helvetica, &quot;lucida grande&quot;, Verdana, sans-serif !important;">Sign in using your account with</div></div><div id="janrainProviderPages" style="padding-top: 5px; left: 5px; position: absolute;"><div class="janrainPage" pageindex="0"><ul class="providers" id="janrainProviders_0" style="float: left !important; list-style-type: none !important; margin: 0px !important; padding: 0px !important;"><li id="janrain-aol" role="button" style="list-style: none !important; height: 30px !important; width: 185px !important; margin-top: 0px !important; margin-right: 5px !important; margin-bottom: 5px !important; position: relative !important; border: 1px solid rgb(204, 204, 204) !important; border-radius: 5px !important; cursor: pointer !important; white-space: nowrap !important; overflow: hidden !important; background-image: -webkit-linear-gradient(bottom, rgb(238, 238, 238), rgb(255, 255, 255)) !important;"><a tabindex="1" href="javascript:void(0);" style="font-family: Helvetica, &quot;lucida grande&quot;, Verdana, sans-serif !important; font-size: 12px !important; line-height: 14px !important; margin-left: auto !important; margin-right: auto !important; text-decoration: none !important; display: block !important; padding-left: 5px !important; padding-right: 5px !important; text-align: left !important; width: auto !important;"><span class="janrain-provider-icon-24 janrain-provider-icon-aol" style="margin-top: 3px !important; background-color: transparent !important;"></span><span class="janrain-provider-text-color-aol" style="font-family: Helvetica, &quot;lucida grande&quot;, Verdana, sans-serif !important; cursor: pointer !important; margin-left: 7px !important; text-align: left !important; margin-top: 9px !important; vertical-align: top !important; display: inline-block !important;">AOL</span></a></li><li id="janrain-openid" role="button" style="list-style: none !important; height: 30px !important; width: 185px !important; margin-top: 0px !important; margin-right: 5px !important; margin-bottom: 5px !important; position: relative !important; border: 1px solid rgb(204, 204, 204) !important; border-radius: 5px !important; cursor: pointer !important; white-space: nowrap !important; overflow: hidden !important; background-image: -webkit-linear-gradient(bottom, rgb(238, 238, 238), rgb(255, 255, 255)) !important;"><a tabindex="3" href="javascript:void(0);" style="font-family: Helvetica, &quot;lucida grande&quot;, Verdana, sans-serif !important; font-size: 12px !important; line-height: 14px !important; margin-left: auto !important; margin-right: auto !important; text-decoration: none !important; display: block !important; padding-left: 5px !important; padding-right: 5px !important; text-align: left !important; width: auto !important;"><span class="janrain-provider-icon-24 janrain-provider-icon-openid" style="margin-top: 3px !important; background-color: transparent !important;"></span><span class="janrain-provider-text-color-openid" style="font-family: Helvetica, &quot;lucida grande&quot;, Verdana, sans-serif !important; cursor: pointer !important; margin-left: 7px !important; text-align: left !important; margin-top: 9px !important; vertical-align: top !important; display: inline-block !important;">OpenID</span></a></li></ul><ul class="providers" id="janrainProviders_1" style="float: left !important; list-style-type: none !important; margin: 0px !important; padding: 0px !important;"><li id="janrain-yahoo" role="button" style="list-style: none !important; height: 30px !important; width: 185px !important; margin-top: 0px !important; margin-right: 5px !important; margin-bottom: 5px !important; position: relative !important; border: 1px solid rgb(204, 204, 204) !important; border-radius: 5px !important; cursor: pointer !important; white-space: nowrap !important; overflow: hidden !important; background-image: -webkit-linear-gradient(bottom, rgb(238, 238, 238), rgb(255, 255, 255)) !important;"><a tabindex="2" href="javascript:void(0);" style="font-family: Helvetica, &quot;lucida grande&quot;, Verdana, sans-serif !important; font-size: 12px !important; line-height: 14px !important; margin-left: auto !important; margin-right: auto !important; text-decoration: none !important; display: block !important; padding-left: 5px !important; padding-right: 5px !important; text-align: left !important; width: auto !important;"><span class="janrain-provider-icon-24 janrain-provider-icon-yahoo" style="margin-top: 3px !important; background-color: transparent !important;"></span><span class="janrain-provider-text-color-yahoo" style="font-family: Helvetica, &quot;lucida grande&quot;, Verdana, sans-serif !important; cursor: pointer !important; margin-left: 7px !important; text-align: left !important; margin-top: 9px !important; vertical-align: top !important; display: inline-block !important;">Yahoo!</span></a></li></ul></div></div><div style="background-color: rgb(255, 255, 255) !important; width: 380px !important; height: 10px !important; position: absolute !important; left: 0px !important; padding-left: 5px !important; padding-right: 5px !important; padding-bottom: 5px !important; bottom: 0px !important; font-size: 10px !important; text-align: left !important; color: rgb(102, 102, 102) !important; font-family: Helvetica, &quot;lucida grande&quot;, Verdana, sans-serif !important; border-radius: 0px 0px 10px 10px !important;"><div style="padding-left: 1px !important;"><a href="http://janrain.com/products/engage/social-login?utm_source=mms.rpxnow.com&amp;utm_medium=Partner&amp;utm_campaign=attribution" target="_blank">Social Login by Janrain</a></div></div></div></div></div><iframe name="captureIFrame_trf1anevz91k97xqjon4abnchujg7vzm8gl18fdz" data-transactionid="trf1anevz91k97xqjon4abnchujg7vzm8gl18fdz" id="captureIFrame_trf1anevz91k97xqjon4abnchujg7vzm8gl18fdz" src="about:blank" class="" data-captureiframeloadeventbound="yes" style="display: none;"></iframe><div id="janrainModalOverlay" style="inset: 0px; position: fixed; background-color: rgb(0, 0, 0); opacity: 0.4; display: none; z-index: 1000;"></div><div id="janrainModal" style="width: 380px; height: 131px; position: absolute; z-index: 1000; display: none;"><a href="#" class="janrain_modal_closebutton" style="position: absolute; cursor: pointer; z-index: 1000;">X</a><div style="display: block;" id="signIn" class="ucc-widgets-nejm-next janrain-capture-ui capture-ui-content capture_screen_container" data-capturescreenname="signIn" data-captureventadded="true">
    <div class="capture_header">
      <h1>Sign In</h1>
    </div>    
    <div class="capture_signin">
      <form id="capture_signIn_signInForm" name="signInForm" data-capturefield="signInForm" action="https://mms.us.janraincapture.com/widget/traditional_signin.jsonp" class="capture_form capture_signInForm" method="POST" novalidate="novalidate" data-transactionid="trf1anevz91k97xqjon4abnchujg7vzm8gl18fdz" target="captureIFrame_trf1anevz91k97xqjon4abnchujg7vzm8gl18fdz" accept-charset="UTF-8" next="{&quot;noop&quot;:&quot;&quot;}"><div id="capture_signIn_signInForm_defaultSavedProfileMessage"></div><div id="capture_signIn_signInForm_errorMessages"></div><input id="capture_signIn_utf8" data-capturefield="undefined" value="✓" type="hidden" class="capture_utf8" name="utf8"><input id="capture_signIn_screen_trf1anevz91k97xqjon4abnchujg7vzm8gl18fdz" data-capturefield="undefined" value="signIn" type="hidden" class="capture_screen_trf1anevz91k97xqjon4abnchujg7vzm8gl18fdz" name="capture_screen"><input id="capture_signIn_js_version_trf1anevz91k97xqjon4abnchujg7vzm8gl18fdz" data-capturefield="undefined" value="d445bf4" type="hidden" class="capture_js_version_trf1anevz91k97xqjon4abnchujg7vzm8gl18fdz" name="js_version"><input id="capture_signIn_transactionId_trf1anevz91k97xqjon4abnchujg7vzm8gl18fdz" data-capturefield="undefined" value="trf1anevz91k97xqjon4abnchujg7vzm8gl18fdz" type="hidden" class="capture_transactionId_trf1anevz91k97xqjon4abnchujg7vzm8gl18fdz" name="capture_transactionId"><input id="capture_signIn_form_trf1anevz91k97xqjon4abnchujg7vzm8gl18fdz" data-capturefield="undefined" value="signInForm" type="hidden" class="capture_form_trf1anevz91k97xqjon4abnchujg7vzm8gl18fdz" name="form"><input id="capture_signIn_flow_trf1anevz91k97xqjon4abnchujg7vzm8gl18fdz" data-capturefield="undefined" value="standard" type="hidden" class="capture_flow_trf1anevz91k97xqjon4abnchujg7vzm8gl18fdz" name="flow"><input id="capture_signIn_client_id_trf1anevz91k97xqjon4abnchujg7vzm8gl18fdz" data-capturefield="undefined" value="qsra7g4d6jwdsgn3zbe6udp6r6278mr9" type="hidden" class="capture_client_id_trf1anevz91k97xqjon4abnchujg7vzm8gl18fdz" name="client_id"><input id="capture_signIn_redirect_uri_trf1anevz91k97xqjon4abnchujg7vzm8gl18fdz" data-capturefield="undefined" value="https://www.nejm.org" type="hidden" class="capture_redirect_uri_trf1anevz91k97xqjon4abnchujg7vzm8gl18fdz" name="redirect_uri"><input id="capture_signIn_response_type_trf1anevz91k97xqjon4abnchujg7vzm8gl18fdz" data-capturefield="undefined" value="code" type="hidden" class="capture_response_type_trf1anevz91k97xqjon4abnchujg7vzm8gl18fdz" name="response_type"><input id="capture_signIn_flow_version_trf1anevz91k97xqjon4abnchujg7vzm8gl18fdz" data-capturefield="undefined" value="20240514181256512029" type="hidden" class="capture_flow_version_trf1anevz91k97xqjon4abnchujg7vzm8gl18fdz" name="flow_version"><input id="capture_signIn_settings_version_trf1anevz91k97xqjon4abnchujg7vzm8gl18fdz" data-capturefield="undefined" value="" type="hidden" class="capture_settings_version_trf1anevz91k97xqjon4abnchujg7vzm8gl18fdz" name="settings_version"><input id="capture_signIn_locale_trf1anevz91k97xqjon4abnchujg7vzm8gl18fdz" data-capturefield="undefined" value="en-US" type="hidden" class="capture_locale_trf1anevz91k97xqjon4abnchujg7vzm8gl18fdz" name="locale"><input id="capture_signIn_recaptcha_version_trf1anevz91k97xqjon4abnchujg7vzm8gl18fdz" data-capturefield="undefined" value="2" type="hidden" class="capture_recaptcha_version_trf1anevz91k97xqjon4abnchujg7vzm8gl18fdz" name="recaptchaVersion">
      <div class="ucc-form-inner-wrapper">
        <div id="capture_signIn_form_item_signInEmailAddress" class="capture_form_item capture_email capture_form_item_signInEmailAddress" data-capturefield="undefined"><label for="capture_signIn_signInEmailAddress">Email Address</label><input id="capture_signIn_signInEmailAddress" data-capturefield="signInEmailAddress" value="" type="email" class="capture_signInEmailAddress capture_required capture_text_input" placeholder="Email Address" name="signInEmailAddress"><div class="capture_tip" style="display:none;"></div><div class="capture_tip_validating" data-elementname="signInEmailAddress">Validating</div><div class="capture_tip_error" data-elementname="signInEmailAddress"></div></div>
        <div id="capture_signIn_form_item_currentPassword" class="capture_form_item capture_password capture_form_item_currentPassword" data-capturefield="undefined"><label for="capture_signIn_currentPassword">Password</label><input id="capture_signIn_currentPassword" data-capturefield="currentPassword" value="" type="password" class="capture_currentPassword capture_required capture_text_input" placeholder="Password" name="currentPassword"><div class="capture_tip" style="display:none;"></div><div class="capture_tip_validating" data-elementname="currentPassword">Validating</div><div class="capture_tip_error" data-elementname="currentPassword"></div></div>
        <div style="padding-top:10px;">
            <div class="capture_form_item capture_form_rememberme">
                <label class="ucc-form-checkbox">                
                    <input checked="checked" id="ucc-remember-me-cb" name="ucc-remember-me-cb" type="checkbox" value="true">
                    <span>Remember Me</span>
                </label>          
            </div>
            <div class="capture_form_item capture_form_forgotpwd">
              <a role="button" class="ucc-anchor-button" data-capturescreen="forgotPassword">Forgot your password?</a>
            </div>
        </div>
        <div class="capture_form_item">
          <button id="ucc-sign-in-submit" class="capture_primary capture-full-width-btn" type="submit">Sign In</button>
        </div>
       
        <div class="capture_form_item">
          <div class="ucc-no-acct-msg">Don't have an account?</div>
          <div class="ucc-no-acct-msg-2" id="signInModalCreateAccountLink">
          <a role="button" class="ucc-anchor-button" onclick="mmsWidgets.closeSignIn(event); mmsWidgets.showRegAuto(event);">Create Account</a>
            <span></span><a href="https://store.nejm.org/nejm?promo=ONF4NRS1">Subscribe</a>
          </div>

          <div class="ucc-no-acct-msg-2" id="signInModalCloseLink" style="display:none">
          <a role="button" class="ucc-anchor-button" onclick="mmsWidgets.closeSignIn(event);">Create Account</a>
            <span></span><a href="https://store.nejm.org/nejm?promo=ONF4NRS1">Subscribe</a>
          </div>

        </div>
     
        <div class="capture_form_item capture_form_submit">
          
        </div>      
      </div>
      </form>
    </div>
  </div></div></body></html>