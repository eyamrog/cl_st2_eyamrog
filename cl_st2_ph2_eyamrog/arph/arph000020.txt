Title: Real-Time Infectious Disease Modeling to Inform Emergency Public Health Decision Making


Section: 

Copyright © 2022 by Annual Reviews. This work is licensed under a Creative Commons Attribution 4.0 International License , which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited. See credit lines of images or other third-party material in this article for license information


Section: ABSTRACT

Infectious disease transmission is a nonlinear process with complex, sometimes unintuitive dynamics. Modeling can transform information about a disease process and its parameters into quantitative projections that help decision makers compare public health response options. However, modelers face methodologic challenges, data challenges, and communication challenges, which are exacerbated under the time constraints of a public health emergency. We review methods, applications, challenges and opportunities for real-time infectious disease modeling during public health emergencies, with examples drawn from the two deadliest pandemics in recent history: HIV/AIDS and coronavirus disease 2019 (COVID-19).

Section: INTRODUCTION

Public health emergencies require real-time evaluation of response options ( 127 ). When emergencies involve infectious diseases, decision making is especially challenging because transmission of disease is a nonlinear process with complex, sometimes unintuitive dynamics. Mathematical modeling can help predict epidemic trends and compare response options. Here, we review methods, applications, challenges, and opportunities for real-time infectious disease modeling during public health emergencies. We acknowledge that, unfortunately, history offers abundant examples of infectious disease emergencies; this review draws primarily on examples from the two deadliest pandemics in recent history: HIV/AIDS and coronavirus disease 2019 (COVID-19) ( 109 ).

Section: METHODS OF INFECTIOUS DISEASE MODELING

A model is a conceptual tool used to describe how a system behaves and how that behavior would differ in alternative circumstances. Mathematical models use equations to precisely describe the system in quantitative terms. Infectious disease models are mathematical models that describe how infectious diseases emerge, transmit, and affect the health states of their hosts. This section briefly summarizes the properties of infectious disease models. Additional information about infectious disease modeling can be found in numerous textbooks ( 79 , 141 ), articles ( 60 , 134 ), conferences ( 44 ; https://smdm.org/meetings ), and courses ( 93 , 133 , 135 ).
Infectious disease models are most commonly thought of as representing transmission in a population, but this is not universally true. Some models focus only on the progression of disease within the host ( 9 , 69 ), and others attempt to predict the risk of the disease ever appearing in a population [e.g., zoonosis risk ( 5 , 117 ) or travel-related importation risk ( 119 )]. In this section, we focus on the more common conception of an infectious disease model: one that represents the process of disease moving from infected to uninfected hosts, giving rise to population-level epidemic trends.
Disease transmission models represent infected and uninfected hosts in two ways. Compartmental models enumerate all possible states that the model can represent, and use equations to govern transitions between states. Agent-based models enumerate the number of individuals and use equations to govern how individuals change and interact. Within the categories of compartmental and agent-based models are myriad choices for model structures.
Compartmental models of infectious disease transmission at a minimum have separate compartments for infected and uninfected hosts, but they may subdivide the population in other ways as well. The most parsimonious disease model represents the number of susceptible hosts (S) and the number of infectious hosts (I), potentially also keeping track of hosts that have been removed from participating in transmission due to immunity or death (R), yielding the well-known SIR model ( 82 ). Adding a compartment for incubating disease in exposed hosts (E) produces the SEIR model, commonly used for respiratory pathogens ( 31 , 120 ). Pathogens with complex disease progression, such as the prolonged latent stages of HIV and Mycobacterium tuberculosis infections ( 49 ), may require states in addition to E and I. The choice of model structure—that is, the states and transitions between them—can be considered types of model assumptions, specifically, structural assumptions. For example, choosing an SIR model rather than an SEIR model implicitly assumes negligible time spent in the E state.
Transmission in compartmental infectious disease models is usually governed by the product of the number of susceptible hosts, the number of infectious hosts, and a transmission rate β representing the biological transmissibility of the pathogen (i.e., how readily it jumps across hosts), as well as the behaviors of interacting hosts (i.e., how likely one host is to interact with any other host in manners that facilitate transmission). When S and I are subdivided according to the characteristics of hosts, models can apply different β values to different pairings of infected and uninfected hosts, representing behavioral or biological differences among hosts and their interactions. Human hosts are often subdivided by age, sex, geography, likelihood of interacting with each other, and other factors affecting transmission or health outcomes. For vector-borne diseases, hosts are also subdivided into human versus vector species.
A challenge with adding subdivisions to a compartmental model is that the number of compartments increases with each subdivision. Eventually, the number of compartments could even exceed the population size (i.e., the hypothetical number of different kinds of people may exceed the actual number of people in the population). When a model requires such a large number of subdivisions, or when it is necessary to make rapid ad hoc changes to how the population is subdivided without drastically changing the model, agent-based models may provide a suitable alternative to compartmental models.
Agent-based models explicitly represent individuals (i.e., agents) in the population. The structure of an agent-based model is defined by the attributes of individuals and the rules governing how attributes change, including interactions with other individuals. Whereas compartmental model equations define transition rates between states, agent-based model equations can define more complex behaviors. For example, rather than multiplying the number of susceptible and infectious hosts to determine population-level transmission, agent-based models can represent person-to-person interactions in a social network ( 14 , 74 , 84 ).
Unlike with compartmental models, adding attributes to agent-based models does not require subdividing the entire population but merely adding an incremental amount of information to each individual. The complexity of agent-based models does not necessarily increase when finer gradations of attributes are used. For example, in an agent-based model, it is as complex to assign every individual an exact date of birth as it is to assign a 5- or 10-year age category, as is commonly done in age-structured compartmental models ( 77 , 83 ).
The time and computational power needed to run agent-based models are usually greater than those for compartmental models, and these demands increase with the modeled population size. For this reason, many agent-based models are actually hybrids of agent-based and compartmental models. For example, vector-borne disease models often represent humans individually but represent the vectors as compartmentalized populations ( 125 ). Similarly, agent-based disease models rarely represent individual viruses, bacteria, or parasites; these are modeled as compartmentalized populations because they are too numerous to model individually.
Some models used in infectious disease emergencies do not incorporate disease transmission at all. Though not a focus of this review, these models can provide important input into decision making, such as the probability of disease importation based on travel patterns ( 33 , 56 ) and short-term forecasting using statistical extrapolation methods ( 24 , 61 ).
Models require numeric values for parameters defined by their structure [i.e., rates of movement between compartments (in compartmental models) or changes in agents’ attributes (in agent-based models)]. Parameters may be informed directly by data related to their probable values (e.g., the measured duration of a disease state) or indirectly by information about model outputs, known as calibration targets. For example, the prevalence of disease at different points in time is a calibration target because it is not a parameter set prior to running the model; it is obtained only after the model is run.
Calibration is the process of modifying parameter values to more closely match calibration targets. Calibration can be performed manually by way of human intuition—for example, if prevalence is too low, one could try increasing β —or automated approaches, including grid sampling ( 122 ), Latin hypercube sampling ( 94 ), or gradient descent algorithms such as the Nelder–Mead method ( 12 ), to select candidate parameter values. More complex calibration algorithms are often required for agent-based models ( 63 ) and other models that are stochastic (i.e., use random number sequences that produce a different result each time they are run).
It is possible to combine direct information about parameter values with indirect information from calibration targets. Bayesian methods of model calibration combine a prior estimate based on direct information with a likelihood based on goodness-of-fit to calibration targets to calculate a posterior estimate for the parameter ( 80 ). Models with many free parameters (i.e., ones with uninformative priors) can be especially challenging to calibrate due to methodological limitations in the number of parameters that can be calibrated simultaneously ( 63 ) and the risk of overfitting calibration targets ( 13 ).
Comparing calibrated model results to their calibration targets is important for establishing model credibility because it tests whether the model successfully recapitulated observed population-level epidemic trends. For example, a recent study estimating progress toward HIV treatment goals in South African metro areas began by displaying how well the model results match past HIV prevalence estimates and health system data on treatment delivery, which helped establish credibility for subsequent estimates and forecasts of treatment coverage ( 138 ).
Model estimates can be uncertain, especially during an emergency when much is unknown about the spread of a disease and the effect of different policy options. However, decisions need to be made even in the face of uncertainty. Quantifying uncertainty can help indicate whether a model is able to provide inferences regarding the choice of public health response options. Here, we briefly describe the sources of uncertainty in models and the strategies to reduce uncertainty in order to provide useful support for decision making.
There are three main types of model uncertainty: structural, parameter, and stochastic ( 19 ). Structural uncertainty arises when it is unclear whether a model structure captures the aspects of disease transmission and pathogenicity that are important for decision making. When a model cannot fit calibration targets using plausible parameter values, this often signals that the model structure is misspecified. Even when models fit calibration targets well, it is possible for models with different structures to provide different predictions about the impact of public health responses. Structural uncertainty can be examined with multimodel comparisons, including models with a wide variety of structures. For example, the HIV Modelling Consortium has coordinated multimodel analyses of HIV-related policy questions such as the cost ( 35 ) and cost-effectiveness ( 36 ) of HIV treatment eligibility options, the impact and cost-effectiveness of voluntary medical male circumcision ( 90 ), and the potential harms of interrupting HIV treatment delivery during COVID-19 lockdowns ( 76 ). Each comparison included both individual-based and compartmental models, with some comparisons involving as many as a dozen models with differing structures and assumptions ( 35 , 36 ), providing insight into how structural uncertainty might affect the implications for decision making.
Parametric uncertainty arises from the use of imperfect information to set parameter values or calibration targets. Examples include sampling-related uncertainty in data, biased data, between-study variance in meta-analysis ( 139 ), and divergent or imprecise expert opinions. Models can propagate parameter uncertainty into uncertainty about the impact of response options by sampling different values for parameters and determining their effects on model outputs. For example, COVID-19 models have examined parameter uncertainty regarding R 0 ( 18 , 68 ) and infection fatality rates ( 37 , 151 ) and reported profound implications of this uncertainty on the magnitude of epidemic forecasts and impact of response options such as lockdowns.
Stochastic uncertainty arises from randomness rather than from misspecified model structure or limited data. It manifests when different random-number sequences are used in different simulation runs. Most agent-based models are stochastic. Compartmental models may be either deterministic or stochastic depending on how they are simulated. For example, the Gillespie method is a stochastic compartmental modeling approach in which transitions between compartments always occur in whole-number increments ( 53 , 140 ). Stochastic uncertainty can become large when the population sizes of interest are small or when the nature of disease transmission lends itself to random variability. For example, stochastic models have suggested, due in part to the large role of superspreading events ( 145 ), that there is substantial random uncertainty about which neighborhoods will experience surges of COVID-19 ( 7 ) and whether new viral variants will outcompete already-prevalent variants ( 59 ).
Uncertainty in model outputs, described above, does not always translate into uncertainty in decision making. At times, even when model results are uncertain, they provide sufficient inference for decision making. In this case, uncertainty does not need to be reduced to inform policy choices. At other times, model results are too uncertain to provide inference for decision making. For example, epidemic projections with confidence intervals spanning from nearly 0% to nearly 100% prevalence are unhelpful to decision makers. Structural and parameter uncertainty can be reduced by incorporating additional data that informs model structure, parameter values, calibration targets, or a combination thereof. Stochastic uncertainty can be reduced by performing more model runs and/or increasing the simulated population size, especially if the simulated population is smaller than the actual population.
If model results are still too uncertain, modelers can bound residual uncertainty by designating distinct model scenarios . Scenarios describe model assumptions regarding properties that decision makers cannot control—in contrast to response options, which decision makers can control. For example, if a large driver of uncertainty is whether a pathogen will evolve drug resistance, then modelers may present separate “with drug resistance” and “without drug resistance” scenarios. Having N response options and M scenarios would produce N × M model results. To avoid an overwhelming number of results, modelers should limit scenarios to those that change inference for decision making, with the rest incorporated into residual uncertainty depicted as error bounds around results. The number of scenarios could be reduced further by showing only scenarios that produce high and low extremes of results: an approach known as bounding analysis. For example, early COVID-19 forecasting for the United States by the Institute for Health Metrics and Evaluation used as an upper bound an assumption, based on the highest-observed rates of facemask usage globally (Singapore), that 95% of the population would adopt facemask usage ( 114 ).
Infectious disease models are most commonly thought of as representing transmission in a population, but this is not universally true. Some models focus only on the progression of disease within the host ( 9 , 69 ), and others attempt to predict the risk of the disease ever appearing in a population [e.g., zoonosis risk ( 5 , 117 ) or travel-related importation risk ( 119 )]. In this section, we focus on the more common conception of an infectious disease model: one that represents the process of disease moving from infected to uninfected hosts, giving rise to population-level epidemic trends.
Disease transmission models represent infected and uninfected hosts in two ways. Compartmental models enumerate all possible states that the model can represent, and use equations to govern transitions between states. Agent-based models enumerate the number of individuals and use equations to govern how individuals change and interact. Within the categories of compartmental and agent-based models are myriad choices for model structures.
Compartmental models of infectious disease transmission at a minimum have separate compartments for infected and uninfected hosts, but they may subdivide the population in other ways as well. The most parsimonious disease model represents the number of susceptible hosts (S) and the number of infectious hosts (I), potentially also keeping track of hosts that have been removed from participating in transmission due to immunity or death (R), yielding the well-known SIR model ( 82 ). Adding a compartment for incubating disease in exposed hosts (E) produces the SEIR model, commonly used for respiratory pathogens ( 31 , 120 ). Pathogens with complex disease progression, such as the prolonged latent stages of HIV and Mycobacterium tuberculosis infections ( 49 ), may require states in addition to E and I. The choice of model structure—that is, the states and transitions between them—can be considered types of model assumptions, specifically, structural assumptions. For example, choosing an SIR model rather than an SEIR model implicitly assumes negligible time spent in the E state.
Transmission in compartmental infectious disease models is usually governed by the product of the number of susceptible hosts, the number of infectious hosts, and a transmission rate β representing the biological transmissibility of the pathogen (i.e., how readily it jumps across hosts), as well as the behaviors of interacting hosts (i.e., how likely one host is to interact with any other host in manners that facilitate transmission). When S and I are subdivided according to the characteristics of hosts, models can apply different β values to different pairings of infected and uninfected hosts, representing behavioral or biological differences among hosts and their interactions. Human hosts are often subdivided by age, sex, geography, likelihood of interacting with each other, and other factors affecting transmission or health outcomes. For vector-borne diseases, hosts are also subdivided into human versus vector species.
A challenge with adding subdivisions to a compartmental model is that the number of compartments increases with each subdivision. Eventually, the number of compartments could even exceed the population size (i.e., the hypothetical number of different kinds of people may exceed the actual number of people in the population). When a model requires such a large number of subdivisions, or when it is necessary to make rapid ad hoc changes to how the population is subdivided without drastically changing the model, agent-based models may provide a suitable alternative to compartmental models.
Agent-based models explicitly represent individuals (i.e., agents) in the population. The structure of an agent-based model is defined by the attributes of individuals and the rules governing how attributes change, including interactions with other individuals. Whereas compartmental model equations define transition rates between states, agent-based model equations can define more complex behaviors. For example, rather than multiplying the number of susceptible and infectious hosts to determine population-level transmission, agent-based models can represent person-to-person interactions in a social network ( 14 , 74 , 84 ).
Unlike with compartmental models, adding attributes to agent-based models does not require subdividing the entire population but merely adding an incremental amount of information to each individual. The complexity of agent-based models does not necessarily increase when finer gradations of attributes are used. For example, in an agent-based model, it is as complex to assign every individual an exact date of birth as it is to assign a 5- or 10-year age category, as is commonly done in age-structured compartmental models ( 77 , 83 ).
The time and computational power needed to run agent-based models are usually greater than those for compartmental models, and these demands increase with the modeled population size. For this reason, many agent-based models are actually hybrids of agent-based and compartmental models. For example, vector-borne disease models often represent humans individually but represent the vectors as compartmentalized populations ( 125 ). Similarly, agent-based disease models rarely represent individual viruses, bacteria, or parasites; these are modeled as compartmentalized populations because they are too numerous to model individually.
Some models used in infectious disease emergencies do not incorporate disease transmission at all. Though not a focus of this review, these models can provide important input into decision making, such as the probability of disease importation based on travel patterns ( 33 , 56 ) and short-term forecasting using statistical extrapolation methods ( 24 , 61 ).
Models require numeric values for parameters defined by their structure [i.e., rates of movement between compartments (in compartmental models) or changes in agents’ attributes (in agent-based models)]. Parameters may be informed directly by data related to their probable values (e.g., the measured duration of a disease state) or indirectly by information about model outputs, known as calibration targets. For example, the prevalence of disease at different points in time is a calibration target because it is not a parameter set prior to running the model; it is obtained only after the model is run.
Calibration is the process of modifying parameter values to more closely match calibration targets. Calibration can be performed manually by way of human intuition—for example, if prevalence is too low, one could try increasing β —or automated approaches, including grid sampling ( 122 ), Latin hypercube sampling ( 94 ), or gradient descent algorithms such as the Nelder–Mead method ( 12 ), to select candidate parameter values. More complex calibration algorithms are often required for agent-based models ( 63 ) and other models that are stochastic (i.e., use random number sequences that produce a different result each time they are run).
It is possible to combine direct information about parameter values with indirect information from calibration targets. Bayesian methods of model calibration combine a prior estimate based on direct information with a likelihood based on goodness-of-fit to calibration targets to calculate a posterior estimate for the parameter ( 80 ). Models with many free parameters (i.e., ones with uninformative priors) can be especially challenging to calibrate due to methodological limitations in the number of parameters that can be calibrated simultaneously ( 63 ) and the risk of overfitting calibration targets ( 13 ).
Comparing calibrated model results to their calibration targets is important for establishing model credibility because it tests whether the model successfully recapitulated observed population-level epidemic trends. For example, a recent study estimating progress toward HIV treatment goals in South African metro areas began by displaying how well the model results match past HIV prevalence estimates and health system data on treatment delivery, which helped establish credibility for subsequent estimates and forecasts of treatment coverage ( 138 ).
Model estimates can be uncertain, especially during an emergency when much is unknown about the spread of a disease and the effect of different policy options. However, decisions need to be made even in the face of uncertainty. Quantifying uncertainty can help indicate whether a model is able to provide inferences regarding the choice of public health response options. Here, we briefly describe the sources of uncertainty in models and the strategies to reduce uncertainty in order to provide useful support for decision making.
There are three main types of model uncertainty: structural, parameter, and stochastic ( 19 ). Structural uncertainty arises when it is unclear whether a model structure captures the aspects of disease transmission and pathogenicity that are important for decision making. When a model cannot fit calibration targets using plausible parameter values, this often signals that the model structure is misspecified. Even when models fit calibration targets well, it is possible for models with different structures to provide different predictions about the impact of public health responses. Structural uncertainty can be examined with multimodel comparisons, including models with a wide variety of structures. For example, the HIV Modelling Consortium has coordinated multimodel analyses of HIV-related policy questions such as the cost ( 35 ) and cost-effectiveness ( 36 ) of HIV treatment eligibility options, the impact and cost-effectiveness of voluntary medical male circumcision ( 90 ), and the potential harms of interrupting HIV treatment delivery during COVID-19 lockdowns ( 76 ). Each comparison included both individual-based and compartmental models, with some comparisons involving as many as a dozen models with differing structures and assumptions ( 35 , 36 ), providing insight into how structural uncertainty might affect the implications for decision making.
Parametric uncertainty arises from the use of imperfect information to set parameter values or calibration targets. Examples include sampling-related uncertainty in data, biased data, between-study variance in meta-analysis ( 139 ), and divergent or imprecise expert opinions. Models can propagate parameter uncertainty into uncertainty about the impact of response options by sampling different values for parameters and determining their effects on model outputs. For example, COVID-19 models have examined parameter uncertainty regarding R 0 ( 18 , 68 ) and infection fatality rates ( 37 , 151 ) and reported profound implications of this uncertainty on the magnitude of epidemic forecasts and impact of response options such as lockdowns.
Stochastic uncertainty arises from randomness rather than from misspecified model structure or limited data. It manifests when different random-number sequences are used in different simulation runs. Most agent-based models are stochastic. Compartmental models may be either deterministic or stochastic depending on how they are simulated. For example, the Gillespie method is a stochastic compartmental modeling approach in which transitions between compartments always occur in whole-number increments ( 53 , 140 ). Stochastic uncertainty can become large when the population sizes of interest are small or when the nature of disease transmission lends itself to random variability. For example, stochastic models have suggested, due in part to the large role of superspreading events ( 145 ), that there is substantial random uncertainty about which neighborhoods will experience surges of COVID-19 ( 7 ) and whether new viral variants will outcompete already-prevalent variants ( 59 ).
Uncertainty in model outputs, described above, does not always translate into uncertainty in decision making. At times, even when model results are uncertain, they provide sufficient inference for decision making. In this case, uncertainty does not need to be reduced to inform policy choices. At other times, model results are too uncertain to provide inference for decision making. For example, epidemic projections with confidence intervals spanning from nearly 0% to nearly 100% prevalence are unhelpful to decision makers. Structural and parameter uncertainty can be reduced by incorporating additional data that informs model structure, parameter values, calibration targets, or a combination thereof. Stochastic uncertainty can be reduced by performing more model runs and/or increasing the simulated population size, especially if the simulated population is smaller than the actual population.
If model results are still too uncertain, modelers can bound residual uncertainty by designating distinct model scenarios . Scenarios describe model assumptions regarding properties that decision makers cannot control—in contrast to response options, which decision makers can control. For example, if a large driver of uncertainty is whether a pathogen will evolve drug resistance, then modelers may present separate “with drug resistance” and “without drug resistance” scenarios. Having N response options and M scenarios would produce N × M model results. To avoid an overwhelming number of results, modelers should limit scenarios to those that change inference for decision making, with the rest incorporated into residual uncertainty depicted as error bounds around results. The number of scenarios could be reduced further by showing only scenarios that produce high and low extremes of results: an approach known as bounding analysis. For example, early COVID-19 forecasting for the United States by the Institute for Health Metrics and Evaluation used as an upper bound an assumption, based on the highest-observed rates of facemask usage globally (Singapore), that 95% of the population would adopt facemask usage ( 114 ).

Section: APPLICATIONS OF REAL-TIME MODELING DURING PUBLIC HEALTH EMERGENCIES

Public health emergencies require real-time deployment of guidance, policies, and interventions by health authorities. The goal of real-time modeling during emergencies is to contribute evidence when it is impractical to empirically measure the effects of different response options in time for decision making. This goal is accomplished by ( a ) estimating the potential impact of the emergency on the population, ( b ) identifying feasible public health response options and comparing their likely effects on the population, and ( c ) identifying the options that best achieve public health goals.
A prerequisite for modeling public health response options is analyzing what the impact of a public health emergency would be in the absence of changes in decision making. This is termed a baseline. The purpose of a baseline is twofold: to determine the magnitude of a public health emergency and to serve as a comparator for alternative public health responses that involve a change in decision making.
The first purpose of a baseline, determining the magnitude of an emergency, informs the need and scope of subsequent analyses. If the problem is expected to be small relative to other public health decision-making priorities, then it may not warrant a decision-making process until higher priorities are addressed. For example, emergences of mild respiratory pathogens with lower infection fatality ratios (IFRs) than seasonal influenza are not scored on the US Centers for Disease Control and Prevention's (CDC) pandemic severity index ( 96 ) and generally are not prioritized for public health response. If the problem is expected to be large, then it may warrant redirecting resources from other priorities, which could fundamentally change available response options. For example, modeling illuminated the prospect of losing a generation to HIV/AIDS, leading to unprecedented global donations enabling low-income countries to access antiretroviral therapy ( 41 ).
A baseline estimate can also help health authorities inform the public about the nature of the emergency, advocate for additional resources, and mobilize sectors such as health care to prepare for anticipated utilization. For example, during the COVID-19 pandemic, baseline model projections were used to estimate hospital and ventilator demand, informing decisions about allocation of national stockpiles and construction of field hospitals ( 113 ).
The second purpose of a baseline, to serve as a comparator for alternative public health responses, predicts the impact of not changing decision making. Although baselines typically assume that the current public health response will continue, at times it is appropriate to assume future changes to the response based on decisions already made, such as prespecified criteria for deploying emergency resources or imposing and relaxing restrictions on activities. For example, after a lockdown early in the COVID-19 pandemic, New York State declared prespecified criteria for lifting county-level restrictions such as closures of nonessential business. These criteria included 14-day declines in hospitalizations and deaths, new hospitalizations not surpassing 2 per 100,000 residents per day, and at least 30% availability of hospital and intensive care unit (ICU) beds ( 101 ). In this case, an appropriate baseline would predict when the epidemic levels would meet these criteria, and simulate the effects of enacting the prespecified policy changes.
Policy changes occur frequently during rapidly evolving emergencies such as COVID-19 and often necessitate revisions to the baseline. For example, New York State transitioned from the abovementioned county-level criteria to neighborhood-level microcluster criteria to determine the stringency of COVID-19 restrictions ( 45 , 57 ), and later lifted restrictions altogether because vaccines were available to all adults ( 58 ). In our modeling for New York City (NYC) health authorities, each of these changes necessitated revising baseline projections for what would occur in the absence of further changes to decision making ( 15 , 86 – 88 ).
Infectious disease emergencies may be met with a wide variety of public health responses, usually more than can be modeled under the time constraints of real-time decision making. This section classifies the types of responses available—with implications for the types of models best suited to evaluate them—as well as techniques for decision makers to hone their focus on the highest-priority options.
Responses to infectious disease emergencies can be classified broadly as prevention (avoiding entry of an infection into a population), containment (avoiding community transmission after entry has occurred), or mitigation (reducing health consequences, usually once containment has failed). Prevention interventions such as traveler screening tend to be emphasized prior to the arrival of the disease in the population. Containment interventions such as contact tracing tend to be emphasized when a disease has been introduced but has not yet spread widely. Mitigation interventions such as lockdowns or field hospitals tend to be emphasized once a disease is widespread.
Prevention provides a first line of defense against public health emergencies and may include avoiding disease introduction through travel restrictions, avoiding zoonosis through restrictions and precautions around human–animal contacts, or reducing population susceptibility through vaccination. Some infrastructural changes are more feasible to establish at the prevention stage because they involve long lead times: air ventilation and filtration to prevent respiratory infections, water and sewage treatment to prevent enteric infections, safe sex education and resources to prevent sexually transmitted infections, and vector control efforts to prevent vector-borne infections. Models that focus on the probability of disease entering the population do not necessarily need to include transmission. For example, after COVID-19 was identified in Wuhan, China, models based on travel originating in Wuhan helped estimate importation risk into major cities ( 33 ).
Containment is an early response in which an emergency is detected and stopped before it becomes widespread. Containment typically combines surveillance with real-time, geospatial or network-focused responses such as outbreak investigations with tracing and quarantine of exposed contacts. Vaccination may or may not facilitate containment depending on the time required for immunity to develop: Some vaccines provide a rapid prophylactic effect, for example, the smallpox vaccine that was successfully used for ring-fencing outbreaks ( 64 ). Fast-acting prophylaxis strategies such as passive immunization and chemoprophylaxis may also contribute to containment ( 23 , 65 ). Models that evaluate containment typically represent the growth of an outbreak from the time of introduction into a population until the outbreak is too large to be contained. Agent-based network models are especially well suited to model containment strategies because they allow for representation of social networks, which are often important in outbreak investigations ( 67 , 84 ).
Mitigation encompasses interventions to reduce the magnitude of an emergency that was not contained and involves strategies that sometimes overlap with strategies used for prevention and containment. Examples include restrictions on gatherings, behavioral changes such as mask-wearing or condom use, and expansion of health care capacity such as construction of field hospitals and purchases of additional medicines and medical equipment. Vaccines introduced after an emergency was not contained can contribute to mitigation. When mitigation strategies overlap with containment strategies (e.g., contact tracing), they generally require more resources and avert fewer deaths and illnesses when used for mitigation than for containment. Modeling mitigation can be done with a wide variety of model types, including both compartmental and agent based. For example, compartmental SEIR models were widely used to simulate COVID-19 mitigation strategies, either by reducing β to represent fewer transmission-promoting interactions ( 70 , 114 , 143 , 149 ) or by adding compartments to remove individuals under quarantine or lockdown ( 4 , 130 ). Agent-based models were also used and represented these interventions as changes to individual-level susceptibility and infectiousness toward other individuals ( 84 ).
To inform which response options ought to be modeled, and to ensure that the results of modeling are ultimately useful to decision makers, the process of identifying response options should ideally occur collaboratively between decision makers and modelers. When there is sufficient time, the process of selecting the response options for modeling can be formalized by enumerating feasible responses in the realms of prevention, containment, and mitigation and then down-selecting the highest-priority responses by a systematic procedure. For example, stakeholders may be invited to classify responses by level of priority for modeling ( 108 ), to rank responses from highest to lowest priority ( 132 , 148 ), or to allocate points across response options ( 32 , 40 ). Modelers can advise stakeholders in the process on the basis of their prior acquaintance with real-time policy modeling, expertise in disease dynamics, and interpretation of the model's baseline projection. High-priority responses are then discussed, with emphasis on the availability of evidence about their effectiveness and the ability of the model to represent them. Modelers and decision makers together decide on simplifications and assumptions to address limitations of existing evidence and of the model. The process of agreeing on assumptions can be formalized; for example, the estimate-talk-estimate technique, or Delphi method, is commonly used in business forecasting ( 62 ).
When there is not sufficient time to systematically enumerate, down-select, and agree on assumptions for response options, abbreviated procedures may be used. Decision makers may communicate options of interest through verbal or written messages, or modelers may anticipate response options of likely interest by observing responses used in past emergencies and external jurisdictions and by considering the arrival of tools and resources that may present new response options. Abbreviated procedures may run a risk of failing to identify options that are feasible and potentially superior to other options under consideration. Nevertheless, the use of abbreviated procedures is common under time constraints. For example, abbreviated procedures were used to select options for modeling during the initial public health responses to COVID-19 in early 2020 ( 46 , 91 ).
Modeling can be used to identify response options that produce the greatest benefits as defined by the decision maker's goals, which usually include improving the health of the population and may also include reducing health disparities. When evaluating the most beneficial response option, models should consider the potential harms of each response; otherwise, results may be biased in favor of responses that reduce the burden of disease but are not optimal for overall health and well-being. Response options may be limited not only by feasibility constraints but also by resource constraints. Methods to identify optimal responses under resource constraints include allocative efficiency analysis when there are stringent constraints such as a fixed budget ( 28 ) and cost-effectiveness analysis when constraints can be relaxed at the expense of other health priorities ( 55 ).
Many stakeholders define beneficial responses on the basis of directly measurable goals, such as reducing the number of deaths due to a disease. These metrics are limited because they do not consider nonfatal illnesses, the duration of life that is saved, or concomitant changes in quality of life. To overcome these limitations, modelers may compare aggregate metrics of population health, such as the total life expectancy of the population or, when options could significantly affect quality of life, the total health and well-being of the population in units of quality-adjusted life years (QALYs) or the loss of health and well-being in units of disability-adjusted life-years (DALYs) ( 115 , 121 ).
Some decision makers have a utilitarian goal of maximizing QALYs or minimizing DALYs, and others also aim to reduce health disparities, even if this comes at a cost of lower total health—a trade-off known as inequality aversion ( 142 ). Models that include inequality aversion need sufficient complexity to represent disparities in health and longevity, either among individuals or among categories that capture determinants of inequality, for example, the CDC's social vulnerability index (SVI) ( 48 ). For example, in our modeling of COVID-19 vaccination in NYC, we subdivided the NYC population by neighborhood. We found that, looking at a utilitarian goal of minimizing city-wide deaths, achieving equal vaccine coverage by neighborhood was only slightly better than reducing vaccination gaps proportionally to the size of the gap. However, considering inequality aversion based on neighborhood-level SVI greatly increased preference for achieving equitable vaccine coverage rather than for just reducing gaps ( 85 ).
Public health responses can cause harm: Some treatments have side effects, some restrictions inhibit economic and social activity, and some behavior changes are unpleasant and reduce well-being. Disutilities measure how harmful these conditions are perceived to be relative to a state of perfect health and well-being, and indeed factor into the calculus of QALYs and DALYs.
Harms of response options can at times outweigh benefits. For example, COVID-19 lockdowns reduced access to preventative care, such as HIV/AIDS prevention in countries already hard-hit by the HIV/AIDS pandemic ( 76 , 128 ). Modeling was used to compare the health benefits of accessing different HIV services with the potential risk of contracting COVID-19 and found that pausing many types of HIV services would be overall harmful in populations doubly hard-hit by HIV and COVID-19 ( 128 ).
It is not always feasible to quantify harms. For example, school closures have myriad economic, educational, social, and noninfectious health harms that are difficult to estimate ( 8 , 27 , 34 ). When such harms are significant enough to affect decision making but cannot be quantified, models may not be capable of determining the net benefit or harm of a response option. A best practice in this situation is to clearly list the potential harms that modelers are aware of but have not incorporated into quantitative estimates of population health. If unquantified harms are plausibly large enough to change inference for decision making, modelers should reinforce that their analysis is only predictive (i.e., estimating some of the outcomes that would occur under different response options) and not prescriptive (i.e., providing a recommendation about which response is optimal).
When responses are limited by a quantifiable resource constraint, such as a fixed budget or limited supply of a commodity, an optimal response can be identified through an approach known as allocative efficiency analysis ( 28 , 106 ). Allocative efficiency analysis can examine different combinations of interventions, in which increasing one intervention necessitates reducing another. It can also examine different ways to allocate the same interventions among possible beneficiaries in the population. Categories of beneficiaries may factor in geography ( 78 ); age ( 88 ); health disparities ( 147 ); or activity level with respect to transmission, for example, social and occupational activity for respiratory diseases ( 147 ), sexual activity for sexually transmitted diseases ( 22 , 98 , 104 , 111 , 136 ), and water/sewer access for waterborne diseases ( 97 , 131 ).
It is not always accurate to assume resource constraints will remain in place during emergencies. Constraints may be relaxed, for example, by releasing emergency funds ( 112 ), redirecting resources from other programs ( 42 ), or deploying external personnel ( 1 , 51 ). Even constraints on production of commodities can be addressed, for example, through the Defense Production Act in the United States ( 47 ). Modeling can inform decision making about relaxing constraints through cost-effectiveness analysis ( 55 ), which compares the ratio of costs to benefits for a response option with hypothetical alternative uses of those resources ( 38 , 39 , 103 ).
Establishing credibility is important because decision making during public health emergencies is high stakes: Lives hang in the balance ( 43 ). Some decision-making entities have preestablished procedures for vetting models. For example, the World Health Organization's (WHO) Strategic Advisory Group of Experts on Immunization is tasked with technical reviews of models for public health decision making, such as those used to compare response options for poliovirus outbreaks ( 146 ). In contrast, other decision makers lack capacity for technical vetting of models. Although modelers are encouraged to develop technical appendices detailing methods, inputs, and assumptions—and these are required for scientific publication of model results—these may be insufficient when a decision maker does not have time or capacity to conduct a technical review.
Instead, decision makers can gain additional confidence in model credibility by examining whether the model's predictions and behaviors comport with intuitive expectations. This is facilitated by providing illustrative model projections with easily interpretable inputs. For example, a fixed number of interventions could be allocated to specific subpopulations to test whether their impact is greatest in populations that have either heightened risk of disease or heightened participation in transmission. Such exercises may or may not directly inform public health response options, but they provide decision makers with a rapid intuitive understanding of the model's behavior.
Once credibility is established, the primary goal is to address priority questions, which usually center around simulations of realistic response options. An effective template for communicating more complex response options includes ( a ) a parsimonious description of key modeling inputs, assumptions, and limitations; ( b ) model results that provide useful inference for decision making; and ( c ) a summary of the interpretation, implications, and limitations of the results. This format can be repeated for successive decision-making questions, which can occur with frequent iterations during a public health emergency.
A prerequisite for modeling public health response options is analyzing what the impact of a public health emergency would be in the absence of changes in decision making. This is termed a baseline. The purpose of a baseline is twofold: to determine the magnitude of a public health emergency and to serve as a comparator for alternative public health responses that involve a change in decision making.
The first purpose of a baseline, determining the magnitude of an emergency, informs the need and scope of subsequent analyses. If the problem is expected to be small relative to other public health decision-making priorities, then it may not warrant a decision-making process until higher priorities are addressed. For example, emergences of mild respiratory pathogens with lower infection fatality ratios (IFRs) than seasonal influenza are not scored on the US Centers for Disease Control and Prevention's (CDC) pandemic severity index ( 96 ) and generally are not prioritized for public health response. If the problem is expected to be large, then it may warrant redirecting resources from other priorities, which could fundamentally change available response options. For example, modeling illuminated the prospect of losing a generation to HIV/AIDS, leading to unprecedented global donations enabling low-income countries to access antiretroviral therapy ( 41 ).
A baseline estimate can also help health authorities inform the public about the nature of the emergency, advocate for additional resources, and mobilize sectors such as health care to prepare for anticipated utilization. For example, during the COVID-19 pandemic, baseline model projections were used to estimate hospital and ventilator demand, informing decisions about allocation of national stockpiles and construction of field hospitals ( 113 ).
The second purpose of a baseline, to serve as a comparator for alternative public health responses, predicts the impact of not changing decision making. Although baselines typically assume that the current public health response will continue, at times it is appropriate to assume future changes to the response based on decisions already made, such as prespecified criteria for deploying emergency resources or imposing and relaxing restrictions on activities. For example, after a lockdown early in the COVID-19 pandemic, New York State declared prespecified criteria for lifting county-level restrictions such as closures of nonessential business. These criteria included 14-day declines in hospitalizations and deaths, new hospitalizations not surpassing 2 per 100,000 residents per day, and at least 30% availability of hospital and intensive care unit (ICU) beds ( 101 ). In this case, an appropriate baseline would predict when the epidemic levels would meet these criteria, and simulate the effects of enacting the prespecified policy changes.
Policy changes occur frequently during rapidly evolving emergencies such as COVID-19 and often necessitate revisions to the baseline. For example, New York State transitioned from the abovementioned county-level criteria to neighborhood-level microcluster criteria to determine the stringency of COVID-19 restrictions ( 45 , 57 ), and later lifted restrictions altogether because vaccines were available to all adults ( 58 ). In our modeling for New York City (NYC) health authorities, each of these changes necessitated revising baseline projections for what would occur in the absence of further changes to decision making ( 15 , 86 – 88 ).
Infectious disease emergencies may be met with a wide variety of public health responses, usually more than can be modeled under the time constraints of real-time decision making. This section classifies the types of responses available—with implications for the types of models best suited to evaluate them—as well as techniques for decision makers to hone their focus on the highest-priority options.
Responses to infectious disease emergencies can be classified broadly as prevention (avoiding entry of an infection into a population), containment (avoiding community transmission after entry has occurred), or mitigation (reducing health consequences, usually once containment has failed). Prevention interventions such as traveler screening tend to be emphasized prior to the arrival of the disease in the population. Containment interventions such as contact tracing tend to be emphasized when a disease has been introduced but has not yet spread widely. Mitigation interventions such as lockdowns or field hospitals tend to be emphasized once a disease is widespread.
Prevention provides a first line of defense against public health emergencies and may include avoiding disease introduction through travel restrictions, avoiding zoonosis through restrictions and precautions around human–animal contacts, or reducing population susceptibility through vaccination. Some infrastructural changes are more feasible to establish at the prevention stage because they involve long lead times: air ventilation and filtration to prevent respiratory infections, water and sewage treatment to prevent enteric infections, safe sex education and resources to prevent sexually transmitted infections, and vector control efforts to prevent vector-borne infections. Models that focus on the probability of disease entering the population do not necessarily need to include transmission. For example, after COVID-19 was identified in Wuhan, China, models based on travel originating in Wuhan helped estimate importation risk into major cities ( 33 ).
Containment is an early response in which an emergency is detected and stopped before it becomes widespread. Containment typically combines surveillance with real-time, geospatial or network-focused responses such as outbreak investigations with tracing and quarantine of exposed contacts. Vaccination may or may not facilitate containment depending on the time required for immunity to develop: Some vaccines provide a rapid prophylactic effect, for example, the smallpox vaccine that was successfully used for ring-fencing outbreaks ( 64 ). Fast-acting prophylaxis strategies such as passive immunization and chemoprophylaxis may also contribute to containment ( 23 , 65 ). Models that evaluate containment typically represent the growth of an outbreak from the time of introduction into a population until the outbreak is too large to be contained. Agent-based network models are especially well suited to model containment strategies because they allow for representation of social networks, which are often important in outbreak investigations ( 67 , 84 ).
Mitigation encompasses interventions to reduce the magnitude of an emergency that was not contained and involves strategies that sometimes overlap with strategies used for prevention and containment. Examples include restrictions on gatherings, behavioral changes such as mask-wearing or condom use, and expansion of health care capacity such as construction of field hospitals and purchases of additional medicines and medical equipment. Vaccines introduced after an emergency was not contained can contribute to mitigation. When mitigation strategies overlap with containment strategies (e.g., contact tracing), they generally require more resources and avert fewer deaths and illnesses when used for mitigation than for containment. Modeling mitigation can be done with a wide variety of model types, including both compartmental and agent based. For example, compartmental SEIR models were widely used to simulate COVID-19 mitigation strategies, either by reducing β to represent fewer transmission-promoting interactions ( 70 , 114 , 143 , 149 ) or by adding compartments to remove individuals under quarantine or lockdown ( 4 , 130 ). Agent-based models were also used and represented these interventions as changes to individual-level susceptibility and infectiousness toward other individuals ( 84 ).
To inform which response options ought to be modeled, and to ensure that the results of modeling are ultimately useful to decision makers, the process of identifying response options should ideally occur collaboratively between decision makers and modelers. When there is sufficient time, the process of selecting the response options for modeling can be formalized by enumerating feasible responses in the realms of prevention, containment, and mitigation and then down-selecting the highest-priority responses by a systematic procedure. For example, stakeholders may be invited to classify responses by level of priority for modeling ( 108 ), to rank responses from highest to lowest priority ( 132 , 148 ), or to allocate points across response options ( 32 , 40 ). Modelers can advise stakeholders in the process on the basis of their prior acquaintance with real-time policy modeling, expertise in disease dynamics, and interpretation of the model's baseline projection. High-priority responses are then discussed, with emphasis on the availability of evidence about their effectiveness and the ability of the model to represent them. Modelers and decision makers together decide on simplifications and assumptions to address limitations of existing evidence and of the model. The process of agreeing on assumptions can be formalized; for example, the estimate-talk-estimate technique, or Delphi method, is commonly used in business forecasting ( 62 ).
When there is not sufficient time to systematically enumerate, down-select, and agree on assumptions for response options, abbreviated procedures may be used. Decision makers may communicate options of interest through verbal or written messages, or modelers may anticipate response options of likely interest by observing responses used in past emergencies and external jurisdictions and by considering the arrival of tools and resources that may present new response options. Abbreviated procedures may run a risk of failing to identify options that are feasible and potentially superior to other options under consideration. Nevertheless, the use of abbreviated procedures is common under time constraints. For example, abbreviated procedures were used to select options for modeling during the initial public health responses to COVID-19 in early 2020 ( 46 , 91 ).
Modeling can be used to identify response options that produce the greatest benefits as defined by the decision maker's goals, which usually include improving the health of the population and may also include reducing health disparities. When evaluating the most beneficial response option, models should consider the potential harms of each response; otherwise, results may be biased in favor of responses that reduce the burden of disease but are not optimal for overall health and well-being. Response options may be limited not only by feasibility constraints but also by resource constraints. Methods to identify optimal responses under resource constraints include allocative efficiency analysis when there are stringent constraints such as a fixed budget ( 28 ) and cost-effectiveness analysis when constraints can be relaxed at the expense of other health priorities ( 55 ).
Many stakeholders define beneficial responses on the basis of directly measurable goals, such as reducing the number of deaths due to a disease. These metrics are limited because they do not consider nonfatal illnesses, the duration of life that is saved, or concomitant changes in quality of life. To overcome these limitations, modelers may compare aggregate metrics of population health, such as the total life expectancy of the population or, when options could significantly affect quality of life, the total health and well-being of the population in units of quality-adjusted life years (QALYs) or the loss of health and well-being in units of disability-adjusted life-years (DALYs) ( 115 , 121 ).
Some decision makers have a utilitarian goal of maximizing QALYs or minimizing DALYs, and others also aim to reduce health disparities, even if this comes at a cost of lower total health—a trade-off known as inequality aversion ( 142 ). Models that include inequality aversion need sufficient complexity to represent disparities in health and longevity, either among individuals or among categories that capture determinants of inequality, for example, the CDC's social vulnerability index (SVI) ( 48 ). For example, in our modeling of COVID-19 vaccination in NYC, we subdivided the NYC population by neighborhood. We found that, looking at a utilitarian goal of minimizing city-wide deaths, achieving equal vaccine coverage by neighborhood was only slightly better than reducing vaccination gaps proportionally to the size of the gap. However, considering inequality aversion based on neighborhood-level SVI greatly increased preference for achieving equitable vaccine coverage rather than for just reducing gaps ( 85 ).
Public health responses can cause harm: Some treatments have side effects, some restrictions inhibit economic and social activity, and some behavior changes are unpleasant and reduce well-being. Disutilities measure how harmful these conditions are perceived to be relative to a state of perfect health and well-being, and indeed factor into the calculus of QALYs and DALYs.
Harms of response options can at times outweigh benefits. For example, COVID-19 lockdowns reduced access to preventative care, such as HIV/AIDS prevention in countries already hard-hit by the HIV/AIDS pandemic ( 76 , 128 ). Modeling was used to compare the health benefits of accessing different HIV services with the potential risk of contracting COVID-19 and found that pausing many types of HIV services would be overall harmful in populations doubly hard-hit by HIV and COVID-19 ( 128 ).
It is not always feasible to quantify harms. For example, school closures have myriad economic, educational, social, and noninfectious health harms that are difficult to estimate ( 8 , 27 , 34 ). When such harms are significant enough to affect decision making but cannot be quantified, models may not be capable of determining the net benefit or harm of a response option. A best practice in this situation is to clearly list the potential harms that modelers are aware of but have not incorporated into quantitative estimates of population health. If unquantified harms are plausibly large enough to change inference for decision making, modelers should reinforce that their analysis is only predictive (i.e., estimating some of the outcomes that would occur under different response options) and not prescriptive (i.e., providing a recommendation about which response is optimal).
When responses are limited by a quantifiable resource constraint, such as a fixed budget or limited supply of a commodity, an optimal response can be identified through an approach known as allocative efficiency analysis ( 28 , 106 ). Allocative efficiency analysis can examine different combinations of interventions, in which increasing one intervention necessitates reducing another. It can also examine different ways to allocate the same interventions among possible beneficiaries in the population. Categories of beneficiaries may factor in geography ( 78 ); age ( 88 ); health disparities ( 147 ); or activity level with respect to transmission, for example, social and occupational activity for respiratory diseases ( 147 ), sexual activity for sexually transmitted diseases ( 22 , 98 , 104 , 111 , 136 ), and water/sewer access for waterborne diseases ( 97 , 131 ).
It is not always accurate to assume resource constraints will remain in place during emergencies. Constraints may be relaxed, for example, by releasing emergency funds ( 112 ), redirecting resources from other programs ( 42 ), or deploying external personnel ( 1 , 51 ). Even constraints on production of commodities can be addressed, for example, through the Defense Production Act in the United States ( 47 ). Modeling can inform decision making about relaxing constraints through cost-effectiveness analysis ( 55 ), which compares the ratio of costs to benefits for a response option with hypothetical alternative uses of those resources ( 38 , 39 , 103 ).
Establishing credibility is important because decision making during public health emergencies is high stakes: Lives hang in the balance ( 43 ). Some decision-making entities have preestablished procedures for vetting models. For example, the World Health Organization's (WHO) Strategic Advisory Group of Experts on Immunization is tasked with technical reviews of models for public health decision making, such as those used to compare response options for poliovirus outbreaks ( 146 ). In contrast, other decision makers lack capacity for technical vetting of models. Although modelers are encouraged to develop technical appendices detailing methods, inputs, and assumptions—and these are required for scientific publication of model results—these may be insufficient when a decision maker does not have time or capacity to conduct a technical review.
Instead, decision makers can gain additional confidence in model credibility by examining whether the model's predictions and behaviors comport with intuitive expectations. This is facilitated by providing illustrative model projections with easily interpretable inputs. For example, a fixed number of interventions could be allocated to specific subpopulations to test whether their impact is greatest in populations that have either heightened risk of disease or heightened participation in transmission. Such exercises may or may not directly inform public health response options, but they provide decision makers with a rapid intuitive understanding of the model's behavior.
Once credibility is established, the primary goal is to address priority questions, which usually center around simulations of realistic response options. An effective template for communicating more complex response options includes ( a ) a parsimonious description of key modeling inputs, assumptions, and limitations; ( b ) model results that provide useful inference for decision making; and ( c ) a summary of the interpretation, implications, and limitations of the results. This format can be repeated for successive decision-making questions, which can occur with frequent iterations during a public health emergency.

Section: CHALLENGES AND OPPORTUNITIES FOR REAL-TIME INFECTIOUS DISEASE MODELING DURING PUBLIC HEALTH EMERGENCIES

Infectious disease modeling under time constraints raises methodological challenges, data challenges, and communication challenges. Modeling has advanced considerably in recent decades, but more remains to be done to improve the timeliness and usefulness of real-time modeling during public health emergencies.
Building, calibrating, and running models during time-sensitive emergencies raise methodological challenges and impose trade-offs. Simpler models are faster to build, calibrate, and run and are not necessarily less accurate, provided they capture the important phenomena and dynamics of the modeled system. However, simple models are not suitable for all questions—for example, those that are specific to social networks—and often require rebuilding in order to answer new questions or offer greater levels of granularity. Complex models are time-consuming to build and may involve time spent on elements that are not strictly required for immediate decision making. However, they provide flexibility to answer new questions or provide higher levels of granularity. Agent-based models are not only flexible but also extensible: New attributes can be added with only small increments in complexity ( 134 ).
Complex models are more computationally intensive, requiring more time to calibrate and to generate results. Advances in supercomputing have enabled use of more complex models, but models that take days or longer to run on modern supercomputers may be impractical for real-time decision-making support. Speed can be improved by profiling and optimizing model code, but this requires additional time to build models and specialized computer programming expertise.
We experienced extremes of model simplicity and complexity in the contexts of the COVID-19 and HIV/AIDS pandemics and reflect here on the challenges and trade-offs during these experiences.
We had only a few days to prepare results for NYC health authorities at the start of the COVID-19 pandemic. Early questions centered on the effects of shutdown on health care demand. We chose the simplest model that could address the question: an SEIR model augmented with hospitalization, ICU admission, ventilator use, and mortality rates adjusted for the NYC population's age and health conditions. We found that our projections were accurate for a short-term forecast of up to 2 weeks, with sufficiently low uncertainty to provide useful input for decision making. However, we were initially unable to provide projections longer than 2 weeks, as uncertainty in our longer-term projections was too large to be useful ( 86 ).
Shortly thereafter, decision making pivoted to establishing the NYC Test & Trace Corps, and we redesigned the model to add testing, contact tracing, and quarantine ( 89 ). At the same time, inputs to our model improved owing to improved estimates of disease progression such as hospital length of stay, transmission such as the household secondary attack rate, and intervention effectiveness such as mask-wearing. Additionally, having some past data regarding epidemic trends—if only a few weeks’ worth—enabled us to perform model calibration, which helped provide inference for uncertain model parameters and improve model credibility. With these improvements, we could provide projections for up to 1 month into the future ( 15 ).
Next, neighborhood-level data revealed disparities in COVID-19 burden, which were a focal point of decision making. We rebuilt our simple model to represent each NYC neighborhood separately. Redesigning and recalibrating the model under time pressure were challenging; we did our best to keep up with decision-making timelines, but at the expense of many nights and weekends. Our revised model was still insufficiently complex to account for superspreading events, which we knew were important contributors to neighborhood-level differences in transmission ( 145 ). For this reason, we continued to limit projections to 1 month into the future and could not address questions closely tied to superspreading, such as emergence rates of new variants ( 59 ).
A year after the start of the COVID-19 pandemic in NYC, we have been able to draw on past observations of transmission, emergence of variants, and impact of past policy changes to make simple assumptions regarding these phenomena. We now provide tentative model forecasts up to 6 months into the future ( 85 ), albeit with clearly stated assumptions and limitations and with frequent revisions as new policies and epidemic conditions emerge.
We had several months during the HIV/AIDS pandemic to prepare model results for the WHO's revision of global HIV treatment guidelines. Through the HIV Modelling Consortium, we contributed evidence to three revisions of global guidelines, a collaboration that ultimately spanned multiple years ( 36 ). Unlike our COVID-19 experience developing short-term projections to inform rapidly evolving policies, this collaboration requested model projections for decades into the future, with the intention of rolling out and monitoring changes to treatment practices across the globe.
The longer lead time of this collaboration enabled us to develop more complex models: a compartmental model with detailed drug adherence and resistance ( 20 ) and an agent-based model with a network of age- and risk-specific sexual relationships and distinct modalities of testing and engagement in care ( 14 ). Both models proved extensible and repurposable: They have been applied to numerous questions ranging from HIV prevention ( 90 , 99 ) to patient care ( 21 , 123 ), including questions suitable only for complex models, such as how sexual networks influence the population distribution of HIV infections ( 2 , 16 , 17 ).
Relative to our experience with COVID-19, we had a long time series of past data regarding HIV epidemic trends. Calibration of our models was time-consuming not only because of the complex history of epidemic trends and past responses but also because the models themselves were more complex, with more free parameters and, in the case of the agent-based model, stochastic uncertainty. Despite using specialized calibration algorithms leveraging supercomputers ( 3 ), calibration took several weeks—a time investment only feasible given the long lead time we received from decision makers.
Once calibration was complete, we benefited from models that captured mechanisms of HIV transmission and progression often overlooked by simple models, that passed rigorous validation tests such as prospectively predicting study results ( 75 ), and that could be used to generate decades-long projections as requested by decision makers ( 36 ).
Though challenging under any circumstances, data access and analysis are especially challenging under the time constraints of emergency decision making. Under time constraints, data might be analyzed with more expedience but with reduced rigor, for example, rapid literature reviews ( 26 , 116 ) versus more time-consuming systematic reviews ( 66 , 152 ) or primary data analyses. Informative data might be inadvertently excluded, or data use agreements may not be negotiated in time.
Data availability may be hindered by delays in data collection, processing, and dissemination: for example, publication delays and delays in establishing data use agreements. For newly emerging pathogens, early data are especially prone to biases such as missing milder or later stages of infection, for example, the long latent stage of HIV infection, which was not evident from early case reports ( 29 ) but proved vital to predicting the long-term course of the HIV/AIDS pandemic ( 81 , 107 ). Early estimates for severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) infection fatality rates were as high as 15% ( 11 , 150 ) due to oversampling of severe cases; recent estimates fall in the 0.20–1.63% range ( 72 , 73 ).
Analyzing data to inform model parameters and calibration targets can be extraordinarily time-consuming. When using estimates from scientific literature, systematic reviews and meta-analyses traditionally take months to complete. In emergencies, less rigorous rapid reviews are sometimes used but risk incomplete evidence synthesis ( 124 ). Primary data analysis can be time-consuming to adjust for bias and test for external validity, especially generalizability from a subpopulation to the overall population ( 92 ) and transportability from an external population to the one of interest ( 126 ), and availability of additional data to assess external validity may be limited. Abbreviating data analysis procedures such as assessments of external validity and adjustments for bias can lead to incorrect model parameterization. For example, the ability to interrupt SARS-CoV-2 transmission through lockdowns in Wuhan, China, proved not to be transportable to the United States, leading to erroneously low initial projections of COVID-19 mortality ( 71 ).
Routinizing generation, dissemination, and analysis of relevant and timely data streams in nonemergency times can improve preparedness for the next public health emergency. Digital open-access data sets such as municipal health data dashboards ( 10 , 100 ) and genome sequence repositories reduce delays in data dissemination ( 54 ). Manuscript preprints reduce publication delays, albeit at the expense of scientific peer review. Crowdsourced data mining is emerging as a valuable data source with demonstrated relevance in seasonal epidemics ( 102 ), for example, successful prediction of respiratory syncytial virus rates from internet search patterns ( 6 , 105 ). The use of crowdsourced data swelled during COVID-19, for example, use of mobile phone geolocation to monitor adherence to stay-at-home guidelines and to identify destinations associated with transmission ( 25 ).
Emergencies place high demands on attention, comprehension, retention, and interpretation of information. Advanced and unfamiliar concepts and time pressure add to the cognitive burden. Comprehension challenges can be especially high when results are unintuitive, as often occurs with the nonlinear dynamics of infectious diseases. Together, these elements pose challenges for communication between modelers and decision makers, but the use of evidence-based practices grounded in cognitive load theory (CLT) can improve communication under even these challenging circumstances.
CLT is a model of cognitive processes based on cognitive psychology research and supported by evolutionary principles ( 129 ). CLT offers insights for modelers into how to diminish the cognitive load that decision makers experience when receiving model results, facilitating better decisions as well as greater comfort and satisfaction with models.
CLT stipulates that most cognitive resources are limited; therefore, maximal efficiency in learning, comprehension, and decision making requires efficient use of those resources. CLT divides memory into working memory (WM) and long-term memory (LTM). WM is the learning bottleneck because its capabilities are limited in volume (limited to 7 ± 2 simple or 3 complex pieces of information) and time (information is retained for approximately 20 seconds) ( 95 ). For learning to occur, WM information must be converted into LTM-compatible knowledge, or schema, within these limited time and throughput constraints. Schema are chunks of conceptually linked information that are structured relative to other knowledge and are organized to facilitate later retrieval. WM is tasked not only with processing new information but also with integrating related knowledge for deliberation and decision making. Because of the profound limitations on WM cognitive resources, typically only a small portion of available information is converted into schema.
CLT distinguishes three types of cognitive resources that affect WM: intrinsic cognitive load (ICL), extraneous cognitive load (ECL), and germane cognitive load (GCL) ( 50 , 129 ). ICL is mostly unmodifiable and arises from the intrinsic complexity of new material. ECL is mostly modifiable and arises from distractions or needlessly complex formats of new material. GCL is that portion of ICL that is usefully harnessed for learning by organizing new information into schema. The cognitive burden of ICL and ECL is additive, so learning is optimized when ECL is minimized, generally by reducing distractions and extraneous information, and ICL is maximally allocated toward GCL, generally by presenting information in a schema-ready manner (i.e., conceptually predigested and with identifiable relations to what is already known).
Modelers communicating results to decision makers should strive to minimize ECL and facilitate GCL-mediated throughput from ICL ( 52 , 110 ). Particularly important practices include eliminating information that is extraneous, redundant, or otherwise unnecessary for decision making; discussing new information in the context of what is familiar and known; and creating presentations free of avoidable distractions or diversions. Table 1 provides some guiding principles for applying CLT to communication of modeling results. Viewed through the lens of CLT, one can notice myriad ways in which modelers communicate results that facilitate attention, comprehension, retention, and interpretation by decision makers, as well as opportunities for improvement.
Guiding principles for applying CLT to communication of modeling results
Abbreviations: CLT, cognitive load theory; ECL, extraneous cognitive load; ICL, intrinsic cognitive load; GCL, germane cognitive load.

Choices regarding display and formatting of numeric data are especially important given the quantitative nature of disease modeling. Multidimensional analyses, such as the interaction of multiple model parameters in determining model results, can be particularly challenging to convey in manners consistent with CLT. During our collaboration with NYC health authorities during the COVID-19 pandemic, we presented model results as time series graphs whenever possible because most audiences find a time axis to be more familiar than other left-to-right axes. Using consistent colors and labels for scenarios helped further reduce cognitive load.
Infectious disease dynamics can be unintuitive, making it challenging to process into schema for integration into LTM. Articulating analogies to commonly observed phenomena can help create the requisite conceptual linkages between unintuitive model results and preexisting knowledge. Common analogies for infectious disease dynamics involve situations in which a random event initiates a process that is self-perpetuating and escalating, for example, a susceptible population as “dry tinder,” introduction of disease as a “spark,” and herd immunity as a fire “burning out” ( 144 ). Seismic metaphors may be used when a population's predisposition for an outcome is dwarfed by the initiating random event (e.g., “epicenter” or “tsunami”). War analogies are sometimes used to emphasize high stakes and the need for complex, sometimes counterintuitive strategies ( 30 ).
Technology can be leveraged to overcome some challenges related to cognitive load. For example, in some situations, decision makers may not know in advance which subset of information will be most relevant in the moment of decision making and therefore may request abundant amounts of information. To circumvent the limitations of retaining abundant information in LTM, interactive dashboards can offer on-demand access to results, with selection menus and toggles to conjure only those results that are immediately relevant. Software packages for facile dashboard development are available in popular programming languages such as R ( 118 ) and Python ( 137 ). For modelers or decision makers who prefer to avoid dashboards, a searchable document or set of digital viewgraphs with a clear table of contents can provide another form of on-demand access to results.
Building, calibrating, and running models during time-sensitive emergencies raise methodological challenges and impose trade-offs. Simpler models are faster to build, calibrate, and run and are not necessarily less accurate, provided they capture the important phenomena and dynamics of the modeled system. However, simple models are not suitable for all questions—for example, those that are specific to social networks—and often require rebuilding in order to answer new questions or offer greater levels of granularity. Complex models are time-consuming to build and may involve time spent on elements that are not strictly required for immediate decision making. However, they provide flexibility to answer new questions or provide higher levels of granularity. Agent-based models are not only flexible but also extensible: New attributes can be added with only small increments in complexity ( 134 ).
Complex models are more computationally intensive, requiring more time to calibrate and to generate results. Advances in supercomputing have enabled use of more complex models, but models that take days or longer to run on modern supercomputers may be impractical for real-time decision-making support. Speed can be improved by profiling and optimizing model code, but this requires additional time to build models and specialized computer programming expertise.
We experienced extremes of model simplicity and complexity in the contexts of the COVID-19 and HIV/AIDS pandemics and reflect here on the challenges and trade-offs during these experiences.
We had only a few days to prepare results for NYC health authorities at the start of the COVID-19 pandemic. Early questions centered on the effects of shutdown on health care demand. We chose the simplest model that could address the question: an SEIR model augmented with hospitalization, ICU admission, ventilator use, and mortality rates adjusted for the NYC population's age and health conditions. We found that our projections were accurate for a short-term forecast of up to 2 weeks, with sufficiently low uncertainty to provide useful input for decision making. However, we were initially unable to provide projections longer than 2 weeks, as uncertainty in our longer-term projections was too large to be useful ( 86 ).
Shortly thereafter, decision making pivoted to establishing the NYC Test & Trace Corps, and we redesigned the model to add testing, contact tracing, and quarantine ( 89 ). At the same time, inputs to our model improved owing to improved estimates of disease progression such as hospital length of stay, transmission such as the household secondary attack rate, and intervention effectiveness such as mask-wearing. Additionally, having some past data regarding epidemic trends—if only a few weeks’ worth—enabled us to perform model calibration, which helped provide inference for uncertain model parameters and improve model credibility. With these improvements, we could provide projections for up to 1 month into the future ( 15 ).
Next, neighborhood-level data revealed disparities in COVID-19 burden, which were a focal point of decision making. We rebuilt our simple model to represent each NYC neighborhood separately. Redesigning and recalibrating the model under time pressure were challenging; we did our best to keep up with decision-making timelines, but at the expense of many nights and weekends. Our revised model was still insufficiently complex to account for superspreading events, which we knew were important contributors to neighborhood-level differences in transmission ( 145 ). For this reason, we continued to limit projections to 1 month into the future and could not address questions closely tied to superspreading, such as emergence rates of new variants ( 59 ).
A year after the start of the COVID-19 pandemic in NYC, we have been able to draw on past observations of transmission, emergence of variants, and impact of past policy changes to make simple assumptions regarding these phenomena. We now provide tentative model forecasts up to 6 months into the future ( 85 ), albeit with clearly stated assumptions and limitations and with frequent revisions as new policies and epidemic conditions emerge.
We had several months during the HIV/AIDS pandemic to prepare model results for the WHO's revision of global HIV treatment guidelines. Through the HIV Modelling Consortium, we contributed evidence to three revisions of global guidelines, a collaboration that ultimately spanned multiple years ( 36 ). Unlike our COVID-19 experience developing short-term projections to inform rapidly evolving policies, this collaboration requested model projections for decades into the future, with the intention of rolling out and monitoring changes to treatment practices across the globe.
The longer lead time of this collaboration enabled us to develop more complex models: a compartmental model with detailed drug adherence and resistance ( 20 ) and an agent-based model with a network of age- and risk-specific sexual relationships and distinct modalities of testing and engagement in care ( 14 ). Both models proved extensible and repurposable: They have been applied to numerous questions ranging from HIV prevention ( 90 , 99 ) to patient care ( 21 , 123 ), including questions suitable only for complex models, such as how sexual networks influence the population distribution of HIV infections ( 2 , 16 , 17 ).
Relative to our experience with COVID-19, we had a long time series of past data regarding HIV epidemic trends. Calibration of our models was time-consuming not only because of the complex history of epidemic trends and past responses but also because the models themselves were more complex, with more free parameters and, in the case of the agent-based model, stochastic uncertainty. Despite using specialized calibration algorithms leveraging supercomputers ( 3 ), calibration took several weeks—a time investment only feasible given the long lead time we received from decision makers.
Once calibration was complete, we benefited from models that captured mechanisms of HIV transmission and progression often overlooked by simple models, that passed rigorous validation tests such as prospectively predicting study results ( 75 ), and that could be used to generate decades-long projections as requested by decision makers ( 36 ).
Though challenging under any circumstances, data access and analysis are especially challenging under the time constraints of emergency decision making. Under time constraints, data might be analyzed with more expedience but with reduced rigor, for example, rapid literature reviews ( 26 , 116 ) versus more time-consuming systematic reviews ( 66 , 152 ) or primary data analyses. Informative data might be inadvertently excluded, or data use agreements may not be negotiated in time.
Data availability may be hindered by delays in data collection, processing, and dissemination: for example, publication delays and delays in establishing data use agreements. For newly emerging pathogens, early data are especially prone to biases such as missing milder or later stages of infection, for example, the long latent stage of HIV infection, which was not evident from early case reports ( 29 ) but proved vital to predicting the long-term course of the HIV/AIDS pandemic ( 81 , 107 ). Early estimates for severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) infection fatality rates were as high as 15% ( 11 , 150 ) due to oversampling of severe cases; recent estimates fall in the 0.20–1.63% range ( 72 , 73 ).
Analyzing data to inform model parameters and calibration targets can be extraordinarily time-consuming. When using estimates from scientific literature, systematic reviews and meta-analyses traditionally take months to complete. In emergencies, less rigorous rapid reviews are sometimes used but risk incomplete evidence synthesis ( 124 ). Primary data analysis can be time-consuming to adjust for bias and test for external validity, especially generalizability from a subpopulation to the overall population ( 92 ) and transportability from an external population to the one of interest ( 126 ), and availability of additional data to assess external validity may be limited. Abbreviating data analysis procedures such as assessments of external validity and adjustments for bias can lead to incorrect model parameterization. For example, the ability to interrupt SARS-CoV-2 transmission through lockdowns in Wuhan, China, proved not to be transportable to the United States, leading to erroneously low initial projections of COVID-19 mortality ( 71 ).
Routinizing generation, dissemination, and analysis of relevant and timely data streams in nonemergency times can improve preparedness for the next public health emergency. Digital open-access data sets such as municipal health data dashboards ( 10 , 100 ) and genome sequence repositories reduce delays in data dissemination ( 54 ). Manuscript preprints reduce publication delays, albeit at the expense of scientific peer review. Crowdsourced data mining is emerging as a valuable data source with demonstrated relevance in seasonal epidemics ( 102 ), for example, successful prediction of respiratory syncytial virus rates from internet search patterns ( 6 , 105 ). The use of crowdsourced data swelled during COVID-19, for example, use of mobile phone geolocation to monitor adherence to stay-at-home guidelines and to identify destinations associated with transmission ( 25 ).
Emergencies place high demands on attention, comprehension, retention, and interpretation of information. Advanced and unfamiliar concepts and time pressure add to the cognitive burden. Comprehension challenges can be especially high when results are unintuitive, as often occurs with the nonlinear dynamics of infectious diseases. Together, these elements pose challenges for communication between modelers and decision makers, but the use of evidence-based practices grounded in cognitive load theory (CLT) can improve communication under even these challenging circumstances.
CLT is a model of cognitive processes based on cognitive psychology research and supported by evolutionary principles ( 129 ). CLT offers insights for modelers into how to diminish the cognitive load that decision makers experience when receiving model results, facilitating better decisions as well as greater comfort and satisfaction with models.
CLT stipulates that most cognitive resources are limited; therefore, maximal efficiency in learning, comprehension, and decision making requires efficient use of those resources. CLT divides memory into working memory (WM) and long-term memory (LTM). WM is the learning bottleneck because its capabilities are limited in volume (limited to 7 ± 2 simple or 3 complex pieces of information) and time (information is retained for approximately 20 seconds) ( 95 ). For learning to occur, WM information must be converted into LTM-compatible knowledge, or schema, within these limited time and throughput constraints. Schema are chunks of conceptually linked information that are structured relative to other knowledge and are organized to facilitate later retrieval. WM is tasked not only with processing new information but also with integrating related knowledge for deliberation and decision making. Because of the profound limitations on WM cognitive resources, typically only a small portion of available information is converted into schema.
CLT distinguishes three types of cognitive resources that affect WM: intrinsic cognitive load (ICL), extraneous cognitive load (ECL), and germane cognitive load (GCL) ( 50 , 129 ). ICL is mostly unmodifiable and arises from the intrinsic complexity of new material. ECL is mostly modifiable and arises from distractions or needlessly complex formats of new material. GCL is that portion of ICL that is usefully harnessed for learning by organizing new information into schema. The cognitive burden of ICL and ECL is additive, so learning is optimized when ECL is minimized, generally by reducing distractions and extraneous information, and ICL is maximally allocated toward GCL, generally by presenting information in a schema-ready manner (i.e., conceptually predigested and with identifiable relations to what is already known).
Modelers communicating results to decision makers should strive to minimize ECL and facilitate GCL-mediated throughput from ICL ( 52 , 110 ). Particularly important practices include eliminating information that is extraneous, redundant, or otherwise unnecessary for decision making; discussing new information in the context of what is familiar and known; and creating presentations free of avoidable distractions or diversions. Table 1 provides some guiding principles for applying CLT to communication of modeling results. Viewed through the lens of CLT, one can notice myriad ways in which modelers communicate results that facilitate attention, comprehension, retention, and interpretation by decision makers, as well as opportunities for improvement.
Guiding principles for applying CLT to communication of modeling results
Abbreviations: CLT, cognitive load theory; ECL, extraneous cognitive load; ICL, intrinsic cognitive load; GCL, germane cognitive load.

Choices regarding display and formatting of numeric data are especially important given the quantitative nature of disease modeling. Multidimensional analyses, such as the interaction of multiple model parameters in determining model results, can be particularly challenging to convey in manners consistent with CLT. During our collaboration with NYC health authorities during the COVID-19 pandemic, we presented model results as time series graphs whenever possible because most audiences find a time axis to be more familiar than other left-to-right axes. Using consistent colors and labels for scenarios helped further reduce cognitive load.
Infectious disease dynamics can be unintuitive, making it challenging to process into schema for integration into LTM. Articulating analogies to commonly observed phenomena can help create the requisite conceptual linkages between unintuitive model results and preexisting knowledge. Common analogies for infectious disease dynamics involve situations in which a random event initiates a process that is self-perpetuating and escalating, for example, a susceptible population as “dry tinder,” introduction of disease as a “spark,” and herd immunity as a fire “burning out” ( 144 ). Seismic metaphors may be used when a population's predisposition for an outcome is dwarfed by the initiating random event (e.g., “epicenter” or “tsunami”). War analogies are sometimes used to emphasize high stakes and the need for complex, sometimes counterintuitive strategies ( 30 ).
Technology can be leveraged to overcome some challenges related to cognitive load. For example, in some situations, decision makers may not know in advance which subset of information will be most relevant in the moment of decision making and therefore may request abundant amounts of information. To circumvent the limitations of retaining abundant information in LTM, interactive dashboards can offer on-demand access to results, with selection menus and toggles to conjure only those results that are immediately relevant. Software packages for facile dashboard development are available in popular programming languages such as R ( 118 ) and Python ( 137 ). For modelers or decision makers who prefer to avoid dashboards, a searchable document or set of digital viewgraphs with a clear table of contents can provide another form of on-demand access to results.

Section: CONCLUSION

Real-time infectious disease modeling during public health emergencies can provide pivotal support for decision making. Methods and applications of infectious disease modeling for decision making advanced significantly during HIV/AIDS, COVID-19, and other infectious disease emergencies, but challenges and opportunities remain. Advancing modeling and calibration methods, data availability and analysis, and training on communication of model results would facilitate more effective decision-making support during future infectious disease emergencies.

Section: disclosure statement

The authors are not aware of any affiliations, memberships, funding, or financial holdings that might be perceived as affecting the objectivity of this review.

Section: literature cited

