Title: Doctor decision making with time inconsistent patients


Abstract: Abstract

Non-adherence to treatments is prevalent. The aim of this paper is to model how doctors should adapt their medical treatment decisions if non-adherence is due to present-bias in the patient population, and to test the predictions of this model in a lab experiment. Under certain conditions, a rational doctor should adapt to non-adherence by choosing a treatment all patients complete (though less effective) when the probability of a patient being present-biased is sufficiently large. This is explored in a lab experiment where we test whether students in the doctor role adapt their behaviour as they learn about the distribution of non-adherence (due to present bias) in the patient population over the rounds of the experiment. We test the model prediction when we align individual incentives with the goal of maximising overall patient welfare. The results show that, on average, participants adapt to non-adherence as they learn about the probability of non-adherence (due to present-bias). However, a proportion of participants do not adapt to the optimal choice. The rate of adaptation was similar for the first 5 rounds under both individual incentives and salary . However, participants continued to adapt after round 5 under individual incentives whilst adaptation plateaued under salary. The adaptation to non-adherence may indicate that adherence can be improved by providing doctors with information about the probability of non-adherence (due to present-bias) in their patients.

Section: 1. Introduction

Non-adherence to medical treatment is prevalent in many conditions. Under different treatments and populations, adherence has been measured between 50% and 80% (Sabaté 2003 ; DIMATTEO, 2004 ; OSTERBERG and BLASCHKE, 2005 ). In addition to potential health losses, non-adherence imposes costs on others in systems like the British NHS if treatments are paid for but not completed. This paper focuses on how doctors should adapt their medical treatment decisions when non-adherence arises from present-bias in the patient population. Present-bias is the enhanced importance people attach to outcomes that occur in the present and is one potential mechanism for non-adherence. Individuals not following through with planned behaviour (including not adhering to medical treatment) can be modelled using discounting that allows for present-bias choices (quasi-hyperbolic model) ( O'DONOGHUE and RABIN, 1999 ; LAIBSON, 2015 ). A patient, for example, may plan to take medication next week as the costs (e.g. side-effects) next week outweigh the future health benefits. However, when the time comes, they do not take the medication because they place extra weight on the immediate costs due to present-bias. The potential of hyperbolic discounting for understanding and predicting non-adherence was first recognised by Christensen-Szalanski and Northcraft (1985) and MØRKBAK et al. (2017) show present-bias is associated with lower glycaemic control in diabetes.
This paper contributes to the literature by applying techniques from behavioural and experimental economics in a health context. The health setting is characterised by an agency relationship due to the asymmetry of information between patients and doctors. We build on work from the principal-agent literature with naivety ( HEIDHUES and KŐSZEGI, 2017 ) and quasi-hyperbolic discounting ( DELLAVIGNA and MALMENDIER, 2004 ; KŐSZEGI, 2014 ) to model how doctors should adapt their medical treatment decisions if non-adherence is due to present-bias in the patient population. The predictions of this model are then explored in a lab experiment where we test whether students in the doctor role adapt their behaviour as they learn about the distribution of non-adherence (due to present-bias) in the patient population over the rounds of the experiment. Whilst evidence exists on how individuals adapt their behaviour as they learn about the decision environment ( EREV and HARUVY, 2015 ), this cannot necessarily be generalised to the health setting. The health setting is characterised by an asymmetry of information between patient and doctor, and this agency relationship means that individuals have to make decisions for others rather than themselves. It is also important to understand how experience and preferences may influence adaptation. For example, medical training may affect an individual's ability to anticipate and or learn about the optimal treatment.
Lab experiments are increasingly used within health economics ( Galizzi and Wiessen, 2018 ; HENNIG-SCHMIDT et al., 2011 ; Godager, Wiesen 2013; Green, 2014; Brosig-Koch, Hennig-Schmidt et al. 2016 ). A lab experiment is used in this study because it allows us to set the relevant model parameters (e.g. the probability that a patient is present-biased) such that responding to non-adherence is welfare improving (in accordance with the model). Adherence problems and doctors' responses to it can be difficult to observe in real-world data. The lab setting allows us to isolate the effects of interest to this study. In the experiment participants have no information on patient preferences (as in a classic agency relationship) but have full information on which patients adhere to medical treatment over the rounds. A similar approach is taken in FEHR and SCHMIDT (2004) where the learning process is not the focus of the experiment, but multiple rounds allow for adaptation by principals to their agents’ unknown behaviour.
We test the model prediction when we align individual incentives with the goal of maximising overall patient welfare. This directly aligns patients' and doctor preferences because doctors are only paid when patients adhere to medical treatment and the payment is proportional to a patient's health outcome. This provides a measure of ‘maximum’ adaptation and acts as a rationality test. We also test the model prediction using a salary condition. This tests whether individual incentives are required to get doctors to act in the social welfare maximising way. In the salary condition, doctors' motivation to address adherence is only their preferences for others'. A salary condition is more in line with how doctors are paid in the UK. Under both conditions real patients' health is affected by the participants' choices through a charity donation; a common way of motivating health outcomes in behavioural lab experiments (Galizzi and Wiessen, 2018).
The experiment provides support for our model prediction. Participants adapt to non-adherence. In early rounds, medical treatment choices are diffuse. In the final round 80% of choices are at the socially optimal level when using individual incentives that directly align doctor and patient preferences. There is also evidence that total welfare losses to patients are higher when doctors are paid by salary. Whilst the simple experimental setting allows us to isolate the effect of non-adherence which would not be possible in non-experimental data, reality is of course far more complicated than our experiment. However, the experiment can be interpreted as providing a “test bed or wind tunnel” ( CROSON and GACHTER, 2010 ). If students in the role of doctors did not respond to non-adherence in this artificial environment, then they would be unlikely to do so in the real world. Here, the results imply that information on non-adherence should be made available to doctors and/or that doctors should be trained to better identify non-adherence so that they can adjust behaviour.

Section: 2. Model

We model the theoretical problem a doctor faces when patients’ time preference types are unknown, using paternalistic decision-making (full details on the model can be found in the online supplementary material). We assume paternalistic decision-making where the doctor makes a single medical treatment decision which the patient accepts or rejects ( CHARLES et al., 1997 ) in period 0. The medical treatments are associated with a more immediate health cost (α in period 1) and longer-term health benefits (f(α) in period 2). The costs could be interpreted as the short-term side effects of a drug. There are a range of treatments available that vary in terms of the costs and benefits: more pain leads to more gain, but at a decreasing rate. The model is relevant to any clinical decision where treatments available vary in terms of relative costs and benefits over time. This includes primary care where doctors make decisions relating to chronic conditions in patients on their practice list and where there is a range of treatments available. The doctor makes a treatment recommendation which the patient either accepts or rejects in period 0. In the next period the patient either adheres or does not adhere to medical treatment.
To allow for time inconsistency , patients have naïve quasi-hyperbolic time preferences ( LAIBSON, 1997 ; O'DONOGHUE and RABIN, 1999 ). Whether they accept a specific treatment in period 0 will depend on their time preferences (δ - the rate at which they discount future outcomes) which for simplicity is assumed to be the same for all patients. Whether they will follow through with an accepted treatment in period 1 will depend on their present-bias (β – the enhanced significance that individuals attach to outcomes that occur in the present). If they are time consistent (β = 1) they will always adhere to the treatment they accepted. If they are present biased (β < 1) they may not adhere to the treatment they accepted which leads to a utility loss. Present-biased patients will adhere if they are offered a lower level of treatment which has sufficiently low immediate costs (and consequently lower health gains). This is the utility maximising choice for present-biased patients. However, it is not the utility maximising choice for time-consistent patients.
The doctor needs to decide what medical treatment to offer when the time preferences of patients are unknown. We assume that the doctor is effectively a health maximiser and does not receive utility from other aspects of medical treatment choice, such as their own income in some health systems. If doctors knew the time preferences of their patients, the (first-best) solution to this problem would be simple to obtain. They would offer two treatments; the welfare maximising one to time-consistent patients, and the best treatment which patients with present-biased preferences would adhere to. As time preferences of specific patients are not known, doctors need to decide on a single (second) best treatment to offer in the face of this informational asymmetry.
In the formal model developed in the online supplementary materials, the distribution of time preferences in patient population is known. In this case the overall welfare maximising choice for a certain patient population depends on the proportion of patients who are present-biased. If the proportion is high enough then doctors should lower the level of medical treatment to the point that keeps present-biased patients adherent, although this reduces the outcomes for the time-consistent patients. They should not lower the level of treatment if the proportion of naïve present-biased individuals in the population is low enough as the loss in outcomes for time-consistent patients by lowering the treatment does not outweigh the gains for the present-biased patients.
In reality the distribution of patients’ time preferences are unknown to the doctor, therefore they do not know what the welfare maximising choice is for their patient population. The doctor can learn about non-adherence (the proportion of present-biased patients) in their patient population by making treatment recommendations and observing adherence. The model predicts that to maximise overall welfare doctors should learn and adapt their treatment recommendation to the welfare maximising choice which depends on the proportion of patients who are present based. This leads to our main experimental hypothesis:
Hypothesis. A doctor adapts medical treatment decisions as they learn about the distribution of non-adherence (due to present-bias) in the patient population.
We test the hypothesis when we align individual incentives in the experiment with the goal of maximising overall patient welfare (in accordance with the model). This direct alignment provides a measure of the ‘maximum’ adaptation to non-adherence by physicians. We also test the model prediction when doctors are paid a salary . This will test whether individual incentives are required to get doctors to act in a social welfare maximising way. Under both conditions, real patients' health is affected by participants' choices through a charity donation.

Section: 3. Experiment design and protocol

Participants are allocated to a doctor role, making medical treatment recommendations to computer-controlled patients, over a series of rounds. By using computer-controlled patients we ensure the patients’ behaviour matches that used in the model so that analysis can focus on the behaviour of the doctors in the presence of time-inconsistent patients. In the context of the model the decisions made by participants are taken in t = 0 , the planning phase. Medical treatments have both side effects (short term pain, a at t = 1) and benefits (long term gain, f(a) at t = 2) expressed as health points. The outcomes in period 1 (patients adhere or do not adhere) and period 2 (longer term outcomes) happen between the rounds that participants see. Information on these outcomes is fed back to doctors in subsequent rounds, mimicking the three-period model (Online supplementary material).
Doctors have to decide on the medical treatment for each of five patients in a round. In the instructions, rounds are framed as clinics. The probability of present-bias is unknown to participants at the start of the experiment. Five computer-controlled patients are generated independently for each round and each participant. To test the predictions, doctors make medical treatment recommendations for ten rounds. This allows them to learn about the distribution of patient types over the rounds and adapt to non-adherence if they want ( FEHR and SCHMIDT, 2004 ). A history box with medical treatment and adherence information for the previous two rounds (10 patients) is provided to help participants learn about patient outcomes and non-adherence. For each patient, doctors see their medical treatment recommendation, whether the patient accepted it, and whether the patient completed medical treatment.
The parameters in the experiment are chosen so that there are clear welfare differences between the different treatment options. Two types of patients exist: present-biased patients ( β L < 1) and time-consistent patients ( β H = 1). All patients have the same health state. Whether a medical treatment offer is accepted, and whether an accepted medical treatment is adhered to, depends on the relative size of side effects and benefits, and the time preferences of the patient. In particular, adherence depends on whether the patient is present-biased or time-consistent. The probability of present-bias is 0.7, so with probability 0.3 a patient has time-consistent (exponential) preferences. This parameter was chosen so that the proportion of present-biased patients is large enough that adapting to non-adherence by lowering the level of treatment is the welfare maximising choice for doctors.
Present-bias ( β L ) is set at 0.42 for present-biased patients. This large present-bias was chosen so that there was clear separation of behaviour between time-consistent and present-bias patients using relatively small health point values. Time preference ( δ p ) is set at 0.9 for both present-biased and time-consistent patients. We use δ < 1 so that time-consistent patients can reject medical treatment offers even when benefits outweigh the side effects. Table 1 shows the seven medical treatment options in the experiment, their outcomes in terms of experimental points, and patient outcomes when offered each medical treatment. Parameters were chosen to be consistent with the model and so that there was a clear separation between the socially optimal medical treatment that all patients adhere to (medical treatment 3) and the medical treatment that maximises the difference between pain and gain (medical treatment 5). If a participant ignores adherence, or had no information (the initial rounds), they would choose medical treatment 5 because it maximises the health benefits ignoring present bias. Medical treatment 3 ( a’ ) is the highest medical treatment level that present-biased patients adhere to and maximises overall welfare. It therefore also maximises expected payment under the individual incentive that aligns patient and doctor payoffs exactly. Equation (8) in the online supplementary material holds: Δ L = 20.2, Δ H = −1.4, 0.7 > 1.4/18.8. Medical treatment 1, giving no side effects or benefits, allows doctors to recommend ‘no medical treatment’. Participants may come to the experiment with priors based on their own experience and preferences. For example, they may have experienced non-adherence due to present-bias and therefore opt for medical treatments with less short-term pain compared to medical treatment 5. Table 1 . Medical treatment and Payment functions. Empty Cell Medical treatment 1 2 3 4 5 6 7 Paid to you a 0 19 26 28 30 28 5 Short-term Pain a 0 8 14 17 18 21 46 Long-term Gain f(a) 0 26 38 42 44 46 50 Model Level a ’ a ∗ , a d Panel A: Linking experiment medical treatments to model. Numbers are the points awarded in the experiment. Side-effect a is experienced as a loss, followed by long-term gain f(a) . An individually incentivised doctor receives the amount ‘Paid to you’ only if the patient adheres to medical treatment. Outcomes Patient type 1 2 3 4 5 6 7 Patient accepts TC, PB b Yes No Adherence TC Yes N/A PB Yes No N/A Individual incentive doctor paid TC Yes No PB Yes No Salary doctor paid TC, PB Yes Panel B: Patient behaviour and doctor payments for medical treatment levels. a ‘Paid to you’ only visible in the Individual Incentive arm. b TC: Time-consistent, PB: Present-biased.
The experiment was conducted in computer classrooms at two campuses at the University of Aberdeen and programmed using oTree ( http://www.otree.org/ ( CHEN et al., 2016 )). In total, 109 students were recruited using flyers and emails. Of the 109 students, 36 were medical students and a further 46 were enrolled in a medicine related degree. The session payment conditions were chosen (randomly) after participants selected a time, so there was no opportunity to self-select on payment condition. Ethical approval was provided by the University of Aberdeen College Ethics Review Board.
In each session, participants were shown to randomly assigned seats and logged onto the online tool. They read an introduction screen and an instructions screen, before completing understanding questions (see online material for all experiment instructions). The instructions explicitly described the medical context, in line with previous health economic experiments ( HENNIG-SCHMIDT et al., 2011 ; GALIZZI and WIESEN, 2018 ). They then have the opportunity to ask any questions, answered in private. Five questions test their understanding of the outcomes and the medical treatment function before starting the experiment. Participants must answer all questions correctly before they can progress to the clinic rounds. They then complete ten rounds, followed by a time and risk preference survey and then the demographic survey. Time and risk preferences are elicited using hypothetical Multiple Price Lists (MPLs) ( ANDERSEN et al., 2008 ; HOLT and LAURY, 2002 ). Participants also completed a question rating the health state on a Visual Analogue Scale (VAS). This question is not used in the analysis because it was not well specified: half of respondents took 100 to be perfect health, while half used 0 for perfect health. The demographic survey collects age, gender, year of study, degree level, degree type (medical related or not) and degree title. The latter two questions separate medical students from those studying medical related courses but that are not yet on-track to become doctors. Finally, they are paid in private. Sessions lasted at most 1 h.
One round is chosen at random to make payments to each participant, and a charity, based on the decisions for all patients in that round. All participants received a show-up fee of £2 and their payment from the randomly chosen round. The experiment programme tells them how much they and the charity will receive by displaying full results for the round and converting experimental points to money. Participants also received a confirmation email when the donation was made.
Our two payment conditions are:
Individual Incentive : If the patient adheres the doctor is paid using the ‘Paid to you’ line of Table 1 . The fees are set exogenously and borne by a third party (the experimenter). The function determining the price and cost of medical treatment is a linear transformation of the medical treatment function. The conditionality of the payment and the linear transformation induce the social-planner preferences in participants by directly aligning patient and doctor preferences.
Salary : The participant receives a one-off payment (£5) for completing the round (clinic), unrelated to patient outcomes. There is no individual financial incentive to maximise social welfare by responding to adherence.
In both conditions participants' choices for hypothetical patients affect real patients’ health through a payment to charity ( HENNIG-SCHMIDT et al., 2011 ). The charity is NHS Grampian Endowments, affecting patient care in the local area. The charity payment reflects patient outcomes: if a patient adheres to medical treatment we take the difference between the gain and pain (see Table 1 ). If a patient does not adhere the charity receives no money, consistent with the model.
All experimental points (the health units and performance payment) are converted into monetary amounts by using an exchange rate of 5p per point. On average each session contained 6 participants. There were 53 participants in the Individual Incentive arm, and 56 in the Salary. The average participant payment was £7 in the salary arm and £6.99 in the individual incentive arm. The average charity donation was £3.94 in the salary arm and £4.59 in the individual incentive arm.
It is first tested whether participants adapt to non-adherence by comparing choice distributions in the first and tenth rounds using Chi-square tests. Ex-ante welfare losses are used to test whether they are adapting as predicted by the model (in a welfare improving way). By design, the welfare maximising choice is medical treatment 3, with (period-0) welfare of 20.2. Welfare loss to patient i is then: (1) L o s s i = ( δ p ∗ g a i n − p a i n ) ∗ f t − 20.2 Where ft is 1 when the individual follows through and 0 otherwise. It is possible for a patient to have a positive welfare loss, when a doctor offers medical treatments 4, 5 or 6 to a β = 1 patient. A paired Wilcoxon signed rank test checks whether welfare losses are from different distributions in round 1 and round 10 (main hypothesis). It is also tested whether welfare losses in round 1 and 10 are different by arm (Individual Incentive or Salary) using a Mann-Whitney U test.
Random effects panel regressions are used to test for adaptation over all rounds whilst controlling for individual level effects. Total welfare loss per round for a participant j (the sum over 5 patients: T W L j t = ∑ i = 1 5 L o s s i ) is regressed on incentive mechanism ( I Sal = 1 for salary arm), dummy variables for the rounds t , and round interacted with payment mechanism. The interaction terms test whether the rate of adaptation varies across arm (Individual Incentive or Salary). A further model is run which includes the participants’ characteristics ( X j ): (2) T W L j t = β 0 + β 1 , t t + β 2 , t ( t ∗ I S a l ) + β 3 I S a l + β 4 X j + u j t
Significant negative interaction effects on β 2 , t would indicate that welfare losses are larger under a salary than an individual financial incentive. The participant characteristics include age, gender ( Female = 1), ‘Medicine’ ( Medic = 1), Other medical related degree ( Other medical related degree = 1), year of study, and time and risk preferences (switching point in the MPL). We are particularly interested in the impact of risk and time preference and studying a medical related degree. A more risk-seeking doctor could prefer to offer treatments that have larger rewards but that patients are less likely to accept. Time preferences are directly tied to decisions in this experiment. More impatient doctors could offer treatments below 5, including the socially optimal treatment. Students in medical-related subjects are more likely to have direct experience of non-adherent behaviour on placements so may already have strategies adaptable to the experiment. Standard errors are clustered at the participant (doctor) level.

Section: 4. Results

Fig. 1 shows the aggregate choice distributions for the first and final round when we align individual incentives with the goal of maximising patients' welfare. Participants adapt to non-adherence in the way predicted by the model. In the first round, when participants have no information about patients' preferences, medical treatment choices are diffuse. As they learn about non-adherence (caused by present-bias) in their patient population they move towards recommending the welfare maximising medical treatment choice (medical treatment 3). In the final round, 81.8% of choices are for medical treatment 3 ( a’ in the model). A Chi-square test rejects equality of the round 1 and 10 choice distributions ( X 2 = 182.6, p < 0.01). Participants go from providing medical treatments that some patients do not stick to, to medical treatments they do stick to, even if these appear to give less net health a priori. Download: Download high-res image (208KB) Download: Download full-size image Fig. 1 . Histogram of medical treatment choices in rounds 1 and 10, Individual Incentive.
In round 10, 18.2% of choices are for medical treatments other than 3. There are at least two possible explanations. Firstly, some participants may still be learning about the outcomes and need further rounds to adapt to the optimal choice. Secondly, some participants may suffer from decision fatigue and may no longer make an effort to explore the optimal choice. It is not possible to distinguish between these two effects with our data but the results for the salary arm (below) shed some light on this.
Fig. 2 shows the aggregate choice distributions for the first and final rounds when participants receive a salary rather than an individual incentive. In the final round 61.1% of choices are for medical treatment 3 ( a’ ). A Chi-square test rejects that choice distributions are equal in rounds 1 and 10 ( X 2 = 134.1, p < 0.01). This suggest that participants also act in a social welfare maximising way without individual (financial) incentives. However, the percentage of respondents choosing the socially optimal medical treatment in round 10 is lower compared to when individual incentives are used. This may suggest that the financial incentive encourages participants to continue to make an effort to learn about the outcomes and make the optimal choice. Download: Download high-res image (202KB) Download: Download full-size image Fig. 2 . Histogram of medical treatment choices in rounds 1 and 10, Salary.
Without any information on the probability of outcomes (reject and adherence), medical treatment 5 is the utility maximising choice in the first round. However, participants may come to the experiment with priors based on experience and/or preferences. For example, participants may already anticipate that patients are less likely to adhere when the immediate costs (pain) are high and therefore opt for medical treatments with less pain (medical treatment 2 and 3) compared to medical treatment 5. Fig. 1 , Fig. 2 show that indeed a substantial proportion chose medical treatments other than 5 in round 1. To gain some insight into these choices we explore whether individual characteristics are associated with choosing medical treatments 5 versus other medical treatments. We first regress choosing medical treatment 5 in round 1 as a function of individuals characteristics using probit regression . The results are shown in Table 2 . Medical students are more likely to choose medical treatment 5 (significant at a 10% level). Preferences also matter. More risk-averse participants are more likely to choose medical treatment 5. Participants with higher rates of time preferences are less likely to choose medical treatment 5. We then explore whether individual characteristics are associated with the specific alternative medical treatment chosen in round one using multinomial probit regression with medical treatment 5 as the base case. The results show that more risk-averse participants and medical students are less likely to choose the more ‘extreme’ medical treatments – medical treatment 2 (small level of benefits) and 6 or 7 (high levels of costs). Women and participants with higher rates of time preference are more likely to choose medical treatment 4. Participants in the salary arm were more likely to choose 6 or 7. Table 2 . Association between medical treatment choice in round 1 and individual characteristics. Empty Cell Probit regresion Multinominal probit regresison Empty Cell Medical treatment 5 Medical treatment 2 Medical treatment 3 Medical treatment 4 Medical treatment 6 or 7 Empty Cell Coefficient p-value Coefficient p-value Coefficient p-value Coefficient p-value Coefficient p-value Salary −0.209 0.26 0.478 0.11 −0.100 0.72 0.043 0.86 0.710 0.02 Age −0.005 0.89 0.036 0.53 −0.008 0.87 0.012 0.79 −0.040 0.47 Female −0.197 0.33 −0.161 0.62 0.357 0.21 0.592 0.03 0.513 0.17 Medical related degree 0.076 0.77 −0.013 0.98 −0.063 0.86 −0.105 0.74 −0.403 0.31 Medicine 0.468 0.06 −0.691 0.09 −0.414 0.28 −0.389 0.25 −1.015 0.01 Year of study −0.056 0.50 0.124 0.39 0.098 0.41 0.083 0.48 −0.125 0.32 Risk preferences 0.079 0.04 −0.138 0.03 −0.017 0.76 −0.073 0.18 −0.129 0.02 Time preferences −0.061 0.08 0.087 0.11 0.043 0.44 0.116 0.03 0.012 0.84 Constant −0.554 0.54 −0.581 0.69 −0.408 0.75 −1.113 0.38 0.894 0.46 N 545 545 N ind 109 109 Pseudo R 2 0.0512 0.0107 * medical treatments 6 and 7 were merged due to small cell sizes.
As mentioned above a proportion of choices in round 10 are for medical treatments other than 3 suggesting that full adaption has not (yet) taken place. We first explore what characteristics are associated with not choosing medical treatment 3 (i.e. not adapting) in the final round. The results are shown in Table 3 . In line with previous findings participants in the salary arm are less likely to choose medical treatment 3 in final round. Risk-averse participants are more likely to choose medical treatment 3 in the final round. We then explore whether individual characteristics are associated with the specific alternative medical treatment chosen in the final round using multinomial probit regression with medical treatment 3 as the base case. Participants in the salary arm are more likely to choose medical treatments 2, 6 and 7 compared to medical treatment 5. Females are more likely to choose medical treatment 4 and less likely to choose medical treatments 6 and 7. Participants with higher rates of time preferences and more risk-averse participants are less likely to choose medical treatment 2, 6 and 7. Interestingly, there no longer is a difference between medical students and non-medical students. Table 3 . Association between medical treatment choice in round 10 and individual characteristics. Empty Cell Probit regression Multinominal probit regression** Empty Cell Not medical treatment 3 Medical treatment 2 Medical treatment 4 Medical treatment 5 Medical treatment 6 or 7 Empty Cell Coefficient p-value Coefficient p-value Coefficient p-value Coefficient p-value Coefficient p-value Salary 0.566 0.01 1.033 0.00 0.431 0.17 0.463 0.16 0.697 0.08 Age 0.012 0.74 0.069 0.30 0.004 0.94 −0.115 0.20 −0.011 0.88 Female 0.011 0.96 −0.259 0.49 0.876 0.03 0.010 0.98 −0.713 0.05 Medical related degree 0.157 0.51 0.074 0.86 0.321 0.33 0.262 0.50 0.275 0.61 Medicine −0.050 0.85 −0.276 0.58 0.021 0.95 0.107 0.79 0.284 0.57 Year of study 0.061 0.49 0.049 0.73 0.188 0.13 0.113 0.52 0.015 0.92 Risk preferences −0.091 0.01 −0.155 0.00 −0.074 0.09 −0.040 0.51 −0.152 0.03 Time preferences −0.052 0.21 −0.053 0.50 −0.072 0.14 −0.035 0.56 −0.182 0.03 Constant −0.599 0.51 −2.365 0.14 −2.524 0.05 0.242 0.88 −0.584 0.76 N 545 544 N ind 109 109 Pseudo R 2 0.0823 0.0180 * medical treatments 6 and 7 were merged due to small cell sizes. a chosen only once and this observation was removed. **Medical treatment 1
Trends in choosing the optimal treatment over the rounds is further explored. Fig. 3 shows the proportion choosing treatment 3 by round. The proportion choosing treatment 3 increases over all rounds. The steepest increase is in the first 5 rounds with the increase levelling off after round 5 especially in the salary arm. Download: Download high-res image (214KB) Download: Download full-size image Fig. 3 . Proportion choosing treatment 3 for each round, Salary and Individual Incentive.
Welfare losses are considered next. These are important as some choices incur larger welfare losses than others. Fig. 4 shows average total welfare losses for the rounds. Welfare losses fall over the course of the experiment. As a further test, a paired Wilcoxon signed rank test rejects equality of the round 1 and 10 welfare loss distributions (p < 0.01, z = −5.313) under individual incentives. Under a salary, the paired Wilcoxon signed rank test also rejects equality of the round 1 and 10 welfare loss distributions (p < 0.01, z = −4.355). Download: Download high-res image (264KB) Download: Download full-size image Fig. 4 . Average total welfare loss for each round, Salary and Individual Incentive.
To explore choices in more detail, and incorporate demographic variables, we regress a participant's total welfare loss in a round on the round number and its interaction with the salary arm. The results are shown in Table 4 . The model prediction is again supported: the coefficients on round numbers 2 to 10 are positive in both models, indicating that welfare losses are lower in these rounds compared to the initial round. Testing whether each round coefficient is statistically significantly different from its lag, round 2 is different from round 1 (p < 0.01, in Table 2 ) and 8 is different from 7 (p = 0.03), otherwise there is no significance at the 5% level, showing that adaptation was incremental. This was set of 9 individual tests with H 0 : β j = β i for i = [2, …, 10] , j = i – 1 . Table 4 . Regression results for round welfare losses. Empty Cell Empty Cell Model 1 Model 2 Empty Cell Empty Cell Coefficient p -value Coefficient p -value Constant −46.830 <0.01 −54.894 <0.01 Salary 3.769 0.45 4.698 0.37 Round number 2 17.272 <0.01 17.272 <0.01 3 21.506 <0.01 21.506 <0.01 4 21.377 <0.01 21.377 <0.01 5 24.981 <0.01 24.981 <0.01 6 29.940 <0.01 29.940 <0.01 7 27.400 <0.01 27.400 <0.01 8 34.313 <0.01 34.313 <0.01 9 35.238 <0.01 35.238 <0.01 10 37.577 <0.01 37.577 <0.01 Salary * Round 2 −9.050 0.19 −9.050 0.19 3 −5.809 0.39 −5.809 0.39 4 −4.267 0.55 −4.267 0.55 5 −1.478 0.83 −1.478 0.83 6 −12.050 0.06 −12.050 0.06 7 −4.879 0.47 −4.879 0.47 8 −11.738 0.07 −11.738 0.07 9 −11.216 0.08 −11.216 0.08 10 −14.620 0.03 −14.620 0.03 Age 0.066 0.88 Female 0.622 0.82 Medical related degree −2.536 0.36 Medicine −2.543 0.38 Year of study 0.195 0.87 Risk preferences 0.967 0.04 Time preferences 0.368 0.44 N 1,090 1,090 Clusters 109 109 Panels 10 10 Adj r-sq 0.122 0.129 Note: Standard errors clustered at participant level. The dependent variable is individual's total welfare loss in a round. This is modelled as function of round number and an interaction between round number and salary condition.
The salary condition tests whether participants also act in a social welfare maximising way if there are no individual incentives aligned with this goal in the experiment. As mentioned above, participants adapt to non-adherence as predicted by the model under a salary but the percentage choosing the socially optimal medical treatment is lower. In round 10 we reject equality of the individual incentive and salary distributions (p < 0.01, z = 2.694). As a robustness check we also compare the distributions in the first round. Using Mann-Whitney U-tests, we do not reject that participants’ total welfare losses are from the same distributions between arms in the first round (p = 0.69, z = −0.398). This suggests that there is greater adaptation when using individual incentives compared to salary. Furthermore, total welfare losses remain more constant after round 5 for salary participants. Using Mann-Whitney U tests we reject that total welfare losses are from the same distribution between individual incentives and salary at the 10% level or better in rounds 6 (p = 0.02), 8 and 9 (both p = 0.06) in addition to round 10 (see above).
These provide aggregate evidence that an individual financial incentive is better at increasing responsiveness to non-adherence than a salary. This is confirmed by the results in Table 4 . There is no average difference in welfare loss between individual incentive and salary participants and in the first round (β salary = 3.77, p = 0.45). However, negative coefficients on interaction terms imply larger welfare losses in a given round for a salaried doctor. This effect is individually significant in later rounds (6, 8, 9, and 10) at the 10% level. While salaried doctors adapt to non-adherence, they do so to a lesser extent than individually incentivised doctors in the later rounds.
Model 2 includes the demographic characteristics. Risk preferences are the only characteristic that is associated with welfare losses at the 5% level. It shows that risk-averse participants have larger welfare losses but the magnitude is small.

Section: 5. Discussion

The aim of this paper was to model how doctors should adapt their medical treatment decisions if non-adherence is due to present bias in the patient population, and to test the predictions of this model in a lab experiment. In the experiment we test whether students in the doctor role adapt their behaviour as they learn about the distribution of non-adherence (due to present bias) in the patient population. Our model contributes to the literature by demonstrating that present-bias preferences in patients only cause non-adherence when doctors do not anticipate patients' potential for time inconsistency . Under certain parameters, when they do not know patients’ preferences in advance a rational doctor should adapt to non-adherence by choosing a medical treatment that is more acceptable to patients (albeit possibly less effective) when the probability of a patient being present-biased is sufficiently large. This would maximise overall welfare of the patient population when weighting each patient equally. It also means that the health gains are the same for time-consistent and present-biased patients thereby removing inequalities in outcome within a patient population. It also reduces inequalities in outcomes between patient populations (who may vary in the probability of being present biased) as overall welfare (health outcomes) is maximised and differences in outcomes between populations are therefore minimised.
Whilst the approach maximises overall welfare it does raise an ethical issue as it creates ‘less health’ to time-consistent patients, who would have adhered to more effective treatment. This means there is a potential conflict between what is best for the time-consistent individual and what is best for the overall patient population. Individuals may be seen to have an ethical right to be offered the best treatment for them. Also, whilst the approach reduces inequalities in outcomes it may increase inequalities in access to treatment across different patient populations. Assume that there are two practices, A and B, and that the probability of present bias in the patient population is higher in practice A compared to practice B. Depending on the relative probabilities of present bias this could mean that a less medically effective treatment is offered to the patients in practice A and a more effective treatment is offered to the patients in practice B. This clearly increases inequalities in access to treatment across the two practices creating an ethical issue. Present bias may be associated with socio-economic status and this may therefore increase socioeconomic inequalities in access to treatment. The ethical issues are clearly difficult to address. In the presence of information asymmetry , the ideal would be to be able to offer all patients a menu of contracts or treatments from which they could choose. Understanding where such an approach might be feasible is a potential area for future research.
The experiment demonstrates that, on average, participants adapt to non-adherence as they learn about the probability of non-adherence (due to present-bias). However, a proportion of participants did not adapt to the optimal choice. The rate of adaptation was similar for the first 5 rounds under both individual incentives and salary. Participants continued to adapt after round 5 under individual incentives whilst adaptation plateaued under salary. Implementing these incentives outside the laboratory would be difficult and may be associated with unintended consequences (for example, doctors not putting in as much effort to encourage adherence to more effective treatments). It is therefore reassuring that motivation for patient benefits leads participants to adapt even when they are not directly incentivised to do so. A different interpretation of those who continue to not adapt is that they have a social welfare function that does not equally weight present-bias and time-consistent patients. This approach could be explored with a different experimental design.
Medical students were more likely to choose the welfare maximising treatment in the first round which may suggest that medical training leads to a better anticipation of non-adherence due to present-bias. There was no difference between medical students and non-medical students in the final round which may suggest that whilst medical students anticipate the adherence problem better, the experiment ‘teaches’ it to non-medics relatively quickly. More generally the adaptation to non-adherence may indicate that adherence can be improved by providing doctors with information about the probability of non-adherence (due to present-bias) in their patients. However, monitoring adherence in a real-world setting is challenging especially with regards to medication. It may be possible to obtain information on whether the patient has collected their prescription but information on whether the patients who collected their prescription actually took the medication most likely is based on self-report from the patient. Patients may feel pressured to say that they adhered even if they did not. Doctors may also have existing beliefs that impact on medical treatment decisions. For example, they may think that younger individuals are less likely to adhere and adapt their medical treatment decisions accordingly even when they have more information about the probability of non-adherence in their patient population. Where doctors were to infer the probability of non-adherence from observed patient characteristics, this could induce other unwarranted inequalities in treatments across patients. Nevertheless, whilst full information on adherence is unlikely to ever be feasible it should be possible to improve information on adherence, through information systems or discussions with the patients and the results suggest that this could improve patient welfare.
Our results showed that individuals’ characteristics mattered for medical treatment decisions. While this is perhaps less surprising for medical treatment decisions in the first round when less information is available, the impact of some characteristics (risk aversion) was also found in the last round. This suggests individuals did not base their decisions solely on the probability of non-adherence but also their own preferences. This may suggest that even when full information on non-adherence in the patient population can be provided, this may not fully eliminate non-adherence.
The advantage of using lab experiments to explore adherence is that the relevant conditions are tightly controlled, in ways that may be impractical or place greater demands on data in real-world settings. The lab experiment means that the model predictions – whether doctors respond to non-adherence (caused by present-bias in the population) – can be tested. This is done by specifying the welfare maximising choice and patients' preferences in advance. It would not be possible to test these specific effects using field data given many complexities. In the real-world doctors have to assess the medical condition and characteristics of real patients, understand guidelines, what treatments are available, and the ability to observe non-adherence may be limited. This means that it would be challenging/most likely impossible to isolate the effect of interest. Another advantage of the lab experiment approach is that the robustness of the result can be tested by replicating the experiment. However, lab experiments clearly require simplification of the real-world. In our experiment several simplifications were required. Doctors were assumed to be paternalistic and make decisions on behalf of their patients. In the real-world setting there is shared decision making between the doctor and patient which allows the exchange of information related to the patient's time preferences (including their present bias) and likely adherence to different treatments. This means that the doctor can better tailor the treatment to individual patients and choose the optimal treatment for the patient rather than having to choose the optimal treatment for the total patient population. In the experiment doctors received full information on adherence. In the real-world adherence is difficult to observe (fully) and doctors can therefore not learn about and respond to non-adherence to the same extent. In the experiment doctors make a single treatment decision only. In the real-world setting doctors will make multiple decisions for patients with chronic conditions. This means that doctors can learn about non-adherence and time preferences as they prescribe different treatments to the same patient. In the experiment patients either adhere or do not adhere. In the real-world setting patients may start and then stop a medical treatment due to misperceived endpoints or side effects. Doctors' treatment decisions are influenced by a wide range of factors including clinical guidelines. These factors mean that non-adherence and present-bias may play less of a role in a real-world setting compared to our experiment. The simplifications mean that we can only draw tentative conclusions and it is not possible to assess actual behaviour in a real-world clinical setting. To fully understand non-adherence requires a variety of methods to explore the wide range of factors that influence adherence. Our study points towards the role of present-bias, as well as doctors' willingness to adapt to this when it is the welfare-maximising choice.
There are a number of limitations to this analysis. Firstly, a number of simplifying assumptions had to be made in the theoretical model. It cannot explain behaviour such as starting and then stopping a medical treatment due to misperceived endpoints or side effects. An important extension would be to separate non-adherence due to worse-than-expected side effects from the agency and discounting effects. Also, a paternalistic interaction was assumed and therefore did not explore the impact of shared decision-making. Secondly, it may be that participants were motivated by a desire to do well at the ‘game’, rather than maximising social welfare. A future experimental design could explore altruism in the presence of non-adherence by varying experimental parameters within-subjects or making medical treatments costly to the doctor even if not adhered to by patients. The impact of varying experimental parameters within the original experiment is also warranted. Third, the experiment used students in the role of doctors and the question arises whether doctors would make the same choices as students. Evidence from other lab experiments suggests that there is no difference in the direction of effect between (medical or non-medical) students and medical professionals. However, the size of the effect might vary across these groups ( GALIZZI and WIESEN, 2018 ). However, this is based on limited evidence and further research is clearly needed. Future lab experiments should also involve doctors and other medical professionals and differences between students and doctors should be explored further.

Section: 6. Conclusion

This paper is the first to introduce a model of non-adherence in the patient-doctor interaction using time inconsistency. Our model shows that under certain parameters a rational doctor should adapt to non-adherence by choosing a medical treatment that is more acceptable to patients (though less effective) when the probability of a patient being present-biased is sufficiently large. The model prediction was tested in a lab experiment. Students in the role of doctors adapt to non-adherence as predicted. The adaptation is stronger when incentives directly align doctor and patient preferences. Future work should explore extensions to the model such as incorporating shared decision making and externalities.

Section: Credit author statement

Alastair Irvine : Conceptualization, Methodology, Formal analysis, Data curation, Writing – original draft, Writing – review & editing. Marjon van der Pol : Conceptualization, Methodology, Formal analysis, Data curation, Writing – review & editing, Supervision. Euan Phimister : Conceptualization, Methodology, Formal analysis, Data curation, Writing – review & editing, Supervision.

Section: Acknowledgements

The Chief Scientist Office of the Scottish Government Health and Social Care Directorates funds HERU. Funding for the experiment was provided in part by the Scottish Economic Society. Alastair Irvine's PhD studentship was funded by the Institute of Applied Health Sciences, University of Aberdeen . The views expressed in this paper are those of the authors only and not those of the funding body.
