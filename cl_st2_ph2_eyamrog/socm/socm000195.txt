Title: Clinical guidelines and the pursuit of reducing epistemic uncertainty. An ethnographic study of guideline development panels in three countries


Abstract: Abstract


Abstract_Section: Purpose

To explore, from a philosophy of knowledge perspective, the contribution of the guideline development process to reducing epistemic uncertainty in clinical decision-making – defined as the challenge of applying evidence to patients, dealing with conflicting information and determining the level of confidence in a medical conclusion.

Abstract_Section: Methods

Longitudinal ethnographic study of national guideline development panels. Fieldnotes were collected from 19 panel meetings in UK, Netherlands and Norway (~120 h of observation) between September 2016 and February 2019. Draft guidelines, review protocols and background material were collated (~200 documents). Data were analyzed thematically to gain familiarity and then theorized using concepts of knowledge development and use and clinical decision-making.

Abstract_Section: Results

Guideline development panels in all three countries wrestled with epistemic tensions – notably between the desire to “purify” an assumed external truth (for example by limiting included evidence to high-quality randomized controlled trials) and a more pragmatic and pluralist approach that drew on a wider range of evidence including qualitative research , real-world data, clinical experience and patient testimony. Detailed analysis of the process by which particular guideline recommendations were constructed allowed us to draw out the implications of these tensions for guideline users in clinical practice.

Abstract_Section: Conclusion

Guideline development panels apply multiple – often conflicting – understandings of knowledge, inference and truth in an attempt to reduce epistemic uncertainty. Guidelines makers, clinicians, scientists and students should engage critically and reflexively with the philosophical assumptions that underpin guideline development and inductive inference to build capability to deal with clinical complexity.

Section: 1. Introduction

This research study addresses what Tonelli and Upshur have called “epistemic uncertainty”, which they define as “[t]he challenge of applying clinical research results to individual patients; dealing with multiple sources of (at times conflicting) information, guidelines, and principles; and determining what level of confidence to have and convey in a medical conclusion” ( Tonelli and Upshur, 2019 ).
Previous literature on uncertainty has addressed how it plays out in the clinical encounter ( Alam et al., 2017 ; Cooke and Lemay, 2017 ; Timmermans and Angell, 2001 ). In this paper, we report an empirical study of efforts to reduce epistemic uncertainty in the guideline development process. We propose that clinical practice guidelines , even when robustly “evidence-based”, incorporate – to a greater or lesser extent depending on their provenance – multiple different kinds of knowledge, ways of reasoning and theories of truth.
Clinical practice guidelines have been depicted as a “central instrument of EBM” ( Timmermans and Berg, 2003 ), aiming to reduce epistemic uncertainty by making diagnosis and treatment more data-driven. Sociological research has shown that distilling guidelines from research-derived knowledge is a complex process. Moreira's meticulous ethnographic studies of local guideline development panels in the UK, for example, revealed that the process involved four interacting repertoires of collective judgement: ‘science’ (in which panel members discussed the technical robustness of research evidence); ‘practice’ (in which they addressed usability); ‘politics’ (in which they considered the guideline's likely acceptability to different stakeholder groups) and ‘[due] process’ (in which they reflected on the adequacy of the guideline development process itself, including quality of group interactions and whether conflicts of interest had been fully declared) ( Moreira, 2005 ).
This and other studies (see for example ( Atkins et al., 2005 ; Calderón et al., 2006 ; Knaapen et al., 2010 ; Nairn and Timmons, 2010 )) have used a sociology of scientific knowledge lens to show that in distilling the “truth” from research studies, guideline development has long been shown to be a contact sport in which science abuts politics and practical reality. However, guideline makers and EBM practitioners have engaged surprisingly little with this literature. Partly to gain insight into why this might be, we chose to use a philosophical lens here and in previous work ( Wieringa et al., 2017 , Wieringa et al., 2018 ), focusing on the ontological and epistemological basis of guideline development. Being aware that purely philosophical-theoretical framings might also suffer from little uptake ( Cartwright, 2018 ), we aimed to take an integrated approach in order to be more accessible for guideline makers, clinicians and social science researchers. We sought not merely to describe what is happening at a social and micropolitical level, but to probe different actors' assumptions about what knowledge creation is .
We formulated the following research questions: 1. How do guideline development panels combine (or why do they find that they are unable to combine) different kinds of evidence such as non-RCT research designs, routinely collected data, patient experience data and clinical experience and wisdom? 2. How is the work of guideline development panels influenced by different perspectives on epistemic hierarchies and approaches to uncertainty?
After an example of a clinical encounter to introduce philosophical principles relevant to EBM, we describe an ethnographic study of how epistemic uncertainty played out in the guideline development process and contemplate the implications for dealing with epistemic uncertainty when using clinical guidelines in practice.

Section: 2. The philosophy of science in evidence-based medicine

In a (fictitious) scenario of evidence-based practice, a 65-year-old patient attends his doctor for annual review of his cardiovascular risk. In making the diagnosis (hypercholesterolemia and hypertension), assessing prognosis (a 20% 10-year risk of a cardiovascular event) and selecting possible therapeutic options (e.g. an ACE inhibitor and a statin), the doctor takes account of research evidence directly pertaining to these issues. But she also incorporates other types of knowledge : more general research evidence (e.g. observational data on the harms of polypharmacy ; qualitative studies of reasons for non-compliance in primary prevention), her clinical assessment of the patient (e.g. he is a smoker; he has gout; he has a history of non-attendance), local knowledge (e.g. of complaints about the smoking cessation clinic) and the patient's own expressed priorities (he does not wish to be on medication long term).
In this scenario, the doctor is concerned to reduce the patient's higher than average risk of a cardiovascular event. But she does not know for certain that he will inevitably develop such an event without active management – nor does she know that quitting smoking and taking medication will prevent such an event. This uncertainty can be expressed in terms of a classic philosophical conundrum – the problem of induction : it is impossible to predict the future (i.e. to make an inference ) even with perfect knowledge ( Hacking, 2001 ). This contrasts with deduction , where perfect knowledge always gives a correct prediction.
Various scholars have drawn on the philosophical work of David Hume (an empiricist) to consider the nature of uncertainty as framed by proponents of EBM ( Anjum, 2016 ; Kelly and Moore, 2012 ; Mumford and Anjum, 2013 ). In the empiricist language that Hume might have used, we might say that randomized trials (and syntheses of trials) have shown the drug will cause an effect of a particular magnitude in a group of patients. This language reflects the frequentist underpinning of the philosophical assumptions of EBM. If this view – that “causation comes down to habit of expectations, based on prior observation” ( Anjum, 2016 )– is taken to extreme, it follows that the only legitimate knowledge that can be incorporated into clinical guidelines will be high-quality meta-analyses of randomized controlled trials . In other words, EBM tends to evade the problem of induction by using frequency-type reasoning ( Hacking, 2001 ). It acknowledges that we cannot be correct in our predictions every time – but it argues that with large, high-quality studies we will be right 95% or 99% or 99.9% of the time. In a sense, we are conceptualizing patients like the roll of dice.
Other scholars have challenged an exclusively empiricist view of causality in medical diagnosis and treatment. Mumford and Anjum, for example, draw on Aristotle and Spinoza to argue that causality should be demonstrated directly rather than inferred from frequentist observations ( Anjum, 2016 ; Mumford and Anjum, 2013 ). To demonstrate causal power, we need rich descriptions of phenomena happening in individuals, not frequentist observations in populations.
In the fictitious scenario above, frequentist reasoning derived from studies of populations is – arguably – unhelpful. The patient (perhaps) wants answers to questions such as “if I don't take a statin , will I have a heart attack ?” and “if I take a statin, will it prevent a heart attack?”. The clinician cannot answer these questions with certainty from frequentist data directly because average group effects do not apply to individuals (the ecological fallacy ). But she can deal with the problem of induction using alternatives for the frequentist type evasion ( Hacking, 2001 ). For instance, she can reason mechanistically based on her knowledge of biological principles; she might use Bayesian reasoning based on pre-test and post-test probabilities (which would allow her to update her belief that the patient will respond to preventive therapy based on findings of an RCT); or she could use means-end reasoning (find multiple actions to make a specific outcome probable). See Table 1 for examples of these and other types of reasoning (( Wieringa et al., 2018 )). Table 1 . Types of reasoning to evade the problem of induction. Type of reasoning (with examples of key scholars) Shorthand description Brief explanation Frequency type (Neyman, Hacking) A series of future events will be like a series of past events This type of inductive inference reflects Hume's proposition that we cannot be correct in our predictions every time, but it argues that with large, high-quality studies we will be right most of the time (say 95% or 99% or 99.9%) about series of future events ( Hacking, 2001 ). It is impossible to talk about the probability of a single event in a single patient: there is no frequency. Bayesian (Bayes, Hacking) Updating degrees of belief This type of reasoning also recognizes that we cannot predict future events exactly but holds that we can learn from our experiences reasonably well. With the input of other types of reasoning, such as frequency type reasoning and mechanistic reasoning, we can update a prior probability (a degree of belief) not only about series of events but also about an individual event in a single patient ( Hacking, 2001 ). Abduction (Peirce) Reasoning to the best explanation Abduction is making a prediction while answering the question “what, if it existed, would best explain what I have directly observed?” Whereas the Bayesian evasion takes prior probabilities as a given and is more about confirming them (or not), abduction allows us to imagine wider contextual influences and causal mechanisms about our prior beliefs even when we do not directly measure them ( Douven, 2011 ; Peirce, 1986 ). Mechanistic How things work This type of reasoning makes an inference based on a mechanism such as a pathophysiological rationale or root cause analysis. Illari et al. define a mechanism as consisting of “entities and activities organized in such a way that they are responsible for the phenomenon” ( Illari and Williamson, 2012 ). Falsification (Popper) Trial and error Popper ( Popper, 1979 ) agreed with Hume: we cannot say anything about the future, there are only theories that cannot even be proven. At best, we can only prove that they are wrong (falsifiable). This ‘anti-inductivist’ reasoning suggests continuing using a certain theory, hypothesis, diagnosis, practice etc, until it is demonstrated that it fails. Precautionary principle In case of uncertainty about the future prevent harm This type of reasoning, often used in environmental decision making and occupational health, favors to take preventive action in the face of uncertainty when making an inference. It puts ‘the burden of proof to the proponents of an activity; exploring a wide range of alternatives to possibly harmful actions; and increasing public participation in decision making’ ( Kriebel et al., 2001 ; van Dijk et al., 2010 ). Means-to-ends reasoning Find many ways to reach a goal This type of reasoning asks the question what ways there are to reach a wanted outcome and which of those ways would be the more efficient? It is about taking multiple measures to reduce the uncertainty that a certain outcome will be achieved (making our inferences more likely to become true) ( Pollock, 2002 ). Tinkering (Mol) Taking care while an uncertain future unfolds In this view healthcare is more like a ‘practice’ than it is about making rational choices ( Mol, 2008 ). This approach puts emphasis on the importance of taking good care for the patient and the prevention of neglect. Inferring is a process that unfolds over time, while addressing many factors on the way. It is taking very small steps, limiting the amount of time between a prediction and the outcome. Non-analytical reasoning (Gigerenzer, Stolper) Using intuition Non-analytical reasoning such as heuristics and gut feelings (combination of heuristics and emotions ( Stolper et al., 2011 )) used to make inferences. These types of reasoning are considered fast, intuitive and automatic thought processes. Non-analytical reasoning can in certain environments outperform analytical reasoning in psychological, biological, sociological and economic inference tasks ( Gigerenzer and Brighton, 2009 ). Please note this table aims to provide only a brief overview of alternative types of reasoning and by no means covers the extensive literature on this topic. Adapted from ‘Different knowledge, different styles of reasoning: a challenge for guideline development’ ( Wieringa, Dreesens et al., 2018 ) with permission from BMJ Publishing Group Ltd.
In making frequentist inductive inferences, EBM requires patients and diseases to be clearly defined in quantifiable categories and to behave like non-loaded dice. Latour describes how science in general is constantly in a process of purifying reality to produce categories that can be manipulated and analyzed (e.g. reframing patients' illnesses in terms of genetic or molecular processes, mental states, organ dysfunctions, blood pressure readings and so on), which requires subsequent work to connect them back together again (clinicians dealing with patients holistically) ( Latour 1993 ; ( Wieringa et al., 2017 )). In the above example, the primary care physician practices EBM when she a) successfully purifies the patient's condition in terms of a combination of risk factors (hypertension, hypercholesterolemia , smoking etc.), b) uses that purified version to make a prediction and select some therapeutic options, and c) converts this knowledge into a format that can be integrated with a wider narrative to address the holistic physiological, psychological and social reality of this particular patient.
EBM's pyramid of evidence appears to equate reality with empirical measurement (the findings from clinical trials , for example) – a position aligned with positivism ( Djulbegovic and Guyatt, 2009 ; Nairn and Timmons, 2010 ). Yet even if we accept EBM's expansion to include integrating patients' values and clinical experience in addition to research evidence, EBM offers little clarity on how this wider reality unfolds other than probabilistically. The clinician may believe that her patient's future is – partly – governed by the probabilities of cardiovascular disease, but his future reality will also emerge from what is negotiated and agreed upon, which in turn will reflect what is viewed by the patient as personally resonant, culturally congruent and affordable and by the physician as ethical, reasonable and practically achievable. This reflects a more fluid and negotiated reality where what is considered true is powerfully influenced by what surfaces as particularly effective in the here-and-now (as in constructivism and pragmatism ). In the empirical study reported below, we show that these broader philosophies are also needed to fully explain the construction of guidelines as well as the use in clinical practice.

Section: 3. Methods

This ethnographic study ran from September 2016 to February 2019. We used purposive sampling ( Palinkas et al., 2015 ) with help from contacts at the Guidelines International Network to select and gain access to national guideline development groups in UK (National Institute for Health and Care Excellence [NICE]), Netherlands (Dutch General Practitioners Association [NHG]) and Norway (Health Directorate) – three countries with different healthcare cultures and processes for guideline development ( Burgers et al., 2003 ; Christiaens et al., 2004 ; Qaseem et al., 2012 ). We were interested in both commonalities and contrasts across these settings, though our aim was not to undertake a formal comparative study ( Lamont and Thévenot, 2000 ). We aimed at a variety of clinical and public health topics. The groups facilitated access to panels depending on availability and interest of the panels themselves.
The study was approved in the UK by the Social Sciences and Humanities Inter-divisional Research Ethics Committee (IDREC, reference number EQ C1A 16-28), in Norway by the Data Protection Official for Research via the University of Oslo (project number 48032) and in the Netherlands by the research ethics committee of the Radboud University Nijmegen Medical Centre (File number CMO: 2016-2680).
Three researchers (an academic GPs and two senior qualitative researcher with experience in guideline development research) observed 19 panel meetings. The panels varied greatly in set up and size, reflecting different remits and set-up histories. The observed NICE panels (UK) were large (up to 25 people) and multidisciplinary (consisting of NICE staff, experts from several disciplines including health economics, and lay members). In contrast, NHG panels (Netherlands) were usually smaller and consisted of only GPs, although we also observed one larger multidisciplinary panel. In Norway the observed panel meetings were multidisciplinary. 4 Panels were followed over time, which included 6 meetings of a Clinical Guidelines Update (CGUT) panel at NICE that were visited in a participant-observer role by SW over the course of 3 years. This panel was part of a NICE pilot project that operated in a significantly more protocolized way compared to the majority of panels at NICE.
We also undertook semi-structured interviews (remotely or face-to-face) with a maximum-variety sample of 10 participants recruited iteratively as the study unfolded and collected relevant documents. Details of data sources and their contribution are given in Table 2 . To disturb the process as little as possible, panel meetings were not audio-recorded, but we made detailed contemporaneous field notes with selected near-verbatim quotes. To maintain anonymity of all participants and interviewees, we followed a validated process to systematically fictionalize conditions, interventions and outcomes related to the guideline topic ( Winter, 1986 ). Table 2 . Overview of data structure. Approach Description of sample Type of data Descriptive insights Higher-order insights Ethnographic observation of guideline development panel meetings 19 meetings lasting 3–9 h each (120 h total) • 10 in UK (NICE) • 6 in Netherlands (NHG) • 3 in Norway (Health Directorate) Field notes focusing on actions and interactions of people involved in the guideline development process, including arguments (e.g. explanations and counter-explanations offered) How panel members collectively drew on different kinds of research evidence and other documentary sources in making (and justifying) recommendations. Nature of arguments among panel members. Insights into the process of “purification” (selection, abstraction and reconfiguration of research evidence to generate carefully shaped evidence statements targeting particular renderings of the patient e.g. as a member of a risk group ( Knaapen et al., 2010 )). Competing discourses and world views among panel members. Semi-structured interviews 10 in total • 6 in UK • 2 in Netherlands • 2 in Norway Interviews with guideline development group members, technical committee members, and managers from participating organisations Individuals' views on particular topics, their assessment of the evidence, and their reflections on how the guideline development process had unfolded for those topics. Addition of nuance to ethnographic findings. Documents >200 documents (publicly available and not publicly available) • 136 from NICE • 64 from NHG • 10 from Health Directorate 1500 pages of agendas, minutes, draft guidelines, review protocols, presentations on review techniques, overviews of evidence, GRADE tables. In NICE, ‘linking evidence to recommendations’ (LETR) tables and chapters with detailed contemplations of panels Material and visual properties of guidelines and interim documents. Elucidation of the (sometimes complex) chains of reasoning through which panels linked particular evidence sources to particular recommendations. Insights into the guideline as a text that ‘does work’ (e.g. inscribing and stabilising particular renderings of patient, illness or risk state, and intervention).
We used an interpretive approach to analyze data. Firstly, field notes, document excerpts and interview transcripts were thematically coded to identify first-order data (broad categories, themes, patterns and relationships through constant comparison ( Glaser and Strauss, 1967 ) with regards to the philosophical concepts as introduced above) using NVivo 12 for Mac by QSR International. To generate the higher-order data in the last column of Table 1 , we selected longer excerpts for more detailed discussion among all authors, inspired by a performativety theory ( Bell, 2006 ; Mol, 2002 ) . For this, we focused mainly on what individuals and panels did , and what was brought into being through this action. Specifically, we were interested in the different ontologies and epistemologies enacted in the guideline groups. Finally, we summarized and checked findings and interpretations through reflection and multidisciplinary discussion with guideline developers and panel members in several e-mail exchanges, presentations and interviews.

Section: 4. Results

Analysis of fieldnotes and documents using the philosophy of knowledge lens revealed findings in relation to three key questions: the nature of knowledge used in guideline development (ontology and epistemology), the different ways of reasoning and the process of making valid recommendations. We consider these questions in turn.
All panels appeared strikingly focused on explicit knowledge, with a particular predilection for published randomized trials and data extracted from research papers. Committee members received large amounts of documentation (via email in advance of meetings or handed out during meetings) in the form of overviews, GRADE tables, forest plots and other graphs. These data would most often be selected on the basis of particular protocols. However, in all three sites, panel members supplemented the supplied texts by actively seeking additional ones – for example by snowballing from those sources, looking up other literature online during meetings or even bringing in personal work as was observed in a NHG guideline panel. Members used laptops in real time to seek additional data, or review sent documentation. In a panel meeting at NHG we observed a panelist reading a publication from a laptop aloud. At the NICE CGUT panels we witnessed recommendations being constructed in Word on the spot en groupe and beamed on screen for all to see.
These findings illustrate how panel members' assume that scientific knowledge is explicit: much like objects, non-changing, stable fragments of text ready to be moved around, combined and translated ( Greenhalgh and Wieringa, 2011a ). Whilst this assumption is largely taken as a given within EBM, it been extensively challenged in the social sciences ( Davies et al., 2008 ; Gabbay and Le May, 2004 ; Lave, 1991 ). Indeed, the question of whether there is a fixed, external truth that science can reveal is perhaps the key epistemological issue which separates the EBM community from social scientists.
Davies et al. have suggested to use the term knowledge ‘intermediation’ instead of ‘translation’ to denote the complex managed interactions between multiple actors ( Davies et al., 2008 ). Previous ethnographic studies of guideline use by clinicians showed that knowledge is handled a few steps removed from the actual data. For instance, Gabbay and Le May found that general practitioners did not consult guidelines or research evidence directly; rather, they cited alternative sources, most notably the collective wisdom and prevailing practice of respected colleagues ( Gabbay and Le May, 2004 ). Our own data showed this to be the case for guideline development panels too. Panelists did not usually read the actual research papers themselves. At NICE, they would work with extracted data from research papers provided and produced by staff members. In some panels, extracted data was also provided by a dedicated panel member who would be assigned to research a sub-question, external experts who would be brought in to inform on a specific topic, or non-panel members from other institutions. At NICE, panels drew directly on systematic reviews produced by the Cochrane collaboration . At NHG, GRADE tables (a method of Grading of Recommendations Assessment, Development and Evaluation, see ( Guyatt et al., 2008 ; Thornton et al., 2013 ) were sometimes produced by a separate team within the organisation). A panel at NHG used a critically appraised topic (CAT) produced by GP trainees.
Gabbay and LeMay coined the term “mindlines” to denote a much broader understanding of knowledge that clinicians actually use to base their decisions on, including implicit and tacit knowledge , practical skills, both individually held and shared within communities ( Gabbay and Le May, 2004 ). We witnessed these kinds of knowledge in guideline development panels too, even though the focus of most guideline panels was on handling and judging explicit knowledge while attempting to observe clear rules and transparency. Members would bring in contextual issues such as potential for litigation, limited resources and cultural differences to judge the applicability of the findings. For instance, outcomes of hip fracture surgery in Scandinavia were deemed not comparable with the UK as Scandinavian patients would be discharged from hospital to nursing homes with more resources. In most if not all cases, many more kinds of knowledge were required to produce the clinical guideline than the explicit, text-based knowledge on which the panel actually focused. For instance, in this example panel members discuss how to advise on whether to operate a patient with an undisplaced hip fracture: Panel member 1: It's about transparency of that decision making , it's inherent judgement, implicit. We should put something about that in the guideline. Panel member 2: Can I challenge you on that? It's a bed-end decision. Panel member 1: Is that implicit, is that transparent? Panel member 2: I would have some idea if someone smells of alcohol. Panel member 3: There is no clear evidence about what is driving that. Chair: But we can make that statement, that we're concerned.
In this example, the first speaker wanted recognition for the role of implicit knowledge in clinical decision making even in the light of evidence. The second panel member tried to explicate this implicit judgment through contextual knowledge, such as the smell of a patient. The chair then suggested putting a statement in the documentation of the guideline apparently trying to leave room in the guidance for tacit knowledge.
We often observed panel members referring to practical knowledge by sharing what is currently being done, what could work in practice or how they would deal with the problem. In this example a panelist explains the steps she takes to place an IUD when it is difficult, without providing any explicit research data: If I do not succeed, I will [try to place an intra-uterine contraceptive device] a second time, and then I will do it with misoprostol and then I usually succeed. - NHG panel member, in meeting to develop a guideline on PID
Observations of nuanced actions by guideline panel members suggested awareness of the influence of social group processes on knowledge creation. For example, a chair would adjust table settings in order to support more reticent members to speak up and bring knowledge in or to oppose a dominant member. It was interesting to note that dominant members were not necessarily experts in the topic being discussed. Furthermore, throughout the succession of the clinical update panel meetings, members appeared to become socialised in what was expected of them. These subtle moves illustrate that the guideline development process is a social process, but they also illustrate a more philosophical point – that panel members (especially panel chairs) appear to recognize that the guideline will not be effectively validated through the technical process alone. Rather, unless the social and interactional aspects are skillfully managed, the resulting guideline could be epistemologically invalid.
In general, however, practical knowledge, personal experience and tacit knowledge were not formally valued in guideline development panels. For example, these kinds of knowledge were almost never included in the minutes, the ‘linking evidence to recommendations’ tables, the draft update or the final guideline. Even explicit knowledge that might have been noteworthy for clinical decision making for an individual patient sometimes never made it into the final version of a guideline. In some cases, sensitive information, such as evidence that doctors had financial (instead of clinical) motives to do certain operations and procedures, was omitted.
Nonetheless, we observed that a restricted view that only explicit knowledge should be used in developing an “evidence based” guideline was becoming problematic. Even in the NICE guideline development panel, which had a reputation for taking a more ‘fact-based’ approach than other panels, there was recognition of the value of other forms of evidence – and indeed that inclusion of this wider evidence increased the robustness of the guideline: We draw upon robust evidence in the meetings, but what physicians [externally] don't realize is that at the meetings, we do draw on a wider range of knowledge. They just see the research evidence we draw upon. But actually, we are confident that our recommendations are sound by drawing on clinical as well as research knowledge. - NICE Commissioning Guidelines manager in panel meeting
In common with other panels in our sample, in a NICE CGUT panel, most of the discussion centered on frequentist reasoning – for example on whether the trial samples were representative of knee fracture patients in the UK; the significance of inadequate blinding; the inconsistency of outcome measures, which made statistical summation impossible; and inappropriate follow-up periods. For all these reasons, the panel systematically “downgraded” the trials being considered (thereby flagging a higher level of epistemic uncertainty) using GRADE criteria.
Despite the predominance of the kind of frequentist reasoning that is highly valued in the EBM community, we also observed various kinds of non-frequentist reasoning, including what might be called ‘non-analytical’ reasoning (“don't like it”, therefore the guideline must be “wrong” or “biased”) and the precautionary principle (justified by an anecdote of a failed procedure in a panelist's relative). The main ‘evidence to recommendations’ table linked to this guideline stated that “certainty around the majority of outcomes was low …. [due to] … several factors based on a full GRADE assessment”. The table thus depicted the recommendation as stemming entirely from frequentist reasoning. It did not capture (indeed, its authors either deliberately or inadvertently ignored) the additional reasoning drawn from panel members' experience and intuition. In other cases and panels however, also at NICE, we observed that clinical reasoning was explicitly mentioned and used to cast doubt on findings from trials and observational studies.
As explained above, frequency type reasoning requires a stable concept to model. But as Latour pointed out, acts to purify reality including defining, categorizing, objectifying, framing, demarcating patients, events and diseases are difficult – and ultimately subjective.
Our observations suggest that although NICE has detailed and informed processes in place to scope a topic and develop a review protocol before a panel commences, in practice these processes were insufficient to achieve a stable and uncontested understanding of the topic.
For example, we observed in a NICE panel a topic presented in a short briefing paper drafted by a (non-clinical) NICE team member. Topic experts were then expected to provide further clarification which proved essential before the panel could proceed. For some meetings of clinical guideline update panels, a conference call with experts preceded the panel meetings to decide on the review protocols (though even when this occurred, there would still be extensive discussions on the scope of the updating). But the assumption that a purely methodological update process based on PICO questions (established model to define clinical questions in Population, Intervention, Comparison, Outcome format) could lead the NICE team to the assumed external truth was not borne out in practice. Rather, as illustrated by a discussion on how a “displaced” fracture should be defined, debates on how to understand the topic of interest were frequent and ongoing, even in the final stages of making recommendations.
We saw a similar struggle with frequentist reasoning and purification on a panel meeting for a screening tool at the Health Directorate in Norway. Here, the project manager proposed the construction of an epistemologically diverse guideline, reminding the panel that they will be considering “research-based, experience-based and user-based” evidence. Once again, the guideline development process seemed to have already begun (in prior meetings) with evidence prepared according to frequentist assumptions: a rational assessment of published research evidence using structured tools designed to assess their methodological quality and external validity. The original plan had been to use such methods to surface the single, “best” screening tool to be used universally. But in the that particular panel meeting, it appeared that notwithstanding the (contested) frequentist evidence, there seemed to be pragmatic reasons why different tools may be more acceptable and suitable in different contexts. Panel members began to stray from the systematic application of a decision tool and instead begin to draw on their own experience (e.g. “what I feel intuitively”, based on widespread custom and practice of the use of one tool in Norwegian hospitals, though it was also noted that this tool was not in widespread use in nursing home and home care settings). The palpable sense of frustration as the meeting ended partly reflected the epistemological clash between the frequentists' continuing conviction that a single, “best” tool should be identified and recommended in the guideline and the pragmatists' conviction that recommendations should be based on what will work in practice.
We observed many activities in all panels as part of their attempt to ensure valid recommendations. For instance, the panel meetings at NICE started every time with re-checking members' declarations of interest. This is consistent with what EBM pioneers deem the positivist position in EBM ( Djulbegovic and Guyatt, 2009 ), which holds that there exists an unbiased “view from nowhere” which the guideline panel should aspire to reflect. The truth is assumed to be what averages of empirical data - found using a superior scientific method - tend to in the long run, so long as the data are assessed without bias like a non-loaded dice ( Wieringa et al., 2018 ).
Of all the observed panels the NICE CGUT panel most explicitly espoused the goal (in the words of a senior member) “to eliminate mindlines from that translation”. In order to do so these pilot panels consisted of a NICE technical team, topic experts, lay people and non-expert standing committee members, working to make rapid updates of sections of existing guidelines. The standing committee members (consisting of clinicians, methodologists, lay people and commissioners) without topic expertise were there to counterbalance the potential dominance of the contributions of the topic experts over the NICE team (who were viewed as less biased). A NICE staff member said: Mixing specialists with neutrals, reduces evangelistic, a religious belief. It can lead to standoff but that's better than using evidence [selectively] to support beliefs.
Epistemologically, panels could also be considered set up to ensure truth and reduce uncertainty by building consensus. But findings of the study presented did not confirm this view. This was markedly clear in the clinical update panels from the pilot at NICE who had been made aware that recommendations could not be based on consensus. The chair often reminded members not to bring in other knowledge (from experience or research, such as observational studies, which did not meet the inclusion criteria) in order to adhere to the analysis as defined in the guideline development protocol. In practice this proved to be quite a challenge. For instance, a panel struggled with insufficient evidence on outcomes for operating on people with cognitive impairment . As they were not allowed to make recommendations based on consensus, they looked at trends in the provided studies instead: Panel member 1: Do we have enough evidence to keep cognitive impairment as a factor? Panel member 2: They weren't in the [X] study. Chair: We're not allowed to make consensus statements, but the studies showed more positive results for operations in the cognitive impaired. Discussion at a NICE guideline panel
In contrast to the appearance the published guidelines contained integration of different voices and explicit knowledge, deliberative (and non-analytical) processes combing different kinds of knowledge were observed in practice. A multitude of more ambiguous remarks by individual panel members appeared to significantly shape the discussions to understand the findings from the systematic reviews , chiming with Bakhtin's dialogism ( Bakhtin, 1984 ). These voices however generally did not end up in the final recommendations or ‘linking evidence to recommendations’ sections. These sections would present summarized deliberations on how to interpret the findings as concise arguments from a seemingly united panel. In a sense this was the case: panel members were given the opportunity after the meetings to amend the sections that portrayed the group discussions . Panelists would need to confirm their agreement with the final guideline as a whole, including those reflections. Members however explained that due to the large size of the update reports, it was uncertain if they had completely understood with what was agreed upon in the guideline.
A classic theory of truth sees coherence with other propositions as another criterion for valid and true statements. Indeed, we saw the wordings of recommendations would be guided by previous recommendations as most panels are now involved in updating guidelines. In contrast to NICE policy, NHG recommendations were generally developed to cohere with other guidelines, such as European guidance, guidance from other national medical professional bodies and NICE:
Panel member 1: We say it does not make sense … is completely contrarian
Panel member 2: There is a new thrombosis guideline from the [Association of Gynaecologists]
Panel member 3: We can work with their questions …
But instead of adhering to a single ‘superior’ scientific method (as the assumptions of EBM might suggest), we observed considerable epistemological pluralism . In a panel meeting on pelvic inflammatory disease (PID) at NHG members started to use frequentist assumptions to challenge the RCT evidence on when best to remove an intra-uterine device (IUD) in a woman with PID. They were concerned, for example, about a lack of a clear definition of PID (meaning that, in Latour's terminology, the population has been inadequately “purified”); they doubted the representativeness of the trial samples to a primary care population; and the CAT (critically appraised topic) technique fails to produce a definitive answer to the PICO question. In the face of limited frequentist evidence, the all-GP panel quickly reverted to other ways of reasoning. For instance, they used mechanistic reasoning when a panelist suggested that an IUD should be seen as a foreign body that needs to be removed. They also started to ask what would or would not work in practice. This could be seen in light of a repertoire of usability, but through our epistemological lens also as applying a pragmatist theory of truth: the recommendation is valid and true if it succeeds in practical application. The panel concluded that, given the high level of uncertainty around the trial evidence, an expectant approach (“authority-based evidence” as captured in a different national guideline from gynecologists) is “probably best”. After discussion, they decided to convey the uncertainty in the guideline and recommended the use of clinical judgement on a case-by-case basis. One member proposed that in every case the GP should set out his or her reasons for removing the IUD.
Reflecting on the contrasting views on kinds of knowledge, reasoning and truths at play in the guideline process, a guideline maker observed much internal debate on the many different guideline committees' approaches all being practiced in the same institution dependent on the topic at hand: First there were the easier questions, there were the RCTs, that's where everybody started. They're easier to understand, because of things like CONSORT. They're easier to make decisions, because you got rules. Before GRADE you had statistics, that we all understood, we all thought we understood p-value, we understood what effectiveness was. But all the time guidelines have tackled harder questions, they moved into public [health] and social care. I think the pendulum swung in order to answer those harder questions; you have to use different types of study design. Now the reproducibility of RCTs is more of a hot item and it swings back [to a purer epistemology]. - NICE guideline developer

Section: 5. Discussion

This ethnographic study of guideline development panels has added to the existing literature by extending previous sociological research with a philosophy of knowledge perspective.
Social scientists who have analyzed the practices of guideline development ( Atkins et al., 2005 ; Knaapen, 2013 ; Moreira, 2005 ; Nairn and Timmons, 2010 ) have repeatedly shown how knowledge other than systematic reviews , controlled trials and other designs in the evidence hierarchy is unavoidably incorporated in guidelines. These knowledges are used not just to challenge the evidence (e.g. biological mechanisms and personal experience), but also to act as justifications (e.g. ethical principles and practice standards) for recommendations.
Researchers who have studied guideline development panels ethnographically have observed that evidence is often perceived to be lacking. Indeed, based on one such empirical study, Knaapen proposed that EBM is less about the quantity or quality of evidence than about “the specific management of the absence of evidence, requiring a transparently reported process of evidence searching, selection and presentation. […] The legitimacy of Evidence-Based Medicine relies neither on experts nor numbers, but on distinct procedures for handling (non-)Evidence, reflecting its ‘regulatory objectivity’.” ( Knaapen, 2013 )
The four repertoires originally described by Moreira (2005) were evident in the work of all three panels, though they played out somewhat differently in each case. Knaapen et al. identified four kinds of evidence that might be (though which were not necessarily) accepted by panellists as scientific and eligible for incorporating into the guideline: clinical trial findings; biological and pathophysiological principles; ethical issues relating to the research process (e.g. whether informed consent was obtained from trial participants); and “knowledge of the clinic” (i.e. current standards of practice and care pathways) ( Knaapen, 2013 ). However, our own findings indicated that much more implicit knowledge beyond Knaapen's types of evidence were required to make recommendations, including an awareness of the subjective nature of decision making and the importance of contextual knowledge.
Our findings support Knaapen's conclusion that EBM is not so much about quantity or quality of evidence. Yet, it not just about transparency either. Our findings illustrated how contrasting philosophies of science underpinned many of the disagreements among panel members, influenced the practice of guideline development and, in some cases, became captured in the guideline itself.
Our focus on the philosophy of knowledge, reasoning and truth adds to findings from the social scientific literature as it joins a social understanding of the practice of guideline production with the objective of the EBM movement: supporting clinical inference for individual patients. Our study illustrates how at least two contrasting, yet linked, epistemologies are performed in guideline development. Whilst multiple epistemological assumptions were evident in each panel meeting, the balance of how these were dealt with varied between the different panels.
We observed guideline panel setups and processes that set the stage for a “pure” kind of EBM, adhering to a certain theory of truth, namely the ideal limit theorem – the assumption that there is a hard reality out there which scientific inquiry can get closer and closer to as techniques get more accurate and studies are replicated ( Wieringa et al., 2018 ), a certain way of reasoning (‘frequentist’), using a certain type of knowledge (only explicit data of frequent events) from a standardized form of purification (PICO). But we also found a practice that aims for a pluralist interpretation of EBM, applying multiple kinds of knowledge, types of reasoning and concepts of truth to help clinicians and patients make valid inductive inferences. Guideline panels do not generally surface or discuss their epistemological perspectives, but they appear to practice a mixture of these two positions, never satisfying either fully.
From its earliest origins, EBM has appeared uncomfortable with epistemic uncertainty, arguing that clinical method should shift from a hermeneutic and imaginative process to a more formulaic approach (ask a focused question, search for evidence from rigorous research using the PICO – population-intervention-comparison-outcome - acronym, apply the evidence in practice) with the aim of reducing (and preferably eliminating) uncertainty in the clinical encounter ( Evidence-Based Medicine Working Group, 1992 ). The philosophical assumptions behind this shift have been questioned ( Greenhalgh et al., 2014 ; Howick, 2011 ; Solomon, 2015 ; Tonelli, 1998 ).
Most clinicians are well aware that whilst clinical practice guidelines may contribute to good clinical practice, clinical decision-making also takes account of a wider range of evidence, including qualitative research , local realities, the patient's needs and preferences, and the experience and clinical wisdom of the physician ( Gabbay and Le May, 2004 ; Timmermans and Angell, 2001 ). When applying (or choosing to ignore or adapt) a guideline in a specific patient scenario, clinicians draw on collective knowledge known as “mindlines”, which incorporate shared tacit knowledge , prior experience and prevailing debates ( Gabbay and Le May 2004 ; ( Wieringa et al., 2018 ); ( Wieringa and Greenhalgh, 2015 ).
We have previously argued that the ideal limit theory of truth has considerable appeal in the EBM community (( Wieringa et al., 2018 )). For instance, the EBM manifesto (a UK based campaign that promotes steps to develop trustworthy evidence) calls to reduce “systematic bias, wastage, error, and fraud” in clinical research . These goals are laudable, but - with the exception of fraud – can only be understood from a purist epistemology of EBM. However, as we saw in all panels, (even in the CGUT panel), it appears impossible to keep elements of other epistemologies out even under strict conditions.
Our findings suggest that, contrary to what is still widely assumed within the EBM movement, the guideline production process is not – and indeed cannot be – restricted to purely frequentist reasoning and objective judgements. To the extent that this is true (and that may vary considerably depending on the topic), the question arises of how to systematize and benchmark the inclusion of other forms of knowledge and reasoning (such as panel members' accumulated caseload of personal clinical experience and their intuitive or emotionally-driven hunches, collective deliberation, mechanistic reasoning and so on). Whilst we caution against any attempt to ‘over-script’ this complex process, we believe that a more pluralist stance, as promoted by many ( Burgess and Burgess, 2014 ; Chang, 2012 ; Shlonsky and Mildon, 2014 ) and in part already practiced by guideline makers including NICE, is required. Guidelines could benefit, for example, from more insights into molecular and physiological mechanisms ( Parkkinen et al., 2018 ; Russo and Williamson, 2007 ), qualitative studies to provide complementary perspectives ( Greenhalgh et al., 2016 ), the influence of local contexts ( Rowe and McDaid, 2007 ; The Council for Health and Society, 2017 ) and the risks of recommendations being wrong. Social and psychological research suggests different roles of guidelines in clinical practice for physicians of different levels of experience ( Dreyfus, 2004 ; Flyvbjerg, 2001 ). In any case users should take in consideration that guidelines are made of and offer different types of knowledge than those that contribute to the mindlines of clinicians used to make decisions for single patients.
Tonelli and Upshur exhort medical educationists to teach students not merely to accept epistemic uncertainty in clinical practice but to actively explicate and mitigate that uncertainty ( Tonelli and Upshur, 2019 ). We have previously argued that far from being a negative influence on clinical practice, epistemic uncertainty can be a positive force, prompting the clinical imagination through reflexive questioning and using active awareness of multiple possibilities to support lateral thinking in the diagnostic process ( Engebretsen et al., 2016 ). We agree with Tonelli ( Tonelli and Upshur, 2019 ) that epistemic uncertainty lies at the heart of what it is to practice excellent medicine.
Although this study did not study how clinicians manage epistemic uncertainty in practice, it highlights how medical guideline development is a complex process with degrees of right and wrong being dependent on multiple and layered epistemic variables, where there are no (or few) absolutes. Further research is required to explore how knowledge of guideline development could help to deal with epistemic uncertainty. Much of the current training offered to students in EBM can be thought of as a systematic approach to undertaking Latour's “purification” (as in reducing the patient's presenting problem to a series of PICO questions). Critics argue that this training encourages them to over-value knowledge that can be made explicit and quantified, ready for frequentist induction. We and others have shown that other epistemologies are at play.
In the process of building capability to cope with clinical complexity (‘the ability to adapt to change, generate new knowledge, and continuously improve performance’) ( Fraser and Greenhalgh, 2001 ), students, but also guideline makers and scientists should be able to debate and consider some of the broader philosophical ideas underpinning inductive inference in medicine. A more prominent dialogue within the EBM movement is needed about the role, the paradoxes, benefits and harms of its everyday practices with the help from epistemologists and social scientists who take into account the goal of making better recommendations. Ultimately, guideline production should become a less standardized and more reflexive practice, which includes being continuously critical and aware of its philosophical assumptions.

Section: Credit author statement

Sietse Wieringa: Conceptualization, Investigation, Data curation, Methodology, Formal Analysis, Writing- Original draft preparation, reviewing and editing. Eivind Engebretsen : Conceptualization, Methodology, Formal Analysis, Writing- Original draft preparation, reviewing and editing. Kristin Heggen : Conceptualization, Methodology, Formal Analysis, Writing- Original draft preparation, reviewing and editing. Trisha Greenhalgh : Conceptualization, Methodology, Formal Analysis, Writing- Original draft preparation, reviewing and editing.

Section: Acknowledgements

The authors wish to thank senior researchers David Wright and Gina Fraas Henrichsen for their contributions toward data collection. We like to thank Toni Tan and Nichole Taske at NICE, Margriet Bouma at NHG and Frode Forland, Specialist Director Infectious Diseases and Global Health, Norwegian Institute of Public Health in Oslo for making this research possible. We like to thank the reviewers for their suggestions and comments to improve the paper. SW and EE’s input were funded by European Union Seventh Framework Programme (FP7‐ PEOPLE‐ 2013‐ COFUND), Grant/Award Number: 609020. TG’s input was funded by the National Institute for Health Research Biomedical Research Centre, Oxford, United Kingdom (grant NIHR- BRC-1215-20008 ).
