Title: The social life of biomedical data: Capturing, obscuring, and envisioning care in the digital safety-net


Abstract: Abstract

Biomedical investment in digital technologies has flooded society with staggering volumes of data , spurring high-tech innovations such as performance metrics, clinical algorithms, and public data dashboards. In examining the social life of data artifacts, scholars draw from actor-network theory to emphasize data's ability to represent social reality while circulating within it, while others suggest formal data models fail to account for invisible relations on the ground. Yet little work has examined the role of human reflexivity in crafting complex human-data configurations in practice , such as how situated human actors relate to data representations within the social reality they intimately know themselves. Drawing on ethnographic fieldwork of Electronic Health Records (EHRs) and data analytics integration from inside the digital safety-net, this article shows how health care workers recognize data simultaneously capture, obscure, and envision their everyday work of caring for the marginalized. By demonstrating how the same data point may in one context demonstrate good care while in another obscure it, these findings suggest need to broaden attention to the social life of data beyond delimited focus on standards and their travels. Digital technologies do not simply capture the social, but multiply it. Biomedical data then do not have one social life, but many.

Section: 1. Background

Rapid advances in EHRs and data analytics have spawned numerous high-tech innovations across health arenas, revealing the eminent centrality of data to contemporary United States biomedicine ( Clarke et al., 2003 , 2021 ; Ruckenstein and Schüll, 2017 ; Altman and Levitt, 2018 ). The explosion of metrics, algorithms, ratings, and other calculative accounts within clinical settings appears as displacement of traditional forms of knowledge and action, grounded in biomedical data sources generated through meaningful use of digital health technologies ( Ferris, 2010 ; Blumenthal, 2010 ; Office of National Coordinator for Health IT, 2010 ). Data-intensive and computational techniques approach these data sources as faithful representations of social reality, drawing from EHR databases as the single source of truth for capturing care proceedings as data points ( IOM, 2014 ; Galetsi et al., 2019 ; Atasoy et al., 2019 ). Data reports of performance metrics and system scorecards now decorate hospital and clinic hallways, open routine department staff meetings, and clutter the screens of powerful decision-makers (opening quotes). Public data dashboards further appear on government websites and community billboards, reflecting the far reach of these same data sources beyond clinical settings and sites of care alone (e.g., CMS Care Compare, medicare.gov/care-compare ; HRSA Uniform Data System, data.hrsa.gov/tools/data-reporting ).
In examining the social life of data artifacts, social science scholarship typically emphasizes data's ability to capture reality and actively transport it within broader society ( Ruppert et al., 2013 ; Ruckenstein and Schüll, 2017 ; Kitchin, 2021 ). Drawing on actor-network theory and its progeny ( Latour, 1987 , 2005 ; Law and Urry, 2004 ; Law, 2009 ), scholars privilege technology's ability to trace out “doings” (e.g., representing reality) and the liveliness of resulting data (its circulation and action): Digital devices observe and follow activities and ‘doings’… such ‘doings’ might include physical movements, but have more to do with actions and their traceability… a device can make, compile, and transmit digital data and/or remake, analyse, and translate data into information and interventions ( Ruppert et al., 2013 : 35).
Data-centered accounts are thus presented as active players in reassembling the social, capturing social reality as digital traces (i.e., immutable data points) while circulating within it as a participating force in their own right ( Law, 2009 ; Savage, 2013 ; Beer and Burrows, 2013 ). Biomedical data may cross into social spheres beyond their origin ( Angell and Solomon, 2014 ; Nelson, 2016 ), and recent programs of accountable care seek to leverage data's transportability to transform care delivery from afar ( Rose and Miller, 2008 ; Shore and Wright, 2015 ; Espeland and Sauder, 2016 ). By measuring everyday care and reporting aggregate data to state agencies, expanded digital infrastructures also disseminate information to expanded public audiences: as a result, data standardization and circulation feature prominently within scholarly and policy accounts of digital transformation ( Blumenthal, 2010 ; Galetsi et al., 2019 ; Atasoy et al., 2019 ).
In prioritizing this technology-centered account, however, scholars risk adopting a managerialist perspective while eliding attention to invisible relations surrounding data systems on the ground ( Star, 1991a ; Bowker and Star, 1999 ; i.e., privileging the viewpoint of scientists and engineers over those of everyday people). Data scientists and AI practitioners may wish to build data-centered models as accurate representations of the world, yet effectively “delete the social” in decontextualizing technology from practice and centralizing a single reality to be taken as universal ( Forsythe, 2001 ; Star, 1991b ). A second line of scholarship has sought to uncover these invisible relations surrounding data systems: clinical algorithms may amplify initial bias within training data, silently encoding inequality within technical artifacts ( Obermeyer et al., 2019 ; Benjamin, 2019 ; Noble, 2018 ; Roberts and Rollins, 2020 ); standards-setting entities conceal value-laden priorities, while carrying particular assumptions about the domains being measured ( Bowker and Star, 1999 ; Merry, 2016 ; Cruz, 2017 ; Westbrook et al., 2021 ); and data reporting minimizes key variation in institutional context, such as differences in care capacity across clinical settings ( Cruz and Paine, 2021 , Thompson, 2021 ; Gaspar et al., 2020 ). Others emphasize the decoupling of data-driven objectives from intimate work on the ground, resulting in limited change despite expanded data availability ( Asdal, 2011 ; Greenhalgh et al., 2014 ; Hoeyer and Bødker, 2020 ; Cruz, 2021 ). Thus data-centered accounts by no means serve as clear stand-ins for “tracing” reality: even as they capture doings as digital representations, they also run the risk of erasing key elements of social experience ( Star, 1991a , 1991b ; Forsythe, 2001 ; Braun et al., 2021 ).
One means of bridging these two approaches is to center human capacity for reflexivity, as only situated human actors are equipped to evaluate standardized data's correspondence with the social reality they intimately participate in and know. Luc Boltanski reminds us human actors are rarely content to merely act or react to representations of themselves, but rather possess reflexive capacities centered around evaluation and judgment ( Boltanski, 2011 ; Boltanski and Thévenot, 2006 ). Human actors further contextualize the relevance of knowledge for embedded social action , drawing from their own understanding of the social worlds they themselves comprise ( Berg and Goorman, 1999 ; Suchman, 2009 ). Reflexive capacity also sustains multiple logics within routine care provision: Annemarie Mol (2008) shows how competing frames may explain differences in medical treatment (e.g., managing diabetes by “care” or “choice”), thus recognizing complexity without reducing it to social position or viewpoint (see also Mol, 2002 ). In sum, human actors — including social scientists as well as actors on the ground — reflexively engage with data-centered accounts within reality itself, resulting in several possible human-data configurations in situated practice.
This article examines how embedded health care workers relate to biomedical data in the everyday practice of care, leveraging qualitative fieldwork from inside the digital safety-net. Numerous policy proposals support widespread integration of EHRs and data analytics within clinical settings, flooding providers and organizations with new data reports on care quality, cost, and equity ( Office of National Coordinator for Health IT, 2010 ; Institute of Medicine, 2014 ; Cantor and Thorpe, 2018 ; Anderson et al., 2018 ). These advances have accordingly created the digital safety-net: a situated context where digitization appears to make the previously invisible now visible, transforming providers and staff, organizations (formerly “of last resort”), and patient care into data points circulated in clinical settings and in broader society. It is a high tension zone ( Star, 1991a ) where high-tech data artifacts infuse low-resource settings, where technoscientific innovation interfaces institutional neglect, and where societal care for the marginalized meets public demand for measured accountability. The digital safety-net is a particularly potent site for examining technoscience in relation to power and inequality, and is but one of many forms of biomedical stratification ( Clarke et al., 2003 , 2021 ; Nelson, 2011 ; Shim, 2014 ; Rubin et al., 2018 ; Cruz and Paine, 2021 ). This research thus examines how health care workers contextualize biomedical data within care in the safety-net, offering an empirical account of the social life of data situated in a particular context of marginality.

Section: 2. Data and methods

This article draws on a qualitative study of data-centered accountable care from inside the digital safety-net. The organizational field site disproportionately cares for low-income, racialized patients insured through Medicaid managed care , yielding it highly sensitive to Medicaid policy reforms and related programs such as Section 1115 Demonstration Waivers ( Institute of Medicine, 2000 ; Fiscella and Epstein, 2008 ). Recent waiver programs have built on policy trends of accountable care and “delivery system transformation,” comprising investment in EHR and health IT capabilities, integration of data analytics and quality metrics within care delivery, and expanded public reporting to state entities to demonstrate system performance ( California Health Care Foundation 2014 ; Centers for Medicare and Medicaid Services, 2021 ). These developments bear affinity with societal tendencies towards quantified accountability ( Shore and Wright, 2015 ; Merry, 2016 ; Espeland and Sauder, 2016 ; Hoeyer et al., 2019 ), yet are remarkable for combining high-tech innovation with anticipated sociopolitical transformation specifically within the safety-net ( Andrulis and Siddiqui, 2011 ; Zhang et al., 2017 ; Pérez-Stable et al., 2019 ; Cantor and Thorpe, 2018 ). Scientific and advisory bodies typically frame investment in safety-net analytics as redressing potential digital divides, despite growing recognition of technology's complex relation to social inequality ( Noble, 2018 ; Benjamin, 2019 ; Timmermans and Kaufman, 2020 ; Obermeyer et al., 2019 ; Chen et al., 2019 ). The present study offers a closer examination of this particular context of data-centered accountable care, focusing on how health care workers make sense of biomedical data from inside the digital safety-net.
As a part of my fieldwork (n = 450 hours; September 2017 to June 2018), I first shadowed a primary data team responsible for introducing data analytics and performance metrics within the larger organization (renamed as County Health System for study purposes). In following this multidisciplinary team of program managers, quality improvement coordinators, data analysts, programmers, and clinic representatives, I was granted unique access to the behind the scenes work of integrating data analytics within systems operations and administration. As a participant-observer, I attended regular meetings between the data team and outpatient clinic staff, where frontline workers were presented with performance reports from EHR data and regularly discussed data-centered program initiatives. I also observed interactions between the data team and C-suite executives, and examined consults with analytics staff and EHR consultants. After several months of observation with the data team, I then targeted two outpatient clinics to observe how providers and staff relate data and technology to routine care practices. This resulted in attendance at internal clinic meetings (i.e., without the data team), observation of provider and staff EHR use, and informal discussion of the numerous data reports surrounding clinic operations. Detailed fieldnotes were supplemented by in-depth, semi-structured interviews (n = 32) with health care workers from the data team, administration, analytics division, and outpatient clinics.
In initiating data analysis, I first isolated all observational and verbal accounts of data work ( Biruk, 2018 ; Christin, 2020 ; see also Hanssmann et al., 2021 ), including the interactional, organizational, and institutional activity of integrating data analytics within care. Following the procedures of grounded theory and situational analysis ( Charmaz, 2007 ; Clarke, 2005 ), open coding yielded an early insight of “data as visibility” across several program metrics and health domains (e.g., blood pressure control, hospital readmissions). Refined coding identified additional heterogeneity within these preliminary categories, including recurring concerns over data standardization and representations of safety-net care specifically. Close examination of these concerns revealed often multiple interpretations around a common data-centered account, sometimes even within a single participant interview. These analyses were then assembled into several possible human-data configurations, emphasizing how human actors make sense of and relate to biomedical data within the everyday practice of care. Given the centrality of visualization within the social life of data ( Merry, 2016 ; Clarke et al., 2021 ), I also reviewed the innumerable data reports encountered during fieldwork to further refine analytical findings.

Section: 3. Findings

By analyzing how health care workers relate to data representations of the social reality they themselves reflexively know, I show data are understood to simultaneously capture, obscure, and envision care in the digital safety-net. I present these findings with supplemental data visuals to underscore how the same data report may be situated within varying contexts; these composite illustrations were crafted by synthesizing across data reports collected in the field as well as additional public data sources (all site and clinic names serve as pseudonyms).
In measuring the social world, data allow things to come into view. When human actors interpret data-centered accounts as meaningful representations, the data are understood to capture the social, directly corresponding with the reality of the world. As people work with metrics, rankings, and data dashboards to lend visibility to otherwise hidden relations, data serve as a means of revealing the social world to itself.
This view of data as meaningful measurement precedes the rise of EHRs and data analytics, as exemplified by the ordinary taking of routine vital signs. By measuring blood pressure at the start of an appointment, for example, a clinician may interpret high values as a potential indicator of hypertension and heightened risk of heart disease. Reflecting on her clinic's attention to a performance metric for controlling high blood pressure, a nurse manager notes how standard measurement allows for the mapping of patient progression over time, with the resulting data dashboard providing an overview of patient and societal health: We finally got a handle on the blood pressure metric by scheduling a return visit for patients and standardizing how we [measure] in the clinic, and it has really improved! (smiles) ( Fig. 1 . County Health Dashboard, “Central Clinic”). When you look at blood pressure as a number, you know that if the number is good, then the patient is getting their health improved, and you start to see things getting better within society. Patients don't just come to appointments when they have urgent needs. Now they come in looking healthier, with their needs maintained. (Nurse Manager, Outpatient Clinic)
The data here are understood to correspond with social reality, with improved blood pressure readings indicating better health as a whole. When aggregated across patients and over time, the blood pressure metric allows for health workers to see the progress made in improving patient health, and compare these numerical reports with what they see on the frontlines in the clinic and in broader society.
Data analysts may also interpret data as meaningful representations, with data standing as a showcase to others within the same organization. Data may not only reveal the current state of patient health or its change over time, but may also be understood to demonstrate the active work being done within the clinic. An analyst explained how data-centered accounts represent the work of becoming “data-driven”: The metrics [data] really are designed to show what we're doing , so you can start seeing the progression from them. When you start seeing the needles moving, showing improvement because people are getting better outcomes, they're getting their care on time, their medications are being reconciled – that's when the case is made [for data-driven care] … It really comes down to the data as the showcase. And providers feel like patients are getting healthier because they can see the metrics moving in the right direction. (Data Analyst)
Thus data reports, such as those created of blood pressure metrics tracking progress over time, are also understood by human actors as conveying the work of providing care within the safety-net. Standard data capture the social : by tracking pre-specified elements and allowing for comparison within everyday reality, measurement is viewed as closely corresponding with the social world. Download: Download high-res image (592KB) Download: Download full-size image Fig. 1 . County Health Dashboard: Controlling High Blood Pressure. Description: Health system data dashboard. Data reports are regularly presented to outpatient clinics during routine meetings between data team and clinic staff. Performance metrics facilitate comparison across clinics and providers over time. Caption: Data report on controlling high blood pressure for County Health System, comparing Central, Downtown, Neighborhood, and Regional outpatient clinics. Standard metrics of blood pressure control facilitate health care worker reflection on their own activity. Composite illustration created from data reports collected during fieldwork, pseudonym clinic names.
This understanding of data is directly linked to accountable care initiatives, with data analytics essential not only for revealing care to providers and staff, but in demonstrating activity to external audiences. One key element of such initiatives is expanded public reporting, and the data generated by routine EHR use (e.g., regular blood pressure checks) ultimately informs the creation of reports circulated beyond the health system itself. The data analyst from above described how data's direct correspondence with care informs this logic of accountability: We roll up the data to [state entity], and they roll it up to CMS, and that allows them to see the care we provide here . It shows them we're doing what we're saying we're going to do, and it allows them to double check we really are taking care of patients in terms of their diabetes care, for example. It also gives [CMS] an avenue to ensure to the public by seeing for themselves what we're doing and what we have done ( Fig. 2 , Fig. 3 . Public Reporting). So the data is used to allow people to basically check and see it for themselves. Because if you can't see it, you don't know if it really happened, right? (Data Analyst)
Data reports are framed as speaking for health systems directly, showing “what is happening” within the organization to government agencies and expanded public audiences. Citing the importance of public transparency, online reporting websites such CMS Care Compare and other data dashboards are framed as revealing the inner-workings of clinical care and patient outcomes, thereby bringing accountability to the safety-net through expanded visibility.
In capturing the social to allow proceedings come into view, EHRs and data analytics also allow health care workers to challenge everyday notions of the safety-net. An on-site programmer shared this understanding of data-as-visibility, with data-centered accounts demonstrating care capacity for patient referrals and provider availability to the general public: Being data-driven is all about seeing what's happening, how can we improve little processes to make the bigger system work better. For example, prior to [EHR and data analytics], we may have had specialist availability, but it was impossible to look into our system . So previously it was like [among general public], “No, you don't want to go to County for care — they're never going to get you in. You'll probably die before you get in.” But with all these data, now it's more like, “You can totally get into County. I don't know why you couldn't — we do have the availability, and with the data, I know we can provide that care.” That's why I'm very data-driven, because without data, we wouldn't know how big of a success we are [in the safety-net; at County Health System]. (Programmer)
Thus health care workers recognize biomedical data as lending visibility to their own organizational operations, providing data-driven “proof” to the public of the quality and value of the care provided in the safety-net. Because data are viewed as standing in for progress in patient health and clinical work, the data are thus understood as meaningful representations of care. By capturing the social, data seemingly stabilize the social world so as to render it publicly knowable and actionable.
In distilling the pulses of social life into numbers, however, data ultimately highlight certain elements of everyday activity at the expense of others. As data reports conceal measurement priorities and the conditions of data production itself, human actors also understand data may fundamentally obscure the social . By reflexively engaging with data of the same world they reside in, human actors suggest data inadequately correspond with the reality they appear to represent.
In recognizing data may obscure social reality, health care workers emphasize standard measurement may prioritize other concerns beyond those on the ground. Standards-setting entities embed priorities within data standardization that oftentimes render the data less-than-useful for the needs of those providing care: as such, the data are understood to reveal certain elements while simultaneously concealing others . This surfaced repeatedly in response to the Hospital Readmissions Reduction Program, with the federal program calculating all-cause readmissions to compare organizations and distribute financial payments accordingly. But embedded health care workers insist that expanded data availability (in this case, standardized measurement of readmissions) oftentimes does not reveal what frontline staff and administrators desire to know, due to the technical specifications of the employed measure: For years now, we've been arguing about all-cause readmissions — I don't want to say it's a bogus measure, but it doesn't tell us what we need to know . We need to know if the patient is coming back because of something related to the first admission — not just did they fall and break an ankle and have to have surgery after an MI [myocardial infarction; heart attack]? How can we have data that's more helpful to us and not as general? (Director of Quality)
In contrast with the human-data configuration presented above, where data are understood to lend visibility to both care and outcomes, here measurement is critiqued for not showing what health care workers deem as meaningful. When federal and state programs count all readmissions as equivalent regardless of cause (given policy objectives of reducing costly admissions), this same practice is precisely what limits the utility of data on the ground. Because the data fail to reveal whether a readmission is related to the first admission, health care workers suggest the data obscure both measurement priorities as well as what they need to know for care.
As reflexive human actors, health care workers further understand data reports do not merely descend from nowhere, but these may also be shaped by their very conditions of production ( Berg and Goorman, 1999 ; Bowker and Star, 1999 ). Essential invisible work — such as the building of data infrastructures (e.g., local configuration of EHR databases), clinical documentation and extraction from the health record, and choices within data analysis and presentation — may all influence the data, but without clear appearance within the final data report itself. This recognition directly challenges general expectations that data stand on their own as straightforward accounts of social reality. One nurse manager emphasized his frustration with the clinic's data dashboard, demanding to know who and what is behind the simple metrics of his team's work : We do have those technical tools [data dashboard]; however, it's a very questionable report ( Fig. 1 . County Health Dashboard). I think there's generally a lack of trust with those reports — how did they come up with these data? Are these just operational measures? I don't really know how they come up with these numbers [referring to essential invisible work]. Interviewer: What would it take for you to trust the data report? What would you want to know? I need to see the details – the specifics of where it came from and how it should be managed – not just a simple metric! There has to be a clear explanation from those pulling the reports [analytics], to those who are trying to make the changes [administration], to those who are providing the services [frontline]. And that's not there. (Nurse Manager, Outpatient Clinic)
In contrast to arguments that data “trace” human activity ( Latour, 2005 ; Ruppert et al., 2013 ), here this nurse manager insists the data reports lack traceability regarding the conditions of data production and supporting human and technical infrastructure. Who is working on the data report, how they draw from EHRs and other data systems, and why the data were analyzed and presented in a particular fashion all fail to show up in the final report itself, yet these contextual elements all constitute the social reality of the safety-net. Thus data reports may be understood to fundamentally obscure the social , only loosely corresponding with the reality of the social world.
This understanding of data distorting social reality carries serious ramifications for data-centered accountable care, with the quantified account treated with suspicion and doubt. Hospital waiting times and five-star ratings systems are publicized — ostensibly for external audiences to see for themselves what is happening in the safety-net — yet such data rely on a complex array of social and institutional arrangements, none of which readily appear within the final data reports: I want to love [data reporting], because it promotes healthy competition, and it's important we inform patients our performance through transparency. But again, I just don't know that I trust that data ( Fig. 2 , Fig. 3 . Public Reporting). It ultimately depends on the reporting agency — who's reporting it out, who's managing those agencies, who's regulating the agency? I'm just going to see the numbers, look at it at a glance, “Oh, that's nice,” you know? (shakes head) Like these big agencies will produce these data reports, and then they present the data back to you. And of course, you don't question them. You take it at face value, but you don't really know — if they say your admission takes only 30 minutes, then sure, it's “30 minutes.” Because how would I know? I wouldn't understand why the score is like that, so if another hospital is five stars, then okay, sure, I guess it's “five stars.” (Nurse Manager, Outpatient Clinic) Download: Download high-res image (2MB) Download: Download full-size image Fig. 2 . Public Data Reporting: Government Website. Description: Public data reporting, government website. Federal and state websites publicly report quality data submitted by hospitals and health care facilities , resulting in five-star ratings and performance information to expanded public audiences. Caption: Care Compare presents hospital performance information and five-star ratings for Los Angeles, CA (location selected for demonstration purposes only). Image taken from CMS Care Compare ( https://www.medicare.gov/care-compare/ ).
This same nurse manager not only questions data internally within his own organization: he also expresses his own inability to know how such data align with “what is happening,” and how such data may be influenced by unmeasured factors when circulated to external agencies and audiences. Because human actors understand data are intricately interwoven with invisible entities that are not readily traceable within the data points themselves, numerical reports fail to stand on their own as straightforward representations of social reality.
The inability of data to adequately capture dimensions of safety-net care also appears within the context of all-cause readmissions. Because CMS uses such measures to compare hospitals against one another, organizations serving different patient populations question the extent to which not-easily-measured “social factors” shape final readmission counts, risking the unfair penalization of providers and systems caring for marginalized patients: The other problem with readmissions is with our patient population, with the underserved and so many homeless people, their readmission rate is going to be higher. Because if you're [the patient] going back out to the homeless encampment — where you're living in unsanitary conditions, you're not well-nourished, you're going to bounce back [to the hospital]. And that's why organizations like us have such value [safety-net] — because we know how to care for that population. We don't get bent out of shape because we've got homeless people with psychiatric issues. So I really think you have to know who your patient population is, beyond just looking at the numbers. (Director of Quality) Download: Download high-res image (793KB) Download: Download full-size image Fig. 3 . Public Data Reporting: Community Billboard. Description: Public data reporting, community billboard. Organizations publicize quality data and performance information within broader society, drawing from real-time EHR data analytics and official public reports from government entities. Caption: Hospital Corporation of America advertises average ER wait times in suburban Tampa, FL (location selected for demonstration purposes only). Image taken from Lean Blog ( https://www.leanblog.org ).
The measurement of hospital readmissions — introduced under policy efforts to reduce costs and induce accountability — here is understood to prioritize standardization while inadequately accounting for differential social conditions and organizational context ( Cruz and Paine, 2021 ). Human actors recognize the multiple influences of final data points as more than just a straightforward accounting of the social world, and as such data are understood to fundamentally misrepresent the safety-net. In sum, health care workers understand data do not simply measure reality to bring it into view: rather, data-centered accounts also conceal as much as they reveal.
Human actors not only assess data as representation or distortion of the social world: data-centered accounts may further be used to outline a social reality that has yet to exist. By facilitating activity beyond the data points themselves, humans and data work to envision the social, inciting renewed possibilities for social transformation. By leveraging their reflexive capacities, human actors thus also relate to data as means of building towards a better world.
Data reports are not always presented as standalone accounts of social reality, but may also be used to envision a goal (to “raise the bar,” as one clinic manager described it). The medical director of the organization's main outpatient clinic explained her development of a data dashboard as not solely to monitor existing progress, but to project future objectives as translated into metrics: So I was thinking of developing a dashboard, and the Harvard Business Review presented a Balanced Scorecard that covered different ways of looking at quality metrics. So they give you a framework, and then you look at what you can do with data — like what do we want, and how do we achieve it? So looking at us, what do we in primary care want to see with our patients? From there, I created this [hands me a printout of her report; Fig. 4 . Balanced Scorecard]... But these numbers are very, very, overly ambitious numbers (“Target” column) — don't forget that. This scorecard is the standard of excellence. Physicians have a competitive spirit, so if you instill healthy competition they will say, “Why not? I can be better.” So you can use [data] positively. (Medical Director, Outpatient Clinic) Download: Download high-res image (741KB) Download: Download full-size image Fig. 4 . Balanced Scorecard: Standard of Excellence. Description: Balanced scorecard created by medical leadership (internal to health system). Scorecard is referenced during internal meetings (independent of data team’s reports); printout is posted in clinic hallways. Benchmarks outline targets for providers and clinic staff. Caption: Balanced scorecard for Central Clinic of County Health System, including clinical, operations, and production measures with scores and target. Scorecard outlines where Central Clinic would like to be as ‘standard of excellence.’ Illustration created from scorecard handed to me during interview, pseudonym clinic name.
The data report in question here does not derive meaning solely from what it reveals: rather, its significance stems from the anticipation of goal achievement. Data dashboards are not merely taken at face value as a reflection of reality, but are understood as tools of numerical ambition. One member of the data team was fond of saying, “It's not a scorecard — it's a worklist. It tells you what you need to work on, where you need to be.” In situating data against a backdrop of possibility, health care workers thus leverage data to recognize more than the present social reality is possible.
Data reports are further understood as more than fixed judgments of stabilized reality by facilitating connection beyond the data points themselves. When outpatient clinics are left to their own devices to improve performance against standard benchmarks, health care workers may identify successful sites of care and follow up to learn more about the practices behind the numbers. The data may simultaneously demonstrate good care while also concealing the details of its provision, as conveyed by a program manager in describing clinic work on blood pressure control: I think the data are all about looking at best practices. Doctor X is at the 90 th percentile and Doctor Y is in the 25 th , what is he or she doing that could be shared with the underperforming physician to bring him up? I think the data has played a great part in that perspective here… Recently our organization was trying to improve blood pressure control, and one of our clinics started doing group visits, and now their numbers are coming up ( Fig. 1 . County Health Dashboard, “Central Clinic”). And other doctors and clinics see that and ask, “Why are your numbers going up?” “Well, we have nurses calling patients based on their last BP reading, we need to get them back to talk about their diet, adjust their medications. I can't see all 1,500 patients but I'm going to see multiple patients at the same time in group visits.” So when one person or clinic is performing very well and another is under-performing, you can look at the best practice there and share it with others. (Program Manager)
The standard metric of blood pressure allows for comparison across clinics and providers, in this case identifying “high performers” but without capturing the best practice within the formal data account itself ( Fig. 1 , Fig. 2 , Fig. 3 ) . But instead of dismissing the data as insufficiently corresponding with the social world, here the numbers serve as a means of connection, supporting additional work to envision the social that has yet to exist (e.g., for Doctor Y to be at the 90th percentile, or for all clinics to control BP at the level of the high performing clinic).
In understanding data as aspirational, the data-centered account brings about a third relation of accountable care to the safety-net, specifically by envisioning new arrangements for the future. This sense of working towards change emerged from providers and staff who expressed a desire for the organization to do more for its marginalized patients, with data standardization viewed as an opportunity to provoke social transformation ( Nelson, 2016 ). Reflecting on her long experience working and caring for the marginalized, one nurse noted how data comparisons may command a sense of duty to advance beyond what has historically been done in the safety-net: The community definitely sees us as a lower ranked system. I think even some of the staff say it, “It's the County, what do you expect?” Patients see that, and they feel that. I can understand because they want to receive good care, but why is it different here than [nearby private system]? What are they doing that we're not doing, or what are we doing wrong? […] I think these ratings could really help us ( Fig. 2 , Fig. 3 . Public Reporting). Our hospital wait times are very bad, and that reflects to the community, “I don't want to go there!” And that's unfortunate, because we are that safety-net . But I also want patients to feel comfortable, to know “I'm going to get the same care here as I would somewhere else.” But if we're rated on our numbers, and that's what they're showing, then I would hope as a system, the higher-ups would see that and ask, “What do I need to do at the lower level? What do we need to do for our patients to make that better?” (Complex Care Registered Nurse, Outpatient Clinic)
In contrast with the human-data configurations presented above — in which data serve as fixed accounts capturing reality (e.g., metrics corresponding with care capacity and availability), or as questionable reports obscuring context (measurement practices influencing hospital wait times) — here ratings are instead expected to inspire change across organizational ranks, introducing the possibility of transformation beyond the actual data points themselves.
Human capacity for vision alongside data standardization takes on particular significance within the safety-net, bringing about a duty to question present social arrangements in caring for the marginalized. A QI coordinator and data team member explicitly challenged the notion that hospital numbers fail to account for differential social conditions and organizational context (as discussed above on hospital readmissions). In her estimation, the use of data is not to question the account itself, but to leverage activity that is better than before . Differential patient populations and their influence on hospital scores is thus less important than actual care improvement: I think we should abolish that mentality, this notion that we don't do good on our hospital numbers just because we have very sick patients [in the safety-net; at County Health System]. Interviewer: What about things like social determinants of health, and how that might affect readmissions? Or patients with housing and transportation challenges, as we discussed earlier? Probably, but that should not be an excuse for us to not deliver better care for all our patients. I think it's our obligation to look at ourselves and really assess and evaluate, and decide how you can better deliver quality care. Ever since the alibi of, “Oh we have really sick patients, we have homeless patients [at County]” — but the question is, what are you doing about them? What are you doing to better your health care delivery ? You cannot say anymore, “We have the sickest patients, the poorest patients, so it's difficult for us.” We have to think creatively now, in other ways to deliver care effectively. (QI Coordinator)
Technical standards, in this instance, are not understood to obscure the reality of safety-net care, even if they do fail to adequately capture differential social conditions. Data-centered accountable care is instead expected to inspire transformation beyond the formal account itself, with human actors relating to data as means of building towards a different kind of safety-net.

Section: 4. Discussion

Biomedical investment in digital technologies is driven out of a seemingly simple logic: by transforming care into the data points, social reality is rendered knowable and actionable ( Galetsi et al., 2019 ; Blumenthal, 2010 ; Atasoy et al., 2019 ; National Academy of Medicine, 2019 ). Computational and data-intensive approaches all depend on data to capture the world for successive calculation and integration, resulting in an explosion of metrics, algorithms, rankings, and dashboards directly within clinical settings and in broader society ( Clarke et al., 2003 , 2021 ; Blumenthal, 2010 ; Ruckenstein and Schüll, 2017 ; Altman and Levitt, 2018 ). Insights from science studies further scholarly understanding of standards and their travels, given data's ability to represent social reality while simultaneously circulating within it ( Latour, 1987 , 2005 ; Law and Urry, 2004 ; Ruppert et al., 2013 ). Others highlight the invisible relations surrounding data systems, including as these intersect with daily practice and issues of power and inequality ( Star, 1991a ; Forsythe, 2001 ; Benjamin, 2019 ; Noble, 2018 ; Braun et al., 2021 ). This article bridges these approaches by going inside the digital safety-net, examining how situated human actors relate to data representations of care for the marginalized within the social reality they intimately know themselves ( Boltanski, 2011 , Boltanski and Thévenot, 2006 ).
Based on empirical fieldwork, it is clear data do not merely do one simple thing (e.g., capture social reality to bring it into view): rather, human actors reveal data-centered accounts do many different things simultaneously . Data measure, compile, transmit, and travel, but they also erase, distort, project, and inspire while circulating across varying contexts. Health practitioners recognize data on routine vital signs may represent health conditions and the clinical work accomplished, yet simultaneously insist data standardization conceals essential invisible work within the social world. In other configurations, data and technology are leveraged not merely to stabilize reality, but to instill movement towards a better version of it that has yet to exist. Data thus neither solely serve as straightforward, immutable traces ( Ruppert et al., 2013 ; Latour, 1987 , 2005 ; Law and Urry, 2004 ), nor do they simply “delete the social” ( Star, 1991a ; Forsythe, 2001 ; Braun et al., 2021 ). The same data point may in one context demonstrate good care while in another obscure it ( Cruz, 2020 , Cruz and Paine, 2021 ), and in another effect change beyond what data mandates themselves can formally itemize and induce ( Timmermans and Berg, 2003 ; Thompson-Lastad and Rubin, 2020 ; Paine, 2021 ). In short, data artifacts appear to be more protean than Janus-faced; biomedical data do not have one social life, but many.
The framework presented in this article — where data simultaneously capture, obscure, and envision the social — holds far-reaching implications for understanding contemporary biomedicine beyond the digital safety-net. Computational and data-intensive approaches are rapidly expanding into numerous health applications and institutional domains, drawing on new digital infrastructures to transform everyday activity into data points ( Galetsi et al., 2019 ; Atasoy et al., 2019 ; Altman and Levitt, 2018 ). The common lifeblood of data , for example, presently informs advances in artificial intelligence/machine learning (AI/ML; National Academy of Medicine, 2019 ; Obermeyer et al., 2019 ; Chen et al., 2019 , Matheny et al., 2020 ), digital health technologies such as consumer wearables ( Alam 2016 ; Ruckenstein and Schüll, 2017 ; Joyce, 2019 ), and large-scale data dashboards within COVID-19 pandemic response (e.g., covid.cdc.gov/covid-data-tracker ). Recent public backlash over algorithmic bias and COVID-19 data reporting suggests these data artifacts attract as much controversy as they do support, yet surprisingly limited attention has focused on the complex relations between data standardization and social reality ( Boltanski, 2011 , Desrosières, 2015 ). In stabilizing the social, data representations create the very conditions for people to contextualize them: human actors recognize the realities represented as well as those that are not, including possible versions that do not yet exist. Instead of blaming human actors for repeated technological and data-intensive failures, this article demonstrates how a more productive approach might humbly seek to learn from them ( Forsythe, 2001 , Greenhalgh et al., 2014 , Nelson, 2016 , Suchman, 2009 ).

Section: 5. Conclusion

This sociological account began as an empirical examination of biomedical data in a particular social context. But upon close inspection, neither data nor reality seem as stable as they otherwise appear. The inside of the digital safety-net is livelier than expected: the data are variable (Figs. 1–4), the people are reflexive (opening quotes), and the situations are complex. Sorting out digital transformation in turn requires situating data's multiple relations with social reality. It requires uncovering what data do, to whom, for what purposes, under which conditions, and in what contexts. Digital technologies do not simply capture the social, but multiply it. Biomedical data then do not have one social life, but many.

Section: Author contributions

Taylor Marion Cruz: Conceptualization, Methodology, Data collection, Data analysis, Writing – original draft, Writing – review & editing, Project administration, Funding acquisition.

Section: Acknowledgements

I am deeply grateful to the participants and organizations that made this research possible, especially the data team and clinic staff who graciously endured my many strange questions on what Susan Leigh Star calls “boring things.” Thank you for welcoming me into your busy operations to show me care in the digital safety-net. I would also like to acknowledge the Health, Tech, and Society Lab, R.J. Gladwell, and Carrie Lane at California State University, Fullerton for providing general research assistance in completing the manuscript. Finally, I give special thanks to Janet K. Shim for inspiring me to embrace science studies in studying the societal dimensions of quantification. Thank you for showing me the joys, wonders, and possibilities of the sociology of science, technology, and medicine.
This study was supported by the following grants: 1144247 from the National Science Foundation ; UCSF Department of Social and Behavioral Sciences (Harrington and Newcomer Health Policy Awards); and UCSF Department of Anthropology, History, and Social Medicine (Forsythe Award for Social Studies of Science, Technology, and Health). The content is solely the responsibility of the author and does not represent the official views of any of the abovementioned organizations.
