Title: Open government data, uncertainty and coronavirus: An infodemiological case study


Abstract: Abstract

Governments around the world have made data on COVID-19 testing, case numbers, hospitalizations and deaths openly available, and a breadth of researchers, media sources and data scientists have curated and used these data to inform the public about the state of the coronavirus pandemic. However, it is unclear if all data being released convey anything useful beyond the reputational benefits of governments wishing to appear open and transparent. In this analysis we use Ontario , Canada as a case study to assess the value of publicly available SARS-CoV-2 positive case numbers. Using a combination of real data and simulations, we find that daily publicly available test results probably contain considerable error about individual risk (measured as proportion of tests that are positive, population based incidence and prevalence of active cases) and that short term variations are very unlikely to provide useful information for any plausible decision making on the part of individual citizens. Open government data can increase the transparency and accountability of government, however it is essential that all publication, use and re-use of these data highlight their weaknesses to ensure that the public is properly informed about the uncertainty associated with SARS-CoV-2 information.

Section: 1. Background

Open government data (OGD) initiatives are government-led programs that make non-confidential publicly-funded data available in an easily accessible form ( Janssen, 2012 ). OGD are often part of a governing jurisdiction's overall open government strategy to make information and decision-making processes more accessible to citizen participation and scrutiny ( Harrison et al., 2012 ). These initiatives were motivated by two general goals: to promote transparency of government, and to increase the value of government-controlled data resources by obtaining feedback from a variety of non-governmental stakeholders ( Attard et al., 2015 ). In the last decade, countries across the globe have implemented open government data initiatives to various degrees using many different benchmarks for openness. To be considered ‘open’, OGD should be complete, collected at the source with the finest possible level of granularity , disseminated in a timely manner, accessible to a wide range of users, machine-processable, non-discriminatory, non-proprietary and license-free ( Dawes, 2010 ; Yi, 2019 ).
Open data standards are important because they influence the design of data portals, visualization and analytical tools as well as the datasets themselves in ways that significantly impact the potential uses of the data ( Goeta and Davies, 2016 ). Standards for OGD initiatives can also help establish consistent data practices and define norms within a government's open government strategy, making it easier for citizens to gain longer-term trust and confidence in their government's institutions. It is worth noting that due to the number of different open data benchmarks currently in use by governments all over the world, inconsistency between benchmarks can at times result in a false sense of OGD success depending on the scope or focus of a government's selected standards ( Susha et al., 2015 ).
OGD has provided health researchers with unprecedented access to large datasets, often by linking data containing aggregated or anonymized individual health records with other sources of data. Importantly, openly available public health data have also been touted as an effective decision-making tool to aid members of the public in assessing risks to their personal health. Examples of public health OGD include data on local immunization rates, prevalence of sexually transmitted infections ( D'Agostino et al., 2018 ) and infectious disease surveillance ( Srivastava and Srivastava, 2014 ). However, the usefulness of open public health data has been questioned on the grounds that much of the data do not include demographic information, information on other known risk factors , and are rarely paired with other important contextual health information ( Martin et al., 2017 ). There are also major concerns over the privacy, confidentiality and control of open public health data and the implications this has on the level of trust citizens must extend to the institutions that collect and store these data ( Kostkova et al., 2016 ). Therefore, the symbolic value of open public health data viewed as a means to increase trust, accountability and transparency must be balanced by considering the actual value of sharing such data to inform individual and policy decision-making. If governments selectively release data under the guise of transparency, they remain largely unaccountable ( Ruijer et al., 2020 ) and any ambiguity in the open data can actually result in users' misunderstanding of it ( Weerakkody et al., 2017 ), which raises serious questions surrounding the value that is created from OGD and for whom.
Public data on positive tests for coronavirus became available soon after the outbreak was first identified. The World Health Organization began generating daily country-level infection reports early in 2020, and many other sources have emerged since that time. Current publicly accessible data sources include data on testing, positive test results , deaths, hospitalization and other data at national and sub-national levels. Many of these sources report daily line-listed data of cases and deaths, and have already been used in research to make infection forecasts ( Anastassopoulou et al., 2020 ), study the relationship between climate and infection ( Harbert et al., 2020 ), the exacerbating effects of air pollution on mortality ( Wu et al., 2020 ) and the effectiveness of social distancing ( Rotondi et al., 2020 ).
Data on SARS-CoV-2 infections have also been used in conjunction with a large and growing number of disease models in an attempt to forecast infections, deaths and hospitalizations under different intervention scenarios ( He et al., 2020 ; Roosa et al., 2020 ; Jiang et al., 2020 ). These models are used to forecast infection trends based on what is known about the virus (such as transmissibility and duration of infectiousness) and the population (such as the number of susceptible individuals and the nature of population mixing) combined with historical infection data. Mechanistic compartmental models, such as the susceptible-infectious-recovered (SIR), were the basis for some widely disseminated early projections of SARS-CoV-2 ( Ferguson et al., 2020 ). An alternative approach, referred to as phenomenological modelling, makes fewer assumptions about what is known about a pathogen , and may be more appropriate in early phases of an epidemic when there is uncertainty about key pathogen attributes ( Chowell et al., 2016 ; Chowell, 2017 ). Data-driven artificial intelligence/machine learning methods have also been applied to forecasting, using data for both model calibration and validation ( Chakraborty and Ghosh 2020 ). Work using SARS-CoV-2 data and various modelling approaches will continue to be applied and developed to make real-time forecasts, and while there remains a high degree of uncertainty in these models due to unknowns about pathogen characteristics and population behaviour, it is clear that data on previous levels of infection are important for forecasting future public health impacts.
Notwithstanding these important research applications, the value that information about SARS-CoV-2 infections provides to the public remains unclear, particularly given the serious shortcomings of most publicly reported case data. First, neither the cumulative nor daily count of new positive cases identified from RT-PCR (reverse transcription polymerase chain reaction) tests provide much contextual information about real-world risk, as neither describe the risk of infection at a moment in time. While these data can be converted into infection prevalence by dividing by the population, crude prevalence measures are difficult to interpret without also removing those who recovered from infection, particularly in areas where infection levels have been high. Moreover, these overall measures are a poor approximation of individual infection risk since they do not account for variations by age, sex, presence of comorbidities, ethnicity and other important risk factors .
Second, there is growing evidence that current testing regimes in most jurisdictions underreport actual infection burden—perhaps by an order of magnitude or more ( Bendavid et al., 2020 ; Doi et al., 2020 ; Asako Doi et al., 2020 ; Shakiba et al., 2020 ; Phipps et al., 2020 ). These infection burden estimates may contain a high degree of uncertainty based on how the testing system operates ( Bennett and Steyvers, 2020 ; Baxter, 2020 ), but there is currently more debate about the magnitude of this underestimation than about whether or not infection prevalence is being underestimated at all.
These and other practical issues involved in the collection of data contribute to two important and well-known technical challenges with making sense of the laboratory test data in the forms typically shared today. The first challenge concerns the sampling of the population tested. In most jurisdictions, selection of persons for laboratory testing has been targeted, at least to some degree, to those considered at high risk, a concept referred to as ‘preferential testing’ ( Campbell et al., 2020 ). When the testing is not random, data on test results alone may not be a good indicator of infection prevalence at a moment in time, as it excludes people who are asymptomatic, prefer not to get tested or are otherwise excluded from the testing pool. If the level of preferential testing varies considerably by geography and time, comparisons of trends in these dimensions can be challenging when preferential testing is not accounted for. This means that not only are the data poor predictors of absolute risk, but they also may not even provide a good indication of trends in risk.
The second challenge is that laboratory test results are not always accurate. The ability of the RT-PCR test to detect true positives depends on how specimens are collected and time since infection, and false positives , while very rare, may occur as a result of contamination and technical errors ( Sethuraman et al., 2020 ). There may also be considerable variation in false negatives depending on the timing of when a sample is taken ( Kucirka et al., 2020 ). Small levels of testing error can still have a large impact on reported data, particularly when infection rates are low. Even if the average testing error is known with some precision, variations across labs, specific testing kits or other differences in precise methodology undertaken in the lab may produce apparent patterns of difference or sameness in the data that obscure true information about variations in COVID-19 risk over time and geography.
Given the limited scope and non-random nature of available data (due to preferential testing schemes) and potential error in test results, it is important to ask whether the publicly available data has value to data consumers, particularly when reported on a daily basis. The following research explores this question using a combination of real reported testing data from Ontario , Canada and simulations of test results under a variety of assumptions about how testing was conducted in the early phase of the coronavirus pandemic. Using these simulations, we show that there is a high degree of uncertainty in testing data, and furthermore, that these data have low short-term decision making value. Our results suggest that there should be a widespread increase in the communication of these issues to the public, and that all participants in the data communication chain (generators, curators and communicators) need to be more open about the shortcomings of these data sources.

Section: 2. Methods

The province of Ontario , Canada is the largest province in Canada, and was, along with Quebec, the epicentre of reported SARS-CoV-2 infections in Canada. This analysis uses data on testing counts and positive cases reported in Ontario from one of its main daily updated web portals, where the government regularly reports the total number of tests completed by the SARS-CoV-2 clinical lab network (including Public Health Ontario, hospital and community laboratories) ( Government of Ontario, 2020a ). Data used start on March 10th, and run to June 3rd, covering an almost three month period from the near the beginning of the outbreak in Canada to a period at the beginning of an apparent decline from the first phase of infection.
Ontario, like most jurisdictions, adopted a preferential testing strategy to select persons for testing that changed considerably over time. Between March 25th and April 8th, testing was not restricted to any specific populations, though the following groups were prioritized when testing supplies were limited: symptomatic health care workers and staff in health care facilities ; symptomatic residents and staff in Long Term Care (LTC) facilities and retirement homes; hospitalized patients admitted with respiratory symptoms; symptomatic members of remote, isolated, rural and/or Indigenous communities; symptomatic travellers identified at point of entry to Canada ( Government of Ontario Ministry of Health (MOH), 2020b ). As of April 8th, testing was mostly restricted to persons in specific populations (hospital inpatients and residents living in LTC or retirement homes, healthcare workers/caregivers/care providers/first responders , and individuals living in remote/isolated/rural/Indigenous communities) who were experiencing fever, respiratory symptoms and/or clinical or radiological evidence of pneumonia. ( MOH, 2020c ). By April 15th, this was expanded to other symptomatic groups ( MOH, 2020d ), and on May 14th testing was expanded to all symptomatic persons ( MOH, 2020e ). By early June, testing was further expanded to include asymptomatic persons in close contact with confirmed positive cases, and tests are now available to any resident on request ( MOH, 2020f ).
Our analysis involves exploring how different SARS-CoV-2 testing regime scenarios provide different information about patterns of infection over time. In this study we assume a reference prevalence 10 times the daily cases reported by the province, which would result in a cumulative prevalence in Ontario of between 2 and 3%. This is a reasonable assumption based on studies suggesting seroprevalence around 2% in a number of countries as of May to June 2020 ( Ioannidis, 2020a ). We refer to this as the ‘reference’ infection level because it gives us a way of comparing testing regime scenarios; however, it is important to note that the real infection burden is currently unknown. To estimate the state of infection in the Ontario population we use a simple susceptible-infected-recovered (SIR) compartmental model in which the transitions between the susceptible and infected compartments are based on this reference infection data rather than model predictions found through ordinary differential equations ( Fig. 1 ). At the beginning of the simulation (March 10), the infected compartment (denoted as active cases) is based on the reference infections on that day, the susceptible compartment is the entire population minus the infected compartment, and the recovered compartment is empty. Each day, new cases are added to the infected compartment based on reported new cases in Ontario and removed from the susceptible compartment. Infected individuals move from the infected compartment into the recovered compartment after 14 days of infection, and are assumed to be free of future infection risk. We acknowledge that there is a decline in some immunological response and potential for reinfection over time ( Ibarrondo et al., 2020 ); however, accounting for this would not greatly change the size of the susceptible population in our analysis, and would have little effect on results. Moreover, there remains considerable uncertainty about how often this happens or the impact of reinfection on overall infection rates. This process runs to June 3rd, resulting in 86 days of simulated data for the infected, susceptible and recovered compartments. It is important to note that the intent of this model is not to forecast future infection but simply to provide a reference number of infected and susceptible persons for comparison of testing methods. Download: Download high-res image (297KB) Download: Download full-size image Fig. 1 . Compartmental model.
Data from the compartmental model were used in 8 different testing scenarios, each of which generates the synthetic test result data used for analysis. For each testing scenario, individuals living in the province are selected for testing equal to the actual number of reported tests conducted in the province on that day. As summarized in Table 1 , the 8 testing scenarios differ with respect to (1) the method of selection for testing, including the use of and/or changes in preferential testing over time (e.g., no preferential testing, testing of symptomatic persons only, transition from preferential to random testing over time), and (2) test error (true positive and true negative rates). Preferential testing was determined by varying the sample weights which are used to select people for testing. Scenarios S1, S2 and S3 all use equal sampling weights, meaning every person is equally likely to be tested regardless of which compartment they are in, though test error rates vary. All other scenarios involve some degree of preferential testing expressed by different sample weights for the three compartments, whereby people who are infected are more likely to be tested than those who are not. This is meant to mimic real-life strategies that restrict testing to people who are experiencing symptoms, ultimately increasing the likelihood that a truly infected person will be tested when compared to random sampling. Two scenarios (S4 and S5) represent situations in which the degree of preferential testing changes linearly over time—from a high level in which a truly infected person is 10 times more likely to be tested, to a low level in which all persons are selected randomly. Scenario S8 also sees a decline from non-random to random selection for testing, except the drop off from non-random to random is a nonlinear function of the number of tests conducted such that when fewer tests are conducted the weight for preferential testing is higher. Scenarios S6 and S7 are both non-random with fixed selection weights—in which a person who is infected is 20 times more likely to be tested. Sampling for testing is done with replacement in all scenarios, which while somewhat unrealistic (since most people will not be selected for testing twice on the same day) it is not very likely to be consequential, since on no day was more than 0.2% of the total population tested. Table 1 . Scenario test selection and test error. Empty Cell Method of selection for testing (Numbers are sample weights for preferential selection of test subjects from each compartment) Hypothetical testing accuracy S1 Random testing (Susceptible = 1, Infected = 1, Recovered = 1) True positive rate = 1; True negative rate = 1 S2 Random testing (Susceptible = 1, Infected = 1, Recovered = 1) True positive rate = 0.80; True negative rate = 0.97 S3 Random testing (Susceptible = 1, Infected = 1, Recovered = 1) True positive rate = 0.99; True negative rate = 0.99 S4 Non random testing (Susceptible = 1, Infected = linear trend a down, Recovered = 1) True positive rate = 0.80; True negative rate = 0.97 S5 Non random testing (Susceptible = 1, Infected = linear trend a down, Recovered = 1) True positive rate = 0.99; True negative rate = 0.99 S6 Non random testing (Susceptible = 1, Infected = 20, Recovered = 1) True positive rate = 0.99; True negative rate = 0.99 S7 Non random testing (Susceptible = 1, Infected = 20, Recovered = 1) True positive rate = 0.80; True negative rate = 0.97 S8 Non random testing (Susceptible = 1,Infected = non-linear trend b down, Recovered = 1) True positive rate = 0.99; True negative rate = 0.99 a Weight = [day since March 10]*0.01163. b Weight = 1908.4*[# tests conducted] −0.7596 .
Once a subject is selected for testing, the results of the test are determined based on the true positive rate and true negative rates also shown in Table 1 . Large error scenarios are based on values from previous research ( Kucirka et al., 2020 ; Cohen and Kessel, 2020 ). Small error scenarios are arbitrarily small, and appear to be at least as good as the best case scenario for the RT-PCR tests used to test coronavirus in laboratory settings, particularly for calculating sensitivity.
All code and all data from simulations are available from the authors.
Most public reporting of SARS-CoV-2 infections is primarily in the form of daily case counts. We assume that one purpose of releasing these data is to convert case counts into measures of infection burden or risk to the population—specifically, the proportion of the population that is infected with SARS-CoV-2 at a moment in time. Three standard ways to measure this are as: 1) a population-based prevalence of active cases, in which the numerator is all persons who are currently infected and the denominator is the total population; 2) a proportion of tests that are positive in which the numerator is the same, but the denominator is the tests conducted; and 3) the incidence rate , as daily cases divided by the total population. If a population is sampled exhaustively without replacement, population-based prevalence equals the proportion of tests that are positive as both the denominators and numerators are equal. If persons are selected for testing at random and the tests are performed without error, then the proportion of tests that are positive is an unbiased estimator of the true prevalence of infection.
We compare the proportion of tests that are positive, daily incidence rate and the prevalence of active infections infectibased on data from each of the 8 testing scenarios with these same indicators based on the reference values . Given that at present, the impact of the actual testing system on estimates of risk and prevalence is not well understood, the scenarios represent a breadth of plausible testing contexts that will help provide some understanding of what information is being conveyed.
Another possible purpose of releasing daily positive case counts is to influence short-term decision making by observing trends over time. We estimate the expected value of daily positive COVID case data on individual decision making . The method for arriving at these values is described in detail in the Supplement and uses a well-known decision analysis approach ( Berger, 1980 ; Smith, 1988 ) to estimate the expected value of information gained from information about daily increases of cases. Informally, the method determines what a decision maker should be willing to pay for information, given 1) the accuracy of the information and 2) the impact of the decision made in response to the information. The amount that a decision maker is willing to pay is the expected value of imperfect information.
Our analysis makes two key assumptions, both of which err on the side of over-valuing information. For one, we assume that the decision under evaluation is whether or not to undertake an activity (e.g., visiting a friend, buying groceries, etc.) based on whether the day-over-day trend in positive SARS-CoV-2 cases is increasing by a small amount. It is unclear whether many real-world decisions would be made based on small day-over-day trends, but by assuming so, we believe our analysis is more likely to be over-estimating the value of information than under-estimating the value of information. The other assumption concerns the costs associated with this decision based on whether or not a trend in cases is increasing. In our analysis, we present results for costs of a decision of $2000 and $200 based on whether or not the trend in infection is increasing. The assumptions made in our analysis and their impact on how value of information is interpreted is further discussed below.

Section: 3. Results

In Fig. 2 , we see the proportion of tests that are positive in Ontario determined by the 8 testing scenarios along with the reference proportion (solid green line near the bottom of the figure). As expected, the best estimator of the reference proportion of tests that are positive is S1, the random sample measured without testing error (dashed line near the bottom of the figure). However, even this estimator is a poor measure of risk early in the series; for the first 11 days, the testing samples from the population were not large enough to detect any cases, and therefore under-represent risk early in the outbreak. Scenarios S6 and S7 (non-random testing with small and large testing error, respectively) greatly over-predicted the reference proportion of tests that are positive. For example, on April 24 the reference proportion was 0.0048 while for S7 the proportion was 0.098—more than 20 times higher. S3 and S8 were closer to the reference proportion, though still 3 to 5 times higher. Download: Download high-res image (532KB) Download: Download full-size image Fig. 2 . Proportion of tests that are positive.
Fig. 3 illustrates the pattern in daily population-based incidence in Ontario measured for the 8 testing scenarios and the reference incidence (solid green line at the top of the figure). When accurate, the incidence rate is an estimator of individual risk of infection. In contrast to proportion of positive tests, all scenarios significantly underestimate reference incidence per 100,000. For example, S7 estimates incidence at around 9.9 per 100,000 on May 7, 2020, when the reference incidence was roughly 32.7 per 100,000. For the same day, S1 estimates incidence at roughly 0.5 per 100,000 persons. The overall trend in population-based incidence for all scenarios is roughly upwards over time, though there are large short-term variations. A significant drop in population-based incidence for all scenarios occurred in mid-May. This corresponds to a drop in testing numbers in the province that occurred at the time, and shows the sensitivity of testing information to test frequency. Download: Download high-res image (497KB) Download: Download full-size image Fig. 3 . Population based incidence per 100,000.
Fig. 4 illustrates the pattern of active infection prevalence, which, when accurate, provides an indication of the potential of exposure to infection. In addition to the 8 scenarios and reference value , this figure also includes an estimate of daily prevalence based on the proportion of positive tests estimated by S1 (PTP-S1). This figure shows that as expected, the proportion of tests that are positive based on a random sample of the population is an unbiased estimator of active case prevalence. Nonetheless, the estimates are still imprecise, showing dramatic day-over-day changes, in some cases of over 100%. Variation about the reference prevalence is a function of sample size; larger random samples would reduce this variation. All other values are significant under-predictors of active case prevalence. Download: Download high-res image (452KB) Download: Download full-size image Fig. 4 . Prevalence of active cases per 100,000.
Qualitative comparisons of the figures do suggest a broad similarity in the patterns over time, with an overall trend of rising prevalence early int he pandemic , and then a flattening of the pattern, particularly for the proportion of tests that are positive. Correlation coefficients were calculated for all proportion of tests that are positive and daily infection incidence estimates and their respective reference values, and most showed moderate to high correlation (all greater than 0.65, and many greater than 0.95) consistent with the overall pattern on the figures.
Another way in which daily reported data could be used is to convey short-term trends that would be used to make specific short-term decisions. During much of the pandemic, many major media sources in Canada (and around the world) produced daily news stories highlighting apparent increases and decreases in case numbers from day to day. Fig. 3 is the most direct representation of this form of information; however, it is hard to see from this graph whether day-over-day changes can predict short-term trends. We use a simple day-over-day forecasting algorithm as an indicator of notable short-term change in case numbers that could be used by a person who is interested in day-over-day variations in SARS-CoV-2 infections. The algorithm works as follows: if data indicate a certain percentage increase over two days, it is a forecast of an increased trend in the following day; otherwise, it is a forecast of no increased trend. Forecasts from scenarios are compared against the trend in the reference value (following the same algorithm), and the agreement between the forecasts based on test data (S1–S8) and the reference incidence are summarized in Table 2 . The values in the table are proportions indicating how often forecasts using this algorithm (based on the scenarios) match the true trend based on reference incidence. Values greater than 0.5 suggest greater forecast accuracy. Most testing scenarios yield predictions near 0.5, meaning that they correctly predicted a true upward trend roughly 50% of the time, which is similar to what would be expected if forecasts were based on the flip of a coin. Estimates of the expected value of these forecasts on decision making are in Table 3 . Results in this table indicate the value of trend forecasts that take into account accuracy (based on Table 2 ) given different decision cost scenarios ($2000 and $200). The most evident pattern in these data is that the S1 scenario has the highest relative value when compared to other testing scenarios. Table 2 . Day-over-day forecast accuracy for each scenario. Empty Cell 1% increase in daily incidence 2.5% increase in daily incidence 5% increase in daily incidence Scenario Positive trend Other Positive trend Other Positive trend Other S1 0.4681 0.4737 0.4324 0.4792 0.4193 0.4815 S2 0.5745 0.3947 0.5676 0.4167 0.5484 0.4814 S3 0.5532 0.4211 0.5405 0.4375 0.5161 0.5000 S4 0.5106 0.3158 0.5135 0.4583 0.4839 0.5185 S5 0.5319 0.3947 0.5135 0.4167 0.5161 0.5000 S6 0.5106 0.3947 0.5135 0.5000 0.5161 0.5185 S7 0.5745 0.3947 0.5676 0.4167 0.5484 0.4815 S8 0.5745 0.4211 0.5676 0.4792 0.6129 0.5556 Table 3 . Expected value ($) of day-over-day forecasts (EVF) of an increasing trend in coronavirus based on $2000 and $200 decision costs. Empty Cell $2000 decision cost $200 decision cost Scenario 1% increase 2.5% increase 5% increase 1% increase 2.5% increase 5% increase S1 84.2 11.5 0.0 6.1 0 0 S2 34.0 32.3 5.7 1 0.9 0 S3 44.8 4.3 14.9 2.2 0 0 S4 12.5 5.1 12.7 0 0 0 S5 12.5 5.1 12.7 0 0 0 S6 10.1 8.3 5.7 0 0 0 S7 26.8 42.0 47.5 0.6 2.2 2.9 S8 0.00 21.2 82.3 6.1 0.2 6.5

Section: 4. Discussion

Perhaps not surprisingly, there was no testing scenario that produced infection estimators for all three of: 1) daily proportion of tests that are positive, 2) daily infection incidence and 3) prevalence of active cases that closely approximate the reference infection values over time. The scenario that used random sample without testing error (S7) did reveal accurate estimates of the proportion of tests that are positive and active case prevalence, but significantly under-estimated population based incidence. Moreover, the active case prevalence was highly variable at the daily scale, indicating that a larger sample would be needed in order to obtain precise daily information. This particular testing scenario almost certainly did not exist in any major jurisdiction in the world at the time this study was conducted, and would be impractical and costly to administer on a daily basis. All other scenarios dramatically underrepresented infection incidence and overrepresented the proportion of positive tests. Even S3, which was based on a random sample of the population for testing with relatively small testing error, reported a proportion of positive tests that was roughly twice that of the reference value and a daily infection incidence estimated that was less than 10% of the reference value. The scenarios with the largest testing error accounted for the largest over-estimation of infection as the proportion of tests that are positive (with estimates 20 times the current level of infection) and also the largest estimates of incidence as population-based prevalence, though still significantly less than the reference value.
Several scenarios (S4, S5 and S8) show the impact of changing sampling methods over time, showing less variation in proportion of positive tests overall. Similarly, S2, random testing with large error, showed almost no change in burden of infection over time. This is not surprising; false positives will make up the majority of positive cases in scenarios with high testing error, and the number of false positives is likely to remain more or less constant over time independent of changes in infection levels. These high error-rate scenarios are probably unrealistic for laboratory based RT-PCR tests, which are very likely to have low false positive rates , but these may prove to be more realistic for other testing methods with higher rates of false positives.
Fig. 3 shows daily estimates of infection incidence, which is most analogous to the daily data reported by media sources. This figure provides a strong indication that daily case data are unlikely to be representative of the true daily infection risk no matter what method of testing is used. Fig. 4 shows infection burden as prevalence of active infections, which is more appropriate when trying to estimate the risk of exposure to the virus. Here, the proportion of tests that are positive can be used to estimate the prevalence of active cases, though the sample would need to be larger than the one used here in order to generate precise daily values . Given the expense and inconvenience of testing, this approach seems very unlikely to be implemented at a large scale.
These figures alone do not indicate the true state of coronavirus in Ontario, but they do nonetheless make clear the real challenges of interpreting case counts (and estimates of the infection burden) for information consumers. Experts may know enough to interpret such data with caution, but it is uncertain whether the data generators (mainly governments) or the many data curators who integrate and present data generated from various sources are properly acknowledging these limitations. Moreover, it is possible that much of the information shared by amateur and professional data journalists may emphasize the storytelling of the data that attracts public interest over the pedantic details of data quality assurance . One of the chief arguments in favour of open government data is that it signals to the public that the government is being transparent and open, and therefore these data contribute to public trust, particularly in times of crisis ( Attard et al., 2015 ). However, open government data are not costless; they require resources to develop and maintain, can threaten privacy, and can contain misinformation ( Kucera and Chlapek, 2014 ). Given the uncertainty and potential for error and misinterpretation, it is reasonable to ask whether the release of daily data that contain so much uncertainty is meeting any important social, political or public health goals.
In addition to comparing accuracy of information over time, our analysis also measured the value of information in terms of day-over-day changes in infection numbers. In our analysis, in order for any testing scenario to return a non-trivial value of information about day-over-day case trends, we had to assume that the impact of decisions made based on these data were large. In dollar terms, we presented results for $2000 and $200 difference in costs of outcome that could be impacted by information about the day-over-day coronavirus case count. This difference is equivalent to gambling this amount of money in one day based on whether or not the count of cases in Ontario would go up by 1, 2.5 or 5%. Outside of a pure gambling exercise, it is difficult to think of many situations in which such a large difference in cost based on information about a one day trend could exist. More realistically, most decisions likely to be made from these day-over-day changes would probably be much less consequential and not depend greatly on small day-to-day differences, and the most realistic estimates of the expected value of information would equal zero.
One obvious counterargument is that people do not use these data for making daily decisions, but rather, as a general guide to trends over longer time frames. Our analysis does suggest some general agreement in linear trend over the period of study; all estimates from testing scenarios correlate reasonably well with reference infection prevalence. This correlation amounts to a general linear upward trend that would, in fact, require very little data, and is not greatly affected by day-over-day (and perhaps even week-over-week) changes in case counts. These general long term trends in case counts suggest that the data may be more useful when consulted on a weekly or bi-monthly basis. We did not determine the value of information over these longer term prediction periods since the 12 weeks of data available at the time the study was conducted were insufficient for estimating prediction accuracy at a weekly scale, but it is plausible that over longer time frames weekly variations have value. Nevertheless, much of the data sharing—on the part of governments as well as data curators—is at the daily level. In our analysis, we have shown evidence that at present, daily data have little decision making value.
Researchers have and will continue to use these data in a variety of ways, and access through open data portals is considerably easier than making ad hoc data requests to government data custodians. Although some have questioned the harms of making significant social changes based on poor data ( Ioannidis, 2020b ), most discussion at present emphasizes the need for timely access to open data access as part of current and future infection control ( Boulos and Geraghty, 2020 ; Dong et al., 2020 ). The value of research based on open government data is very hard to estimate, and was not considered here specifically. Most researchers—particularly in social medicine , public health and epidemiology—are well aware of the shortcomings of infectious disease data, and the standard peer-review vetting process is likely to screen out low quality research. However, as discussed by Lawton (2020) , the combination of rapidly generated research and the easy sharing of preliminary results through social media and preprint servers have led to a rise in misinformation . This is amplified by an expertise gap, where non-expert consumers of data lack the background knowledge to properly scrutinize the evidence as it emerges, but may have larger audiences than experts ( Lawton, 2020 ).
Eysenbach (2002) characterized infodemiology as the “study of the determinants and distribution of health information and misinformation […] useful in guiding health professionals and patients to quality health information”; however, the coronavirus pandemic is characterized by a more fundamental problem—all open SARS-CoV-2 infection data are probably wrong by a magnitude that we do not yet know. It is possible that many data generators and curators are aware of these shortcomings, but it is unclear if the communication of these errors and uncertainties has been adequate. Reversing the trend in open data is neither possible nor desirable at this time, and instead, emphasis must be placed on comprehensive communication of errors and uncertainties associated with these data. We have provided evidence that the two primary methodological challenges we analyzed—preferential testing and testing error—need to be clearly explained at a level that is appropriate for every audience likely to be consuming information about coronavirus epidemiology . Our simulations show the sensitivity of short-term patterns to small differences in preferential testing and testing error, and we believe that this is evidence enough to justify universal qualification of all day-over-day variations in coronavirus positive case counts. This means that all participants in the information chain—data generators, data curators, data communicators including journalists, academics and social media influencers—must be transparent about these shortcomings if they are to ensure that the public is being honestly informed. This will not only reduce misinterpretation, but could contribute to greater trust in open government data in the long run, particularly if future research finds that current data contain a larger degree of error and uncertainty than is generally believed.
The scenarios used in our analysis were chosen in an attempt to capture a range of possible realities, none of which may reflect what is actually occurring in Ontario or elsewhere. It is plausible, for example, that the preferential testing process is very effective at identifying all potential cases, resulting in an exhaustive selection of all people infected with SARS-CoV-2. If this is the case, then current estimates of infection based on population-based prevalence may in fact be very good estimators of risk, and short term trends in case counts may be accurate. However, as noted above, seroprevalence surveys are suggesting that current test regimes have underestimated the infected population. Furthermore, it is widely believed that some infected people are asymptomatic ( Pan et al., 2020 ; Gandhi et al., 2020 ), suggesting that any preferential testing process based on symptoms is very likely to miss many (and possibly the majority) of cases.
Our analysis of value of information is based on assumptions about decision making without a basis in empirical data. We attempt to price decisions in response to daily changes in the count of cases, but it is difficult to know what the costs of such decisions would be. For this reason, we chose a decision cost matrix that very likely greatly overestimates the actual impact of a decision that most people would make in the real world in response to daily changes in coronavirus cases. As such, the estimates of information value reported do not contain much real world meaning, except about the relative value of the testing scenarios. Ideally, we would have analyzed trends over longer periods of time—for example, on a weekly basis—however as the series contains less than three months of data, this would not yield numbers large enough to evaluate the accuracy of testing data trends.
All scenarios in this analysis are being compared to a reference infection prevalence that may in fact be unrepresentative of reality. Provided that this reference infection shows roughly plausible variation over time, the fact that it may not be an accurate representation of risk does not greatly impact our conclusions. Somewhat paradoxically, since this reference infection estimates are based on actual reported data in Ontario, if it is not representative of reality, it might well provide even more support for our underlying argument.

Section: 5. Conclusions

There are many problems with publicly reported SARS-CoV-2 infection data that were not discussed here. Population infection data alone do not estimate risk, since they do not take into account the population at risk , or differences in demographics or other factors that could influence the risk faced by a given individual. These data also underestimate exposure to infection, since some people may be infected and infectious for a period before getting tested.
We do not conclude that governments should stop releasing data on SARS-CoV-2 infection data, even on a daily basis. Rather, we offer evidence that all data generators and curators should highlight uncertainties and errors associated with these data in any data portal, data dashboard or infographic in which these data are being shared. Our analysis also strongly suggests that short term variations on case counts (measured as a proportion of positive tests or as daily incidence) provide almost no information value to most data consumers. This is an intuitive conclusion, but nonetheless important given the widespread reporting of daily case numbers as part of the regular news cycle. Whatever the value that individual members of the public or researchers gain from these data, we believe it is clear that communicating data errors and uncertainties are an essential part of the data dissemination process.

Section: Credit author statement

Niko Yiannakoulias: Conceptualization, Coding, Analysis, Writing, Reviewing and Editing, Cathy Slavik: Conceptualization, Writing, Reviewing and Editing, Shelby Sturrock: Conceptualization, Writing, Reviewing and Editing, Connor Darlington: Conceptualization, Writing, Reviewing and Editing

Section: Acknowledgement

The authors would like to thank the anonymous reviewers for their helpful comments. This project was supported by the Social Sciences and Humanities Research Council (# 435-2020-0257 ).
