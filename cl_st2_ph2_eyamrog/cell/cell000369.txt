Title: High-precision coding in visual cortex


Abstract: Summary

Individual neurons in visual cortex provide the brain with unreliable estimates of visual features. It is not known whether the single-neuron variability is correlated across large neural populations, thus impairing the global encoding of stimuli. We recorded simultaneously from up to 50,000 neurons in mouse primary visual cortex (V1) and in higher order visual areas and measured stimulus discrimination thresholds of 0.35Â° and 0.37Â°, respectively, in an orientation decoding task. These neural thresholds were almost 100 times smaller than the behavioral discrimination thresholds reported in mice. This discrepancy could not be explained by stimulus properties or arousal states. Furthermore, behavioral variability during a sensory discrimination task could not be explained by neural variability in V1. Instead, behavior-related neural activity arose dynamically across a network of non-sensory brain areas. These results imply that perceptual discrimination in mice is limited by downstream decoders, not by neural noise in sensory representations.

Section: Introduction

Sensory neurons respond with high variability to repeated presentations of the same stimulus ( Tolhurst et al., 1983 82. Tolhurst, D.J. âˆ™ Movshon, J.A. âˆ™ Dean, A.F. The statistical reliability of signals in single neurons in cat and monkey visual cortex Vision Res. 1983; 23 :775-785 Crossref Scopus (744) PubMed Google Scholar ; Softky and Koch, 1993 74. Softky, W.R. âˆ™ Koch, C. The highly irregular firing of cortical cells is inconsistent with temporal integration of random EPSPs J. Neurosci. 1993; 13 :334-350 Crossref PubMed Google Scholar ; Zohary et al., 1994 90. Zohary, E. âˆ™ Shadlen, M.N. âˆ™ Newsome, W.T. Correlated neuronal discharge rate and its implications for psychophysical performance Nature. 1994; 370 :140-143 Crossref Scopus (933) PubMed Google Scholar ; Mainen and Sejnowski, 1995 45. Mainen, Z.F. âˆ™ Sejnowski, T.J. Reliability of spike timing in neocortical neurons Science. 1995; 268 :1503-1506 Crossref Scopus (1525) PubMed Google Scholar ; Arieli et al., 1996 3. Arieli, A. âˆ™ Sterkin, A. âˆ™ Grinvald, A. ... Dynamics of ongoing activity: explanation of the large variability in evoked cortical responses Science. 1996; 273 :1868-1871 Crossref Scopus (1350) PubMed Google Scholar ; Shadlen et al., 1996 69. Shadlen, M.N. âˆ™ Britten, K.H. âˆ™ Newsome, W.T. ... A computational analysis of the relationship between neuronal and behavioral responses to visual motion J. Neurosci. 1996; 16 :1486-1510 Crossref PubMed Google Scholar ; de Ruyter van Steveninck et al., 1997 17. de Ruyter van Steveninck, R.R. âˆ™ Lewen, G.D. âˆ™ Strong, S.P. ... Reproducibility and variability in neural spike trains Science. 1997; 275 :1805-1808 Crossref Scopus (537) PubMed Google Scholar ; Deweese and Zador, 2004 20. Deweese, M.R. âˆ™ Zador, A.M. Shared and private variability in the auditory cortex J. Neurophysiol. 2004; 92 :1840-1855 Crossref Scopus (54) PubMed Google Scholar ). This variability is thought to limit the accuracy of perceptual judgements because it is pervasive ( Faisal et al., 2008 23. Faisal, A.A. âˆ™ Selen, L.P. âˆ™ Wolpert, D.M. Noise in the nervous system Nat. Rev. Neurosci. 2008; 9 :292-303 Crossref Scopus (1910) PubMed Google Scholar ; Averbeck et al., 2006 4. Averbeck, B.B. âˆ™ Latham, P.E. âˆ™ Pouget, A. Neural correlations, population coding and computation Nat. Rev. Neurosci. 2006; 7 :358-366 Crossref Scopus (1126) PubMed Google Scholar ; Churchland et al., 2010 12. Churchland, M.M. âˆ™ Yu, B.M. âˆ™ Cunningham, J.P. ... Stimulus onset quenches neural variability: a widespread cortical phenomenon Nat. Neurosci. 2010; 13 :369-378 Crossref Scopus (702) PubMed Google Scholar ; Cohen and Kohn, 2011 14. Cohen, M.R. âˆ™ Kohn, A. Measuring and interpreting neuronal correlations Nat. Neurosci. 2011; 14 :811-819 Crossref Scopus (676) PubMed Google Scholar ), and it is reduced during attentional engagement ( Mitchell et al., 2009 47. Mitchell, J.F. âˆ™ Sundberg, K.A. âˆ™ Reynolds, J.H. Spatial attention decorrelates intrinsic activity fluctuations in macaque area V4 Neuron. 2009; 63 :879-888 Full Text Full Text (PDF) Scopus (518) PubMed Google Scholar ; Cohen and Maunsell, 2009 15. Cohen, M.R. âˆ™ Maunsell, J.H.R. Attention improves performance primarily by reducing interneuronal correlations Nat. Neurosci. 2009; 12 :1594-1600 Crossref Scopus (747) PubMed Google Scholar ; Gu et al., 2011 29. Gu, Y. âˆ™ Liu, S. âˆ™ Fetsch, C.R. ... Perceptual learning reduces interneuronal correlations in macaque visual cortex Neuron. 2011; 71 :750-761 Full Text Full Text (PDF) Scopus (159) PubMed Google Scholar ) and over the course of perceptual learning ( Ni et al., 2018 52. Ni, A.M. âˆ™ Ruff, D.A. âˆ™ Alberts, J.J. ... Learning and attention reveal a general relationship between population activity and behavior Science. 2018; 359 :463-465 Crossref Scopus (109) PubMed Google Scholar ). The hypothetical links between neural variability, sensory information, and perception form the foundations of several theoretical frameworks, such as the efficient coding hypothesis ( Barlow, 1961 5. Barlow, H.B. Possible principles underlying the transformation of sensory messages Rosenblith, W.A. (Editor) Sensory Communication MIT, 1961; 217-234 Google Scholar ; Simoncelli and Olshausen, 2001 72. Simoncelli, E.P. âˆ™ Olshausen, B.A. Natural image statistics and neural representation Annu. Rev. Neurosci. 2001; 24 :1193-1216 Crossref Scopus (1716) PubMed Google Scholar ), the information bottleneck ( Tishby et al., 2000 81. Tishby, N. âˆ™ Pereira, F.C. âˆ™ Bialek, W. The information bottleneck method arXiv. 2000; arXiv:physics/0004057v1 https://arxiv.org/abs/physics/0004057 Google Scholar ), the ideal observer model ( Geisler, 2011 25. Geisler, W.S. Contributions of ideal observer theory to vision research Vision Res. 2011; 51 :771-781 Crossref Scopus (180) PubMed Google Scholar ), the Bayesian coding hypothesis ( Ma et al., 2006 44. Ma, W.J. âˆ™ Beck, J.M. âˆ™ Latham, P.E. ... Bayesian inference with probabilistic population codes Nat. Neurosci. 2006; 9 :1432-1438 Crossref Scopus (1041) PubMed Google Scholar ; Doya et al., 2007 21. Doya, K. âˆ™ Ishii, S. âˆ™ Pouget, A. ... Bayesian Brain: Probabilistic Approaches to Neural Coding MIT, 2007 Google Scholar ; Knill and Pouget, 2004 40. Knill, D.C. âˆ™ Pouget, A. The Bayesian brain: the role of uncertainty in neural coding and computation Trends Neurosci. 2004; 27 :712-719 Full Text Full Text (PDF) Scopus (1587) PubMed Google Scholar ), and the probabilistic sampling hypothesis ( Buesing et al., 2011 8. Buesing, L. âˆ™ Bill, J. âˆ™ Nessler, B. ... Neural dynamics as sampling: a model for stochastic computation in recurrent networks of spiking neurons PLoS Comput. Biol. 2011; 7 :e1002211 Crossref Scopus (241) PubMed Google Scholar ; Haefner et al., 2016 30. Haefner, R.M. âˆ™ Berkes, P. âˆ™ Fiser, J. Perceptual decision-making as probabilistic inference by neural sampling Neuron. 2016; 90 :649-660 Full Text Full Text (PDF) Scopus (119) PubMed Google Scholar ).
However, it is not clear how variability measured from single neurons or from pairs of neurons scales to local circuits of tens of thousands of neurons ( Averbeck et al., 2006 4. Averbeck, B.B. âˆ™ Latham, P.E. âˆ™ Pouget, A. Neural correlations, population coding and computation Nat. Rev. Neurosci. 2006; 7 :358-366 Crossref Scopus (1126) PubMed Google Scholar ). Intuitively, one might expect the noise to be averaged out. Theoretical studies show that most types of noise are harmless at the population level ( Abbott and Dayan, 1999 1. Abbott, L.F. âˆ™ Dayan, P. The effect of correlated variability on the accuracy of a population code Neural Comput. 1999; 11 :91-101 Crossref Scopus (612) PubMed Google Scholar ; Ecker et al., 2011 22. Ecker, A.S. âˆ™ Berens, P. âˆ™ Tolias, A.S. ... The effect of noise correlations in populations of diversely tuned neurons J. Neurosci. 2011; 31 :14272-14283 Crossref Scopus (176) PubMed Google Scholar ; Sompolinsky et al., 2001 75. Sompolinsky, H. âˆ™ Yoon, H. âˆ™ Kang, K. ... Population coding in neuronal systems with correlated noise Phys. Rev. E Stat. Nonlin. Soft Matter Phys. 2001; 64 :051904 Crossref Scopus (8) PubMed Google Scholar ; Moreno-Bote et al., 2014 50. Moreno-Bote, R. âˆ™ Beck, J. âˆ™ Kanitscheider, I. ... Information-limiting correlations Nat. Neurosci. 2014; 17 :1410-1417 Crossref Scopus (329) PubMed Google Scholar ); only a special kind of correlated noise is detrimental to neural coding because it limits the total information available in the system. This â€œinformation-limitingâ€ noise arises when the estimation errors of single neurons are correlated to each other across the population ( Moreno-Bote et al., 2014 50. Moreno-Bote, R. âˆ™ Beck, J. âˆ™ Kanitscheider, I. ... Information-limiting correlations Nat. Neurosci. 2014; 17 :1410-1417 Crossref Scopus (329) PubMed Google Scholar ). In geometric terms, noise only affects the encoding of a stimulus when it aligns to the same neural subspaces that the stimuli drive ( Montijn et al., 2016 48. Montijn, J.S. âˆ™ Meijer, G.T. âˆ™ Lansink, C.S. ... Population-level neural codes are robust to single-neuron variability from a multidimensional coding perspective Cell Rep. 2016; 16 :2486-2498 Full Text Full Text (PDF) Scopus (65) PubMed Google Scholar ; Ruff and Cohen, 2019 65. Ruff, D.A. âˆ™ Cohen, M.R. Simultaneous multi-area recordings suggest a novel hypothesis about how attention improves performance bioRxiv. 2019; Crossref Scopus (0) Google Scholar ; Romo et al., 2003 63. Romo, R. âˆ™ HernÃ¡ndez, A. âˆ™ Zainos, A. ... Correlated neuronal discharges that increase coding efficiency during perceptual discrimination Neuron. 2003; 38 :649-657 Full Text Full Text (PDF) Scopus (181) PubMed Google Scholar ).
Even small amounts of information-limiting noise can put absolute bounds on the precision of stimulus encoding ( Moreno-Bote et al., 2014 50. Moreno-Bote, R. âˆ™ Beck, J. âˆ™ Kanitscheider, I. ... Information-limiting correlations Nat. Neurosci. 2014; 17 :1410-1417 Crossref Scopus (329) PubMed Google Scholar ). Estimating these bounds requires decoding studies from large neural populations. Previous studies in anesthetized macaques show that one-dimensional variables, like the orientation of a grating, can be decoded from populations of 10â€“100 simultaneously recorded neurons with errors in the 3Â°â€“20Â° range ( Vogels and Orban, 1990 86. Vogels, R. âˆ™ Orban, G.A. How well do response changes of striate neurons signal differences in orientation: a study in the discriminating monkey J. Neurosci. 1990; 10 :3543-3558 Crossref PubMed Google Scholar ; Graf et al., 2011 28. Graf, A.B. âˆ™ Kohn, A. âˆ™ Jazayeri, M. ... Decoding the activity of neuronal populations in macaque primary visual cortex Nat. Neurosci. 2011; 14 :239-245 Crossref Scopus (182) PubMed Google Scholar ; Berens et al., 2012 7. Berens, P. âˆ™ Ecker, A.S. âˆ™ Cotton, R.J. ... A fast and simple population code for orientation in primate V1 J. Neurosci. 2012; 32 :10618-10626 Crossref Scopus (80) PubMed Google Scholar ). It is not known whether these errors represent an absolute lower bound or may decrease further for larger neural populations. Some studies claim that small, random subsets of neurons are as discriminative as the entire population ( Graf et al., 2011 28. Graf, A.B. âˆ™ Kohn, A. âˆ™ Jazayeri, M. ... Decoding the activity of neuronal populations in macaque primary visual cortex Nat. Neurosci. 2011; 14 :239-245 Crossref Scopus (182) PubMed Google Scholar ; Newsome et al., 1989 51. Newsome, W.T. âˆ™ Britten, K.H. âˆ™ Movshon, J.A. Neuronal correlates of a perceptual decision Nature. 1989; 341 :52-54 Crossref Scopus (833) PubMed Google Scholar ), although others show consistent improvements in decoding with increasing numbers of neurons ( Stringer et al., 2019a 78. Stringer, C. âˆ™ Pachitariu, M. âˆ™ Steinmetz, N. ... High-dimensional geometry of population responses in visual cortex Nature. 2019; 571 :361-365 Crossref Scopus (232) PubMed Google Scholar ). It is also not known whether having more training trials would reduce overfitting and thus allow the decoding of even smaller orientation differences; previous studies were limited to stimulus densities of 4â€“10 trials/Â° ( Graf et al., 2011 28. Graf, A.B. âˆ™ Kohn, A. âˆ™ Jazayeri, M. ... Decoding the activity of neuronal populations in macaque primary visual cortex Nat. Neurosci. 2011; 14 :239-245 Crossref Scopus (182) PubMed Google Scholar ; Berens et al., 2012 7. Berens, P. âˆ™ Ecker, A.S. âˆ™ Cotton, R.J. ... A fast and simple population code for orientation in primate V1 J. Neurosci. 2012; 32 :10618-10626 Crossref Scopus (80) PubMed Google Scholar ).
Here, we investigate whether neural noise puts fundamental limits on stimulus encoding accuracy by recording from populations of up to 50,000 neurons in mice, using stimulus sets with densities of up to 2,000 trials/Â°. We found discrimination thresholds as low as 0.35Â° for stimulus orientation. Extrapolating beyond the number of neurons and trials in our experiments, we found the asymptotic value of the discrimination threshold to be âˆ¼ 0.1Â°. Thus, the information-limiting noise is very small and cannot account for the limits of perceptual discrimination. To further investigate the neural limitations affecting sensory processing, we analyzed neural recordings in a visual discrimination task. We found that the neural activity in primary visual cortex (V1) could not explain behavioral variability on a trial-by-trial basis, and this behavioral variability appeared to be generated dynamically in a network of non-sensory brain areas.

Section: Results

We recorded from V1 in awake, head-fixed mice that were free to run on an air-floating ball ( Figure 1 A). Our main stimuli were static gratings of a random orientation on each trial, which lasted for 750 ms, followed by 250 ms of gray screen. We recorded neural activity from visual cortex using multi-plane two-photon calcium imaging, with 10â€“17 planes spaced 25 Î¼m apart in depth, scanning the entire stack repeatedly at an average of âˆ¼ 3 Hz ( Figure 1 B). For the main stimulus set, we obtained 19,665 Â± 3,062 (SD; n = 6 mice) neurons per recording using the processing pipeline Suite2p ( Pachitariu et al., 2016 54. Pachitariu, M. âˆ™ Stringer, C. âˆ™ Schrder, S. ... Suite2p: beyond 10,000 neurons with standard two-photon microscopy bioRxiv. 2016; Crossref Google Scholar ; Figure 1 C; Video S1 ). All analyses were performed on deconvolved data, which localizes in time the fluorescence responses of the calcium indicator ( Pachitariu et al., 2018 55. Pachitariu, M. âˆ™ Stringer, C. âˆ™ Harris, K.D. Robustness of spike deconvolution for neuronal calcium imaging J. Neurosci. 2018; 38 :7976-7985 Crossref Scopus (81) PubMed Google Scholar ). The responses to each stimulus were defined as the average, deconvolved fluorescence over the 2 bins following stimulus onset. We have publicly shared the data and code base ( Pachitariu et al., 2019 56. Pachitariu, M., Michaelos, M., and Stringer, C. (2019). Recordings of 20,000 neurons from V1 in response to oriented stimuli. https://janelia.figshare.com/articles/dataset/Recordings_of_20_000_neurons_from_V1_in_response_to_oriented_stimuli/8279387 . Google Scholar ).
eyJraWQiOiI4ZjUxYWNhY2IzYjhiNjNlNzFlYmIzYWFmYTU5NmZmYyIsImFsZyI6IlJTMjU2In0.eyJzdWIiOiIzMjJmZmRlNGM2NTBlMWJlNGFlMDA0MzA4OGYxNWMyMSIsImtpZCI6IjhmNTFhY2FjYjNiOGI2M2U3MWViYjNhYWZhNTk2ZmZjIiwiZXhwIjoxNzQ5NjExNjYyfQ.eKbVxT8MypAwVuVoZSa8E3pNBVhIyAPHOfl1PxSNqaHWGW4fQAfx64DJhIpVoG5FyukjJhnRBu27PrUncSeBk2oVuZ5JLaqrur1ypJ7eb-H_BJSKzI8PU0g4ct_agKAXHMf9yqzquyC39yns0ZJrefOatACGegudyJn1TvCW4L0QqhDy7I1g0iCxTod-BhvzkRvlfQMnCDkqAdqNtQTbbC8ISxYyLEhc6aTiHbebngKB4Cq-iVkxZv63PbcBzGsD3cqey94u2voEuIPrUD96D7fJ9V_833k0t1bIVb4AN-LZtiSUJgwIwVgTeu529Bd6UDauXQtPvoSLdeMi8kcZ-g Video (43.36 MB) Video S1. Neural activity in response to two repeats of the same set of stimuli, related to Figure 1 Neurons recorded using calcium imaging were shown the same set of 10 oriented gratings twice. The top panel shows the first presentation and the bottom panel shows the second presentation. They are played at the same time to illustrate the variability across presentations of the same stimuli.
To visualize the patterns of population activity in a raster plot, we sorted neurons by their preferred stimulus ( Figure 1 D). As previously shown ( de Vries et al., 2018 18. de Vries, S.E.J. âˆ™ Lecoq, J. âˆ™ Buice, M.A. ... A large-scale, standardized physiological survey reveals higher order coding throughout the mouse visual cortex bioRxiv. 2018; Crossref Scopus (0) Google Scholar ), single neurons had high trial-to-trial variability and sometimes failed to respond at all to their preferred stimulus ( Figure 1 E; Video S1 ). We quantified this variability by the signal-to-noise ratio (SNR) ( Figures 1 F and 1G) and found a mean SNR of 0.11 for the example session and 0.13 Â± 0.01 (SEM; n = 6) across recordings, similar to the single-trial SNR previously reported for natural image stimuli ( Stringer et al., 2019a 78. Stringer, C. âˆ™ Pachitariu, M. âˆ™ Steinmetz, N. ... High-dimensional geometry of population responses in visual cortex Nature. 2019; 571 :361-365 Crossref Scopus (232) PubMed Google Scholar ). We also compared the signal variance of single neurons from our two-photon datasets to the signal variance of neurons recorded by electrophysiology and found that there was little loss of information due to our recording method ( Figures S1 Aâ€“S1C; Siegle et al., 2019 71. Siegle, J.H. âˆ™ Jia, X. âˆ™ Durand, S. ... A survey of spiking activity reveals a functional hierarchy of mouse corticothalamic visual areas bioRxiv. 2019; Crossref Scopus (0) Google Scholar ). The aligned, population-averaged tuning curves had a mean half-width at half-maximum of 14.1Â° ( Figure S1 E; Niell and Stryker, 2008 53. Niell, C.M. âˆ™ Stryker, M.P. Highly selective receptive fields in mouse visual cortex J. Neurosci. 2008; 28 :7520-7536 Crossref Scopus (723) PubMed Google Scholar ). The correlation between neural response vectors for different orientations decayed smoothly as a function of the difference in orientation ( Figures S1 H and S1I). Using a manifold embedding algorithm in three dimensions ( Tenenbaum et al., 2000 80. Tenenbaum, J.B. âˆ™ de Silva, V. âˆ™ Langford, J.C. A global geometric framework for nonlinear dimensionality reduction Science. 2000; 290 :2319-2323 Crossref Scopus (11106) PubMed Google Scholar ), we found a noisy, one-dimensional representation of the stimulus space ( Figure S1 J).
We distinguish and analyze three types of neural variability, which can affect coding in different ways: independent; partially correlated; and fully correlated or information limiting ( Figure 1 H).
Consider the first possibility, that the neural variability was independent across neurons. If that was true in the data, we could decode from the neural population using the â€œnaive Bayesâ€ classifier ( Rennie et al., 2003 62. Rennie, J.D. âˆ™ Shih, L. âˆ™ Teevan, J. ... Tackling the poor assumptions of naive bayes text classifiers Proceedings of the 20th International Conference on Machine Learning (ICML-03). AAAI, 2003 616-623 Google Scholar ). Given a response ğ‘… â¡ ( ğ‘› , ğ‘¡ ) of neuron n on trial t , we estimated the probability of ğœƒ â¢ | ğ‘… â¡ ( ğ‘› , ğ‘¡ ) âˆ¼ ğ’© â¢ ( ğ‘… â¡ ( ğ‘› , ğ‘¡ ) | â¢ ğ‘“ ğ‘› â¡ ( ğœƒ ) , ğœ ğ‘› ) for every possible angle Î¸ ( Figure 2 A). On training data, we derived ğ‘“ ğ‘› â¡ ( ğœƒ ) and ğœ ğ‘› as the mean tuning curve and the variance of the neural response, respectively ( Figure 2 A). The naive Bayes classifier multiplies these probabilities across neurons or equivalently sums the log-likelihoods ( Figure 2 A). Finally, the stimulus with the highest summed probability was selected as the decoded orientation, using interpolation to predict fractional stimulus values (see STAR Methods ).
This population decoder had a median error of 2.31Â° Â± 0.14Â° (SEM; n = 6 mice; Figures 2 B and 2C). This error may be either due to single-neuron noise that was not fully averaged out or due to correlations in decoding errors between neurons. To distinguish between these two scenarios, we split the neurons into two populations, decoded from each, and asked whether their decoding errors were in the same direction with respect to the true stimulus ( Figure 2 D). We found that the errors were highly correlated (Spearmanâ€™s R = 0.65 Â± 0.12; SEM; n = 6), which invalidated the independence assumption of the naive Bayes decoder ( Figure 2 E). This suggested that the error may decrease further if correlations are taken into account, which we show in the next section.
To account for correlations, a decoder must be able to appropriately weigh neurons, potentially discounting neurons that have correlations that are detrimental to coding. This is easily achieved with simple linear decoders, which we trained to predict continuous functions of the stimulus orientation ( Figure 2 F). We call these intermediate functions â€œsuper-neuronsâ€ and chose them to have von Mises tuning to orientation Î¸ ( Figure 2 F): ğ¹ â¡ ( ğœƒ | ğœƒ p r e f ) = e x p â¡ ( c o s â¡ ( ğœƒ âˆ’ ğœƒ p r e f ) / ğœ ) with ğœ = 0 . 1 . Different super-neurons had different values of ğœƒ p r e f that tiled the full range [ 0 , 2 â¢ ğœ‹ ] . On test data, the decoded stimulus was the preferred angle of the super-neuron with the highest activation, using interpolation methods to decode fractional angles ( Figure 2 F).
The error of the linear classifier was 1.03Â° Â± 0.04Â° (SEM; n = 6 mice) compared to 2.31Â° for the independent decoder ( Figures 2 G and 2H). The linear classifier outperformed two other common approaches ( Figures S2 Aâ€“S2F; Jazayeri and Movshon, 2006 33. Jazayeri, M. âˆ™ Movshon, J.A. Optimal representation of sensory information by neural populations Nat. Neurosci. 2006; 9 :690-696 Crossref Scopus (1) PubMed Google Scholar ; Graf et al., 2011 28. Graf, A.B. âˆ™ Kohn, A. âˆ™ Jazayeri, M. ... Decoding the activity of neuronal populations in macaque primary visual cortex Nat. Neurosci. 2011; 14 :239-245 Crossref Scopus (182) PubMed Google Scholar ). Furthermore, the decoder was robust to reductions of dimensionality â‰¥128 ( Figures S2 Gâ€“S2I), the decoder performed well for all stimuli ( Figures S3 Aâ€“S3C), and it was robust to the presence/absence of spontaneous activity patterns ( Figure S3 D).
To determine whether the linear classifiers achieved the minimum possible decoding error, we analyzed the asymptotic behavior of the error. We found that the error continued to decrease with increasing numbers of neurons ( Figure 2 I), even when restricted to the neurons with the highest SNR ( Figures S2 Jâ€“S2L). The error decreased even more with increasing number of stimulus presentations, due to a reduction in overfitting ( Figure 2 J). Therefore, a promising way to further improve decoding performance could be to show more stimulus trials.
Although we could not increase the total number of trials per recording, we were able to increase the stimulus density from âˆ¼ 10 trials/Â° to âˆ¼ 1,000 trials/Â° by restricting the stimuli to the 43Â°â€“47Â° range. All other stimulus parameters were kept the same, except for a subset of experiments with drifting grating stimuli localized to a 50Â° disk (the â€œlocalizedâ€ set). This subset of experiments was designed to reproduce the setup from Rumyantsev et al. (2020) 66. Rumyantsev, O.I. âˆ™ Lecoq, J.A. âˆ™ Hernandez, O. ... Fundamental bounds on the fidelity of sensory cortical coding Nature. 2020; 580 :100-105 Crossref Scopus (98) PubMed Google Scholar as closely as possible, including the extended 2 Ã— 2 mm recording area, which we achieved with the 2p-RAM ( Sofroniew et al., 2016 73. Sofroniew, N.J. âˆ™ Flickinger, D. âˆ™ King, J. ... A large field of view two-photon mesoscope with subcellular resolution for in vivo imaging eLife. 2016; e14472 Crossref Scopus (383) PubMed Google Scholar ). In addition, we increased the number of recorded neurons to 37,224â€“50,954 per experiment using the dual-plane upgrade of the 2p-RAM ( Tsyboulski et al., 2018 83. Tsyboulski, D. âˆ™ Orlova, N. âˆ™ Griffin, F. ... Remote focusing system for simultaneous dual-plane mesoscopic multiphoton imaging bioRxiv. 2018; Crossref Scopus (0) Google Scholar ), we increased the number of trials to âˆ¼ 2,000 trials/Â° and we also used closed-loop eye-movement correction.
We used a linear decoder to predict the stimulus and classified each stimulus relative to the middle stimulus of 45Â° ( Figure 3 A). We found that the discrimination threshold of the decoderâ€”at which it achieved 75% correct performanceâ€”was 0.34Â° Â± 0.04Â° (SEM; n = 5 mice) for the full-field stimuli and 0.35Â° Â± 0.02Â° (SEM; n = 4 mice) for the localized stimuli ( Figure 3 B). As a sanity check, we performed control recordings with the laser path blocked and found no ability to decode from the very low bleedthrough of the screen into the microscope ( Figures S3 Eâ€“S3G).
To check whether the decoder achieved the best possible performance, we studied the asymptotic behavior of the discrimination threshold ( Figure 3 C). We designed a parametric model of the threshold as a function of the number of trials and neurons, which provided excellent fits, and used this parametric model to extrapolate the asymptotic value of the discrimination threshold to âˆ¼ 0.10Â° ( Figures 3 C and 3D). We also calculated the inverse mean squared error of the decoder ( Figure S4 ), which is a lower bound on the information content, due to the Cramer-Rao bound ( Dayan and Abbott, 2005 16. Dayan, P. âˆ™ Abbott, L.F. Theoretical Neuroscience: Computational and Mathematical Modeling of Neural Systems MIT, 2005 Google Scholar ). There were no signs of saturation in this measure, raising the possibility that even the 0.10Â° asymptotic value is an overestimate.
In contrast to these very small neural discrimination thresholds, behavioral discrimination thresholds in mice are in the range of 20Â°â€“30Â° when directly estimated ( Abdolrahmani et al., 2019 2. Abdolrahmani, M. âˆ™ Lyamzin, D.R. âˆ™ Aoki, R. ... Cognitive modulation of interacting corollary discharges in the visual cortex bioRxiv. 2019; Crossref Scopus (0) Google Scholar ) or inferred from available data ( Lee et al., 2012 43. Lee, S.H. âˆ™ Kwan, A.C. âˆ™ Zhang, S. ... Activation of specific interneurons improves V1 feature selectivity and visual perception Nature. 2012; 488 :379-383 Crossref Scopus (422) PubMed Google Scholar ; Havenith et al., 2018 31. Havenith, M.N. âˆ™ Zijderveld, P.M. âˆ™ van Heukelum, S. ... The virtual-environment-foraging task enables rapid training and single-trial metrics of attention in head-fixed mice Sci. Rep. 2018; 8 :17371 Crossref Scopus (11) PubMed Google Scholar ; Table 1 ). Why is neural decoding from V1 so much better? One hypothesis is that the stimulus information never leaves the primary sensory area. To test this, we repeated the experiments in higher order visual areas that are lateral to V1, identified by retinotopic mapping at single-cell resolution ( Figure 3 E). Again, we found very low discrimination thresholds of 0.37Â° Â± 0.05Â° (SEM; n = 3 mice; Figure 3 F), which did not saturate at the number of neurons and stimuli we considered ( Figure 3 G).
To further investigate what might account for the discrepancy between behavioral performance and neural coding, we performed a large screen of experiments and analyses where we varied stimulus, behavioral, and/or neural properties ( Figures S5 Aâ€“S5K). Under all manipulations, the decoding performance remained high and degraded by less than a factor of 2 from its best value.
To directly test whether trial-by-trial neural variability in visual cortex results in behavioral variability, we re-analyzed a dataset of over 30,000 neurons from a recent study using Neuropixels probes ( Steinmetz et al., 2019 76. Steinmetz, N.A. âˆ™ Zatka-Haas, P. âˆ™ Carandini, M. ... Distributed coding of choice, action and engagement across the mouse brain Nature. 2019; 576 :266-273 Crossref Scopus (331) PubMed Google Scholar ; Jun et al., 2017 36. Jun, J.J. âˆ™ Steinmetz, N.A. âˆ™ Siegle, J.H. ... Fully integrated silicon probes for high-density recording of neural activity Nature. 2017; 551 :232-236 Crossref Scopus (1127) PubMed Google Scholar ). During the recordings, mice performed a visual two-alternative unforced choice task by reporting which side of their visual field contained a higher contrast Gabor stimulus. First, we verified that this task is not information limited at the level of visual cortex by recording from large populations of neurons while we presented the stimuli for 100 ms at a time ( Figures 4 A and 4B), a duration chosen to match the reported stimulus integration times in this task ( Zatka-Haas et al., 2020 88. Zatka-Haas, P. âˆ™ Steinmetz, N.A. âˆ™ Carandini, M. ... A perceptual decision requires sensory but not action coding in mouse cortex bioRxiv. 2020; Crossref Scopus (0) Google Scholar ). Neurons from two simultaneously recorded fields of view responded to either the left or the right stimulus in proportion to the contrast of that stimulus ( Figures 4 C and 4D). The neural decoding performance for consecutive stimulus contrasts (0 versus 0.25, 0.25 versus 0.5, and 0.5 versus 1) was on average 97.5% ( Figures 4 E and 4F), well above the behavioral performance of the mice in the task, which was 82% correct for the same contrast comparisons ( Figure 4 G). In their analysis, Steinmetz et al. (2019) 76. Steinmetz, N.A. âˆ™ Zatka-Haas, P. âˆ™ Carandini, M. ... Distributed coding of choice, action and engagement across the mouse brain Nature. 2019; 576 :266-273 Crossref Scopus (331) PubMed Google Scholar found that primary and higher order visual cortical areas appeared to encode visual and action signals but did not appear to encode the behavioral choices the mice made. However, these analyses were done on neural responses aligned to movement onset, and we are primarily interested in the variability of sensory responses at stimulus onset. When we aligned the neural data to stimulus onset and performed an analysis similar to that in Steinmetz et al. (2019 76. Steinmetz, N.A. âˆ™ Zatka-Haas, P. âˆ™ Carandini, M. ... Distributed coding of choice, action and engagement across the mouse brain Nature. 2019; 576 :266-273 Crossref Scopus (331) PubMed Google Scholar ; Figures S6 Aâ€“S6D), we did in fact find choice-related activity in primary as well as in higher order visual cortex ( Figures S6 E and S6G). To rule out technical differences between our analysis and that in Steinmetz et al. (2019) 76. Steinmetz, N.A. âˆ™ Zatka-Haas, P. âˆ™ Carandini, M. ... Distributed coding of choice, action and engagement across the mouse brain Nature. 2019; 576 :266-273 Crossref Scopus (331) PubMed Google Scholar , we applied our approach to neural responses aligned to movement onset. In that case, we found a distribution of choice selectivity across the brain that was very similar to that reported in Steinmetz et al. (2019) 76. Steinmetz, N.A. âˆ™ Zatka-Haas, P. âˆ™ Carandini, M. ... Distributed coding of choice, action and engagement across the mouse brain Nature. 2019; 576 :266-273 Crossref Scopus (331) PubMed Google Scholar , including a lack of choice-related activity in visual cortical areas ( Figures S6 F and S6H).
The presence of choice-related activity in visual cortex does not necessarily imply a causal role of these signals in driving perception and action; the signals could also represent non-causal feedback. A stronger test must be passed by any putative choice-driving signals: they need to be large enough to swing neural responses on incorrect trials over the decision threshold and toward the responses on correct trials for the opposite stimulus. We therefore considered as test data the incorrect trials where the mice made left/right choices on right/left trials, respectively ( Figures 5 A and 5B). We also included in the test data a subset of correct trials that were matched to the same distribution of stimuli ( Figure 5 B). We trained decoders on the remaining correct trials to predict the difference in contrast between the right and left stimuli ( Figure 5 C).
It is not possible on correct trials to distinguish a sensory from a choice signal, because the two experimental variables are fully correlated. The ambiguity is resolved on incorrect and matched correct trials, which by construction have uncorrelated sensory and choice variables ( Figures 5 B and 5D). At stimulus onset, we found that nearly all brain regions were much more correlated with the stimulus than the choice ( Figures 5 D and 5E). During the pre-movement epoch, most of these regions became approximately equally correlated with the stimulus and choice. Finally, during movement, these same regions became highly correlated with the choice but only weakly correlated with the stimulus. The only exceptions to this pattern were in hippocampal areas and in primary sensory cortices, including visual cortex, which did not develop substantial choice selectivity. In the midbrain, the deeper, motor-related part of the superior colliculus contained strong choice signals, although the superficial, sensory-related part contained little if any ( Figures S6 G and S6H).
To interpret these results, it is instructive to consider how different types of signals in a perceptual decision-making circuit would correlate with the stimulus and with the choice ( Figure 5 F). The experimental results are consistent with a scenario in which the perceptual decision gradually and simultaneously develops across many brain areas, accumulating internal noise from across most of the brain, with the notable exception of primary sensory cortices ( Figure 5 G). However, we cannot rule out the possibility that the choice signals represent internal feedback or efference ( Cisek and Kalaska, 2010 13. Cisek, P. âˆ™ Kalaska, J.F. Neural mechanisms for interacting with a world full of action choices Annu. Rev. Neurosci. 2010; 33 :269-298 Crossref Scopus (1022) PubMed Google Scholar ).
Thus, we found a faulty link between the purely sensory representations that have high-information content and the noisy neural representations used during behavior. Because behavioral representations are established during an active learning process that can take weeks, we wondered whether that learning process might be suboptimal, impaired perhaps by the sequential, trial-based nature of learning and by the incomplete information the animals get on every trial. To mimic learning, we turned to perceptron-based decoders that process sensory stimuli sequentially and are only provided binary feedback ( Rosenblatt, 1958 64. Rosenblatt, F. The perceptron: a probabilistic model for information storage and organization in the brain Psychol. Rev. 1958; 65 :386-408 Crossref Scopus (6443) PubMed Google Scholar ; Devos and Orban, 1990 19. Devos, M. âˆ™ Orban, G.A. Modeling orientation discrimination at multiple reference orientations with a neural network Neural Comput. 1990; 2 :152-161 Crossref Google Scholar ; Seung and Sompolinsky, 1993 68. Seung, H.S. âˆ™ Sompolinsky, H. Simple models for reading neuronal population codes Proc. Natl. Acad. Sci. USA. 1993; 90 :10749-10753 Crossref Scopus (454) PubMed Google Scholar ; Dayan and Abbott, 2005 16. Dayan, P. âˆ™ Abbott, L.F. Theoretical Neuroscience: Computational and Mathematical Modeling of Neural Systems MIT, 2005 Google Scholar ; Burak et al., 2012 9. Burak, Y. âˆ™ Chung, S. âˆ™ Sompolinsky, H. Quadratic networks for invariant perceptual discrimination Computational and Systems Neuroscience. Cosyne, 2012 Google Scholar ; Figure 6 A). The perceptron sums the activities of its input neurons â†’ ğ‘¥ multiplied by a set of weights â†’ ğ‘¤ : ğ‘¦ p r e d = â†’ ğ‘¤ â‹… â†’ ğ‘¥ . The sign of ğ‘¦ p r e d is then used to predict the label ğ‘¦ l a b e l âˆˆ ( âˆ’ 1 , + 1 ) . The objective of learning in a perceptron is to change the weights â†’ ğ‘¤ in order to minimize the mean-squared error of the prediction.
Simple forms of online learning in a perceptron can be biologically realistic if they only require global error signals in addition to the signals available locally at a synapse. We investigate three such versions here. First, we consider a â€œsupervised Hebbianâ€ learner, which changes the weight of neuron k ( ğ‘¤ ğ‘˜ ) using the trial label ğ‘¦ l a b e l and the neural response ğ‘¥ ğ‘˜ ( Figure 6 A): Î” â¢ ğ‘¤ ğ‘˜ = ğ‘¦ l a b e l â‹… ğ‘¥ ğ‘˜ . We also consider a gradient descent learner, which changes the weights by Î” â¢ ğ‘¤ ğ‘˜ = ( ğ‘¦ l a b e l âˆ’ ğ‘¦ p r e d ) â‹… ğ‘¥ ğ‘˜ , and a restricted form of gradient descent called â€œreinforcement descent,â€ which uses the choice in place of the continuous prediction: Î” â¢ ğ‘¤ ğ‘˜ = ( ğ‘¦ l a b e l âˆ’ s i g n â¡ ( ğ‘¦ p r e d ) ) â‹… ğ‘¥ ğ‘˜ . To test these online learning strategies, we designed two tasks, one easy and one hard. In the easy task, the learning agents used the neural responses to our first stimulus set with 10 trials/Â°, restricted to angles between âˆ’30Â° and âˆ’5Â° for the â€œleftâ€ choice and 5Â° and 30Â° for the â€œrightâ€ choice ( Figure 6 B). All three perceptron learners performed the easy task perfectly, using a small number of training trials ( Figure 6 B). In the hard task, the learners had to discriminate between positive and negative stimulus angles of up to 2Â°, using the neural data recorded at 1,000 trials/Â° ( Figure 6 C). The supervised Hebbian learner was unable to perform well in this task with an asymptotic performance of 66%. However, the learners based on gradient descent and reinforcement descent performed relatively well at 83% and 81% compared to 85% for the optimal linear decoder, which had instantaneous access to all trials in its history ( Figure 6 C). Therefore, the perceptrons that used error feedback acquired information nearly as efficiently as the optimal linear decoder.
We conclude that simple online decoders can learn even difficult orientation discrimination tasks from neural data in a sample-efficient way. Therefore, sequential learning strategies do not fundamentally limit behavioral task performance. It follows that animals use suboptimal learning strategies in laboratory experiments, perhaps because those strategies are favorable in ecological contexts. We end this study by proposing examples of suboptimal but potentially relevant decoders and leave it to future work to evaluate these weak learners against animal behavior. The decoders we propose ( Figure 6 D) are (1) the â€œbest neuronâ€ learner, which finds the neuron most correlated with the correct choice on the training set and uses this neuron to make predictions on the test set; (2) the â€œone-shotâ€ learner, which learns from only one trial of each stimulus category and builds a linear decoder along the discriminant direction of these two trials; and 3) the â€œrandom projectionâ€ learner, which evaluates 100 different random projections and retains the one that maximizes training set performance. These decoders had test set performance on the easy task in the 65%â€“90% range ( Figure 6 E), which is in line with mouse behavioral performance on similar tasks ( Lee et al., 2012 43. Lee, S.H. âˆ™ Kwan, A.C. âˆ™ Zhang, S. ... Activation of specific interneurons improves V1 feature selectivity and visual perception Nature. 2012; 488 :379-383 Crossref Scopus (422) PubMed Google Scholar ; Abdolrahmani et al., 2019 2. Abdolrahmani, M. âˆ™ Lyamzin, D.R. âˆ™ Aoki, R. ... Cognitive modulation of interacting corollary discharges in the visual cortex bioRxiv. 2019; Crossref Scopus (0) Google Scholar ; Poort et al., 2015 60. Poort, J. âˆ™ Khan, A.G. âˆ™ Pachitariu, M. ... Learning enhances sensory and multiple non-sensory representations in primary visual cortex Neuron. 2015; 86 :1478-1490 Full Text Full Text (PDF) Scopus (239) PubMed Google Scholar ; Glickfeld et al., 2013 26. Glickfeld, L.L. âˆ™ Histed, M.H. âˆ™ Maunsell, J.H. Mouse primary visual cortex is used to detect both orientation and contrast changes J. Neurosci. 2013; 33 :19416-19422 Crossref Scopus (133) PubMed Google Scholar ; Havenith et al., 2018 31. Havenith, M.N. âˆ™ Zijderveld, P.M. âˆ™ van Heukelum, S. ... The virtual-environment-foraging task enables rapid training and single-trial metrics of attention in head-fixed mice Sci. Rep. 2018; 8 :17371 Crossref Scopus (11) PubMed Google Scholar ).

Section: Discussion

Here, we showed that mouse visual cortex encodes visual features to a very high precision on a single-trial basis, despite large single-neuron variability and multi-neuron correlations. To show this, we recorded from large populations of neurons in primary and higher order visual cortex and used decoders to compute neurometric discrimination thresholds as low as 0.35Â° in mice, a species thought to have poor visual acuity. Simple linear decoders were sufficient to achieve this performance, although it is possible that nonlinear decoders may perform even better ( Shamir and Sompolinsky, 2004 70. Shamir, M. âˆ™ Sompolinsky, H. Nonlinear population codes Neural Comput. 2004; 16 :1105-1136 Crossref Scopus (100) PubMed Google Scholar ; but see our analyses of multi-layer networks and random forest classifiers in Figure S5 L). Furthermore, the neural discrimination threshold did not appear to saturate with the number of neurons and trials, leading to asymptotic estimates of âˆ¼ 0.1Â°. The neural discrimination thresholds we measured are âˆ¼ 100Ã— lower than behavioral discrimination thresholds reported by previous studies ( Abdolrahmani et al., 2019 2. Abdolrahmani, M. âˆ™ Lyamzin, D.R. âˆ™ Aoki, R. ... Cognitive modulation of interacting corollary discharges in the visual cortex bioRxiv. 2019; Crossref Scopus (0) Google Scholar ; Havenith et al., 2018 31. Havenith, M.N. âˆ™ Zijderveld, P.M. âˆ™ van Heukelum, S. ... The virtual-environment-foraging task enables rapid training and single-trial metrics of attention in head-fixed mice Sci. Rep. 2018; 8 :17371 Crossref Scopus (11) PubMed Google Scholar ; Lee et al., 2012 43. Lee, S.H. âˆ™ Kwan, A.C. âˆ™ Zhang, S. ... Activation of specific interneurons improves V1 feature selectivity and visual perception Nature. 2012; 488 :379-383 Crossref Scopus (422) PubMed Google Scholar ). The difference between behavioral and neural discrimination could not be explained by differences in stimuli or arousal states. Instead, we found that behavioral errors in a visual discrimination task correlated with trial-by-trial internal noise in a large network of non-sensory brain areas. Although all these areas start with a purely sensory representation at stimulus onset, they gradually develop noisy stimulus representations that reflect the incorrect decisions. Our results imply that neural noise in sensory representations does not set a fundamental limit on the accuracy of sensory perception and that behavioral errors arise downstream of the sensory representations.
Consistent with our results, a recent study in monkeys showed that neural variability in primary and secondary visual cortex did not account for the variability in perceptual report in an orientation discrimination task ( Goris et al., 2017 27. Goris, R.L.T. âˆ™ Ziemba, C.M. âˆ™ Stine, G.M. ... Dissociation of choice formation and choice-correlated activity in macaque visual cortex J. Neurosci. 2017; 37 :5195-5203 Crossref Scopus (30) PubMed Google Scholar ). Another study in primates found that the neurometric detection sensitivity slightly exceeded the animalâ€™s behavior ( Chen et al., 2006 10. Chen, Y. âˆ™ Geisler, W.S. âˆ™ Seidemann, E. Optimal decoding of correlated neural population responses in the primate visual cortex Nat. Neurosci. 2006; 9 :1412-1420 Crossref Scopus (155) PubMed Google Scholar ), however by a much smaller amount than what we have shown here. The neural discrimination thresholds of 0.35Â° that we measured in mice are lower than even the reported thresholds of highly trained primates in this taskâ€”2Â° to 3Â° in macaques and 1Â° to 2Â° in humans ( Webster et al., 1990 87. Webster, M.A. âˆ™ De Valois, K.K. âˆ™ Switkes, E. Orientation and spatial-frequency discrimination for luminance and chromatic gratings J. Opt. Soc. Am. A. 1990; 7 :1034-1049 Crossref Scopus (139) PubMed Google Scholar ; Table 1 )â€”despite a 100- and 1,000-fold difference in brain volume, respectively.
Independent from our work, three groups have recently claimed to have found large information-limiting correlations in visual cortex ( Montijn et al., 2019 49. Montijn, J.S. âˆ™ Liu, R.G. âˆ™ Aschner, A. ... Strong information-limiting correlations in early visual areas bioRxiv. 2019; Crossref Scopus (0) Google Scholar ; Kafashan et al., 2020 37. Kafashan, M. âˆ™ Jaffe, A. âˆ™ Chettih, S.N. ... Scaling of information in large neural populations reveals signatures of information-limiting correlations bioRxiv. 2020; Crossref Scopus (0) Google Scholar ; Rumyantsev et al., 2020 66. Rumyantsev, O.I. âˆ™ Lecoq, J.A. âˆ™ Hernandez, O. ... Fundamental bounds on the fidelity of sensory cortical coding Nature. 2020; 580 :100-105 Crossref Scopus (98) PubMed Google Scholar ). However, these studies did not directly measure the information content of large populations of neurons and instead used extrapolations from much smaller recordings with fewer trials per stimulus ( Table S1 ).
We suggest three potential explanations for the discrepancy between behavioral performance and neural information content. First, it is possible that animals cannot integrate information from hundreds or thousands of stimulus presentations, which would be required to find the optimal decoders ( Beck et al., 2012 6. Beck, J.M. âˆ™ Ma, W.J. âˆ™ Pitkow, X. ... Not noisy, just wrong: the role of suboptimal inference in behavioral variability Neuron. 2012; 74 :30-39 Full Text Full Text (PDF) Scopus (192) PubMed Google Scholar ; but see Figure 6 for simple biophysically plausible decoders). Second, it is possible that the fine stimulus information is not available for perceptual report but is used by other visual functions, such as change detection or sensory-guided motor behavior ( Glickfeld et al., 2013 26. Glickfeld, L.L. âˆ™ Histed, M.H. âˆ™ Maunsell, J.H. Mouse primary visual cortex is used to detect both orientation and contrast changes J. Neurosci. 2013; 33 :19416-19422 Crossref Scopus (133) PubMed Google Scholar ; Jin and Glickfeld, 2020 34. Jin, M. âˆ™ Glickfeld, L.L. Mouse higher visual areas provide both distributed and specialized contributions to visually guided behaviors Curr. Biol. 2020; 30 :4682-4692.e7 Full Text Full Text (PDF) Scopus (25) PubMed Google Scholar ; Pruszynski et al., 2018 61. Pruszynski, J.A. âˆ™ Flanagan, J.R. âˆ™ Johansson, R.S. Fast and accurate edge orientation processing during object manipulation eLife. 2018; 7 :e31200 Crossref Scopus (30) PubMed Google Scholar ; Milner and Goodale, 2006 46. Milner, D. âˆ™ Goodale, M. The Visual Brain in Action Oxford University, 2006 Crossref Scopus (725) Google Scholar ). Finally, it may be that animals have latent task knowledge even when their behavior is poor ( Kuchibhotla et al., 2019 41. Kuchibhotla, K.V. âˆ™ Hindmarsh Sten, T. âˆ™ Papadoyannis, E.S. ... Dissociating task acquisition from expression during learning reveals latent knowledge Nat. Commun. 2019; 10 :2151 Crossref Scopus (18) PubMed Google Scholar ). Although it is possible that mouse discrimination thresholds are lower than currently reported, it is unlikely they would be low enough to bridge the gap to the super-human neural thresholds that we estimated in mice.
Two-photon calcium imaging introduces some noise into the recordings and also lacks precise temporal information about neural events. We therefore verified our results with electrophysiological recordings in which mice were also shown oriented gratings ( Figures S1 Aâ€“S1C; Siegle et al., 2019 71. Siegle, J.H. âˆ™ Jia, X. âˆ™ Durand, S. ... A survey of spiking activity reveals a functional hierarchy of mouse corticothalamic visual areas bioRxiv. 2019; Crossref Scopus (0) Google Scholar ). These recordings were performed with gratings spaced 30Â° apart, not at random orientations like in our study, and furthermore, the maximum population size was 100â€“200 neurons. Therefore, we could not estimate the limits of information coding in these populations.
All of the large-scale recordings we performed were in passive animals that were not engaged in perceptual discrimination tasks. We analyzed electrophysiological recordings during a task, but this was a simpler contrast discrimination task, rather than an orientation discrimination task ( Steinmetz et al., 2019 76. Steinmetz, N.A. âˆ™ Zatka-Haas, P. âˆ™ Carandini, M. ... Distributed coding of choice, action and engagement across the mouse brain Nature. 2019; 576 :266-273 Crossref Scopus (331) PubMed Google Scholar ). For most brain areas, we could not distinguish between choice-related signals that have a causal contribution to behavior and those that merely represent feedback. However, we did rule out the presence of causal choice-related signals in the V1 in this task.

Section: STARâ˜…Methods

REAGENT or RESOURCE SOURCE IDENTIFIER Bacterial and virus strains AAV-GCaMP6s-P2A-nls-dTomato Addgene RRID:Addgene_51084 Deposited data Oriented stimuli dataset (current study) https://janelia.figshare.com/articles/Recordings_of_20_000_neurons_from_V1_in_response_to_oriented_stimuli/8279387/3 Electrophysiological recordings in mouse visual cortex Siegle et al., 2019 71. Siegle, J.H. âˆ™ Jia, X. âˆ™ Durand, S. ... A survey of spiking activity reveals a functional hierarchy of mouse corticothalamic visual areas bioRxiv. 2019; Crossref Scopus (0) Google Scholar https://allensdk.readthedocs.io/en/latest/visual_coding_neuropixels.html Electrophysiological recordings during behavior in mice Steinmetz et al., 2019 76. Steinmetz, N.A. âˆ™ Zatka-Haas, P. âˆ™ Carandini, M. ... Distributed coding of choice, action and engagement across the mouse brain Nature. 2019; 576 :266-273 Crossref Scopus (331) PubMed Google Scholar https://allensdk.readthedocs.io/en/latest/visual_coding_neuropixels.html Experimental models: organisms/strains TetO-GCaMP6s x Camk2a-tTA mice JAX RRID:IMSR_JAX:024742 and RRID:IMSR_JAX:007004 Software and algorithms Suite2p v0.7.5 Pachitariu et al., 2016 54. Pachitariu, M. âˆ™ Stringer, C. âˆ™ Schrder, S. ... Suite2p: beyond 10,000 neurons with standard two-photon microscopy bioRxiv. 2016; Crossref Google Scholar http://www.suite2p.org ScanImage 2018 Pologruto et al., 2003 59. Pologruto, T.A. âˆ™ Sabatini, B.L. âˆ™ Svoboda, K. ScanImage: flexible software for operating laser scanning microscopes Biomed. Eng. Online. 2003; 2 :13 Crossref Scopus (909) PubMed Google Scholar http://www.scanimage.vidriotechnologies.com/display/SIH;jsessionid=B2A864795336D50F5F4FABFC07AD67AA Psychtoolbox-3 Kleiner et al., 2007 38. Kleiner, M. âˆ™ Brainard, D. âˆ™ Pelli, D. ... Whats new in psychtoolbox-3 Perception. 2007; 36 :1-16 Crossref Scopus (1) Google Scholar http://psychtoolbox.org numpy van der Walt et al., 2014 85. van der Walt, S. âˆ™ SchÃ¶nberger, J.L. âˆ™ Nunez-Iglesias, J. ..., scikit-image contributors scikit-image: image processing in Python PeerJ. 2014; 2 :e453 Crossref Scopus (3207) PubMed Google Scholar https://www.numpy.org scipy Jones et al., 2001 35. Jones, E. âˆ™ Oliphant, T. âˆ™ Peterson, P. SciPy: open source scientific tools for Python 2001 https://www.scipy.org/ Google Scholar https://www.scipy.org scikit-learn Pedregosa et al., 2011 58. Pedregosa, F. âˆ™ Varoquaux, G. âˆ™ Gramfort, A. ... Scikit-learn: Machine learning in python J. Mach. Learn. Res. 2011; 12 :2825-2830 Google Scholar https://scikit-learn.org matplotlib Hunter, 2007 32. Hunter, J.D. Matplotlib: a 2D graphics environment Comput. Sci. Eng. 2007; 9 :90-95 Crossref Scopus (20585) Google Scholar https://www.matplotlib.org Analysis and figure code for paper (current study) https://www.github.com/mouseland/stringer-et-al-2019 Open table in a new tab
Further information and requests for resources and reagents should be directed to and will be fulfilled by the Lead Contact, Marius Pachitariu ( pachitarium@janelia.hhmi.org ).
There were no newly generated materials associated with the paper.
All of the processed neural activity generated during this study is available on figshare ( Pachitariu et al., 2019 56. Pachitariu, M., Michaelos, M., and Stringer, C. (2019). Recordings of 20,000 neurons from V1 in response to oriented stimuli. https://janelia.figshare.com/articles/dataset/Recordings_of_20_000_neurons_from_V1_in_response_to_oriented_stimuli/8279387 . Google Scholar ) ( https://figshare.com/articles/dataset/Recordings_of_20_000_neurons_from_V1_in_response_to_oriented_stimuli/8279387 ). The code to analyze the data and create the figures is available on github ( https://github.com/MouseLand/stringer-et-al-2019 ).
All experimental procedures were conducted according to IACUC. We performed 21 recordings in 12 mice bred to express GCaMP6s in excitatory neurons: TetO-GCaMP6s x Camk2a-tTA mice (available as RRID:IMSR_JAX:024742 and RRID:IMSR_JAX:007004). We also performed 21 recordings in three wild-type C57 mice. In these mice, AAV-GCaMP6s-P2A-nls-dTomato (RRID:Addgene_51084) was expressed virally through injections into visual cortex. These mice were male and female, and ranged from 2 to 12 months of age. Mice were housed in reverse light cycle.
Surgeries were performed in adult mice (P35-P125). Mice were anesthetized briefly using 3% Isoflurane until breathing slowed to approximately 1-2 breaths per second. Marcaine (no more than 8 mg/kg) was injected subcutaneously beneath the incision area, the surgical site shaved and the animal transferred to the stereotax and nosecone setup. After transferring to the nosecone, warmed fluids + 5% dextrose and Buprenorphine 0.1 mg/kg (systemic analgesic) were administered subcutaneously along with Dexamethasone 2 mg/kg via intramuscular route. Anesthesia was maintained throughout the entire procedure at 1.5%â€“2% Isoflurane. Eye lubrication was applied and the skin prepped using alternating swabs of ethanol and betadine. Prior to the first incision, anesthesia depth was confirmed by loss of toe-pinch reflex. Upon confirming appropriate depth of anesthesia, an incision was made and a small area of skin excised over the skull. The tissue was cleared away and the skull dried using cotton swabs and 3% hydrogen peroxide. Vetbond was applied to the skin around the edges of the incision area and any excess Vetbond was scraped away from the surface of the skull using the edge of a scalpel blade.
Measurements were taken to determine bregma-lambda distance and location of a 4 mm window over V1 cortex, as far lateral and caudal as possible without compromising the stability of the implant. The coordinates were marked and surface of the skull etched using a No.10 scalpel blade. A thin layer of Optibond Solo Plus was applied to the entire surface of the skull and UV cured for 40 s. The headbar was placed over the marked craniotomy location while following the curvature of the skull, then secured using Calibra Universal Resin Cement. Any excess cement was wiped away using sterile absorption spears and UV cured for 20 s. Upon securing the headbar, the craniotomy was drilled slowly and carefully to avoid any damage to the brain. Progress was periodically checked by gently pressing on the center of the craniotomy to determine whether the skull was thinned enough to flex under pressure. Once the edges were sufficiently thin, cold sterile-filtered cortex buffer was placed over the well of the headbar and allowed to sit for several minutes. Once the edges softened, the entire bone piece was carefully lifted away using Dumont forceps.
A 4+5 mm double window was placed into the craniotomy so that the 4mm window replaced the previously removed bone piece and the 5mm window lay over the edge of the bone. While holding gentle pressure over the window with curved forceps, any excess cortex buffer was removed and Vetbond applied around the edges of the window. The window was held in place for 5 minutes until the Vetbond fully dried. Then, Calibra Universal Resin Cement was applied over the edges of the 5mm window and covering the inner sides of the headbar and UV cured. The mouse was removed from the stereotax, Ketoprofen 5mg/kg administered subcutaneously and the animal allowed to recover on heat. The mice were monitored for pain or distress and Ketoprofen 5mg/kg administered for 2 days following surgery.
A subset of surgeries were performed in wild-type C57 mice, in which case we expressed GCaMP6s virally through injection. We targeted virus injections (50-200 nl, 1-3 Ã— 1012 GC/ml) to monocular V1 (2.1-3.3 mm laterally and 3.5-4.0 mm posteriorly from Bregma). To obtain large fields of view for imaging, we typically performed several injections at nearby locations, at multiple depths ( âˆ¼ 500 Î¼m and âˆ¼ 200 Î¼m).
We used a custom-built 2-photon mesoscope ( Sofroniew et al., 2016 73. Sofroniew, N.J. âˆ™ Flickinger, D. âˆ™ King, J. ... A large field of view two-photon mesoscope with subcellular resolution for in vivo imaging eLife. 2016; e14472 Crossref Scopus (383) PubMed Google Scholar ) to record neural activity, and ScanImage ( Pologruto et al., 2003 59. Pologruto, T.A. âˆ™ Sabatini, B.L. âˆ™ Svoboda, K. ScanImage: flexible software for operating laser scanning microscopes Biomed. Eng. Online. 2003; 2 :13 Crossref Scopus (909) PubMed Google Scholar ) for data acquisition. Multi-plane acquisition was controlled by a resonance mirror, with planes spaced 25 Î¼m apart in depth. 10-17 planes were acquired sequentially, scanning the entire stack repeatedly on average at 3 Hz. We synchronized stimulus presentation to the beginning of each frame for the first plane, and computed stimulus responses from the first two frames acquired after stimulus onset for each plane. We used a custom online Z-correction module (now in ScanImage), to correct for Z and XY drift online during the recording.
For almost all experiments, an area of âˆ¼ 1 mm by 650 Î¼m was acquired. In a subset of experiments (â€localizedâ€ with dense stimulus set), we used a much larger recording area of 2 Ã— 2 mm (three stripes of 650 Î¼m width) to match the recording area from Rumyantsev et al. (2020) 66. Rumyantsev, O.I. âˆ™ Lecoq, J.A. âˆ™ Hernandez, O. ... Fundamental bounds on the fidelity of sensory cortical coding Nature. 2020; 580 :100-105 Crossref Scopus (98) PubMed Google Scholar .
The mice were free to run on an air-floating ball. For all static image presentations an LED tablet screen at a 45 Â° from the left eye (we recorded in right visual cortex). For drifting grating image presentations a custom circular screen made of LED arrays was placed around the head of the mouse ( Seelig et al., 2010 67. Seelig, J.D. âˆ™ Chiappe, M.E. âˆ™ Lott, G.K. ... Two-photon calcium imaging from head-fixed Drosophila during optomotor walking behavior Nat. Methods. 2010; 7 :535-540 Crossref Scopus (230) PubMed Google Scholar ). We also repeated the static grating experiments with this screen and obtained comparable decoding errors. To prevent direct contamination of the PMT from the screen, we placed gel filters in front of the screen which exclude green light, and used only the red channel of the screens.
For each mouse, recordings were made over multiple days, always returning to the same field of view. The field of view was selected on the first recording day such that large numbers of neurons could be observed, with clear calcium transients and a retinotopic location that was localized on the screen (identified by neuropil fluorescence responses to sparse noise). For three mice, we recorded in higher-order visual areas, located based on retinotopic responses to sparse noise. We were able to identify with high confidence the reversal in horizontal retinotopic preference, and used the random-access mesoscope to record from two fields of view simultaneous in higher-order visual areas that would correspond primarily to areas LM and PM in the Allen Brain Atlas ( Zhuang et al., 2017 89. Zhuang, J. âˆ™ Ng, L. âˆ™ Williams, D. ... An extended retinotopic map of mouse cortex eLife. 2017; 6 :e18372 Crossref Scopus (135) PubMed Google Scholar ).
In a subset of experiments (â€localizedâ€ with dense stimulus set), we used an upgrade of the mesoscope that allowed us to approximately double the number of recorded neurons. The dual-plane mesoscope replicates the setup from Tsyboulski et al. (2018) 83. Tsyboulski, D. âˆ™ Orlova, N. âˆ™ Griffin, F. ... Remote focusing system for simultaneous dual-plane mesoscopic multiphoton imaging bioRxiv. 2018; Crossref Scopus (0) Google Scholar , which utilized temporal multiplexing ( Cheng et al., 2011 11. Cheng, A. âˆ™ GonÃ§alves, J.T. âˆ™ Golshani, P. ... Simultaneous two-photon calcium imaging at different depths with spatiotemporal multiplexing Nat. Methods. 2011; 8 :139-142 Crossref Scopus (237) PubMed Google Scholar ; Stirman et al., 2016 77. Stirman, J.N. âˆ™ Smith, I.T. âˆ™ Kudenov, M.W. ... Wide field-of-view, multi-region two-photon imaging of neuronal activity in vivo Optics and the Brain. Optical Society of America, 2016 BTu2D.2 Crossref Google Scholar ) to allow simultaneous recording from two stacked imaging planes. The original mesoscope from Sofroniew et al. (2016) 73. Sofroniew, N.J. âˆ™ Flickinger, D. âˆ™ King, J. ... A large field of view two-photon mesoscope with subcellular resolution for in vivo imaging eLife. 2016; e14472 Crossref Scopus (383) PubMed Google Scholar was modified to use two orthogonally polarized excitation beams/pulse trains derived from an 80 MHz femtosecond laser (Mai Tai Deep See, Spectra Physics) emitting at 920 nm, with a relative time delay of 6.25 ns. A polarizing beam-splitter (PBS) directed the incoming collinear beams based on their polarization toward two similar remote-focusing (RF) assemblies, consisting of a l/4 wave plate, a custom RF objective and a movable mirror. The returning beams with rotated by 90 Â° polarization were recombined at the PBS and directed toward optical scanners. Each RF assembly controlled an axial position of a corresponding focal plane and by design provided spherical aberration compensation at different beam defocus values associated with RF mirror position. Temporally interleaved fluorescence signals from PMT corresponding to different planes were separated into the corresponding data acquisition channels by a custom de-multiplexing circuit ( Tsyboulski et al., 2018 83. Tsyboulski, D. âˆ™ Orlova, N. âˆ™ Griffin, F. ... Remote focusing system for simultaneous dual-plane mesoscopic multiphoton imaging bioRxiv. 2018; Crossref Scopus (0) Google Scholar ) synchronized with the laser excitation. The ScanImage software was modified by Vidrio, LLC to control excitation power, independent axial positioning, and image recording from two focal planes arbitrarily positioned within the accessible imaging volume.
Because the two planes contaminate each other with about 8% of the signal ( Tsyboulski et al., 2018 83. Tsyboulski, D. âˆ™ Orlova, N. âˆ™ Griffin, F. ... Remote focusing system for simultaneous dual-plane mesoscopic multiphoton imaging bioRxiv. 2018; Crossref Scopus (0) Google Scholar ), we removed all â€double-countedâ€ regions of interest (ROIs) detected by Suite2p at similar locations in the two planes and with activity correlation above a conservatively chosen 0.5 threshold. Depending on the recording, 5%â€“10% of the ROIs were removed this way.
We showed various gratings and localized images. To present stimuli, we used PsychToolbox-3 in MATLAB ( Kleiner et al., 2007 38. Kleiner, M. âˆ™ Brainard, D. âˆ™ Pelli, D. ... Whats new in psychtoolbox-3 Perception. 2007; 36 :1-16 Crossref Scopus (1) Google Scholar ). The stimuli were presented for 750 ms (unless otherwise stated), alternating with a gray-screen inter-stimulus interval lasting on average 650 ms. After every 150 stimuli, the screen was left blank (gray screen) for 32 s. The activity during these non-stimulus periods was used to project out spontaneous dimensions from the neuronal population responses (see below).
All gratings stimuli (except the ones in the localized, high-density set) had a spatial frequency of 0.05 cycles / degree. Almost all stimuli were square gratings at a fixed phase, except for the sinusoidal-intensity gratings, which also had a random phase. All stimuli had full contrast, except for the low contrast and low contrast+noisy drifting gratings, which had a contrast of 5%. Drifting gratings had a temporal frequency of 2 Hz. We showed random orientations of these stimuli between 0 Â° and 360 Â° on each trial. For the stimuli with random phase, there is no difference between orientations that are 180 Â° out of phase, therefore we pooled those trials, resulting in a range of orientations between 0 Â° and 180 Â° . The localized stimulus was restricted to 30 Â° of visual space and used a lower frequency grating, so that it contained only one black and one white sub-field. The complex â€minimouseâ€ stimulus also spanned 30 Â° of visual space and was rotated around its center. Outside of these stimuli, the screen was gray.
In an additional set of experiments (â€localizedâ€ in Figure 3 ), we used drifting gratings of 0.04 cycles per degree, a temporal frequency of 2 Hz, and localized to a 50 Â° annulus, to replicate the setup from Rumyantsev et al. (2020) 66. Rumyantsev, O.I. âˆ™ Lecoq, J.A. âˆ™ Hernandez, O. ... Fundamental bounds on the fidelity of sensory cortical coding Nature. 2020; 580 :100-105 Crossref Scopus (98) PubMed Google Scholar . The stimuli were presented for 660 ms followed by âˆ¼ 340 ms of gray screen, with a grating orientation of 4 5 âˆ˜ . The contrast was full, and the monitor luminance was 1-3 lux at the mouse eye, which is similar to Rumyantsev et al. (2020) 66. Rumyantsev, O.I. âˆ™ Lecoq, J.A. âˆ™ Hernandez, O. ... Fundamental bounds on the fidelity of sensory cortical coding Nature. 2020; 580 :100-105 Crossref Scopus (98) PubMed Google Scholar .
In an additional set of experiments (contrast comparison Figure 4 ), we used static Gabor stimuli that match the stimuli from Steinmetz et al. (2019) 76. Steinmetz, N.A. âˆ™ Zatka-Haas, P. âˆ™ Carandini, M. ... Distributed coding of choice, action and engagement across the mouse brain Nature. 2019; 576 :266-273 Crossref Scopus (331) PubMed Google Scholar . These stimuli had a spatial frequency of 0.1 cycles-per-degreee (cpd), with a standard deviation of 9 âˆ˜ for the Gaussian mask and an orientation of 4 5 âˆ˜ . On each trial, two stimuli were shown: one was directly in front of the mouse and the other was approximately to the left, with small deviations performed by the experimenter to better match the retinotopic preference of the imaged neurons.
In a subset of experiments (â€localizedâ€ with dense stimulus set), we used closed-loop stimulus correction to compensate for eye-movements. Each frame was obtained from a Point Grey Flea3 camera using the Python API of the Spinnaker SDK. A custom modification of the Facemap software ( https://github.com/MouseLand/facemap ) was used to detect the pupil in Cartesian coordinates, which were then transformed into approximate polar coordinates using left and right control points specified by the user. Finally, the horizontal rotation of the eye was transformed into screen coordinates and used to shift the stimulus to compensate for the eye movement. We did not apply vertical correction, because most of the eye movements were primarily along the horizontal axis. To ensure that the stimulus appeared similarly to the mouse regardless of the eye rotation, we used a cylindrical projection of the monitor and corrected the stimulus horizontally to take into account the viewing angles of the mouse.
The calcium imaging processing pipeline and the subsequent analyses use numpy, scipy, numba, scikit-image, and scikit-learn ( van der Walt et al., 2011 84. van der Walt, S. âˆ™ Colbert, S.C. âˆ™ Varoquaux, G. The numpy array: a structure for efficient numerical computation Comput. Sci. Eng. 2011; 13 :22-30 Crossref Scopus (7425) Google Scholar , 2014 85. van der Walt, S. âˆ™ SchÃ¶nberger, J.L. âˆ™ Nunez-Iglesias, J. ..., scikit-image contributors scikit-image: image processing in Python PeerJ. 2014; 2 :e453 Crossref Scopus (3207) PubMed Google Scholar ; Jones et al., 2001 35. Jones, E. âˆ™ Oliphant, T. âˆ™ Peterson, P. SciPy: open source scientific tools for Python 2001 https://www.scipy.org/ Google Scholar ; Lam et al., 2015 42. Lam, S.K. âˆ™ Pitrou, A. âˆ™ Seibert, S. Numba: a llvm-based python jit compiler Proceedings of the Second Workshop on the LLVM Compiler Infrastructure in HPC. ACM, 2015 7 Crossref Scopus (760) Google Scholar ; Pedregosa et al., 2011 58. Pedregosa, F. âˆ™ Varoquaux, G. âˆ™ Gramfort, A. ... Scikit-learn: Machine learning in python J. Mach. Learn. Res. 2011; 12 :2825-2830 Google Scholar ). The figures in the paper were made using matplotlib in jupyter ( Hunter, 2007 32. Hunter, J.D. Matplotlib: a 2D graphics environment Comput. Sci. Eng. 2007; 9 :90-95 Crossref Scopus (20585) Google Scholar ; Kluyver et al., 2016 39. Kluyver, T. âˆ™ Ragan-Kelley, B. âˆ™ PÃ©rez, F. ... Jupyter Notebooks-A Publishing Format for Reproducible Computational Workflows ELPUB, 2016 87-90 Google Scholar ).
Calcium imaging data was processed using the Suite2p toolbox ( Pachitariu et al., 2016 54. Pachitariu, M. âˆ™ Stringer, C. âˆ™ Schrder, S. ... Suite2p: beyond 10,000 neurons with standard two-photon microscopy bioRxiv. 2016; Crossref Google Scholar ), available at https://www.github.com/MouseLand/suite2p . Suite2p performs motion correction, ROI detection, cell classification, neuropil correction, and spike deconvolution as described elsewhere ( Stringer et al., 2019b 79. Stringer, C. âˆ™ Pachitariu, M. âˆ™ Steinmetz, N. ... Spontaneous behaviors drive multidimensional, brainwide activity Science. 2019; 364 :eaav7893 Crossref Scopus (644) Google Scholar ). For non-negative deconvolution, we used a timescale of decay of 1.25 s ( Friedrich et al., 2017 24. Friedrich, J. âˆ™ Zhou, P. âˆ™ Paninski, L. Fast online deconvolution of calcium imaging data PLOS Comput. Biol. 2017; 13 :e1005423 Crossref Scopus (249) PubMed Google Scholar ; Pachitariu et al., 2018 55. Pachitariu, M. âˆ™ Stringer, C. âˆ™ Harris, K.D. Robustness of spike deconvolution for neuronal calcium imaging J. Neurosci. 2018; 38 :7976-7985 Crossref Scopus (81) PubMed Google Scholar ). We obtained 18,496 Â± 3,441 (s.d., n = 35) neurons in the standard recordings, and 37,224-50,954 neurons (n = 4) in the dual-plane mesoscope recordings.
In three recordings, we closed the shutter on the 2p laser. In this case the extracted ROIs were randomly placed disks with similar numbers of average pixels as measured for real cells. These traces were neither neuropil-corrected, nor deconvolved.
We defined the stimulus response as the summed activity of the first two bins ( âˆ¼ 650ms) following stimulus onset. We split the trials 75/25 into training and testing sets, with every fourth trial assigned to the test set.
When looking at correlated decoding errors, we split the neurons into two populations. We first divided the XY plane into 8 non-overlapping strips of width 150 Î¼m, and assigned the neurons in the even strips to one group, and the neurons in the odd strips to the other group, regardless of the neuronâ€™s depth. Thus, there did not exist neuron pairs in the two sets that had the same XY position but a different depth. This special division was performed to avoid contamination artifacts between overlapping cells or between consecutive planes.
We fit the training trials with ğ‘› b a s i s = 1 0 cosine and sine basis functions, where Î¸ is the angle of the stimulus shown in radians: ğµ = â› âœ â c o s â¡ ( 0 ) s i n â¡ ( ğœƒ ) c o s â¡ ( ğœƒ ) â‹® s i n â¡ ( ğ‘› b a s i s â‹… ğœƒ ) c o s â¡ ( ğ‘› b a s i s â‹… ğœƒ ) â âŸ â  We performed linear regression from B to the neural responses and used the fitted function ğ‘“ ğ‘› â¡ ( ğœƒ ) as the tuning curve. To compute the signal-to-noise ratio, we defined the signal as the variance of the tuning curve and the noise as the variance of the residual noise after subtracting out the tuning curve value.
Approximately a third of the variance of visual cortical population activity represents behavior-related fluctuations ( Stringer et al., 2019b 79. Stringer, C. âˆ™ Pachitariu, M. âˆ™ Steinmetz, N. ... Spontaneous behaviors drive multidimensional, brainwide activity Science. 2019; 364 :eaav7893 Crossref Scopus (644) Google Scholar ). In Figure S3 D we projected out the ongoing activity dimensions to show that they had no influence on sensory coding. To do this we computed the top 32 principal components of z-scored and binned (2 frames â‰ˆ 650ms) ongoing activity. The spontaneous, ongoing neural activity was recorded during gray screen presentations, and these were presented after every 150 stimulus presentations for 32 s each time. To remove these dimensions from stimulus responses, the stimulus-driven activity was first z-scored (using the mean and variance of each neuron computed from ongoing activity), and then we computed the projection onto the 32 top spontaneous dimensions and subtracted it off from the z-scored stimulus-driven activity ( Figure S3 D, y axis).
For the independent decoder, we built generative models of the neural data by modeling the mean and standard deviation of each neuron on the training set. The mean was obtained as a function of stimulus angle using the tuning curve fits ğ‘“ ğ‘› â¡ ( ğœƒ ) above. The standard deviation ğœ ğ‘› â¡ ( ğœƒ ) was fit similarly, after subtracting the mean predictions on the training set, by squaring the residuals and fitting them in the same set of basis functions. With the mean and standard deviation defined for each neuron and each stimulus, we computed the probability that a novel neural pattern ğ‘… â¡ ( ğ‘› ) was produced by a putative stimulus orientation ğœƒ â€² : ğœƒ â€² â¢ | ğ‘… â¡ ( ğ‘› ) âˆ¼ ğ’© â¢ ( ğ‘… â¡ ( ğ‘› ) | â¢ ğ‘“ ğ‘› â¡ ( ğœƒ â€² ) , ğœ ğ‘› â¡ ( ğœƒ â€² ) ) . These probabilities were evaluated in log-space for a discrete set of ğœƒ â€² (n = 48 orientations) and summed across neurons. To decode orientations more finely, we upsampled the log-probability curves by a factor of 100 using kriging interpolation. The stimulus angle corresponding to the peak of the upsampled curve was used as the decoded orientation.
We also tested an extension of this decoder with multiplicative single-trial gains. On single trials, we determined the best-fitting multiplicative gain ğ‘” ğ‘› and used it to compute the likelihood: ğœƒ â€² â¢ | ğ‘… â¡ ( ğ‘› ) âˆ¼ ğ’© â¢ ( ğ‘… â¡ ( ğ‘› ) | â¢ ğ‘” ğ‘› â¢ ğ‘“ ğ‘› â¡ ( ğœƒ â€² ) , ğœ ğ‘› â¡ ( ğœƒ â€² ) ) .
To decode circular angles using locally linear decoders, we regressed the neural activity onto â€superâ€-neurons (see Figure 2 F). These super-neurons were von Mises tuning curves ( ğ‘› = 4 8 ) with peaks equally spaced along 360 Â° and with ğœ = 0 . 1 : ğ‘£ ğ‘˜ = ğ‘’ ( c o s â¡ ( ğœƒ âˆ’ ğœƒ ğ‘˜ ) âˆ’ 1 ) / ğœ ğœƒ ğ‘˜ = 3 6 0 â¢ ( ğ‘˜ âˆ’ 1 ) / ğ‘› We fit the transformation from neurons to super-neurons on training trials using a ridge regularization constant of 1 (the default for the scikit-learn Python package), and then predicted the super-neuron responses on test trials. We then upsampled the super-neuron responses from 48 to 4,800 to decode stimulus angle more finely (like we did in the independent decoder). For efficient estimation of the linear decoder we used the matrix inversion lemma in the case where the number of trials was less than the number of neurons. For the fine classification of Figure 4 , the difference between the stimulus and the mean stimulus of 45 Â° was predicted directly with linear regression, without the need for intermediate super-neurons.
In Figures S2 Dâ€“S2F we evaluate a conditional probability model, which can account for correlations, just like the linear models shown in the main text. The model is a generalization of the population vector approach and follows in the footsteps of previous work in this direction ( Jazayeri and Movshon, 2006 33. Jazayeri, M. âˆ™ Movshon, J.A. Optimal representation of sensory information by neural populations Nat. Neurosci. 2006; 9 :690-696 Crossref Scopus (1) PubMed Google Scholar ; Graf et al., 2011 28. Graf, A.B. âˆ™ Kohn, A. âˆ™ Jazayeri, M. ... Decoding the activity of neuronal populations in macaque primary visual cortex Nat. Neurosci. 2011; 14 :239-245 Crossref Scopus (182) PubMed Google Scholar ). We fit the model directly by maximum likelihood estimation, unlike previous methods which used indirect fitting procedures. The conditional probability model is defined implicitly by its energy function l o g â¡ ğ‘ â¡ ( ğœƒ âˆ£ â†’ ğ‘Ÿ ) = â†’ ğ‘ â‹… â†’ ğ‘Ÿ â¢ c o s â¡ ğœƒ + â†’ ğ‘ â‹… â†’ ğ‘Ÿ â¢ s i n â¡ ğœƒ âˆ’ l o g â¡ ğ‘ â¡ ( â†’ ğ‘ , â†’ ğ‘ , â†’ ğ‘Ÿ ) where ğ« is the vector of neural activity in response to a stimulus, ğš , ğ› are parameters to be learned from the training data, and Z is the partition function of this energy model, which ensures that probabilities normalize to 1. The advantage of this model is that it is defined probabilistically and has fewer parameters than the linear decoders. However, fitting ğš , ğ› is analytically intractable. We adopt a gradient descent optimization strategy, which requires numerical integration of the log-partition function over the 1-dimensional orientation variable: âˆ‚ l o g â¡ ğ‘ â¡ ( â†’ ğ‘ , â†’ ğ‘ , â†’ ğ‘Ÿ ) âˆ‚ â†’ ğ‘ = âˆ‚ ğ‘ â¡ ( â†’ ğ‘ , â†’ ğ‘ , â†’ ğ‘Ÿ ) ) âˆ‚ â†’ ğ‘ â‹… 1 ğ‘ â¡ ( â†’ ğ‘ , â†’ ğ‘ , â†’ ğ‘Ÿ ) ) ğ‘ â¡ ( â†’ ğ‘ , â†’ ğ‘ , â†’ ğ‘Ÿ ) = âˆ« 2 â¢ ğœ‹ 0 ğ‘’ â†’ ğ‘ â‹… â†’ ğ‘Ÿ â¢ c o s â¡ ğœƒ + â†’ ğ‘ â‹… â†’ ğ‘Ÿ â¢ s i n â¡ ğœƒ ğ‘‘ ğœƒ âˆ‚ ğ‘ â¡ ( â†’ ğ‘ , â†’ ğ‘ , â†’ ğ‘Ÿ ) ) âˆ‚ â†’ ğ‘ = âˆ« 2 â¢ ğœ‹ 0 ğ‘Ÿ â¢ c o s â¡ ğœƒ â¢ ğ‘’ â†’ ğ‘ â‹… â†’ ğ‘Ÿ â¢ c o s â¡ ğœƒ + â†’ ğ‘ â‹… â†’ ğ‘Ÿ â¢ s i n â¡ ğœƒ â¢ ğ‘‘ â¢ ğœƒ and an equivalent derivation for âˆ‚ l o g â¡ ( ğ‘ ) / âˆ‚ ğ‘ . Thus, on each step of gradient descent, numerical integrals must be computed for Z , âˆ‚ ğ‘ / âˆ‚ ğ‘ and âˆ‚ ğ‘ / âˆ‚ ğ‘ , for each sample â†’ ğ‘Ÿ of neural activity on the training set. The gradients for the rest of the l o g â¡ ğ‘ â¡ ( ğœƒ âˆ£ â†’ ğ‘Ÿ ) are straightforward. On test data, the most likely presented stimulus can be easily inferred as the angle of the complex number â†’ ğ‘ â‹… â†’ ğ‘Ÿ + ğ‘– â¢ â†’ ğ‘ â‹… â†’ ğ‘Ÿ .
We used a momentum of 0.95, and ran the optimization for 800 iterations. No further improvements on the validation set could be observed by running the optimization longer. We also tested L2 regularized versions of this model, which brought small improvements and constitute the results shown in Figures S2 E and S2F. The optimization code is included in the repository for this paper.
For the discrimination task, we used a simple linear decoder for the high density stimulus set, because the range of predicted angles is small (4 Â° ) and thus the behavior of the neural data is expected to be linear in that range. For the low density stimulus set, we predicted angles in the range Â± 30 Â° by first predicting a function f of the stimulus Î¸ and the threshold stimulus ğœƒ 0 , which was a difference of von Mises basis functions: ğ‘“ â¡ ( ğœƒ ) = ğ‘’ ( c o s â¡ ( ğœƒ âˆ’ ğœƒ ğ‘˜ + 1 5 âˆ˜ ) âˆ’ 1 ) / ğœ âˆ’ ğ‘’ ( c o s â¡ ( ğœƒ âˆ’ ğœƒ 0 âˆ’ 1 5 âˆ˜ ) âˆ’ 1 ) / ğœ where Ïƒ was the same as it was for the linear decoder. We used the sign of the neural prediction f on test trials as the predicted class label of the decoder.
To quantify discrimination performance, we computed the probability ğ‘ƒ â¡ ( ğœƒ ) as the fraction of correct predictions when Î¸ was in a bin of 1 Â° (10 trials/deg. stimuli) or a bin of 0.1 Â° (1,000 trials/deg. stimuli). This produced the neurometric data points. For the 10 trials/deg. stimuli, we used 32 different threshold stimuli ( ğœƒ 0 ), spaced evenly from 0 Â° to 360 Â° , and averaged the neurometric curves from these 32 different discrimination tasks. To symmetrize the neurometric curves, we used ğ‘ƒ s y m m â¡ ( ğœƒ ) = ğ‘ƒ â¡ ( ğœƒ ) + 1 âˆ’ ğ‘ƒ â¡ ( âˆ’ ğœƒ ) 2 , as if the discrimination task was repeated with left versus right labels interchanged. To fit ğ‘ƒ â¡ ( ğœƒ ) we used centered sigmoids with a single free parameter Î²: ğ‘ƒ â¡ ( ğœƒ ) â‰ˆ 1 1 + e x p â¡ ( âˆ’ ğœƒ / ğ›½ ) . We fit Î² using the â€curve_fitâ€ function in scipy ( Jones et al., 2001 35. Jones, E. âˆ™ Oliphant, T. âˆ™ Peterson, P. SciPy: open source scientific tools for Python 2001 https://www.scipy.org/ Google Scholar ). The fit curves are shown as continuous lines in Figures 4 B, 4F, and S5 . To compute the discrimination threshold at 75% correct, we performed: ğœƒ ğ· â¢ ğ‘‡ = âˆ’ ğ›½ â¢ l o g â¡ ( 1 / 0 . 7 5 âˆ’ 1 ) .
To fit the asymptotic error, we modeled the scaling of the median error with the parametrization ğ›¼ + ğ›½ âˆš ğ‘ , where N is the number of neurons or ğ›¼ + ğ›¾ âˆš ğ‘‡ , where T is the number of trials ( Figures 2 I and 2J). The scaling of 1 / âˆš ğ‘ was chosen because it corresponds to the decay of the standard deviation of an average of independent random variables with the same variance. We fit Î± and Î² (or Î± and Î³) to the last 12 points of each curve in Figures 2 I and 2J using linear regression.
In Figure 4 E we fit the function ğ›¼ + ğ›½ âˆš ğ‘ + ğ›¾ âˆš ğ‘‡ , where N is the number of neurons and T is the number of trials per degree (4 degrees total shown in these experiments). We fit this function using linear regression to the discrimination thresholds obtained with data subsampled at > 1 0 0 trials/deg. and > 1 , 0 0 0 neurons (72 points in total).
We used PyTorch ( Paszke et al., 2017 57. Paszke, A., Gross, S., Chintala, S., Chanan, G., Yang, E., DeVito, Z., Lin, Z., Desmaison, A., Antiga, L., and Lerer, A. (2017). Automatic differentiation in PyTorch. https://openreview.net/pdf?id=BJJsrmfCZ . Google Scholar ) to train a neural network to perform the discrimination task in Figure 2 on the 10 trials/degree recordings. This network consisted of two rectified-linear layers and an output sigmoid. The input layer consisted of 256 units using the top principal components from the data (this reduced over-fitting). The two hidden layers consisted of 100 units each. We trained the network for 50,000 iterations using stochastic gradient descent with momentum of 0.9 and a learning rate of 1e-3. The cost was a binary cross-entropy loss. We averaged over 5 random initializations of the neural network for each recording. Figure S5 L (left) shows the average discrimination performance over all recordings.
We used scikit-learn ( Pedregosa et al., 2011 58. Pedregosa, F. âˆ™ Varoquaux, G. âˆ™ Gramfort, A. ... Scikit-learn: Machine learning in python J. Mach. Learn. Res. 2011; 12 :2825-2830 Google Scholar ) to train a random forest ensemble classifier to perform the discrimination task using the neural activity from the 10 trials/degree recordings. We used 1000 trees and averaged over 5 random initializations of the classifier for each recording. Figure S5 L (right) shows the average discrimination performance over all recordings.
The perceptrons used the learning rule for weight ğ‘¤ ğ‘˜ for neuron k : ğ‘¤ ğ‘˜ = ğ‘¤ ğ‘˜ + ğœ‚ â‹… ğ‘¥ ğ‘˜ â‹… E , E âˆˆ { ğ‘¦ l a b e l , ğ‘¦ l a b e l âˆ’ s i g n ( ğ‘¦ p r e d ) , ğ‘¦ l a b e l âˆ’ ğ‘¦ p r e d } where Î· is the learning rate and ğ‘¦ p r e d = ğ° â‹… ğ± . The three cases for E correspond to the supervised Hebbian, the reinforcement descent and the gradient descent decoders. The gradient descent decoder has been derived from the error cost function: C o s t â¡ ( â†’ ğ‘¤ ) = âˆ‘ ğ‘¡ â¢ ğ‘Ÿ â¢ ğ‘– â¢ ğ‘ â¢ ğ‘™ â¢ ğ‘  ( â†’ ğ‘¤ â‹… â†’ ğ‘¥ âˆ’ ğ‘¦ l a b e l ) 2 .
We computed the signal variance of the static gratings responses using two repeats of the same stimuli ( Stringer et al., 2019a 78. Stringer, C. âˆ™ Pachitariu, M. âˆ™ Steinmetz, N. ... High-dimensional geometry of population responses in visual cortex Nature. 2019; 571 :361-365 Crossref Scopus (232) PubMed Google Scholar ; Pachitariu et al., 2018 55. Pachitariu, M. âˆ™ Stringer, C. âˆ™ Harris, K.D. Robustness of spike deconvolution for neuronal calcium imaging J. Neurosci. 2018; 38 :7976-7985 Crossref Scopus (81) PubMed Google Scholar ). We estimated the signal variance as the correlation coefficient between the two repeats - the â€repeat correlation.â€ Because the stimuli we presented were of random orientation, we did not have two repeats of the exact same stimulus. Therefore we sorted the stimuli by orientation and divided the responses into two halves using this sorting: one half was the odd stimuli and the other half was the even stimuli. The average repeat correlations over all neurons in 6 recordings was 0.11.
We quantified the signal variance of mouse electrophysiological recordings collected by the Allen Institute using Neuropixels probes ( Siegle et al., 2019 71. Siegle, J.H. âˆ™ Jia, X. âˆ™ Durand, S. ... A survey of spiking activity reveals a functional hierarchy of mouse corticothalamic visual areas bioRxiv. 2019; Crossref Scopus (0) Google Scholar ). We used the recordings in which the â€brain_observatory_1.1â€ stimulus set was shown and used all neurons from these recordings classified as primary visual cortical neurons (â€VISpâ€). During these recordings a variety of stimuli were shown including static gratings with 4 possible phases, 6 possible orientations, and 5 different spatial frequencies presented for 400 ms each. We used the responses of neurons to the static gratings at spatial frequency 0.04 cpd (because this was closest to our gratings of 0.05 cpd). The response of each neuron was defined as the sum of spikes in a 400 ms window following the stimulus onset. Since the orientations shown were restricted to the interval 0 Â° to 180 Â° , we used the responses to phase 0 Â° and phase 90 Â° as an effective 180 Â° rotation of the stimulus, thereby spanning the entire 0 Â° to 360 Â° range. This resulted in at least 246 responses per stimulus. The repeat correlation of each neuron was computed in the same way as it was for the two-photon calcium imaging data, using the correlation coefficient between two repeats of the same stimulus sets ( Figures S1 A and S1B).
For the decoding analyses, we decoded which of the 12 orientations were shown. As with all other decoding analyses, we z-scored the responses of each neuron across all trials. We then used scikit-learn ( Pedregosa et al., 2011 58. Pedregosa, F. âˆ™ Varoquaux, G. âˆ™ Gramfort, A. ... Scikit-learn: Machine learning in python J. Mach. Learn. Res. 2011; 12 :2825-2830 Google Scholar ) to train a multi-class logistic regression classifier to classify the 12 different stimuli using 75% of the trials as training trials, leaving 25% of the trials for testing. We used the default settings in scikit-learn other than the learning procedure, which we set to â€™newton-cgâ€™. We repeated this analysis for 5 random subsets of neurons for each population size, as well as for a stimulus set assembled from the phases 45 Â° and 135 Â° (instead of 0 âˆ˜ and 9 0 âˆ˜ ) and averaged all samples ( Figure S1 C).
The gratings shown in the electrophysiological data are discrete unlike in our recordings. Therefore, for the two-photon data we used responses within a range of Â± 2 Â° around the corresponding orientations in the ephys data. This orientation bin size of 4 Â° resulted in a similar median number of trials across recordings in the 2p and the ephys data.
We started by downloading the data from https://figshare.com/articles/dataset/Dataset_from_Steinmetz_et_al_2019/9598406 .
We then converted the recordings into a more convenient trial-based, array format using custom scripts ( https://github.com/MouseLand/steinmetz2019_NMA ). The trials were aligned to stimulus onset, and the spiking data was binned at 10 ms. For the main text analysis ( Figure 5 ), trials were included for the analysis if the left and right contrasts were different from each other and the mice made an active choice (left/right), as opposed to a no-go response. See the Supplemental information for details about the analysis in Figure S6 .
For the linear decoder, we weighted neurons independently according to their projection onto the stimulus difference axis, which was defined as the difference between right and left contrasts. Define ğ« as the vector of firing rates of neuron n across all correct trials in the 100ms time bin, and Î” â¢ ğ¬ as the vector of stimulus differences. Then the weight ğ‘¤ ğ‘› of neuron n in the decoder was defined as ğ‘¤ ğ‘› = â†’ ğ‘Ÿ â‹… Î” â¢ â†’ s ğœ† + â†’ ğ‘Ÿ â‹… â†’ ğ‘Ÿ , with ğœ† = 100 serving as a regularizer. For each recording, we only considered brain areas that had at least 20 neurons, and used this independent decoder to make predictions on test trials. We used leave-one-out cross-validation on correct trials, thus making predictions on each trial based on decoders trained on all other correct trials. For incorrect trials, we used the same single decoder trained on all correct trials.
For all analyses, we combined the decoder predictions on trials from the same brain region across all recordings, leading to 100-300 total incorrect trials per brain region. To compute error bars for the decoder averages, we used 100 repetitions of bootstrapping by picking random subsets of trials without replacement. In the case of correct matched trials, the bootstrap probabilities were matched to the probabilities of each visual condition on incorrect trials. Furthermore, on correct matched trials we only drew as many total samples as available on incorrect trials, in order to make combined incorrect+correct trial sets with our required orthogonality between the choice variable and stimulus variable.
Trials were included for this analysis if the mice made an active choice (left/right), as opposed to a no-go response ( Figure S6 A). This included some trials with no stimulus on either side of the visual field, in which the correct response would have been a no-go, but the animal nonetheless responded with a left/right choice. We did not consider trials without a motor response for any of the analyses.
To start, we separated trials where the animal made a left/right choice into correct trials and incorrect/ambiguous trials ( Figure S6 A). On correct trials, the average firing rate of neurons in visual cortex appeared to be selective to both stimuli and choices ( Figures S6 B and S6C). However, the latter may simply be due to the correlation between stimuli and correct choices. To determine the choice selectivity of these neurons, we examined the incorrect & ambiguous trials, after subtracting out the portion of the neural response accounted for by the left and right stimuli ( Figure S6 D). After subtraction, the â€excess firing rateâ€ was still selective for left- and right- choice trials, but only in a restricted time window of the task from âˆ¼ 100 to âˆ¼ 200 ms.
We obtain the â€excess firing rateâ€ by subtracting out the stimulus component of the neural responses. We performed the following analysis for each neuron N and each stimulus bin T . First, a design matrix A of size ğ‘ ğ‘¡ â¢ ğ‘Ÿ â¢ ğ‘– â¢ ğ‘ â¢ ğ‘™ â¢ ğ‘  by 8 was constructed, where ğ‘ ğ‘¡ â¢ ğ‘Ÿ â¢ ğ‘– â¢ ğ‘ â¢ ğ‘™ â¢ ğ‘  is the number of correct trials. ğ´ â¡ ( ğ‘› , ğ‘˜ ) was 1 if the left contrast on trial n was the k -th contrast from the list [0, 0.25, 0.5, 1], otherwise it was 0. Similarly, ğ´ â¡ ( ğ‘› , ğ‘˜ + 4 ) = 1 if the right contrast on trial n was the k -th contrast from the list, otherwise it was 0. For each neuron and stimulus bin, we fit a vector â†’ ğ‘ ğ‘ , ğ‘‡ of length 8 to minimize | | â¢ â†’ s ğ‘ , ğ‘‡ âˆ’ ğ´ â¢ â†’ ğ‘ ğ‘ , ğ‘‡ â¢ | | 2 , where ğ¬ ğ‘ , ğ‘‡ is the vector of responses of neuron N at time bin T across trials. We refer to ğ‘  ğ‘ , ğ‘‡ âˆ’ ğ´ â¢ â†’ ğ‘ ğ‘ , ğ‘‡ as the excess firing rate, and we calculate it on incorrect and ambiguous trials (not used for fitting â†’ ğ‘ ğ‘ , ğ‘‡ ), by replacing A with the equivalent stimulus design matrix on these trials.
To see how these choice signals relate to those in the rest of the brain, we added one step to the analysis: instead of averaging all selective neurons in a brain area, we use a decoding axis to potentially weigh some neurons with a âˆ’ 1 weight, if their selectivity in the task is for ipsilateral choices. To determine the decoding axis â†’ ğ‘¤ on active trials, we tested the tuning of each neuron to the difference between right and left contrasts. We used the non-parametric Spearmanâ€™s rank-order correlation, and assigned the weight of neuron N , ğ‘¤ ğ‘ = 0 , if the correlation was not significant, and Â± 1 otherwise, with the sign of the weight equal to the sign of the correlation. The decoding axis on passive trials was obtained in a similar way.
The excess firing rates in primary visual cortex remained relatively unchanged (compared to Figure S6 D), since few neurons in this area have ipsilateral selectivity ( Figure S6 E). Higher-order visual areas, frontal cortical areas and some midbrain areas all had some selectivity ( Figures S6 E and S6G). To determine the significance of choice signals identified on incorrect and ambiguous trials, we considered the average firing rate in the first 200 ms following stimulus onset, which was before the animalâ€™s movement on a majority of trials. We projected this firing rate on the decoding axes, and tested for each choice option (right/left) whether the excess firing rate was significantly greater/smaller than 0 using a non-parametric Wilcoxon signed-rank test ( Figures S6 G and S6H). Following common practice, we only applied this test to brain areas with at least 20 tuned neurons for the tested choice option.
These results depart from those reported in Steinmetz et al., primarily because we found choice selectivity in visual cortex and they did not. To account for the discrepancy, we considered whether our analysis is fundamentally different. Like us, the analysis in Steinmetz et al. also starts by subtracting out an estimate of the stimulus and action contribution to firing rates, before testing for residual choice signals. However, there are some differences: 1) their model uses low-rank regularization to determine these contributions, while we subtract the best matching fit on correct trials, separately for each time point, 2) they test their population decoder on all trials, rather than just the incorrect go trials like we do here, and 3) we align the neural data to stimulus onset, while Steinmetz et al. aligns to movement onset. To test if the discrepancy might arise from data alignment, we performed our analysis on movement-aligned data, and used the last 200 ms before movement onset to determine choice selectivity. In this case we found much weaker and barely significant choice signals in visual cortex ( Figures S6 F and S6H), similar to Steinmetz et al.
This analysis shows that while there are some choice-selective signals in visual cortex, they are relatively small, and do not persist throughout the task. The analysis in the main text suggests that these signals are not strong enough to account for the behavioral errors on incorrect trials ( Figure 5 ).
All the experiments in this section were performed using stimuli with a density of 10 trials/deg in primary visual cortex, like the data from Figure 2 . We therefore expected decoding errors in the range of 1-2 Â° , rather than the smaller âˆ¼ 0.35 Â° errors for the high-density stimulus sets in Figure 3 . For these analysis, we picked 12 boundary stimuli uniformly in the range 0-360 Â° , and discriminated stimuli within Â± 30 Â° . The discrimination thresholds for full-field, static, square gratings were 1.06 Â± 0.04 Â° ( Figure S5 A), somewhat lower than the âˆ¼ 2 âˆ˜ estimate for the same number of trials using the high density stimulus set ( Figure 4 C). This discrepancy may be explained by the higher response adaptation for the dense stimulus set.
We wondered if some of the difference between neural and behavioral discrimination could be related to behavioral states, because the mice in our experiments were free to run on an air-floating ball. To quantify running-related differences, we split test trials (but not training trials) in two groups based on locomotion, and found that passive trials had modestly increased discrimination thresholds of 1.27 Â° compared to 1.06 Â° for running trials ( Figure S5 B). Thus, behavioral states cannot account for the large discrepancy between behavioral and neural discrimination thresholds.
We next asked if the discrepancy might be accounted for by stimulus properties. We recorded neural responses to new stimulus sets ( Figures S5 Câ€“S5I) to investigate this possibility. We varied the duration of the static grating stimuli from 750ms to 100ms ( Figure S5 C), and changed it from a square to a sinusoidal grating, varying the phase randomly on every trial ( Figure S5 D). We also varied the size of the static grating stimuli from full field to 30 Â° ( Figure S5 E), and we presented a complex stimulus that was rotated around its center ( Figure S5 F). Finally, we presented drifting gratings (2Hz), drifting gratings with low contrast (5%) and drifting gratings with low contrast and large added noise ( Figures S5 Gâ€“S5I). These manipulations either did not increase discrimination thresholds or did so modestly, up to at most 1.86 Â° for the low-contrast, drifting gratings ( Figure S5 H).
We also considered the possibility that the neural code might change over time, making decoders obtained from the first half of the recording ineffective on the second half. We therefore split train/test trials chronologically rather than the original interspersed split. We found a modest increase in discrimination threshold to 1.17 Â° compared to the original 1.06 Â° ( Figure S5 J). We also did not find a difference in discrimination threshold between layers 2/3 and layer 4 ( Figure S5 K).
Thus, neither the stimulus properties nor the behavioral states can account for the wide discrepancy between behavioral and neural discrimination thresholds. We conclude that mice are not using the available neural information efficiently in laboratory tasks. There may be several reasons for this, which we explore in the discussion.
Statistical tests, error bar types and sample sizes are stated in the figure legends.
No data was excluded from the study.

Section: Acknowledgments

We thank Dan Flickinger for assistance with the two-photon microscope, Salvatore DiLisio for some of the surgeries, and James Fitzgerald, Nicholas Steinmetz, and Ruben Moreno-Bote for useful discussions. This research was funded by the Howard Hughes Medical Institute through the Janelia Research Campus.
M.P. and C.S. designed and carried out the study, preprocessed and curated the data, performed all analyses, and wrote the manuscript with feedback from all authors. D.T. designed and implemented the dual-plane mesoscope. S.L. performed the animal surgeries, and M.M. performed the two-photon recordings. M.P. obtained funding.
The authors declare no competing interests.

Section: Supplemental information (1)

PDF (143.22 KB) Table S1. Neural discrimination thresholds at 75% correct, related to Figure 3 1 Estimated from ğ‘‘ â€² . 2 Estimated from recording duration and stimulus rate. 3 Estimated using Figure 3E.
