Section: Abstract

Mobile health applications (apps) have transformed the possibilities for health promotion and disease self-management; however, their promise is not fully realized owing to their reliance on commercial ecosystems for development and distribution. This review provides an overview of the types of mobile health apps and describes key stakeholders in terms of how apps are used, developed, and regulated. I outline key challenges facing consumers, public health professionals, and policy makers in evaluating the quality of health apps and summarize what is known about the impact of apps on health outcomes and health equity. I suggest that factors within the wider mobile ecosystem largely define the impact of health apps and, most notably, practices around the collection and commercialization of user data. Finally, I suggest that upstream public health strategies, grounded in an understanding of corporate influences on health, are necessary to promote healthy digital environments in which mobile health app innovation can flourish.

Section: Introduction

Articles about mobile health applications (apps) nearly always begin with a series of staggering statistics describing the billions of smartphone users worldwide, the millions of health apps available through commercial app stores and downloaded each year, and the booming market, worth tens of billions of dollars, fueling this space. These statistics reflect the interest in the potential for mobile health apps to positively affect population health outcomes and to reduce health disparities in access to care on the part of consumers, public health, governments, and industry ( 79 , 84 , 111 ).
Mobile health refers to the use of technologies enabled by mobile devices for public health purposes ( 110 ); it first promised accessible health promotion in the form of texting/SMS and phone calls owing to the ease of use, acceptability, and prevalence of mobile phones, including within low- and middle-income countries ( 37 , 70 , 111 ). With technological developments in smartphones that include WiFi, the global positioning system (GPS), Bluetooth pairing, cameras, microphones, accelerometers, sensors, and cloud storage, mobile health now promises ubiquity. A health app can accompany and collect intimate information about its user—heart rate, mood, movements, sleep patterns, food and water intake, and sexual activity—from their waking moments through their deepest sleep ( 68 ). The true promise of mobile health apps thus lies in the possibility of personalizing, tailoring, and adapting behavior change interventions based on real-time user and environmental data to improve health outcomes ( 9 ). Given the sensitivity, variety, and volume of user data collected through health apps, the promise of mobile health is matched by unprecedented threats to privacy ( 27 ) and growing scrutiny of the sharing, aggregation, and commercialization of app user data within the wider mobile ecosystem ( 43 , 51 ).
As such, mobile health app interventions have largely comprised tools for self - monitoring and self-management ( 4 , 22 , 29 ) and are grounded in behavior change theories ( 1 ), which posit that behavior change techniques constitute the active ingredients in mobile health apps ( 29 , 73 , 105 ). Bolstered by the emphasis on personal responsibility for health ( 63 ), interest in mobile health apps is also driven by the possibility of replicating resource-intensive, face-to-face interventions for health promotion and management of chronic conditions, thereby increasing the efficiency of overburdened health systems ( 86 ), extending their reach and capacity ( 9 , 29 , 35 , 56 ), and alleviating barriers to access, such as stigma, logistical challenges, or cost ( 9 , 56 ). This review focuses on the vast majority of health apps that address some aspect of health and wellness, are largely exempt from oversight by health regulators ( 102 ), and are marketed directly to the consumer, meaning that the involvement of health professionals to recommend, prescribe, or monitor the use of such apps is not required ( 25 ) (see the sidebar titled Mobile Medical Apps).
The US Food and Drug Administration (FDA) defined a mobile medical app as a software function deployed on a mobile platform that meets the definition of a medical device ( 102 ). Numerous apps have been designed for use by health professionals, and a small number of them have received regulatory approval as “software as a medical device” (SaMD) because they treat, diagnose, cure, mitigate, or prevent disease ( 90 ). In 2015, the FDA released guidance indicating that the vast majority of health and wellness apps were not considered “medical devices” and were not subject to FDA regulation ( 90 ). However, the FDA intends to exercise enforcement discretion over those apps that may meet the definition of a medical device but are judged as posing a low risk to the public in terms of health and safety, including medical calculators or apps providing health coaching ( 102 ). Given that apps and user data can easily cross national boundaries, medical device regulators have made efforts to harmonize requirements, largely following FDA guidance ( 52 ).
Now, more than a decade after the first smartphone apps targeted at health were published in commercial app stores, the field of mobile health is no longer emerging. The population of mobile health apps is characterized by rapid flux and iteration ( 59 ), and it is important to understand not only what is unique, important, and potentially durable about mobile health apps, but also the wider economic and sociopolitical contexts in which they are developed, distributed, and evaluated. In this review, I draw on diverse data sources, including systematic content analyses of commercially available apps, systematic reviews and meta-analyses of randomized controlled trials of health app interventions, national surveys, meta-syntheses and in-depth qualitative research of user experiences, industry reports of developer economics, and policy analyses of an evolving regulatory environment. I first describe the facets of the mobile health app market—the types of apps that are available, key aspects of user demand and developer supply, and the nature of regulatory oversight—and the key challenges faced in assessing and ensuring app quality within a largely commercial space. I outline the state of the science on the health impact of mobile health apps and implications for health equity that stem from factors within the wider mobile ecosystem and may largely define the true impact of health apps. Building off this considerable body of work, I suggest that public health research, practice, and policy shift focus from downstream efforts to develop, identify, evaluate, recommend, and incentivize the use of specific apps. To create safe and healthy mobile environments, upstream approaches, grounded in an understanding of corporate influences on health and a commitment to health equity, are required to assess, monitor, and regulate the larger mobile ecosystem.

Section: Literature Review, Methodology, Results, Discussion

Ten years after the first health apps launched in Apple's App Store, there are now more than 325,000 health apps available across mobile platforms’ commercial app stores ( 85 ). Hundreds of evaluations have been performed of the availability, content, functionality, and usability of health apps that are publicly available through commercial app stores, leading to the conclusion that there is, in fact, “an app for that.” Researchers have critically appraised top-ranked apps targeted at users across the life span [including infants and their caregivers ( 113 ), children ( 40 ), college students ( 71 ), pregnant people ( 101 ), and older adults ( 83 )]; health promotion [including physical activity ( 16 ), nutrition ( 22 ), sleep ( 23 ), and menstruation and fertility ( 116 )]; disease prevention [including substance use ( 98 ), hypertension ( 4 ), and unintended pregnancy ( 67 )]; and chronic disease self-management [including depression and anxiety ( 108 ), asthma ( 48 ) and cancer ( 2 )]. Across studies, sampled apps had limited functionality and focused on providing information or education, tracking, and self-monitoring functions (e.g., calorie or step counting, calendars, mood assessments), and occasionally provided automatic feedback or reminders ( 4 , 22 , 42 , 83 , 98 , 101 ). However, comprehensive, multifunction apps remained rare ( 42 ), and apps, especially among those that are free, rarely provided interventions such as exercise programs, meal plans, personalized feedback, or connection with trained professionals ( 22 , 83 , 108 ).
Users downloaded commercially available health apps about 3.7 billion times in 2017, though recent surveys suggest that the development of new health apps is outpacing demand ( 84 ). Users cite tracking purposes as the main reason for downloading health apps ( 57 ), which is likely associated with the fact that the majority of commercially available health apps provide this function. Like researchers and clinicians, app users are techno-optimistic, expressing their desired functionalities for apps and, simultaneously, their disappointment in the limited functionality of existing apps. Users expressed this sentiment in app reviews as the feeling of “I love this, but…,” articulating nonspecific “helpfulness” and “ease of use” but also a “wishlist” of additional features or improved functionality ( 75 ). Users have expressed the desire for more accurate, easy-to-use methods for tracking ( 6 , 20 , 57 , 64 , 75 ), greater customization of tracking functions ( 64 , 75 ), and personalization of recommendations in ways that account for an individual's health history and goals ( 6 , 20 , 57 , 64 ). In contrast, users often found that apps were designed for a very particular use case (typically able-bodied people based in the United States) ( 64 ), addressed a narrow range of experience ( 75 ), and required time-consuming, tedious, or complicated data entry ( 6 , 20 , 57 , 64 , 75 ). Users desired greater integration with their existing care system, which might include health professionals, electronic health records, and other apps ( 57 ).
The proliferation of commercially available health apps is driven by a rapidly expanding mobile ecosystem composed of diverse actors and entities beyond those traditionally associated with health or health care ( 44 , 68 ). Targeting the mobile health app market are more than 84,000 health app publishers ( 84 ), infused with $5.4 billion globally from early-stage investments from accelerators, incubators, and venture capital firms ( 84 ). Public health, government, and other not-for-profit health organizations have little presence within commercial app stores ( 2 , 83 ) and represent less than 10% of health app publishers ( 84 ).
Most health app developers are small, privately held companies with little publicly available information ( 44 ) and limited reach and revenue ( 85 ). Around 80% of developers attract fewer than 50,000 downloads per year and have fewer than 10,000 active users, while about half of developers make less than $10,000 per year ( 85 ). The mobile health app market is dominated by a few large, established, and mostly North American companies, which attract the lion's share of downloads to their large app portfolios focused on running, exercise, diabetes, women's health, and weight loss ( 85 ). They also secure the largest proportion of app revenues by selling accompanying devices or sensors, licensing their app, or selling services such as consulting or coaching ( 85 ).
Health apps pose unique regulatory challenges in their direct-to-consumer distribution, their rapid iteration in terms of new product introductions and modifications, cybersecurity vulnerabilities, and their ability to impact health outcomes ( 90 ). Most health regulatory authorities among the Organization for Economic Co-Operation and Development (OECD) countries have not developed specific guidance related to health apps ( 34 ); in 2015, the US Food and Drug Administration (FDA) released guidance indicating that the vast majority of health and wellness apps were not subject to FDA regulation ( 90 ). Thus, prominent clinicians and researchers have characterized health apps as “digital snake oil” ( 5 ) and the field as a “wild west” ( 7 ).
However, the ability of an app to affect health outcomes depends not only on the safety and effectiveness of the app intervention itself, but also on the safety and quality standards of the environment in which it is developed, distributed, promoted, and used. Though medical device regulators have taken a relatively hands-off approach in deciding that the majority of apps are low risk in terms of health and physical safety, regulation in other sectors may pertain to other aspects of the app and the mobile environment (such as advertising, finance, media, and privacy) ( 79 ). Promising regulatory developments around mobile health apps have come from agencies with a mandate to address fairness and competition within the market ( 106 ). For example, the US Federal Trade Commission (FTC) has taken action against several app developers, beginning in 2011, for unsubstantiated claims that apps could treat or improve health conditions, for endorsements by individuals who failed to disclose conflicts of interest, for misrepresentation of scientific evidence, and for lack of transparency around billing practices and technical problems ( 106 ).
Despite interagency collaboration, key gaps remain in the regulatory framework because no single regulator is responsible for oversight ( 79 ) and guidance is largely siloed ( 34 ). Consequently, researchers and policy makers have produced tools to help app developers navigate the various regulations that apply to health apps and the complex legal and technical knowledge required for compliance ( 12 , 31 , 81 ). In light of these regulatory challenges and the focus on app developers as a policy target population, policies and accompanying guidance tend to address the burdens posed by regulation or seek to promote compliance among developers as a means by which to avoid legal liability or damage to commercial reputations; in contrast, consumer protection remains a minor theme throughout policies at all levels ( 79 ).
In the place of comprehensive government oversight, industry self-regulation in the form of codes of conduct (e.g., Digital Advertising Alliance), standardization bodies (e.g., ISO's standard on privacy engineering), commercial app store policies, and a plethora of postmarket evaluative frameworks, including certification programs, determines which apps are available on the market and are designated as “preferred” ( 53 , 60 , 79 ). Owing to the relatively permissive regulatory environment, public health's attention has been focused largely downstream on curating apps postmarket and on developing frameworks to help consumers navigate app markets safely ( 79 ).
In many respects, Apple Inc. and Google Inc. remain the de facto regulators for health app quality, as they have set and enforce the standards that determine whether an app can be distributed through their respective commercial app stores, Apple App Store and Google Play ( 46 ), which accounted for approximately two-thirds of the 218 billion total app downloads in 2020 ( 93 ). Anyone with a subscription to Apple's or Google's developer programs and who can write code for an app can distribute an app, provided that it passes the app store review processes, which are largely automated but also include manual review; it is the developer who designates their app for inclusion in the “medical” or “health and wellness” store categories ( 46 ). Despite having the greatest influence over the health app market in terms of market entry, visibility, and enforcement of safety and quality standards, corporations such as Apple, Google, and the behind-the-scenes data aggregators and digital advertisers have largely escaped policy scrutiny and regulatory oversight ( 79 ).
“Quality” in the context of commercial app stores refers to the performance and stability of the software (i.e., free of software bugs), user interface design, legal compliance around restricted content and intellectual property, prevention of deception, use of malware or spam, and transparency around the collection and use of personal information ( 8 , 41 ). In 2016, Apple updated its guidelines to include an entire section on physical harm, suggesting that medical apps “may be reviewed with greater scrutiny” if they have the potential to provide inaccurate information or “may be rejected” if they promote activities that pose a risk of physical harm (e.g., smoking or excessive alcohol consumption) ( 8 ).
The United Kingdom's National Health Service (NHS) made a notable implementation effort in 2013 to offer consumers a curated library of vetted apps; however, they took this service offline in 2015 when public health researchers found that the majority of apps posed risks to data security by sending unencrypted personal information over the Internet ( 50 ). This pivotal study placed a spotlight on the key challenges and accountabilities facing health systems or providers seeking to take on the role of evaluating, curating, and endorsing health apps for consumers and generated widespread recognition that quality assessment must go beyond information quality. The NHS relaunched a similar initiative in 2017 and in 2020 implemented the Digital Technology Assessment Criteria as the baseline criteria for apps entering into or endorsed by the health system; these criteria include clinical safety, data protection, technical security, interoperability and usability, and accessibility standards ( 74 ).
However, the focus of efforts by researchers, professional associations, and the private sector has been on the development rather than the implementation and evaluation of quality assessment frameworks designed to help clinicians and consumers identify safe, effective, and quality health apps. Consequently, quality assessment frameworks have proliferated and currently reflect a high degree of variety among the criteria proposed and a lack of consensus on what constitutes “quality.” For example, in a systematic review of 87 studies published through 2018, reviewers identified 48 different rating scales for evaluating the usability and quality of health apps ( 11 ). Quality assessment frameworks remain largely focused on content quality and usability, with still less attention given to design, security and privacy, functionality, user-perceived value, and ethical issues ( 76 ). Prominent quality frameworks, including the American Psychiatric Association app evaluation framework and the Mobile App Rating Scale (MARS), have undergone expert evaluation ( 58 ), usability testing ( 100 ), and evaluation for metric quality ( 96 ). However, there has been no empirical nor comparative assessment of the ability of various frameworks to identify and select safe, quality, and secure apps.
Researchers have determined that the quality of commercially available apps, while often highly downloaded and positively rated on usability and engagement, varies widely. The majority of these apps are not evidence based or are discordant with public health guidelines ( 67 , 83 , 98 , 101 , 108 , 113 , 116 ), lack empirical evidence for effectiveness or validation of measurement tools ( 4 , 16 , 23 , 40 , 71 ), are not theoretically grounded ( 16 , 98 ), lack expert involvement ( 4 , 16 , 42 , 113 , 116 ), lack user involvement ( 4 ), and fail to provide assurances around privacy, security, or health risks ( 4 , 16 , 67 , 71 , 83 , 98 , 101 ). Longitudinal assessments suggest that little has changed with respect to the quality of available offerings ( 49 ).
Thus, we currently have a better idea of what apps are not rather than what they are ( 62 ). In their search for markers of quality that might help consumers navigate app markets, researchers have noted that app popularity, store ratings, and usability do not always correlate with quality dimensions such as clinical utility, presence of evidence-based information, incorporation of behavior change techniques, or security and privacy measures ( 22 , 83 , 91 , 101 ). The variable association between store popularity metrics and researchers’ quality measures may suggest an incongruence between what users value and what researchers value. For example, app users do not appear to have much awareness around the source or validity of health information ( 65 ), and in their reviews, they rarely comment on the evidence base or scientific quality of an app ( 75 ). Rather, users’ dominant concerns and reasons for discontinuing app use—the deal breakers—are consumer related and focus on apps crashing or being slow or unresponsive; data loss; hidden costs; excessive data usage; battery drainage; lack of instructions; or the presence of ads rather than being specifically health related ( 20 , 57 , 64 , 75 ).
The mismatch may also be due to the dominant research focus on content quality, which is frequently assessed using surrogate measures (i.e., they indirectly measure the outcome of interest), such as the presence of citations, health professional involvement, or number of health behavior theory constructs as opposed to apps’ actual impact on health outcomes, clinical utility, or the quality of the underlying evidence ( 46 ). Reliance on the mere existence of citations or expert involvement as a marker of quality fails to address risks of bias arising from commercial conflicts of interest or sponsorship, which have yet to be seriously attended to within mobile health ( 46 , 55 ) and can create misleading and confusing signals of quality ( 44 ). For example, app developers sometimes name-drop credible health institutions or appropriate their branding, and their scientific and clinical advisors may occupy multiple roles beyond the creation or vetting of content, including commercial interests related to for-profit clinical services, product lines, intellectual property, or ownership interests ( 44 ).
Underpinning critiques related to the quality of commercially available health apps is the assumption that if apps were evidence based and theoretically grounded and possessed a high degree of acceptability and usability among consumers, then they would have a positive impact on health outcomes. Thus, a major focus of mobile health researchers has been to design and generate an evidence base for effective health apps. However, a persistent critique of mobile health has been that scientific evaluation of effectiveness and safety has not kept pace with the burgeoning commercial health app market ( 9 , 25 ). In a 2014 publication, de la Vega & Miró ( 25 ) characterized mobile health as “a strategic field without a solid scientific soul,” noting a chasm between the scientific literature and commercial app stores. Researchers have noted that often none of the apps evaluated within systematic reviews of the scientific literature were available to the general population through app stores ( 25 , 35 , 98 ), whereas those available in app stores were not associated with any published, scientific evaluation ( 25 ).
The current body of evidence evaluating the specific health impact of mobile health apps, many of which are designed and developed for research or clinical purposes, remains equivocal. There is little clear, high-certainty evidence to suggest that the use of mobile health apps impacts health outcomes, particularly beyond the short term, either positively or negatively. Meta-analyses of randomized controlled trials (RCTs) of mobile health app interventions have found small to moderate, positive effects on some outcomes such as decreased sedentary behavior ( 29 ), anxiety ( 35 ) or postpartum depression ( 114 ) scores, and health-related quality of life ( 69 ) but not on other outcomes such as physical activity promotion ( 29 ) or smoking cessation ( 109 ). However, authors have concluded that the body of evidence is frequently inconclusive and of insufficient certainty to advise health professionals, service providers, or consumers ( 69 , 77 , 109 ), noting high or unclear risk of bias ( 33 , 61 , 69 , 109 ), heterogeneity among interventions and outcomes ( 18 , 21 , 29 , 33 , 54 , 107 ), and small sample sizes ( 21 , 24 , 77 , 107 ).
The current evidence for mobile health apps may best support the conclusion that apps may be better than nothing ( 35 ), but there is little high-certainty evidence that apps improve health outcomes compared with lower-tech alternatives such as text messaging ( 109 ), which has a much stronger evidence base ( 33 , 37 , 109 ). In RCTs, control groups are typically allocated to usual care rather than active comparators, which may include paper-based information, being wait-listed for a health service, or nothing; seldom are apps compared with the gold standard, evidence-based, face-to-face intervention they aim to replace ( 35 ).
Key sources of bias in RCTs of health app interventions are high attrition rates and incomplete outcome data ( 24 , 47 , 69 , 77 ), and among longer-duration studies (typically defined as >12 weeks), observed effects on health outcomes ( 61 , 69 ) and participant engagement ( 18 , 21 ) declined over time. Given the high rates of attrition documented in clinical trials where participants meet specific inclusion criteria, are often incentivized, and are closely followed, understanding the reasons why people stop using an app should be priority research questions ( 36 ).
However, evaluation studies typically do not measure and/or report harms associated with app use ( 35 , 56 ). Critical appraisals of app quality and functionality, however, suggest that numerous safety risks exist, including incorrect, incomplete, or variable information, gaps in features, lack of validation, delayed processing, failure to respond to a health danger, or faulty alarms ( 3 ). The literature examining effectiveness rarely assesses the possibility that harm may also arise from the use of quality, appropriate, or otherwise evidence-based apps. For example, unnecessary health information and lifestyle advice may actually create worry and be a source of stress even if evidence based ( 54 , 77 ).
Determining who uses health apps is essential for understanding their ability to affect population health outcomes. Apps “do not act alone,” and the ability to change how a user thinks about their health status and body, the types and frequency of their health behaviors, and the resulting health and well-being outcomes can occur only in concert with the user and the way they engage with a health app ( 64 , p. 12). For example, in one study of app store reviews, users described developing a therapeutic partnership with an app, alluding to working on mental health “together” ( 75 ). A synthesis of qualitative research on users’ experiences of health apps emphasized “personal factors” as a determinant of health app use: People who sought out apps to support their existing health promotion goals were those who most engaged with them ( 20 ).
Population-based surveys of socioeconomically and geographically diverse adults in the United States ( 19 , 57 ) and Germany ( 31 ) have found that those who downloaded and used apps were significantly more likely to be younger and to have a higher income, a higher level of education ( 19 , 31 , 57 ), and a higher level of health literacy ( 31 ). Those who have downloaded health apps were also significantly more likely to report very good to excellent health ( 19 , 87 ) and reported the intention to engage in health promotion related to diet, physical exercise, and weight loss ( 19 , 31 ).
Across app categories, users value tracking and self-monitoring functions for offering an internal sense of control over various factors, including their weight and appetite ( 64 ), mood triggers and duration ( 75 ), and the ability to manage their life ( 92 ). However, a sense of control suggests an evaluative dimension to self-tracking. While health apps support and validate a user's health-promoting efforts, apps can also trigger feelings of guilt and avoidance behavior, provoke resentment or other negative emotions, and undermine users’ confidence when users struggle to meet health-related goals or targets ( 6 , 64 , 80 ).
Consequently, those who might stand to benefit most from health apps appear to be least likely to use these tools ( 6 , 87 ). Mobile health app interventions may be particularly likely to produce or exacerbate health inequities because they require smartphone, Internet, and/or data access; rely on a level of digital literacy; often contain hidden costs impacting adherence; and are likely to be less effective in populations facing a greater number of structural barriers to individual behavior change ( 104 ). However, the existence of a digital divide may be less a problem of technology access and digital literacy [approximately 85% of US adults now own a smartphone, with similar rates across racial and ethnic groups ( 10 )] than the fact that developments in mobile health such as apps and wearables largely target the “wealthy, worried, and well” demographic ( 28 ). For example, despite the striking disparities in pregnancy-related mortality and morbidity among racialized pregnant people in the United States, peripartum mobile health apps infrequently provided health information about conditions that disproportionately affect racialized people and lacked inclusivity in their imagery ( 101 ). Thus, mobile health apps may risk widening health disparities through lack of inclusivity and the provision of health information and digital interventions that disproportionately address the health needs of already advantaged groups ( 17 , 80 , 101 ).
To mitigate unintended “intervention-generated inequalities,” researchers propose that health app developers implement precautions related to technology access (e.g., offline functionality), adoption (e.g., through social networks, proactive technical support), adherence (e.g., universal design principles), and effectiveness (e.g., upstream interventions, reduced technical complexity) ( 104 , p. 1080). Participatory app design processes, ranging from user-centered design to community-based participatory action research methodologies, can ensure the inclusion of racially, culturally, and linguistically diverse app users, leverage trusted social networks to promote uptake and adherence, and ensure that health apps are relevant and effective within users’ particular social contexts ( 17 , 26 , 104 ).
Given the uptake of health apps among healthy, well-resourced users and the limited evidence for effectiveness, the question arises: What—and who—are mobile health apps really for? The market and nonmarket factors shaping mobile health apps are generated largely within the larger mobile ecosystem, which is a complex network of organizations that includes app users, developers, venture capitalists, commercial partners, scientists and clinicians, and celebrities, but also—and much less visibly—digital advertisers, data brokers, industry associations, law and lobby firms, and regulators ( 44 ). What has emerged is a picture not so much of a user, but rather of a consumer who is attentive to their health and self-improvement, with the means, resources, and time to optimize their health and strive for health-related goals ( 85 ).
Thus, the value of user data collected through health apps is recognized not just for its potential to shape health outcomes. Mobile health apps have attracted billions of dollars in investment ( 84 ) and serve as gateways for user data to enter and flow through a larger mobile ecosystem made up of third-party analytics, social media, data aggregation, and digital advertising companies ( 43 , 45 ). Mobile health apps are just one source of behavioral data that are shared, aggregated, and commercialized in ways that allow companies to document, predict, and influence people's social, political, and consumer behaviors, sometimes with exploitive or discriminatory results ( 30 , 39 , 82 , 115 ).
The tension for public health is that the success of mobile health is theorized in terms of behavior change techniques, which emphasize the importance of tailoring, sharing, social connection, and interactivity for the uptake of health behaviors, all of which depend on the collection of personal and health data ( 27 ). Consequently, researchers have assessed that ∼95% of health apps carry some security or privacy risk, though these risks vary with the app's functionality, and the apps with the greatest risk may also have the greatest clinical utility ( 27 ) (see the sidebar titled Research Methods for App Privacy and Security). Analyses of the health app market at scale confirm that health apps are designed to track and share user data: Of 20,991 Android health apps, 88% had tracking capabilities programmed in their code and 80% of all data collection operations were on behalf of third-party services ( 95 ).
App developers routinely and legally collect user data ( 15 , 43 , 51 , 78 ), both user generated and passively collected via the smartphone, wearables, and sensors, and share these data with third parties to enhance the app's functionality and the user's experience (e.g., enabling a user to post to social media, providing location-based services) and also to monetize the app (e.g., through embedded ad libraries) ( 103 ). Through traffic analysis of user data sent from a health app to the network, researchers have identified and classified third-party recipients of user data, which were largely analysis-related services related to the collection, collation, analysis, and commercialization of user data (e.g., app analytics or advertising) or infrastructure-related services related to back-end functionality and data storage ( 43 , 78 ). Researchers found that while transmission of identifying information rarely occurred, the majority of apps transmitted weak identifiers such as advertising IDs and sometimes strong identifiers such as fixed-device IDs and usernames ( 43 , 51 ); among apps that pertained to medications and were targeted at consumers and clinicians, there were a few instances of transmission of the user's email address, the list of medications taken, the user's name, medical conditions, and date of birth ( 43 ). Even if data sources are not clearly sensitive, personal, identifying, or health-related, once aggregated, they may be used to infer health status, to make health-related decisions, or to uniquely identify a user, even if not by name ( 43 , 51 ). Consequently, a much broader definition of health data and what constitutes protected health information may be warranted ( 68 ).
Interest in app privacy is growing among the scientific community; however, much like quality appraisals, the data sources, focus, methods, and criteria to evaluate privacy practices are diverse and not always easily reproducible ( 13 , 53 ). Studies have most commonly conducted content analyses of mobile health apps’ privacy policies, which focus on the transparency and openness of apps; although this approach is critical for informed consent, it is insufficient for verifying security and privacy compliance ( 13 , 53 ). Significantly fewer studies have conducted analyses of actual data collection and sharing ( 13 , 95 ), security audits, vulnerability scanning, or app- or server-side security analyses ( 53 ). How app users’ data are treated once in the hands of third parties, whether and how they are shared, and the health impacts of data commercialization practices remain very much a black box ( 30 , 43 , 82 ).
Once data are transmitted to third parties, third-party data aggregators and digital advertisers may collate data from multiple sources, creating highly detailed pictures of users and user groups; users have no way to know whether the apps or websites they use share their data with the same third parties or how their data are aggregated ( 103 ). Within the Android health app market, researchers determined that 50 third-party services were responsible for about 70% of all user data collection operations, and, reflecting Google's control over the Android platform, Google-owned services (e.g., Google Analytics, Google Ads) were most recurrent ( 95 ). Data sharing networks appear to be dominated by large companies, including major tech and social media companies, apparel manufacturers, and private equity firms, which may enable them to control the flow of data and to aggregate user information from diverse sources ( 43 , 45 , 51 , 95 ).
Information about data security and privacy is communicated to users via privacy policies, which might be more aptly named sharing policies, given that they typically outline the ways that data are collected and shared rather than protected ( 15 ). Both Apple and Google require developers to obtain permission for user data collection and to outline data sharing practices in privacy policies ( 8 , 41 ). In 2017, Google began notifying developers if they did not provide a valid privacy policy; however, enforcement within app stores appears limited, given that many health apps still do not have accessible privacy policies and those that do tend to be long and written at a postsecondary reading level and fail to address privacy practices comprehensively or transparently ( 12 , 15 , 88 , 89 , 94 ). When researchers have analyzed actual data transmission, apps with and without privacy policies did not significantly differ in terms of likelihood to share user information ( 15 ), and nearly a quarter of all Android medical, health, and fitness apps collected and transmitted user data in ways that violated the terms set out in their privacy policy ( 95 ).
In 2018, the European Union (EU) implemented the General Data Protection Regulation (GDPR), which governs how the personal data of EU persons can be collected and shared ( 68 ), and it has had a notable impact on transparency and consent practices ( 12 , 43 ). However, this landmark privacy regulation and others in jurisdictions around the world still rely heavily on the notion of an informed consumer and the “notice-and-consent” model, which assumes that individual app users can know how and why their data are collected and shared and have the autonomy and means to control how their personal data are processed ( 68 ). In maintaining a focus on the individual data subject, the GDPR and other digital privacy regulations cannot address the collective harms that arise from the aggregation of deidentified user data, which are used to algorithmically cluster individuals into groups on the basis of their behavior, preferences, and other nonidentifying characteristics ( 68 ). Scholars have thus advocated for more upstream measures to assess the potential harms of processing big data and collective, rather than individual, forms of control and oversight ( 68 ).
While mobile health is no longer emerging, its promise may not be fully realized. Mobile health apps exist largely in a commercial space and must operate and compete according to market rather than public health norms ( 44 ). With a tendency toward advancing individualized and largely privatized app solutions for health promotion, and potentially exacerbating existing health inequities, the role of public health within mobile health is called into question ( 72 , 86 , 104 ).
Faced with the volume of available health apps and issues with the quality of commercially available apps outlined in this review, a key focus of public health research and practice has been on the development of guidelines for clinicians and consumers around how to choose a safe and high-quality health app. Given the number and variety of available frameworks, researchers have called for a consensus approach ( 99 ). To inform consensus, a public health priority should be to evaluate the ability of existing frameworks to select for culturally relevant, safe, high-quality, and effective apps. For example, the security assessment of apps endorsed in the initial NHS health apps library ( 50 ) demonstrated the key role that public health researchers can play in safeguarding consumers and holding institutions accountable.
Reimagining an effective and equitable mobile public health will require an upstream research, practice, and policy focus. Mobile health researchers can contribute to understanding the broader economic, social, cultural, and political contexts in which health apps are developed, distributed, used, and commercialized, for example, prying open the black boxes around the commercialization of app user data ( 30 , 82 ) and documenting the composition, activities, and health impacts of the mobile ecosystem. Because health apps are powerful tools for self-help and the democratizing of health information ( 55 ), serve as nonprofessional communities of support ( 75 ), support caregiver relationships ( 33 , 42 ), and are used for community organizing and citizen science ( 63 ), many will be developed, downloaded, and used without the involvement of health professionals. Thus, public health advocates need to focus their efforts on upstream actions to ensure that consumers can navigate mobile health app markets and digital environments safely and in ways that promote population health. Efforts should concentrate on ensuring safety and quality standards for market entry, promotion, security and privacy, transparent and fair business practices, and secondary uses of user data, with the goal of creating healthy digital environments in which health app innovation and use can flourish ( 81 ).
Upstream approaches should be informed by awareness of corporate influences on health ( 38 , 112 ), including the growing interest in and political action related to the activities and impact of the tech industry on public health ( 39 ). A handful of corporations not only control the platforms on which apps operate, but also monopolize the user's experience, control their access to apps and the data they generate, and dictate how developers can operate within the market ( 106 ). The most compelling reason to directly address the activities of Big Tech and the constellation of developers, data brokers, and digital advertisers that comprise the mobile ecosystem may be that privacy is emerging as a powerful commercial determinant of health. The commercial value of aggregated data lies in the ability to generate insights into users and user behavior, which are used for highly tailored advertising and also for the development of proprietary algorithms that are commercialized and used to make decisions about key social determinants of health. These algorithms affect such determinants as insurance eligibility and premiums, employability, health care services, financial services, and suitability for housing ( 30 , 82 ).
Upstream actions to promote digitally healthy environments may begin with assessment and education. For example, through public-facing education, information, and mobilization campaigns, public health professionals can raise awareness about the activities of Big Tech corporations and their health effects ( 38 ). While the ability of consumers to select safe, private, and effective apps is limited, public health can disseminate technical tools and practical strategies that support data transparency, enable consumer control over data sharing, and make it more difficult for trackers to track ( 97 , 103 ).
Policy action should promote accountability on the part of entities with the greatest influence over the health app market, including app developers, commercial app stores, and key commercial players within the mobile ecosystem ( 79 ). Thus far, policy efforts have been focused on the behaviors of stakeholders with the least ability to effect change ( 79 ). For example, guidance produced by data protection authorities in the OECD countries covers rules around user consent, rights to access one's data, and data portability, but it largely fails to address privacy impact assessment, third-party access and use, use of data for marketing purposes, or protection of vulnerable users such as children ( 34 ). The FDA recently introduced the Pre-Cert Pilot Program, which, instead of trying to evaluate the thousands of rapidly iterating mobile health apps, will review companies: Those who demonstrate “an existing track record” on quality will be exempted from review or permitted streamlined review ( 90 ). While the focus on companies rather than individual products may be an effective regulatory strategy, this development still appears to favor commercial interests in that its prime objective is to reduce regulatory burden ( 79 ) or to emphasize transparency over accountability ( 68 ). For example, the streamlined review process decreases the incentive for companies to evaluate the clinical utility of their products, meaning that companies and their apps may garner regulatory approval without any evidence of effectiveness ( 60 ). And some evidence suggests that major corporations have played a role in shaping regulation in their own interests. Journalists, through freedom of information requests, documented that representatives from Apple have been secretly meeting with International Medical Device Regulators Forum and FDA officials for years but have ensured that these meetings are omitted from public records ( 66 ).
To further equity-focused, upstream policy developments that can correct the power imbalances among tech corporations, regulators, public health, and consumers, public health advocates should consider adopting successful strategies implemented in other industries to counter the health-related harms of corporate activities. Using litigation, legislative action, industry denormalization, investor campaigns, and social movements, public health advocates have addressed the negative population health impacts of tobacco, alcohol, infant formula, pharmaceutical, and other corporations ( 39 ). Owing to the global influence of multinational tech corporations and the ease with which health apps and user data cross national borders, global health policy tools are also required. Two examples include the Framework Convention on Tobacco Control, which bans tobacco advertising and promotion in all media and could be leveraged to prohibit prosmoking apps within app stores ( 14 ), and the International Code on Marketing of Breast-Milk Substitutes, which could address advertising for infant formula within breastfeeding apps ( 113 ).

Section: Conclusion

Mobile health apps have taken their place on the smartphones of billions of consumers, recording highly detailed data about consumers’ digital and real worlds and how they move through them, offering the possibility of greater self-knowledge, self-help, connection, and community. However, a persistent individualistic focus on health promotion, the dominance of large corporations, and business models fueled by the collection and commercialization of user data threatens the promise of health promotion and greater health equity. Thus, public health needs to extend its research, practice, and policy foci beyond the quality and safety of individual health app interventions to the broader mobile health ecosystem, to corporate influences on health, and to the contexts in which consumers engage with health apps.

Section: Acknowledgements

I thank Chantal Campbell, Lindsay Jibb, Lisa Parker, and Andrea Robinson for their valuable comments. Support for this research came from the Government of Canada's New Frontiers in Research Fund (NFRFE-2019-00806) and a Bertha Rosenstadt Faculty Small Research Grant from the Lawrence S. Bloomberg Faculty of Nursing at the University of Toronto.
