Section: Abstract

Chronic stress is both theoretically and methodologically challenging to operationalize through biomarkers. Yet minimally invasive, field-friendly biomarkers of chronic stress are valuable in research linking biology and culture, seeking to understand differential patterns of human development across ecological contexts, and exploring the evolution of human sociality. For human biologists, a central question in measurement and interpretation of biomarkers is how stress-responsive physiological systems are regulated across diverse human ecologies. This article aims to describe a conditional toolkit for human biologists interested in the study of chronic stress, highlighting a mix of longstanding and novel biomarkers, with special focus on hair/fingernail cortisol, latent herpesvirus antibodies, allostatic load indices, and serial/ambulatory data collection approaches. Future trends in chronic stress biomarker research, including epigenetic approaches, are briefly considered. This overview considers: (1) challenges in separating a distinctly psychosocial dimension of chronic stress from adversity more broadly; (2) essential characteristics of human ecology that shape interpretation; (3) retrospective vs. longitudinal sampling; (4) the role of age, developmental effects, and local biologies; (5) different timescales of chronicity; and (6) the role of culture.

Section: Introduction

In human biology and allied fields, identifying associations between stressors, especially psychosocial stressors, and biomarkers of the associated physiological stress response has proven a powerful way to link biology and culture, understand differential patterns of human development across ecological contexts, and explore the evolution of human sociality (Brown, 1981 ; Dressler, 2012 ; Flinn et al., 2011 ; James & Brown, 1997 ; McDade, 2012 ; Worthman & Costello, 2009 ). Often these purposes are best served by a focus on measuring how stress responses unfold over extended periods of time; that is, chronic stress. Hence, minimally invasive biomarkers indexing chronic stress generally, and when practicable chronic psychosocial stress specifically, are of value to human biologists to the extent that they are applicable in a wide range of field conditions.
While terminology varies somewhat in the literature, we use as our starting point the convention that stressors are environmental challenges (including social challenges) that carry the potential to threaten homeostasis, stress is the resulting pressure against homeostasis, and the stress response is a suite of physiological and behavioral responses that have evolved to restore or maintain homeostasis, but in some cases may fail to achieve this end (e.g., James & Brown, 1997 ; McEwen & Wingfield, 2003 ). When considering the psychosocial dimension of stress, cognitive appraisal of experience creates a bridge from stressor to stress response. This bridging is well illustrated by the capacity for a strong stress response to be elicited by the anticipation of challenges, and the subjective perception of unpredictability or loss of control (Sapolsky, 2021 ).
Moreover, we understand human ecology to comprise a comprehensive, integrated set of interactions among humans and their environments, including social interactions, interactions with the built environment, and with the natural world. Human biology is invariably and profoundly shaped by the interplay of individuals with local conditions and broader political-economic forces. The concept of “local biologies” has been employed in medical and biocultural anthropology to describe the process through which structural inequalities and other macrosocial forces are variably embodied within specific, local settings, often producing fundamental differences in patterns of biological regulation (Brewis et al., 2020 ; Leatherman & Goodman, 2020 ; Leatherman & Hoke, 2016 ; Lock & Kaufert, 2001 ; Worthman & Kohrt, 2005 ). For instance, distress related to water insecurity is dependent on interactions among institutions for distributing and sharing water, social status, gendered division of labor, and other local sociocultural/ecological considerations (Brewis et al., 2020 ), and the response of arousal regulation systems to the vagaries of daily life is heavily dependent on early life experiences (Worthman & Kohrt, 2005 ).
The development and interpretation of biomarkers of chronic stress have been hampered by several interrelated theoretical and practical challenges, however. First, physiological responses to diverse stressors share common features. Primary mediators of the stress response, such as the autonomic nervous system and the hypothalamic-pituitary-adrenal (HPA) axis, are evolutionarily ancient, and have broad roles in regulating arousal, sociality, and energetics (Porges, 2001 ; Sapolsky, 2021 ). Chronic activation of the stress response is particularly likely to carry adverse consequences for health, but chronic stress responses with a limited capacity to mitigate the underlying stressors are a relatively recent phenomenon closely tied to the evolution of primate social complexity and arguably serve as an example of mismatch (McEwen & Wingfield, 2003 ; Sapolsky, 2021 ). Reflecting the broad, multisystem regulatory role and complex evolutionary history of the HPA axis, glucocorticoid levels may reflect psychosocial distress, positive emotions, diurnal rhythms, nutrient intake, physical activity and, generally, the management of life history trade-offs across the lifespan (McEwen & Wingfield, 2003 ; Pollard, 1995 ). When measuring biomarkers, the theoretical impediment to isolating a single dimension of stress by simply controlling for all the others is illustrated by two observations: (1) psychosocial and “physical” stress often flow from the same font of systematic disempowerment, and thus are not truly independent, and (2) physical deprivation and ill health are themselves psychosocially stressful. See, for instance, the excellent discussion regarding psychosocial dimensions of food insecurity by Weaver and Hadley ( 2009 ). We will argue throughout this paper that it is most appropriate to view these biomarkers as reflective of chronic adversity in socio-ecological context, including but not limited to psychosocial stress.
Second, local biologies may develop in specific biocultural and political-economic contexts (Lock & Kaufert, 2001 ; Worthman & Kohrt, 2005 ), resulting in sufficiently profound divergences in biological regulation as to challenge the uniform interpretation of biomarkers. Consider, for instance, elevated Epstein-Barr virus (EBV) antibody titers as a marker of chronic stress, via EBV reactivation following suppression of cell-mediated immunity (McDade, Stallings, Angold, et al., 2000 ). While potentially powerful, this presumes consistency in the “nonstressed” baseline operation of a complex system. Hence, when Worthman and Panter-Brick ( 2008 ) found evidence of lower EBV titers in their apparently most stressed subset of children in Nepal, they raised the possibility that modified functioning of the humoral immune response due to nutritional and other stresses intersecting with the distinct political and cultural ecologies of four groups of Nepalese children fundamentally alters the interpretation of the biomarker, compared to Western settings where it had been applied. Among the local factors critical to interpretation were the fluid nature of urban homelessness, and certain special risks associated with rural poverty in this sociocultural context.
Finally, while it is tempting and simplifying to freeze research participants in time, as Worthman and Costello ( 2009 ) note, “by shaping both objective and subjective conditions of living, culture informs biology through development, across the life course, and even across generations.” (Internal citations omitted.) Hence, neither the conceptualization nor the measurement of stress can be divorced from human development.
Here, we build a case for a conditional toolkit, rather than propose any single solution to these longstanding challenges. A conditional toolkit requires a measurement strategy that is maximally sensitive to person-in-context; that is, an ecological approach. It also requires that for any given study, stress is rigorously theorized rather than loosely presupposed, and the linkage between research questions and the strengths and limitations of available methods is closely examined on a study-by-study basis.
Exploring all possible methods and their contingencies is far beyond the scope of any single article, although excellent resources are available (e.g., Brewis et al., 2021 ; Ice & James, 2007 ). Some promising new methods are included here only by brief reference, such as the conserved transcriptional response to adversity (Cole, 2019 ; Snodgrass et al., 2018 ), telomere length (Rej et al., 2021 ; Rej et al., 2020 ), and epigenetic aging (Gettler et al., 2020 ; Palma-Gudiel et al., 2020 ). Our focus will be on a subset of methods that are (1) currently accessible to the broadest possible range of human biologists working in a variety of field contexts; (2) minimally invasive; and (3) sufficiently well-established to provide for a discussion of strengths, weaknesses, and ecological contingencies when working across diverse human populations. For the purposes of this article, recognizing that there is no one definition of “minimally invasive,” we focus principally on the collection of saliva, hair, fingernail, and capillary blood samples (through finger prick), although where appropriate we also briefly reference other less-invasive methods such as urine collection and blood pressure measurement.

Section: Literature Review, Methodology, Results, Discussion

Anticipated or realized insults to homeostasis lead to activation of the HPA axis, initiating a stress response. This triggers production of cortisol, the main glucocorticoid produced by humans. Cortisol increases blood pressure, allowing greater blood flow to muscles in case there is a need for physical exertion, and directs glucose to mobilize the energy needed to sustain a response to the situation at hand. Further, cortisol inhibits the function of nonessential processes, allowing the body to focus energy on responding to an acute stressor. Additionally, cortisol plays several other important roles in the body, including maintenance of metabolism, regulation of the sleep–wake cycle, reduction of inflammation, and regulation of immune function. Long-term or excess activation of the HPA axis, however, can have negative consequences for both the brain and the rest of the body, including (but not limited to) high blood pressure, suppression of immune function, metabolic disorders, depression, and deficiencies in memory and cognition (Bellavance & Rivest, 2014 ; Chrousos, 2009 ; Moylan et al., 2013 ; Newcomer et al., 1999 ).
The effects of cortisol also reflect its complex interactions with other hormones. For instance, dehydroepiandrosterone and its sulfate (DHEA/S) is a known cortisol antagonist, suppressing some of cortisol's more damaging effects, particularly in the brain (Goodyer et al., 2001 ). High cortisol/DHEA ratios are indicative of increased risk to mental or physical health due to stress and have been correlated with major depression in children 8–16 years old (Goodyer et al., 1998 ) as well as increased risk of metabolic syndrome among adult males (Phillips et al., 2010 ). Yet low cortisol/DHEA ratios also carry risks (see Kamin & Kertes, 2017 for a review). Thus, it is likely that a delicate balance of these hormones over time is essential to well-being.
Additionally, while cortisol is generally understood as a chronic stress marker in its persistently elevated state, hypocortisolism also has been identified as a correlate of severe stress in some circumstances. Generally viewed as a form of HPA dysfunction, the etiology and correlates of hypocortisolism are complex, incompletely understood, and beyond the scope of this article. However, caution is warranted in interpreting cortisol levels when working with populations at elevated risk for hypocortisolism, such as among those with post-traumatic stress disorder (Heim et al., 2000 ).
Cortisol can be detected in numerous matrices, including blood (serum/plasma or capillary whole blood), urine, saliva, hair, and fingernails. Blood, saliva, and urine samples provide insight into stress responses on a short (acute) timeframe, with elevations in cortisol evident within minutes to hours following exposure to a stressor (Dickerson & Kemeny, 2004 ; Flinn, 1999 ; Nicolson, 2008 ; van Eck et al., 1996 ). Hence, repeat sampling is typically required to make inferences regarding chronic stress. By contrast, hair provides a retrospective account of stress ranging from 1–6 months, depending on sample length (Gao et al., 2010 ; Kirschbaum et al., 2009 ; Russell et al., 2012 ). Fingernails generally capture stress experienced 5–6 months prior (Fischer et al., 2020 ).
By far the most common matrix in human biology field research has been saliva. Rather than review salivary cortisol methods in detail here, we point the reader toward an extensive literature (e.g., Brewis et al., 2021 ; Decker, 2000 ; Ellison, 1988 ; Flinn, 2006 ; Flinn & England, 1997 ; Gettler et al., 2011 ; Nepomnaschy et al., 2012 ; Pike & Wllliams, 2006 ; Pollard, 1995 ). Dried blood spots (DBS; McDade et al., 2007 ; Worthman & Stallings, 1997 ) are another well-established, field-friendly alternative for measuring acute cortisol responses, easier to store and ship than saliva and far less invasive than serum or plasma. When using DBS or saliva samples, researchers must at minimum control for time of day as well as day of the week, and repeated collection is essential (Hruschka et al., 2005 ; Kudielka & Wust, 2010 ).
Limitations on interpreting serially collected DBS or salivary cortisol as markers of chronic stress include the potential for the collection methods to trigger a stress response (Lorenz, 2021 ), and a variety of well-documented confounds such as recent food intake, physical activity, and smoking (Pollard, 1995 ). Regular sample collection to address chronic stress requires habituation to the method, can lead to high overall participant and investigator burden, and requires a clear understanding of the context of each measurement to evaluate individual patterning and environmental influences. These challenges are not insurmountable, however. Flinn and colleagues' extensive body of research over the past 30+ years has demonstrated the utility of regular saliva sampling in studying long-term effects of stress on child development (Flinn, 1999 , 2006 ; Flinn & England, 1997 ; Flinn & England, 2003 ; Flinn & Ward, 2005 ). A key advantage of this approach is that it provides the granularity to link chronic stress to specific day-to-day variations in experience (Flinn, 1999 ).
Hair and fingernails provide an attractive alternative because collection may be experienced by subjects as less physically invasive than saliva or DBS, and a single sample provides retrospective insight into cortisol production (Fischer et al., 2020 ; Russell et al., 2012 ; Van Uum et al., 2008 ). Hair and fingernails also do not require specialized training for collection and can be stored indefinitely at room temperature. Moreover, serially collected hair/fingernail samples may yield novel insights into associations between chronic stress and health across development. For instance, by following changes in cortisol output throughout pregnancy, repeated maternal hair collection during each trimester and postpartum may help reveal mechanisms linking maternal chronic stress and perinatal/infant health outcomes (Horan et al., 2022 ).
An important caveat is that social and cultural concerns around hair collection may reduce advantages relative to saliva or DBS in terms of invasiveness. Such considerations include social expectations or experiences around hair tied to ethnicity, gender and/or religion, hair styling/cutting, and what hair signals about the wearer (e.g., Alexander, 2003 ; Mageo, 1994 ; Pergament, 1999 ). In addition, hair is considered powerful in some cultural contexts and, should it fall into the wrong hands, a variety of ailments are possible. Clear explanations of the proposed research and methodology are essential to successful use of this approach (Coetzee et al., 2012 ). While the literature on fingernail collection is less developed, the sociocultural acceptability of providing fingernails similarly should be considered in collaboration with local experts.
Although hair hormone analysis has a long history, Davenport et al. ( 2006 ) were among the first to validate its use in rhesus macaques for studies of cortisol and their methodology has been adapted for use in humans. Hair hormone analysis allows for a calendrical examination of hormone production from a single hair sample, at least for 1 to 6-months prior to the time of collection (Gao et al., 2010 ; Kirschbaum et al., 2009 ; Russell et al., 2012 ), as growth rates are a relatively predictable 1 cm per month (Wennig, 2000 ), albeit with some individual, population, and possibly sex variation, and differences depending on collection site (Greff et al., 2019 ; Loussouarn, 2001 ). Numerous studies have demonstrated the utility of hair cortisol concentrations (HCC) in investigations of chronic psychosocial stress and mental health (e.g., Dettenborn et al., 2012 ; Faresjö et al., 2014 ; Karlén et al., 2011 ; Luo et al., 2012 ; Stalder et al., 2010 ; Steudte et al., 2011 ).
Similarly, Warnock et al. ( 2010 ) first demonstrated the utility of fingernails for insights into cumulative cortisol production over time (see also Fischer et al., 2020 ; Izawa et al., 2015 ). Among Iranian students, increased nail cortisol was found to correlate with experiences of greater stress (Nejad et al., 2016 ) and among Chinese medical students, perceived stress predicted nail cortisol (Wu et al., 2018 ). Fingernails grow more slowly than hair, at a rate of approximately 0.1 mm per day or 3 mm per month (de Berker et al., 2007 ). As a result, 1 mm of distal nail likely represents a 10-day period approximately 3–5 months prior to collection (Fischer et al., 2020 ), requiring that any measures of hypothesized correlates of the stress response are collected well in advance of fingernail samples or retrospectively. As this method is relatively novel, the full range and impact of potential confounds (e.g., UV exposure, age, sex, hand washing practices, occupation, nail varnish, and smoking) remain poorly characterized, although this remains an area of vigorous investigation (Fischer et al., 2020 ; Ortiz et al., 2022 ).
There is not yet a gold standard for hair cortisol extraction and analysis, although the following methodology using ELISAs and derived from Davenport et al. ( 2006 ) is fairly well established (see also Fourie & Bernstein, 2011 ; Helfrecht et al., 2018 ). In short, following hair collection from the posterior vertex of the participant's head, the area with the least intra-sample variation (Sauvé et al., 2007 ), the procedure requires processing the hair before assay. Any foreign matter should be removed from the sample to avoid external effects, through a wash in isopropanol. For example, sweat (Noppe et al., 2014 ; Russell et al., 2014 ) and relative humidity (Boesch et al., 2015 ) may increase measured cortisol concentrations, as can topical medications. Isopropanol is a preferred wash medium because it efficiently removes any remaining debris but does not extract cortisol from the interior of the hair shaft (Davenport et al., 2006 ). After hair is dried, it should be minced or ground for extraction; more hormone can be recovered from ground hair than minced (Davenport et al., 2006 ). To extract the hormone, a predetermined quantity of powdered hair (usually 10–30 mg) is weighed into a plastic tube and extracted in methanol. Following extraction and evaporation, the dry extracts are reconstituted in assay buffer, and resultant samples are assayed using commercially available ELISA kits. Formulas accounting for the quantity of buffer used to reconstitute the sample, the proportion of the original extraction dried down, and the initial weight of powdered hair are then used to calculate HCC expressed as pg/mg (Helfrecht et al., 2018 ; Horan et al., 2022 ).
A recent review by Fischer et al. ( 2020 ) provides an overview of the procedure for extracting hormone from fingernails. It is comparable to that for hair, but consensus is still being established due to its relative novelty. After first cutting their nails prior to the start of the study, participants provide either a predefined length or all the newly grown distal portion of the fingernail from every finger of both hands after a defined amount of time has passed. Due to variation in fingernail growth rates across the fingers and consequent variation in nail cortisol concentrations, clippings from all fingers are generally included in the collection. Prior to analysis, nails are washed to remove potential contaminants. Wash solution, methods, length, and frequency vary across studies, but isopropanol is most often used. After the wash, nails are allowed to dry and then homogenized. Although they can be cut, use of a ball mill to pulverize likely allows for more complete extraction of cortisol.
To extract the hormone, samples are incubated in a solvent, usually methanol, under a variety of conditions of movement (e.g., ultrasonic bath, platform shaker), temperature (room temp, 45–60°C), and time (1–24 h). After centrifuging, the supernatant is transferred to another vial and dried down, either through evaporation or under nitrogen. Samples are usually then reconstituted in assay buffer if using a commercially available ELISA, although liquid chromatography/mass spectrometry measurement approaches also have been employed. Fingernail cortisol concentrations may be expressed as nmol/g (Warnock et al., 2010 ).
Both with respect to hair and fingernail cortisol analyses, care should be taken to confirm that the assay kit, typically developed for saliva, has been validated with respect to its reliability in measuring cortisol extracted and reconstituted from these other matrices.
Cortisol plays numerous roles in the body other than responding to psychosocial stressors and, as a result, cortisol may be chronically elevated in response to other challenges tied to maintenance of homeostasis. Thus, broad consideration of socio-ecological effects is important to our understanding of what cortisol concentrations mean. Acknowledging the voluminous literature in this area, a few illustrative examples will be used to highlight key features of human ecology that should be considered in interpreting cortisol responses measured over timescales relevant to chronic stress.
Undernutrition is associated with persistently elevated cortisol, which in turn contributes to the etiology of stunting, to metabolic programming that increases long-term disease risk, and ultimately to impairments in quality of life (Martins et al., 2011 ). This cascade of developmental events, in turn, can increase vulnerability to subsequent episodes of chronic stress (McEwen & Wingfield, 2003 ; Worthman & Kohrt, 2005 ). Another intriguing case study comes from Nyberg ( 2012 ), who found exceptionally low mean cortisol and diurnal slopes among Tsimane’ foragers in the Amazon, especially when compared to industrialized populations. As the authors point out, however, Tsimane’ do not live “stress-free” lives, given adversity stemming from logging encroachment, debt burden, and other structural inequalities. Instead, low cortisol levels may reflect the action of developmental factors such as pathogen exposure history and infant care practices. Infectious disease alone may at once elevate cortisol over short periods of time, while cumulatively leading to decreased HPA activity over the lifespan (Nyberg, 2012 ). Hence, nutritional status and pathogen load are more than simply confounds; they are interacting, developmentally salient ecological factors that challenge an over-simplistic understanding of cortisol as a marker of chronic stress.
Hence, it may not always be possible to separate out a singular dimension of this comprehensive ecology in relation to cortisol. Research on family environments further illustrates this point. Several studies have identified associations among child cortisol and family characteristics (e.g., family structure and routines; DeCaro & Worthman, 2011 ; Flinn, 1999 ). Yet despite considerable differences in parenting norms and beliefs that generate distinct contexts for child development (Hewlett, 1991 ; Hewlett et al., 2000 ), Helfrecht et al. ( 2018 ) did not find a difference in hair cortisol among Aka hunter-gatherer and Ngandu horticulturalist children. This suggested that shared ecological pressures, such as high infant and childhood mortality rates, disease burden, parasite load, and resource restriction have led to elevated cortisol in both of these neighboring populations.
Herpesvirus antibody titers as a marker of chronic psychosocial stress—especially, the Epstein-Barr virus (EBV)—have roots in US-based psychoneuroimmunology research with medical students during major examinations (Glaser et al., 1991 ), family caretakers of adults with Alzheimer's Disease (Kiecolt-Glaser et al., 1987 ), and others experiencing chronic psychosocial stress. These and other studies validated a model based on the near ubiquity of latent EBV infection in adults, wherein surveillance by the cell-mediated arm of the immune system minimizes opportunities for viral reactivation. However, suppression of surveillance during periods of sustained psychosocial stress is sufficient for EBV to reactivate partially, releasing antigens that prompt an antibody response. Hence, among those who are EBV seropositive, higher antibody titers are theorized to reflect diminished cellular surveillance secondary to elevated psychosocial stress over the several preceding weeks (Glaser et al., 1991 ; McDade, Stallings, Angold, et al., 2000 ). This model has the key advantage that single samples may serve as an effective chronic stress marker.
McDade and colleagues adapted this procedure for use with minimally invasive dried capillary blood spots (DBS) collected from finger prick (McDade, Stallings, Angold, et al., 2000 ; McDade, Stallings, & Worthman, 2000 ). Since then, higher EBV titers have been found in association with status incongruity among Samoan adolescents (McDade, 2002 ), social stress among female university students in Afghanistan (Panter-Brick et al., 2008 ), lifestyle incongruity among indigenous Yakut herders in Siberia (Sorensen et al., 2009 ), lower perceived quality of life in rural Hainan Island, China (Inoue et al., 2014 ), and household marital disputes among children from a fisher-farmer community in the Republic of the Congo (Boyette et al., 2018 ). On the other hand, the expected relationships between EBV and various measures of stress or vulnerability were not found among Awajún communities in the Peruvian Amazon (Tallman, 2016 ), type 2 diabetic women in New Delhi (Weaver et al., 2015 ), new mothers in São Paulo, Brazil (Rudzik et al., 2014 ), Maya or non-Maya women undergoing menopausal transition in Campeche, Mexico (Sievert et al., 2018 ), and children and adolescents experiencing culture change among the Hagahai of Papua New Guinea (DeCaro et al., 2010 ). These conflicting findings likely are due to a combination of very different settings and operationalizations of stress, and the complex regulation of immune activity (see also Blackwell & Garcia, 2022 , this issue).
Because methods for collecting DBS and measuring antibodies against EBV and other latent herpesviruses, such as cytomegalovirus (CMV), are well-established and have been described in detail within the literature (Dowd et al., 2011 ; Eick et al., 2016 ; McDade et al., 2007 ; McDade, Stallings, Angold, et al., 2000 ), we discuss them only briefly. Also, we focus on EBV, since it has been the most widely used.
Blood spots from finger prick are collected on filter paper and dried (McDade et al., 2007 ). This enhances stability of the sample compared to serum or plasma, allowing short-term storage at room temperature and nonrefrigerated shipping to a lab. These are major advantages in field settings where cold storage and local laboratory facilities are limited. Once in the lab, dried blood is eluted into a buffer from small discs of filter paper of uniform size. The eluate is assayed using an ELISA optimized for quantitative determination of antibodies against an EBV viral capsid antigen (most commonly, protein p18). Only those samples that show evidence of seropositivity (i.e., high enough antibody titers to suggest prior infection) are usable in analysis (Eick et al., 2016 ; McDade, Stallings, Angold, et al., 2000 ). This yields variable rates of missing data depending on age- and population-specific variation in seroprevalence (Dowd et al., 2013 ).
Available methods rely on optimization of existing commercially available ELISA kits for quantitative analysis of EBV antibodies in DBS. It is not appropriate to substitute another kit designed for use with plasma/serum without extensive revalidation. When the commercial kit originally validated by McDade, Stallings, Angold, et al. ( 2000 ) became unavailable, Eick et al. ( 2016 ) validated a new assay procedure merging components from two kits that as of this writing remain on the market. Should the commercial availability of kits change again, it is important to work closely with laboratory scientists skilled in assay development to confirm the feasibility of a new EBV antibody titer assay.
A central challenge with any immunological marker of chronic stress is that the immune system is exceptionally complex in its regulation and, given its high energetic cost, also is implicated in life history allocation trade-offs that shape immune system development from an early age (McDade et al., 2016 ). Nutritional status, hygiene, co-infection, and microbiome differences are among the factors that may influence adaptive immunity, including cell-mediated immune responses (Kau et al., 2011 ; McDade et al., 2016 ). Moreover, Wander et al. ( 2013 ), working with children in Kilimanjaro, Tanzania, not only found that EBV titers were largely unassociated with a variety of markers of adversity in this setting (primarily related to undernutrition and infectious disease), but also that EBV titers were unrelated to their more direct marker of cell-mediated immunity, delayed-type hypersensitivity to Candida albicans . In short, the underpinnings of the stress marker—that is, that EBV antibodies serve as an indirect measure of cell-mediated immune function—are at minimum greatly complicated outside the relatively hygienic settings and well-nourished populations where the model was developed and initially validated.
Hence, it is perhaps not surprising that EBV titers have proven inconsistent in their reliability as a marker of chronic stress across diverse field contexts, particularly settings characterized by high nutritional stress and infectious disease burden. As noted above, expected associations between chronic stress and EBV titers have not been found in roughly as many cases as they have. There are also at least two cases where the EBV-stress relationship is apparently reversed. Comparing adolescent Syrian refugees and Jordanian nonrefugees, the refugees unexpectedly displayed lower EBV titers (Panter-Brick et al., 2020 ). This echoes an earlier finding that, when constructing an allostatic load index (ALI) to assess the burden of childhood adversity in Nepal, it was necessary to treat higher EBV antibodies as a marker of well-being rather than adversity-related immunocompromise – effectively, turning the model on its head (Worthman & Panter-Brick, 2008 ).
Here, the concept of local biology is again useful, recognizing that different ecologies may not simply produce confounders, but also population-specific patterns of biological regulation in the underlying stress-responsive system being measured (in this instance, adaptive immunity). In many instances of null or contrary findings described earlier, the psychosocial dimension of stress arguably was indivisible from economic and political forces that also produce poor nutrition, negative energy balance, infectious disease risk, and other physical insults.
Allostatic load is founded in the concept of allostasis, sometimes glossed as “stability through change,” wherein regulatory systems undergo marked changes in state to mitigate the cost of stressors, maintain homeostasis, and optimize physiological functioning (hence, to maximize fitness). “Primary mediators” of allostasis include regulatory molecules such as cortisol, epinephrine, thyroid stimulating hormone, and cytokines. These typically are released rapidly and unleash responses across multiple systems, such as increased inflammation and blood pressure, altered glucose metabolism, and so forth. In this literature, such intermediate-level responses are often referred to as “secondary mediators” of allostasis. Hence, in response to acute stressors, primary mediators work in conjunction and adaptively, through secondary mediators, to optimize energy allocation, regulate attention and arousal, and otherwise prepare to meet an anticipated or realized threat. Yet repeated or continuous activation of the stress response has multisystem, cumulative effects that are harmful to health, especially if the response is unsuccessful in mitigating the stress. Allostatic load, sometimes differentiated as “overload” when allostatic regulation breaks down in the face of extreme or persistent stress, is thus the cumulative burden of allostasis. Typically, it is operationalized by measuring stress markers across multiple systems, including markers of the primary and secondary response, and combining them into an index (Edes & Crews, 2017 ; McEwen & Wingfield, 2003 ).
Yet rarely do two studies operationalize allostatic load in precisely the same way, nor is there a recognized gold standard. For instance, Edes and Crews ( 2017 ), in their comprehensive review of allostatic load and its measurement provide a table with 35 commonly used markers, reflecting functioning of the neuroendocrine, metabolic, cardiovascular, immune, pulmonary, and excretory systems, only a small subset of which are likely to be included in any single study. While lack of standardization limits direct comparison across studies, it does provide an opportunity to build a study-specific index incorporating minimally invasive markers that are feasible in the relevant field context, sensitive to the stressors of greatest interest, and age-appropriate.
The minimum requirements for a useful ALI remain a matter of debate, although typical practices include incorporating both primary markers (e.g., of HPA activity) and secondary markers (e.g., of inflammation), reflecting multiple systems with known cumulative effects on health (Edes & Crews, 2017 ; Guidi et al., 2021 ). Edes and Crews ( 2017 ), drawing from their literature review, suggest that an optimal index will include markers at least of the neuroendocrine, cardiovascular, metabolic, and immune systems. A few examples of well-established correlates of higher allostatic load include economic and racial/ethnic marginalization, work-related stress, and long-term caregiving (Guidi et al., 2021 ). Allostatic load is sensitive to early life adversity, which is unsurprising since its common components such as neuroendocrine, immune, and metabolic regulation each have developmental origins (Edes & Crews, 2017 ). Human biologists have shown growing interest in allostasis and allostatic load (e.g., Crews et al., 2019 ; James, 2020 ; Worthman & Costello, 2009 ), yet deploying ALIs as markers of chronic stress remains uncommon in human biology, especially outside the United States. Several interesting recent applications have involved children or adolescents. Burris and Wiley ( 2021 ) found no association between food security and allostatic load in United States adolescents. However, Worthman and Panter-Brick ( 2008 ) used an ALI among Nepali children to highlight the burden of rural poverty and, among late adolescents and young adults in the United States, Cullin ( 2021 ) found that allostatic load was associated with perceived fat stigma independent of adiposity.
Minimally invasive measurement of allostatic load requires finding an appropriate multisystem combination of biomarkers that can be collected without relying on venipuncture and determining the best way to combine them into a single index. A simple index using readily available markers for adults, for instance, might include hair cortisol (neuroendocrine, primary), HbA1c using a point-of-care device (metabolic, secondary), DBS C-reactive protein (immune, secondary), and the average of several measurements of resting systolic blood pressure (cardiovascular, secondary). Working with children, Worthman and Panter-Brick ( 2008 ) combined height- and weight-for-age (metabolic, secondary), cortisol from serial saliva collection (neuroendocrine, primary), EBV antibody titers and the inflammatory marker alpha1-antichymotrypsin from DBS (immune, secondary), and two heart rate variability measures related to cardiovascular fitness: sitting versus lying pressor response and rest versus active flex heart rate. Notably, given the young age of the study participants, they avoided markers that tend to emerge later in life, such as those associated with hyperglycemia, hyperlipidemia, and hypertension. In each case, the key criterion is met that multisystem measures allow a window into overall “wear and tear” across allostatic systems that are responsible for maintaining homeostasis and protecting against long-term health risk. High allostatic load implies that allostatic systems are overtaxed, although not necessarily (yet) to the extent of producing disease. Hence, age-appropriate markers are selected for an ALI that have sufficient variation to illustrate the accumulation of risk through chronic stress, often prior to actual pathology.
Integrating diverse markers into an ALI is a complex methodological problem, given different scales and nonlinear associations of continuous markers with health risk. There are a few general approaches. Many researchers have established cut-points based on the sample distribution of markers and add an increment to the index for each marker that is in the highest risk category (e.g., top quartile) relative to the sample (McEwen & Seeman, 1999 ). Others employ cut-points derived from clinical risk thresholds (Bird et al., 2010 ). The sample distribution-based approach better allows for population and age-specific variation in associations between markers and risk, as well as scenarios where no meaningful clinical cut-point exists. The clinical approach may be more strongly associated with health outcomes. Another alternative, designed to capture the full range of variation, is converting each marker into a z-score and averaging them (Hawkley et al., 2011 ). This works best if it is reasonable to assume a linear association with adversity and normal distributions across the full range of each marker. None of the preceding methods requires that allostatic load components covary, and the choice among them may not matter very much to study results (McLoughlin et al., 2020 ). On the other hand, some authors argue for the use of factor analysis to combine markers and test the underlying structure of an ALI (McCaffery et al., 2012 ; Wiley et al., 2016 ). This likely does make a meaningful difference and is as much a theoretical stance as a methodological one: if allostatic load is a generalized, multisystem phenomenon, then it will be captured best through the examination of shared variance.
Finally, there are trade-offs between collapsing multisystem information into a single index versus examining them individually in the interest of understanding chronic stress. Weighing in favor of an index, allostatic load helps resolve a problem inherent in the stress concept itself. Stress, in a generalized sense, is difficult to pin down because it is not directly observable. Instead, if a collection of markers reflecting multiple systems captures different dimensions of stress, combining them may unmask broad patterns of response to adversity that individual markers would miss. The purest expression of this is when allostatic load is treated as a latent variable in the factor analytic approach (McCaffery et al., 2012 ; Wiley et al., 2016 ). Weighing against, creating any index involves loss of information, and elides specific biological pathways toward disease. These are not mutually exclusive, of course—an index may be unpacked into its component parts and analyzed both ways—but allostatic load can prove useful in picking out the chronic stress “signal” from the “noise” of its constituent parts.
As with other markers, it is often challenging to isolate the specific, proximate stressors that yield elevated allostatic load, given that it reflects cumulative adversity across the lifespan. This includes prenatal life and cross-generational effects, given that dysregulation in many systems incorporated into ALIs have early developmental origins and are subject to biosocial inheritance (cf. Hoke & McDade, 2014 ; Kuzawa & Fried, 2017 ). Hence, an ALI is most useful if chronic stress can be conceived broadly, by comprehensively considering socio-ecological interactions and multiple forms of adversity experienced across time. Nevertheless, chronic psychosocial stress is both directly and indirectly implicated, whether through stress-associated behaviors with adverse consequences for health risk (Suvarna et al., 2020 ), or physiological mechanisms mediated by neuroendocrine pathways (McEwen & Wingfield, 2003 ).
Age is a major consideration and limitation in the measurement of allostatic load. There have been successful attempts to develop analogous indices that capture multisystem wear and tear in childhood (e.g., Worthman & Panter-Brick, 2008 ). However, depending on the markers and the population, it may be much later in life before individual or group differences in the cumulative load placed on developing allostatic systems become easily measurable. Hence, in practice, most studies have focused on adults (Guidi et al., 2021 ). Further, ecological effects on the functioning of individual systems being measured are no less important when markers are subsumed within an index. The paradoxical operation of EBV antibody titers in Worthman and Panter-Brick's ( 2008 ) ALI, discussed earlier, is one example. For another, consider inflammation, a routine component of ALIs. In high income countries with low infectious disease loads and limited energetic stress, low-grade inflammation is a common, independent cardiovascular risk factor (Lagrand et al., 1999 ), and also is correlated with obesity (Park et al., 2005 ). Yet, in longitudinal research among Shuar communities in the Ecuadorian Amazon characterized by high infectious disease load, chronic low-grade inflammation was absent. Instead, acute elevations of CRP associated with infectious symptoms quickly reverted to a low baseline, likely due to developmental trade-offs that down-regulate the inflammatory response (McDade et al., 2012 ). In short, if no one marker is immune from the operation of local biology, then certainly neither is an index combining them.
In an idealized study design, it would not be necessary to rely on any measurement at a single timepoint to study chronic stress. Instead, we would examine chronic stress as a dynamic process, produced and reproduced through repeated, often highly correlated acutely stressful experiences that we can examine as they unfold. Most of the biomarker approaches discussed in this article aim to capture the outcome of such a process that has unfolded over the course of weeks (e.g., EBV), months (e.g., hair/fingernail cortisol), or years (e.g., allostatic load). In that sense, they provide a retrospective sum or average, which is useful for many research designs, especially large-scale population health surveys. Yet where measures are sufficiently low burden, repeated or even continuous sampling may be an option, in which case physiological stress markers can be examined as they respond to changing social contexts in real time. Hence, daily processes underlying chronic stress may be uncovered. This is particularly of interest when investigating stress in relation to developmental trajectories.
In the section on cortisol, we noted the utility of repeated saliva sampling to capture the emergence of chronic stress over time; similar approaches may also be used to assess alpha-amylase, a marker of autonomic arousal (DeCaro, 2008 ). One can reasonably ask motivated research participants to self-collect saliva several times per day over 5+ days (DeCaro & Worthman, 2008 ; 2011 ), and Flinn et al. ( 2012 ) have demonstrated the feasibility of following children for multiple episodes of serial saliva collection stretching across years. Catecholamines, while similar to cortisol in their very limited utility in single measurements, can be collected repeatedly in urine and linked to daily experience (Pearson et al., 1993 ). Ambulatory blood pressure monitoring demonstrates systematic patterns of fluctuation over the day associated with context (e.g., work vs. home), job strain, familial stress, and emotional states, with effects that are gender-differentiated and sensitive to stress appraisal (James, 2013 ). Increasingly, ambulatory versions have become available of even more sensitive noninvasive psychophysiology equipment that can differentiate between sympathetic and parasympathetic responses to social context. For instance, mobile impedance cardiography can be used to generate indices such as respiratory sinus arrhythmia (a parasympathetic marker derived from high-frequency heart period variation) and pre-ejection period (a sympathetic marker based on the delay between electrical systole and the initiation of ventricular ejection) (DeCaro, 2016 ). While the most advanced psychophysiology solutions have not yet crossed the threshold where they are easy to apply in the full range of field settings where human biologists work, ongoing miniaturization of sensors and their incorporation even into consumer-grade electronics offers near-term hope.
Like any form of longitudinal research, the length and frequency of follow-up that is merited depends entirely on the research question, and a high level of commitment from research participants may be required. Also, cost and investigator burden are typically high compared to single timepoint measurements. These are not insignificant barriers. Thus, while one could simply take an average of measurements collected over days, weeks, or months and use this as a marker of chronic stress, that arguably is a waste of the power of such designs and the additional effort involved in collecting the data. Instead, human biologists considering such an approach should partner with statisticians fluent in multilevel analysis that can properly handle both intra- and inter-individual variability (Hruschka et al., 2005 ). Researchers also are presented with the question, variability in relation to what? A range of methods including participant observation (Flinn et al., 2012 ), paired video recording (Pritzker et al., 2019 ), diaries (DeCaro & Worthman, 2008 ; James, 2013 ), and experience sampling (Weisner et al., 2001 ) can help provide critical information regarding corresponding variation in psychosocial context.

Section: Conclusion

It would be impossible to adequately capture all the cutting-edge work in stress biology currently being integrated into the human biologist's toolkit. Three key examples related to how chromosomal structure, epigenetic marking, and gene regulation are being employed in studies of psychosocial stress may suffice to provide a taste of what is to come, however.
Some researchers have described evidence of stress-related acceleration in processes associated with aging at the chromosomal and epigenetic level. For example, methods are now available for reliable extraction from DBS of DNA suitable for measuring telomere length (Rej et al., 2021 ). Telomeres shorten with age, leading to elevated risk of poor health, but there also is evidence that they shorten more rapidly in light of chronic stress; for example, among African American adults in Florida experiencing greater racial discrimination (Rej et al., 2020 ). Another emerging measure is epigenetic aging, which reflects methylation patterns associated with advancing age that may accelerate in the presence of persistently elevated stress (Palma-Gudiel et al., 2020 ). For instance, employing DBS, Gettler et al. ( 2020 ) found associations between intrinsic epigenetic age acceleration and parental conflict among children in a fisher-farmer society in the Republic of Congo. This association was evident only after adjusting for anthropometric measures that aimed to capture allocation trade-offs in this high pathogen load, high energetic stress population, however. Another innovation has been the application in biocultural research of the conserved transcriptional response to adversity (CTRA), which involves quantifying RNA transcripts of genes that are disproportionately up- or down-regulated in immune cells during stress (Cole, 2019 ). Snodgrass et al. ( 2018 ) found that CTRA from DBS was correlated among young adults in the United States with patterns of problematic versus positive experiences in internet gaming. Much remains to be learned about how each of these markers translate across populations and relate to various forms of chronic stress in a wider variety of field settings, but they already show considerable promise.
Finally, methods may be combined to overcome their individual limitations, and to avoid becoming boxed into a less suitable method because it is familiar or most readily available. The continual emergence of new and promising methods for examining the impact of adversity highlights the value of broad collaborative networks including anthropologists, molecular biologists, immunologists, statisticians, psychophysiologists, and others. Human biologists offer to interdisciplinary teams, among other things, grounding in evolutionary theory, global perspective, and in many cases expertise in deep engagement with bioecocultural context. These competencies greatly expand the range of questions that can be addressed with respect to chronic stress and human health. Moreover, chronic psychosocial stress—for all its caveats and complexity—remains a construct that's “good to think with.” Minimally invasive biomarkers, in turn, are a critical tool for researchers concerned with how and why experience gets under the skin in a wide range of field settings, as people go about their daily lives outside of the lab.
